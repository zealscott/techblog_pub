<p align="center">
  <b>Priciple concepts of machine Learning</b>
</p>

## 统计学习概述

1. 分类
   - 监督学习/非监督学习/半监督学习/强化学习
2. 统计学习方法的三要素
   - **模型**：模型的假设空间
     - 在监督学习中，就是所要学习的条件概率或决策函数
   - **策略**：模型选择的准则
     - 对应风险函数（衡量平均预测的好坏）和损失函数（衡量一次预测的好坏）
     - **经验风险最小化**：极大似然估计（容易造成过拟合）
       - 例如：极大似然估计
     - **结构风险最小化（对应于正则化）**：加入正则化项，
       - 例如：Bayes最大后验估计
   - **算法**：模型学习的算法
3. 问题分类
   - 回归问题：输入变量与输出变量均为连续变量
   - 分类问题：输出变量为有限个离散变量
   - 标注问题：输入与输出变量都是变量序列​
4. 监督模型类型
   - 生成模型
     - GDA/Naive Bayes/HMM
     - 可以快速还原出联合概率分布$P(X,Y)$，学习收敛速度更快
   - 判别模型
     - Logistic/SVM/条件随机场
     - 可以直接对数据进行各种程度的抽象，定义特征，简化学习问题
5. 模型选择
   - 假设空间中有不同复杂度的模型，需要涉及到模型选择问题。模型选择主要考虑到过拟合问题。
   - 主要的模型选择方法：
     - 正则化
       - $\min \frac{1}{N}\sum\limits_{i=1}^NL(y_i,f(x)) + \lambda J(f)$
       - 一般使用$L_1$或者$L_2$范数
     - 交叉验证 
       - 分为训练集，验证集和测试集
       - 验证集用于模型的选择，选择对于验证集有最小误差的模型
       - **简单交叉验证**（前70%为训练集），**S折交叉验证**（前S-1个子集的数据进行训练，重复S次 ），**留一交叉验证**
6. 评价标准
   - 准确率（accuracy）：给定的测试数据集，分类正确的样本数与总样本数的比
   - 精确率（precision）：$P = \frac{TP}{TP+FP}$
     - 所有预测正类中正确的
   - 召回率（recall）：$P = \frac{TP}{TP+FN}$
     - 所有预测正确中是正类的
   - F1值：$F_1 = \frac{2TP}{2TP+FP+FN}$





## SVM

- 原始问题建模
  - $\min \frac{1}{2} ||w||^2$
  - $s.t. \quad y_i(w\cdot x_i + b ) -1 \ge 0, i = 1,2,...,N$
  - 当$y_i(w\cdot x_i + b) =1$时是support vector
- 对偶问题
  - $\min \frac{1}{2}\sum_i\sum_j \alpha_i \alpha_j y_i y_j(x_i\cdot x_j) - \sum_i \alpha_i$
  - $s.t. \quad \sum \alpha_iy_i = 0\quad \alpha_i \ge 0$
  - 由KKT条件，$w = \sum \alpha_iy_ix_i$，同时可求得对应的b
  - 决策函数只依赖于输入样本的内积
  - 求得了$\alpha$，当$\alpha_j>0$时对应的$j$是support vector（真正对$w$有用的） 