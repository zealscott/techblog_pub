<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Scott&#39;Log</title>
    <link>https://tech.zealscott.com/</link>
    <description>Recent content on Scott&#39;Log</description>
    <image>
      <url>https://tech.zealscott.com/papermod-cover.png</url>
      <link>https://tech.zealscott.com/papermod-cover.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Tue, 13 Oct 2020 20:44:01 +0800</lastBuildDate><atom:link href="https://tech.zealscott.com/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Loss functioin in neural network</title>
      <link>https://tech.zealscott.com/deeplearning/misc/loss/</link>
      <pubDate>Tue, 13 Oct 2020 20:44:01 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/deeplearning/misc/loss/</guid>
      <description>Kullback-Leibler divergence Information theory  Quantify information of intuition1  Likely events should have low information content Less likely events should have higher information content Independent events should have additive information. For example, finding out that a tossed coin has come up as heads twice should convey twice as much information as finding out that a tossed coin has come up as heads once.   Self-information  $I(x)=-\log P(x)$ Deals only with a single outcome   Shannon entropy  $H(\mathrm{x})=\mathbb{E}_{\mathrm{x} \sim P}[I(x)]=-\mathbb{E}_{\mathrm{x} \sim P}[\log P(x)]$ Quantify the amount of uncertainty in an entire probability distribution    KL divergence and cross-entropy  Measure how different two distributions over the same random variable $x$  $D_{\mathrm{KL}}(P | Q)=\mathbb{E}_{\mathrm{x} \sim P}\left[\log \frac{P(x)}{Q(x)}\right]=\mathbb{E}_{\mathrm{x} \sim P}[\log P(x)-\log Q(x)]$   Properities  Non-negative.</description>
    </item>
    
    <item>
      <title>在服务器上部署 Jupyter Notebook</title>
      <link>https://tech.zealscott.com/misc/jupyter-notebook/</link>
      <pubDate>Wed, 22 Apr 2020 22:31:03 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/misc/jupyter-notebook/</guid>
      <description>安装 Ananconda  使用命令行安装  1  wget wget https://repo.continuum.io/archive/Anaconda3-5.2.0-Linux-x86_64.sh    注意，选择安装路径时，如果想要所有用户都能使用，则安装在usr/local/ananconda3目录下 注意修改/etc/profile.d下的conda.sh，指定环境变量（在登入另外的用户时会提醒） 更改源。创建~/.condarc文件，输入  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  channels: - defaults show_channel_urls: true channel_alias: https://mirrors.tuna.tsinghua.edu.cn/anaconda default_channels: - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/pro - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2 custom_channels: conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud    至此，已经完成 python、conda 及 jupyter-notebook 的安装。  部署远程云服务  生成Jupyter Notebook配置文件  1  jupyter notebook --generate-config     生成的配置文件，后来用来设置服务器的配置</description>
    </item>
    
    <item>
      <title>使用 Hugo 进行持续集成写作及同步</title>
      <link>https://tech.zealscott.com/misc/hugo-integration/</link>
      <pubDate>Wed, 22 Jan 2020 20:31:03 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/misc/hugo-integration/</guid>
      <description>我们通常会在本地计算机上写 Markdown 文件，然后使用 Hugo 建立静态博客网站。因此需要一种方法将本地文件同步到服务器上，同时实现 GitHub 集成，确保网站的可维护性。我使用了 Git hook 的方法进行同步与集成。
服务器上 更新 1 2 3  yum update yum install nginx yum install git   新建 hugo 用户：
1 2  adduser hugo passwd hugo   安装 hugo 安装 go 1 2  yum -y install golang go version   源码安装 1 2 3 4 5  mkdir $HOME/src cd $HOME/src git clone https://github.com/gohugoio/hugo.git cd hugo go install --tags extended   yum 安装 有些主题需要支持sass/scss功能，如果使用 yum 安装 hugo，则没办法安装extend版本，会导致编译失败。</description>
    </item>
    
    <item>
      <title>Go Hugo!</title>
      <link>https://tech.zealscott.com/misc/go-hugo/</link>
      <pubDate>Tue, 21 Jan 2020 20:31:03 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/misc/go-hugo/</guid>
      <description>The world’s fastest framework for building websites</description>
    </item>
    
    <item>
      <title>Laravel Homestead 安装小记</title>
      <link>https://tech.zealscott.com/misc/laravel-installation/</link>
      <pubDate>Fri, 11 Oct 2019 20:15:55 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/misc/laravel-installation/</guid>
      <description>环境配置 在Laravel官网上，推荐使用Laravel Homestead虚拟机部署安装环境。Homestead是Laravel官方提供的基于Vargrant的Box，也就是虚拟机原型系统，预装了一切 Laravel 需要的东西。
这里使用VirtualBox虚拟机，而Vagrant是一个虚拟机管理工具。
配置Laravel环境的主要步骤有：
 安装VirtualBox和Vagrant 安装Homestead Vagrant Box 安装Homestead（Clone 项目） 修改配置文件（Homestead.yaml和/etc/hosts） 启动虚拟机，SSH登陆虚拟机 下载Laravel  安装VirtualBox和Vagrant 直接官网安装dmg即可：
  VirtualBox 下载地址
  Vagrant下载地址
  验证是否安装成功在终端使用以下命令行，显示版本信息就 OK 了。
1  vagrant -v   安装 Homestead Vagrant Box 在线安装 直接输入以下命令行：
1  vagrant box add laravel/homestead   这个步骤相当于下载虚拟机的预装系统，下载文件超过1个G，实测非常慢，及时是挂VPN，也太慢。
离线导入 下载Box 最后我选择了首先下载.box文件，然后导入的方式。
在Vagrant官网进入Homestead box，选择最新的版本，例如8.2.1，然后进入该版本页面，如https://app.vagrantup.com/laravel/boxes/homestead/versions/8.2.1，直接在后面添加/providers/virtualbox.box组成完整的URL，即可使用迅雷等下载工具进行下载，完整的URL为：
 https://app.vagrantup.com/laravel/boxes/homestead/versions/8.2.1/providers/virtualbox.box
 下载完成后得到virtualbox.box的文件，在命令行中进入该文件的目录，然后输入以下命令即可成功导入。
 vagrant box add laravel/homestead ./virtualbox.box
 导入 注意，这里导入时vagrant并不知道版本信息。因此，我们需要进入box的文件夹，手动增加版本信息。</description>
    </item>
    
    <item>
      <title>梯度下降原理及理解</title>
      <link>https://tech.zealscott.com/deeplearning/misc/gradientdescent/</link>
      <pubDate>Sun, 01 Sep 2019 20:57:00 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/deeplearning/misc/gradientdescent/</guid>
      <description>梯度下降是神经网络中最常用的求极值点（鞍点）的方法，本文以BP神经网络为例，介绍梯度下降的数学原理及推广</description>
    </item>
    
    <item>
      <title>Learning from positive and unlabeled data with a selection bias</title>
      <link>https://tech.zealscott.com/deeplearning/pulearning/nnpusb/</link>
      <pubDate>Tue, 20 Aug 2019 22:07:12 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/deeplearning/pulearning/nnpusb/</guid>
      <description>本文主要考虑的是PU learning，也就是在只有正类数据和无标记数据的情况下，对数据进行二分类。在case-control情境下（也就是two samples问题），之前大部分研究基于都基于selected completely at random的假设，但本文argue这种假设不符合实际，因此对该假设进行了放松：如果$P(o = +1| x)$越高，则$P(y = +1| x)$也越高，反之亦然，这种性质被称为invariance of order。
使用Bayes公式推导可以得到，密度比也符合这种偏序关系。因此，论文认为，虽然我们很难得到$P(y=+1|x)$具体的值，但通过估计密度比，能得到样本间是正类的概率偏序关系，这样通过一个合理的阈值作为分类器即可区分正负类。
作者通过两种方法来估计密度比：一种是根据之前研究定义的classification risk推广到有based的classification risk函数，然后根据公式$\hat{r} = \frac{\hat f}{\pi}$计算得到；另一种方法是直接用uLSIF进行估计。得到密度比$r$之后，根据先验信息$\pi$，对数据进行遍历即可得到$\theta_\pi$阈值，通过该阈值可以实现在未标记数据上将正负样本进行区分。
最后，作者在几个常见的数据集上进行了改造以符合PU learning的假设，同时使用了一个real-world数据集，使用论文提到的两个方法估计$\hat{r}$，然后可以得到阈值$\theta_\pi$，进而得到二分类器。最后还验证了在未知先验$\pi$的情况下，其算法的robust较好。
Intuition  cast-control scenario  P 是从正类中采样的，U 是从整个样本空间采样的，这两者相互独立。这个假设符合现实中的认识，因为如果有标记的样本都是正例，那么一定是人为忽略或是丢弃了负类样本。换句话说，unlabel data 中既包含正样本，也包含负样本，称为为 two samples 问题，即有 P 和 U 两个采样集。   selected completely at random (SCAR)  对于cast-control的问题，常见的假设是：正类被标记的采样集和未标记的采样集是独立同分布的。 作者 argue 这种假设在现实问题中很多时候不成立，例如在异常检测中，异常的更容易被选中；在人脸识别中，用户更倾向于提供清晰的照片（labeled），而未标记的数据更可能非常不清晰。   select bias  因此在现实中，作者认为$P(x|y = +1,o = 0) \ne P(x|y = +1,o = +1)$，不能简单的通过Bayes公式推断得到$P(y = +1 | x)$的概率。 虽然不能直接得到$P(y = +1 | x)$的值，但根据之前的假设，如果数据更容易被标记，则它是正样本的概率更大，可以得到这样的偏序关系：  $P(y = +1 | x_i) \le P(y = +1| x_j) \Leftrightarrow P(o = +1 | x_i)\le P(o = +1| x_j)$   如果取等号，那么就满足了SCAR假设，因此，本文定义的invariance of order可以看作是SCAR的推广。    Strategy 作者主要的思路是：</description>
    </item>
    
    <item>
      <title>PU learning Overview</title>
      <link>https://tech.zealscott.com/deeplearning/pulearning/pu-learning-overview/</link>
      <pubDate>Sat, 17 Aug 2019 21:00:30 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/deeplearning/pulearning/pu-learning-overview/</guid>
      <description>Papers  Learning Classiﬁers from Only Positive and Unlabeled Data KDD 2008 （PUAdapter）  经典论文，在SCAR假设下，证明了$p(y|x)$与$p(s|x)$只相差一个常数c，因此可以使用经典的分类模型，将positive和unlabel数据看成两类，直接得到$p(s|x)$的概率，进而估计$p(y|x)$。同时给出了估计常数$c$和先验$p(y)$的方法。 本文还提出了一个非常重要的思想，就是把Unlabel数据看成是Positive和Negative样本的不同权重组合，引出了后来的unbiased risk estimators。 Code available 论文笔记   Analysis of Learning from Positive and Unlabeled Data NIPS 2014  从基本的分类损失出发，推导了PU的分类问题其实就是Cost-sensitive classiﬁcation的形式。详细推导了risk function：$R(f) = 2\pi R_1(f) + R_X(f) -\pi $，论文以这个risk function出发，对不同的loss function进行了讨论。（部分推导可结合 Semi-Supervised Novelty Detection 再看） 同时证明了如果使用凸函数hinge loss作为loss function，会导致错误的分类边界（多一项惩罚项），因此需要使用非凸ramp loss作为loss function。同时证明了使用PU进行分类的误差小于监督学习误差的$2\sqrt{2}$倍（这里待看）。  即loss需要满足 $l(t,+1) + l(t,-1) = 1$，也就是symmetric condition   论文笔记   Convex formulation for learning from positive and unlabeled data IMCL 2015 （uPU）  这篇文章主要是对之前提出的非凸loss进行改进，主要想法是根据risk function对正类样本和未标记样本使用不同的loss function。 从另一个方面推导了risk function： $R(g) = \pi E_1[ \hat{l}(g(x))] + E_X[l(-g(x))]$，考虑当$\hat{l}$为凸时，证明了其一定为线性函数，将hinge loss修改为double hinge loss，变为凸优化问题。通过实验说明其效果不比non-convex loss function差，同时减少了计算开销。  即loss需要满足$l(t,+1) + l(t,-1) = -t$，也就是linear-odd condition   同时，这篇文章用的分类器为linear-in-parameter model，使用高斯核将样本映射到feature space，具体定义可以参考 Introduction to Statistical Machine Learning By Masashi Sugiyama 2016 一书的Chapter21。 Code available 论文笔记   Positive-Unlabeled Learning with Non-Negative Risk Estimator NIPS 2017 （nnPU）  由于之前的risk estimator $\hat{R}_{pu}(g) = \pi_p\hat{R}_p^+(g) -\pi_p\hat{R}_p^-(g) + \hat{R}_u^-(g)$中，有可能出现$-\pi_p\hat{R}_p^-(g) + \hat{R}_u^-(g) &amp;lt; 0 $的情况，会导致risk不断减小变为负数。因此对risk进行改写，提出nnPU，能有效的防止过拟合，能使用更强大的学习器（神经网络）进行学习。同时，论文对这个risk estimator的bias，consistency和MSE reduction进行了理论分析。 Code available   Learning from positive and unlabeled data with a selection bias ICLR 2019 （nnPUSB）  放松了SCAR的假设，认为如果$P(o = +1| x)$越高，则$P(y = +1| x)$也越高（不一定相同）。使用贝叶斯公式得到密度比和$P(y = +1|x)$满足同样的偏序关系，因此使用两种方法估计密度比（risk function/uLSIF），并设定阈值实现对PU的分类。 Code available / My implementation 论文笔记    Formula Risk 推导  定义在decision function $g$ 下的risk为：  $R(g) = E_{(X,Y)\sim p(x,y)}[l(g(X),Y)] = \pi_pR_p^+(g) + \pi_nR_n^-(g)$ 其中$R_p^+(g) = E_p[l(g(X)),+1]$也就是对正类分类错误的risk，$R_n^-(g) = E_p[l(g(X)),-1]$也就是对负类分类错误的risk   由于我们没有办法直接得到负类样本，因此由公式 $\pi_np_n(x) = p(x) - \pi_pp_p(x)$可得负类样本分类错误的损失：   $\pi R_n^-(g) = R_u^-(g) - \pi_pR_p^-(g)$</description>
    </item>
    
    <item>
      <title>Convex Formulation for Learning from Positive and Unlabeled Data</title>
      <link>https://tech.zealscott.com/deeplearning/pulearning/npu/</link>
      <pubDate>Mon, 05 Aug 2019 09:00:30 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/deeplearning/pulearning/npu/</guid>
      <description>该论文在之前PU learning中使用非凸函数作为loss的基础上，对正类样本和未标记样本使用不同的凸函数loss，从而将其转为凸优化问题。结果表明，该loss（double hinge loss）与非凸loss（ramp）精度几乎一致，但大大减少了计算量。
Introdution Background 论文首先强调了PU问题的重要性，举了几个例子：
 Automatic face tagging  用户对自己的画像标记为正类，其余都是未标记数据，需要正确识别用户的照片   Inlier-based outlier detection  需要在只有inliers和未标记数据中识别outliers，这种方法比完全无监督学习的效果要好   Class is too diverse  如果要识别的数据集中类别太多，也就是one-vs-rest classification   Negative-class dataset shift  由于训练数据和测试数据采集的实践差异导致负类样本的概率分布发生了变化，那么如果使用PU learning，可以减少重新标记的代价    Method 作者简单回顾了之前PU learning的常见做法：
 直接在正类样本和未标记样本中训练一个分类器。但很显然这样的效果非常差，因为未标记样本中包含两类数据。 根据先验$\pi$使用一个loss function来权衡每个样本的权重，目标是使得loss function最小化。但这样做的结果是会产生bias。 使用满足$l(z) + l(-z) = 1$条件的loss function可以消除这种bias，但对于ramp loss，是非凸函数，导致在优化过程中可能求导局部解。  因此，本文提出了一种新的凸函数的loss function，也就是double hinge loss，不仅能够消除bias，同时也能保证凸性。关键点在于对未标记数据和正类数据使用不同的loss function。
Non-convex PU classification 作者回顾了在 Analysis of Learning from Positive and Unlabeled Data 这篇文章中的方法。</description>
    </item>
    
    <item>
      <title>Analysis of Learning from Positive and Unlabeled Data</title>
      <link>https://tech.zealscott.com/deeplearning/pulearning/pu-learning-non-convex/</link>
      <pubDate>Mon, 29 Jul 2019 11:23:30 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/deeplearning/pulearning/pu-learning-non-convex/</guid>
      <description>本文从基本的分类损失出发，推导了PU的分类问题其实就是Cost-sensitive classiﬁcation的形式，同时，通过实验证明了如果使用凸函数作为loss function，例如hinge loss会导致错误的分类边界（有bias），因此需要使用例如ramp loss之类的凹函数。同时，论文还对先验$\pi$存在偏差的情况进行了讨论，说明了如果样本中大部分都是正样本，那么就算先验差距比较大，但对总体的分类效果没有太大影响。最后对分类边界进行讨论，证明了使用PU进行分类的误差小于监督学习误差的$2\sqrt{2}$倍。
基本概念和定义  Ordinary classification  Bayes optimal classiﬁer的目标是最小化misclassiﬁcation rate，这在Introduction to Statistical Machine Learning By Masashi Sugiyama 书里有定义，直观理解就是最小化期望错分率： $R(f) = \pi R_1 (f) + (1 - \pi) R_{-1}(f)$ 这里的$R_1$表示false negative rate，也就是分错正类的概率，乘以先验正类的概率$\pi$ $R_{-1}$表示false positive rate，也就是分错负类的概率，乘以先验负类的概率$1-\pi$ 这样，对分错样本的概率分别乘以其先验概率，就是其错分概率的期望。   Cost-sensitive classiﬁcation  如果对于某种错误我们的敏感程度不一样，那么就乘以不同的权重，重新定义为： $R(f) = \pi c_1 R_1(f) + (1-\pi) c_{-1}R_{-1}(f)$ 这里用$c_1$和$c_{-1}$分别表示对两种错分的代价   PU classification   定义在未标记数据集$X$ 中的分布：
  $P_X = \pi P_1 + (1-\pi) P_{-1}$</description>
    </item>
    
    <item>
      <title>Learning Classiﬁers from Only Positive and Unlabeled Data</title>
      <link>https://tech.zealscott.com/deeplearning/pulearning/pu-learning/</link>
      <pubDate>Sun, 28 Jul 2019 21:00:30 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/deeplearning/pulearning/pu-learning/</guid>
      <description>本文主要考虑在SCAR假设下，证明了普通的分类器和PU分类器只相差一个常数，因此可以使用普通分类器的方法来估计$p(s|x)$，进而得到$p(y|x)$。同时提供了三种方法来估计这个常数，最后，还对先验$p(y)$的估计提供了思路。
Learning a traditional classifier   概念定义
 $x$ 表示一个样本，$y$ 表示其label（0或者1），$s$表示是否被select 那么，在PU问题中，当$s =1 $时，一定有$y = 1$ $P(s = 1| x,y=0) = 0 $ 一定成立    两种采样假设
 signle-training-set  所有的样本都是从$(x,y,s)$这个三元组的分布中采样的   case-control  两个数据集（正类，未标记）是从三元组中独立的抽样出来的。当采样正类时被称为case，采样未标记数据时称为contaminated controls   这两种假设有很明显的区别。总的来说，第一种假设比第二种假设要严格得多，也就能提供更多的信息：  两种假设都能让我们估计$p(x)$ 但只有在第一种假设下，能够让我们很容易的估计出$p(s = 1)$，因此也更容易估计出$p(y = 1)$，二第二种条件不可以。      基本假设
 我们需要训练的传统分类器是：$f(x) = p(y = 1|x)$ 然而，对正类数据没有任何假设的前提下，我们很难得到较好的分类器 因此，论文给出的假设是，正类样本数据是从正类数据中完全随机的抽取出来的。  也就是说，当$y = 1$时，无论$x$取说明值，它们的概率都是相同的：  $p(s = 1| x,y=1) = p(s =1|y=1)$   这个假设被称为selected completedly at random   我们定义一个nontraditional classifier：$g(x) = p(s =1|x)$ 因此，我们需要一些定理来证明如何将非传统的分类器转化为传统的分类器    Lemma：假设SCAR条件成立，那么$p(y = 1|x) = \frac{p(s=1|x)}{c}$，其中$c = p(s=1|y=1)$</description>
    </item>
    
    <item>
      <title>ThingWorx 安装及部署</title>
      <link>https://tech.zealscott.com/misc/thingworx-installation/</link>
      <pubDate>Thu, 11 Jul 2019 17:46:57 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/misc/thingworx-installation/</guid>
      <description>本文以Windows系统为例，介绍ThingWorx的安装步骤。
H2版 安装  从PTC官网下载合适版本的Thingworx（h2版） 访问Tomcat 网站下载32-bit/64-bit Windows 服务安装程序。 下载JDK8以上的版本。  注意，H2为内嵌数据库，并不需要安装。
部署 Tomcat   在“HTTP/1.1 连接器端口” 字段，键入“80” (或其他可用端口)，其余默认设置安装
  启动Tomcat，在“Java 选项”字段中，将以下内容添加至选项字段的末尾：
  1 2 3 4  -Dserver -Dd64 -XX:+UseG1GC -Dfile.encoding=UTF-8 -Djava.library.path=&amp;lt;path to Tomcat&amp;gt;\webapps\Thingworx\WEB-INF\extensions       清除Initial memory pool 和 Maximum memory pool字段中的任意值。
  在Tomcat 的安装位置，打开CATALINA_HOME/conf/web.xml。通过将以下内容添加至web.xml 文件来替换默认错误页面。将以下内容置于web-app 标记内(在welcome-list 标记后)
  1 2 3 4  &amp;lt;error-page&amp;gt; &amp;lt;exception-type&amp;gt;java.lang.Throwable&amp;lt;/exception-type&amp;gt; &amp;lt;location&amp;gt;/error.jsp&amp;lt;/location&amp;gt; &amp;lt;/error-page&amp;gt;       要增加影响静态文件缓存的默认缓存设置，请在$CATALINA_HOME/conf/context.</description>
    </item>
    
    <item>
      <title>Seq2Seq 理解</title>
      <link>https://tech.zealscott.com/deeplearning/models/seq2seq/</link>
      <pubDate>Wed, 13 Mar 2019 20:44:01 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/deeplearning/models/seq2seq/</guid>
      <description>基本思想 NLP中有很多sequence to sequence的问题，例如机器翻译，人机对话等等。对于句子而言，我们已经有RNN能够很好的处理序列之间的关系，但同时，RNN只能被用于输入和输出的维度都固定且已知的情况。但很多情况下，我们没办法确定输出序列的长度和维度。因此，为了处理这种general的序列问题，Seq2Seq框架被提出来了。
流程 最基本的Seq2Seq框架主要的流程是：
 用一个LSTM来处理input的sequence，得到一个特定维度的向量表示，我们可以认为这个向量能很好的捕捉input中的相互关系。  每一个timestep，cell将当前词的embedding向量和上一个hidden state进行concat作为输入，输出当前timestep的hidden state作为下一个cell的输入，依次进行，直到sentence的EOS标志符，得到最终的vector representation作为decoder的最初hidden state输入。   用另一个LSTM，将这个vector representation映射成target sequence。每个timestep输出一个目标单词，直到输出EOS为止。  接受来自上一个timestep的hidden state输入（最开始为vector representation），与上一个timestep的output进行concat作为当前timestep的输入，依次进行，直到最终生成的单词为EOS。    缺点  Encoder将输入编码为固定大小状态向量的过程实际上是一个信息有损压缩的过程，如果信息量越大，那么这个转化向量的过程对信息的损失就越大。 随着sequence length的增加，意味着时间维度上的序列很长，RNN模型也会出现梯度弥散，无法让Decoder关注时间间隔非常长的关联，精度下降。  Attention  在普通的seq2seq模型中，我们输出的条件概率可以表示为：  $p(y_t| {y_1,..,y_{t-1}},c)=g(y_{t-1},s_t,c) $ 其中$s_t$表示$t$时刻的hidden state，$c$表示我们从Encoder学到的context vector，$g$表示非线性映射   而在attention based seq2seq中，条件概率可以表示为：  $p(y_i|y_1,&amp;hellip;,y_{i-1},x) = g(y_{i-1},s_i,c_i)$ hidden state表示为：$s_i = f(s_{i-1},y_{i-1},c_i)$ 也就是说，这里的每个单词$y_i$的条件概率都由不同的$c_i$决定，而不仅仅依赖于同一个$c$   在Decoder中，对每个timestep，Input是上一个timestep的输出与特定的 $c_i$ (context vector)进行Attention后的结果，而hidden state和普通的seq2seq一样，为上一个timestep输出的hidden state  实现Attention的方式有很多，例如直接点积，先concat后再进行线性变换等等。   那么，现在关键的问题是，每一个$c_i$到底是如何计算的？  论文中将Encoder的BiRNN产生的同一个timestep中两个hidden state进行concat组成一个annotations：$(h_1,&amp;hellip;,h_{T_x})$，可以认为，每一个$h_i$都包含了在一个sequence中主要focus于第$i$个单词周围的相互关系 因此，我们使用这种学习到的关系在不同的位置赋予不同的权重，来组成我们的context vector $c_i$：  $c_i = \sum\limits_{j=1}^{T_x} \alpha_{ij}h_j$   每一个$\alpha_{ij}$是通过annotations $h_i$ 与上一个hidden state 计算出来，然后进入softmax函数得到当前位置的权重：  $\alpha_{ij} = \frac{\exp(e_{ij})}{\sum_{k=1}^{T_x} \exp(e_{ik})}$   这里的每一个$e_{ij}$衡量了在input的$j$位置和output的$i$位置的匹配程度，也就是论文中提到的alignment model，是由RNN前一个timestep的hidden state $s_{i-1}$和input的$h_j$计算出来的：  $e_{ij} = a(s_{i-1},h_j)$ 这里的$a$是一个简单的前向网络      流程 Encoder：</description>
    </item>
    
    <item>
      <title>图卷积神经网络入门基础</title>
      <link>https://tech.zealscott.com/deeplearning/models/gnn/</link>
      <pubDate>Tue, 19 Feb 2019 15:34:10 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/deeplearning/models/gnn/</guid>
      <description>卷积 定义 卷积是一种数学运算，称$(f*g)(n)$为$f,g$的卷积，
其连续的定义为：
$$(f*g)(n) = \int_{-\infty}^{+\infty} f(\tau)g(n-\tau)d\tau$$
离散的定义为：
$$(f*g)(n) = \sum\limits_{\tau = -\infty}^\infty f(\tau)g(n-\tau)$$
若令$x = \tau,y = n-\tau$，则$x+y = n$表示的是平行的直线。
对于图像来说，图像上的滑动窗口很好的解释了卷积的定义：
可以发现，我们对$f,g$进行卷积操作，保证$x,y$坐标的和都为1：
写成卷积公式为：
$$(f*g)(1,1) = \sum\limits_{k=0}^{2}\sum\limits_{h=0}^{2}f(h,k)g(1-h,1-k)$$
这样就实现了使用$g$这个算子在图像上的滑动。但注意，在数学中的卷积运算中，卷积核与原始的矩阵乘积，是围绕着中心元素进行180度旋转后，才是对应的元素。
而在实际的图像空间滤波中，我们是将设计的特定卷积核，然后将其与像素矩阵的对应元素（不进行上述的旋转）相乘得到。例如，在CV中常见的平滑滤波，高斯滤波。这些滤波被设计出来，以提取不同的特征。
..对于神经网络来讲，最大的不同是，这些滤波不需要我们自己去定义（也就是提取特征的过程），而是通过网络自身训练每一个卷积层的滤波器..。让这些滤波器组对特定的模式有高的激活，以达到CNN网络的分类/检测等目的。因此，在CNN中，由于这些卷积核都是未知参数，需要根据数据训练学习，那么翻不翻转已经没有关系了。
理解 对于离散卷积来说，本质上就是一种加权求和。CNN中的卷积本质上就是利用一个共享参数的过滤器（kernel），通过计算中心像素点以及相邻像素点的加权和来构成feature map实现空间特征的提取，当然加权系数就是卷积核的权重系数。
那么卷积核的系数如何确定的呢？是随机化初值，然后根据误差函数通过反向传播梯度下降进行迭代优化。这是一个关键点，卷积核的参数通过优化求出才能实现特征提取的作用，GCN的理论很大一部分工作就是为了引入可以优化的卷积参数。
Laplacian matrix 我们上离散数学都学过，图拉普拉斯矩阵的定义为：
$$L = D -W$$
其中，$D$ 是顶点的度矩阵（对角矩阵），$W$是图的邻接矩阵（带边权重）。其normalized形式为：
$$L^{nor} = D^{-\frac{1}{2}}LD^{-\frac{1}{2}}$$
但为什么是这样定义呢？我们先从拉普拉斯算子说起。
Laplacian 其数学定义为：
$$\Delta = \sum\limits_i \frac{\delta^2}{\delta x_i^2}$$
即为非混合二阶偏导数的和。
图像中的拉普拉斯算子 图像是一种离散数据，那么其拉普拉斯算子必然要进行离散化。
从导数定义：
$$f&#39;(x) = \frac{\delta f(x)}{\delta x} \approx f(x+1) - f(x)$$
因此可以得到二阶导为：
$$f&#39;&#39;(x) = \frac{\delta^2 f(x)}{\delta x^2} \approx f&#39;(x) - f&#39;(x-1) \approx f(x+1) + f(x-1) - 2f(x)$$</description>
    </item>
    
    <item>
      <title>VIM 使用简介</title>
      <link>https://tech.zealscott.com/misc/vim/</link>
      <pubDate>Thu, 20 Sep 2018 10:52:29 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/misc/vim/</guid>
      <description>VIM的启动  启动命令：vi my.txt 如果文件存在，则vi显示文件内容并等待用户的命令。 如果指定的文件不存在，则vi将告知用户这是未命名的文件，并进入一个空白的界面。 启动vi时都是默认处于命令模式。用户必须使用命令切换到文本输入模式才能进行输入编辑，或者可执行删除、复制等编辑命令。  VIM的退出  冒号进命令行模式下：  :q! 不存档强制退出。 :w 保存但不退出，w(rite)后可加所要存档的文档名。 :wq 存档后退出。 :x 与:wq相同   命令模式  ZZ、ZQ  保存/不保存退出    编辑 插入模式   输入:set nu 可设置vi显示行号
  新增 (append)
 a ：从光标所在位置后面开始新增资料 A： 从光标所在行最后面的地方开始新增资料。    插入 (insert)
 i： 从光标所在位置前面开始插入资料 I ：从光标所在行的第一个非空白字元前面开始插入资料。    开始 (open)
 o ：在光标所在行下新增一列并进入输入模式。 O: 在光标所在行上方新增一列并进入输入模式。    命令模式 删除 #表示数字</description>
    </item>
    
    <item>
      <title>写在第 100 篇博文之际</title>
      <link>https://tech.zealscott.com/misc/100-blogs-goal/</link>
      <pubDate>Wed, 08 Aug 2018 11:47:00 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/misc/100-blogs-goal/</guid>
      <description>想写博客的念头已经很久了，在年初的春节终于有时间折腾出了自己的博客。一开始，仅仅是想用博客来记录自己学习中遇到的问题，作为备忘；后来上课了发现，与其将自己课上做的笔记写在 OneNote 上，还不如直接写在博客上，也许能帮助到一些同学呢；再到后来上数学课，就索性将数学公式、笔记也写在博客上（写 LaTeX 还是件很蛋疼的事）；到现在，我将自己做的一些小项目也记录下来，也许未来也会写点琐碎的感悟，也不一定呢。
写博客是件很美妙的事情，一方面，每次的记录其实并没有那么愉快，虽然 Markdown 已经足够简单不用担心排版的问题，但每天总得多花一两个小时总结也有点繁琐（不过慢慢就习惯了这种记录方式），另一方面，当我第一次收到陌生朋友评论的感谢时，我才发现原来我的博客也有人看呀，成就感满满。于是我开始在网站中加入百度统计和 Google Analysis，时不时看看今天有没有人看我的博客，也算是激励我不断更新的动力吧。
很惭愧的是，自己能力有限，多数博文也仅仅是上课的笔记和总结，并没有太多“干货”。好在自己还算勤快，半年就达到了自己定的一年目标（完成 100 篇博文）。这半年来其实自己的收获是巨大的，虽然每天都学的很累，但是总算是有种 feeling &amp;ndash;终于在 cs 上入门了。转专业这一年来，拒绝了所有的活动与比赛，静下心来搞学习，总算是有所收获。一年的时间说长也长，说短也短，原专业的朋友保研的保研，考研的考研，出国的出国。总有人半开玩笑的问我，“现在你看见他们都保研清北啦，你后不后悔”。我只是笑笑，当然不后悔了。但羡慕是有点羡慕的，毕竟是更好的平台，而自己选择了竞争压力太很多的行业，很难再像以前那样“游刃有余”。好在自己是个喜欢折腾且异常固执的人，倒也不觉得有什么。
最近博客更新得不勤，主要是因为放假了，以及自己在做两个小项目、学英语，没太多东西可以记录。经过一年的“闭关”，自己也觉得是时候参加一些比赛来实践实践（没点奖状怎么丰富自己简历啊哭），找了两三个自己认为还挺有挑战的比赛，从 9 月份开始玩玩。
当然，目前最重要的事情还是考好雅思&amp;hellip;&amp;hellip;</description>
    </item>
    
    <item>
      <title>Hexo 博文加密</title>
      <link>https://tech.zealscott.com/misc/hexo-encrypt/</link>
      <pubDate>Wed, 11 Jul 2018 10:15:55 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/misc/hexo-encrypt/</guid>
      <description>很多时候当我们写了一篇博客，但并不想所有人能够访问它。对于WordPress这很容易做到，但是对于hexo，由于是静态网页，并不能做到完全的加密。
在GitHub上发现了有个人做了一个加密的插件，还挺好用，推荐给大家。
安装 在你的hexo根目录的package.json文件夹中添加：
 &amp;ldquo;hexo-blog-encrypt&amp;rdquo;: &amp;ldquo;2.0.*&amp;rdquo;
 然后在命令行中输入：
 npm install
 这样这个插件就安装好了。
找到根目录下的_config.yml文件，添加如下：
1 2 3 4  # Security ## encrypt: enable: true   这样就可以使用插件了。
使用 在你要加密的文章头部写入password，例如：
1 2 3 4 5 6 7  --- title: Hello World date: 2016-03-30 21:18:02 password: abc123 abstract: Welcome to my blog, enter password to read. message: Welcome to my blog, enter password to read. ---   这样就可以需要输入密码访问了。</description>
    </item>
    
    <item>
      <title>如何选择神经网络中的超参数</title>
      <link>https://tech.zealscott.com/deeplearning/misc/parameters/</link>
      <pubDate>Mon, 04 Jun 2018 21:19:37 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/deeplearning/misc/parameters/</guid>
      <description>启发式策略 对于新拿到的一个训练集，我们首先的目的是：训练出来的结果至少要比随机要好。
初看这个目的很简单，但实际上很困难，尤其是遇到一种新类型的问题时。
简化数据集 例如，如果我们处理MNIST分类集，我们可以只处理0，1两个数字的集合，这样，不仅简化了分类目的，也能让神经网络的训练速度得到5倍的提升。
当使用更简单的分类集时，我们能更好的洞察神经网络的结构调整。
简化网络 我们应该从简单的网络开始进行训练，例如，只含一层的隐藏层，这样的训练速率更快，而且，若简单的网络都不能得到较好的结果，那么训练复杂的网络将会更加困难。
提高监控频率 我们可以在神经网络框架中每隔几百次epoch就打印当前的准确率，这样会让我们更好的洞察网络的拟合情况，提早发现过拟合或学习速率过慢等问题。
在每一步，我们使用验证集来衡量网络的性能，这些度量将会帮助我们找到更好的超参数。一旦准确率上升或者loss开始下降，就可以通过微调超参数获得快速的性能提升。
基本超参数 学习速率（learning rate） 对于学习速率，我们可以使用不同量级的参数（0.1，1，10等）先初步进行训练，根据loss的大小确定参数量级。
一般来说，我们使用验证集准确率来调整超参数，但在learning rate中倾向于使用loss，这是因为学习速率的主要目的是控制梯度下降的步长，监控训练loss是最好的检验步长过大的方法。
学习速率调整 一直以来，我们都将学习速率设置成常数。但通常来讲，可变的学习速率更加有效。
 在学习的前期，学习速率比较大，可以让训练变快 在准确率开始变差或者不变时，按照某个量依次减少学习速率（除以10）。  规范化参数 在开始时不包含规范化参数，直到确定了学习速率后，在根据验证数据来选择好的 规范化参数。一般规范化参数从1开始调整。
迭代期（epoch） Early stopping表示在每个回合的最后，我们都要计算验证集上的分类准确率。当准确率不再提升，就终止训练。
但一般来说，在训练过程中总会存在波动，每次准确率下降一点点就直接终止不是一个好的策略。一般来说，当分类准确率在一段时间内不再提升的时候终止比较好。
这样，使用Early stopping就可以简单的选择迭代期。
Mini Batch 如果值太小，不会用到并行计算的资源，速度也不会有所提升，倒会使得学习缓慢；
如果值太大，则不能够频繁的更新权重。
经验表明，Mini Batch其实时一个相对独立的参数，可以将其他参数选取合适的值之后，再来根据训练集准确率调整。
随机梯度下降的改进 Hessian技术 实际上就是二阶导的矩阵，理论上来说Hessian方法比标准的SGD收敛速度更快。
Momentum 我们可以认为这种方法引入了类似于摩擦力的量，使得梯度下降变化规则从原始的
$w→w′=w−η∇C$变为：
$$v \to v&#39; = \mu v +\eta \triangledown C$$
$$w′=w+v′$$
其中，$\eta$是用来控制阻碍或者摩擦力的量的超参数。
以上的公式可以理解为，力$\triangledown C$改变了速度$v$，速度再控制$w$的变化率。
$\eta$被称为moment coefficient，在物理中为动量。</description>
    </item>
    
    <item>
      <title>防止神经网络过拟合的基本方法</title>
      <link>https://tech.zealscott.com/deeplearning/misc/overfit/</link>
      <pubDate>Tue, 15 May 2018 19:58:58 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/deeplearning/misc/overfit/</guid>
      <description>过拟合是训练神经网络中常见的问题，本文讨论了产生过拟合的原因，如何发现过拟合，以及简单的解决方法</description>
    </item>
    
    <item>
      <title>交叉熵与 softmax </title>
      <link>https://tech.zealscott.com/deeplearning/misc/softmax/</link>
      <pubDate>Sun, 13 May 2018 22:58:46 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/deeplearning/misc/softmax/</guid>
      <description>二次代价函数 之前我们一直使用二次代价函数，貌似在一定程度上也挺work。但其实，当输入值与目标值差距很大时，二次代价函数就不是很恰当了；**这是因为当差距很大时，此函数的学习速率会很慢。**我们可以通过一个简单的例子观察这种变化：
假设我们只使用一个神经元与一个输出神经元，定义代价函数为：
$$C = \frac{(y-a)^2}{2}$$
使用链式法则计算权重和偏置的导数：
$$\frac{\partial C}{\partial w}= (a-y)\sigma&#39;(z)x$$
$$\frac{\partial C}{\partial b} = (a-y)\sigma&#39;(z)$$
假设我们训练输入为$x = 1$，目标输出为$y = 0$，可以看见此时输入输出差距很大，则带入：
$$\frac{\partial C}{\partial w}= a\sigma&#39;(z)$$
$$\frac{\partial C}{\partial b} = a\sigma&#39;(z)$$
回忆一下$\sigma$函数：
可以看出，当神经元的输出接近于1时，曲线变得相当平缓，因此$\sigma&#39;(z)$就很小了。这就是学习缓慢的原因。
交叉熵代价函数 因此，我们引入交叉熵代价函数，我们希望这个函数能弥补我们之前遇到的问题（在差距较大时学习缓慢）：
$$C = -\frac{1}{n}\sum\limits _x [y\ln a+(1-y)\ln (1-a)]$$
这个函数的表达式看起来十分晦涩难懂，首先我们来看它为什么能成为一个代价函数。
why cost function   $C &amp;gt; 0$
代价函数需要满足非负性。
在求和中，由于$y、a\in [0,1]$，因此都是负数，在前面加上一个负号就变为正数。
  在神经元输出接近目标值时，代价函数接近于0
我们假设$y = 0 , a \approx 0 $，则带入可发现$C\approx 0$
同样，在$y = 1,a \approx 1$，也发现$C \approx 0$</description>
    </item>
    
    <item>
      <title>VScode 使用技巧</title>
      <link>https://tech.zealscott.com/misc/vscode/</link>
      <pubDate>Mon, 23 Apr 2018 15:39:35 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/misc/vscode/</guid>
      <description>编辑技巧  跳出括号  直接再输入一次右括号   快速换行  默认快捷键Ctrl + Enter，可以使用键盘映射将Shift + Enter转换为快速换行   选中一行  默认ctrl +i   切换显示侧边栏  默认ctrl+B   搜索  ctrl+d匹配当前词 alt+w搜索时以当前完整词 alt+c搜索时区分大小写    插件及设置  使用C/C++，将自带的代码补全关闭，下载clang以及对应的插件，设置：  &amp;quot;C_Cpp.autocomplete&amp;quot;: &amp;quot;Disabled&amp;quot;， &amp;quot;clang.executable&amp;quot;: &amp;quot;C:\\Program Files\\LLVM\\bin\\clang.exe&amp;quot;,   使用sync插件自动同步  shift + alt + U自动上传配置 shift + alt + D 自动下载配置 牢记自己的token    </description>
    </item>
    
    <item>
      <title>前馈神经网络原理与实现</title>
      <link>https://tech.zealscott.com/deeplearning/misc/fnn/</link>
      <pubDate>Sun, 01 Apr 2018 19:29:00 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/deeplearning/misc/fnn/</guid>
      <description>本文适用于已经对感知机、神经网络有初步了解，但上手比较困难，愿意推导公式，更深入了解神经网络的朋友</description>
    </item>
    
    <item>
      <title>在 Sublime Text3 中配置并使用 LaTex </title>
      <link>https://tech.zealscott.com/misc/sublime/</link>
      <pubDate>Wed, 28 Feb 2018 14:55:39 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/misc/sublime/</guid>
      <description>准备工作  Sublime Text3 安装并配置好Package Control，若没有安装也没关系，我已经把常用的插件都放到了我的GitHub，可以按照说明复制到指定路径即可。 MiKTeX,下载并安装。 LaTeXTools(后面会有安装介绍) Sumatra PDF，下载并安装。  LaTeXTools 安装 最简单的方法是直接fork我的GitHub，按照ReadMe文件中的指示复制到指定路径。 或者使用Package Control，按组合键Ctrl+Shift+P，然后再输入install，选择 Package Control: install package。进入库后，搜索LaTeXTools，直接回车即可安装。
配置 重启sublime text3，按组合键Ctrl+Shift+P，然后再输入LaTeXTools：Reset user settings to default，回车。再在 Sublime Text3 的安装路径中找LaTeXTools.sublime-settings文件，例如，我的默认的文件路径为C:\Users\scott\AppData\Roaming\Sublime Text 3\Packages\User。打开文件，搜索关键词texpath，再输入
 &amp;ldquo;texpath&amp;rdquo; : &amp;ldquo;C:\Program Files\MiKTeX 2.9\miktex\bin\x64;$PATH&amp;rdquo;,
 如图所示： 配置SumatraPDF 添加环境变量 打开环境变量设置，在user的环境变量中添加SumatraPDF 的主程序目录，如图所示： 配置反向搜索 打开命令提示符（win+R），执行以下命令：（将其中的安装路径替换成你实际的安装路径）
 sumatrapdf.exe -inverse-search &amp;ldquo;&amp;quot;C:\Program Files\Sublime Text 3\sublime_text.exe&amp;quot; &amp;quot;%f:%l&amp;quot;&amp;rdquo;
 使用 自动补全 现在环境已经基本配置好了。但我们习惯了自动补全，没有自动补全哪行。因此在 Sublime Text3 中，Preference-settings-user，添加
 &amp;ldquo;auto_complete_selector&amp;rdquo;: &amp;ldquo;source, text&amp;rdquo;,
 即可实现自动补全。
中文支持 在.tex文件的开头，加上\documentclass[UTF8]{ctexart}，即可实现中文支持。第一次编译可能需要下载安装支持包，一直continue即可。
使用和编译 每次在 Sublime Text3 中新建文件，保存为.</description>
    </item>
    
    <item>
      <title>Hexo 多设备同步与版本控制实现</title>
      <link>https://tech.zealscott.com/misc/hexo-sync/</link>
      <pubDate>Wed, 21 Feb 2018 10:37:07 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/misc/hexo-sync/</guid>
      <description>我们知道，hexo是一个静态网页个人博客，所有的资源和文件都是储存在本地的，但这样不利于实现网页的版本控制和随时随地发表博客，因此Google了一下hexo多设备同步的问题</description>
    </item>
    
    <item>
      <title>Hexo 下 LaTeX 无法显示的解决方案</title>
      <link>https://tech.zealscott.com/misc/hexo-latex/</link>
      <pubDate>Thu, 08 Feb 2018 20:31:03 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/misc/hexo-latex/</guid>
      <description>今天写博客时需要用到LaTeX，但使用了晚上说的各种方法依然无法成功，折腾了一晚上终于可以了，给同样困惑的小伙伴一些参考</description>
    </item>
    
    <item>
      <title>Hexo 中 scaffolds 创建模板问题</title>
      <link>https://tech.zealscott.com/misc/hexo-scaffolds/</link>
      <pubDate>Thu, 08 Feb 2018 11:47:00 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/misc/hexo-scaffolds/</guid>
      <description>由于经常要写同一类型的文章，懒得每篇文章都添加同样的tags和categories，因此可使用scaffolds创建模板，每次只需要hexo new layout &amp;quot;标题&amp;quot;即可生成相同样式的文章。
但近期使用时发现一些问题，如下图所示，我创建了一个名为Hexo的模板，并正确放到scaffolds中： 然后再git中输入： 到这一步都没有任何问题，但当我们查看文章时，发现并没有生成我们想要的tags和categories，而是多了一个layout，这不是我们想要的。 后来发现，在scaffolds中创建模板时，模板标题不能为大写，中文也可以，但就是不能大写，不知道为什么，先占个坑，望有同样问题的同学能看见这篇文章。</description>
    </item>
    
    <item>
      <title>树莓派之BT下载器</title>
      <link>https://tech.zealscott.com/misc/bt-downloader/</link>
      <pubDate>Fri, 02 Feb 2018 22:06:22 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/misc/bt-downloader/</guid>
      <description>配置环境 首先安装transmission：
 sudo apt-get install transmission-daemon
 然后创建下载目录，一个是下载完成的目录（complete），一个是未完成的目录（incomplete），不建议将移动硬盘长时间挂载在树莓派上运行
1 2  mkdir -p /home/pi/incomplete # for incomplete downloads mkdir /home/pi/complete # finished downloads   设置权限
1 2 3 4 5  sudo usermod -a -G debian-transmission pi sudo chgrp debian-transmission /home/pi/incomplete sudo chgrp debian-transmission /home/pi/complete chmod 770 /home/pi/incomplete chmod 770 /home/pi/complete   修改配置文件,配置文件目录为
 vim /etc/transmission-daemon/settings.json
 打开文件如图所示 修改其中的三项即可，分别为：
1 2 3  &amp;#34;download-dir&amp;#34;: &amp;#34;/home/pi/complete&amp;#34;, &amp;#34;incomplete-dir&amp;#34;: &amp;#34;/home/pi/incomplete&amp;#34;, &amp;#34;rpc-whitelist&amp;#34;: &amp;#34;192.</description>
    </item>
    
    <item>
      <title>树莓派设置静态IP地址</title>
      <link>https://tech.zealscott.com/misc/static-ip/</link>
      <pubDate>Thu, 01 Feb 2018 22:08:03 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/misc/static-ip/</guid>
      <description>首先打开树莓派的命令行，输入：
 sudo vi /etc/dhcpcd.conf
 即可用vi编辑配置文件。
在文件末尾输入：
1 2 3 4 5 6 7 8 9 10 11  interface eth0 static ip_address=192.168.0.10/24 static routers=192.168.0.1 static domain_name_servers=192.168.0.1 interface wlan0 static ip_address=192.168.0.200/24 static routers=192.168.0.1 static domain_name_servers=192.168.0.1   其中，eth0是有线的配置，wlan0是无线配置
ip_address就是静态IP，后面要接/24
routers是网关
static domain_name_servers是DNS
然后再在命令行执行
 sudo reboot
 重启树莓派，即可根据树莓派的联网方式用静态IP连接。</description>
    </item>
    
    <item>
      <title>远程调试树莓派（PyCharm实现）</title>
      <link>https://tech.zealscott.com/misc/raspberry-python/</link>
      <pubDate>Thu, 01 Feb 2018 21:18:40 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/misc/raspberry-python/</guid>
      <description>对于Linux和文本编辑器不那么熟悉的小伙伴来说，直接在树莓派中写程序可谓是痛苦万分。本文将介绍如何使用PyCharm远程调试树莓派，并同步当前python文件到树莓派中</description>
    </item>
    
    <item>
      <title>树莓派首次上手</title>
      <link>https://tech.zealscott.com/misc/setup/</link>
      <pubDate>Wed, 31 Jan 2018 17:51:57 +0800</pubDate>
      
      <guid>https://tech.zealscott.com/misc/setup/</guid>
      <description>寒假突发奇想买了一个树莓派，参考了网上很多教程，终于安装成功，下面分享下折腾经验</description>
    </item>
    
    
    
  </channel>
</rss>
