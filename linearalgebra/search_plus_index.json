{"./":{"url":"./","title":"Introduction","keywords":"","body":"如何理解线性代数 不得不说，对于我来说，线性代数一直是很头疼的。这种头疼不在于说计算特征值、求PCA有多么多么复杂；而是自己一直没有办法直观理解矩阵是什么、向量又是什么、矩阵乘法为什么这么定义、特征值代表什么。我想这些问题也同样困扰着学习线性代数的很多同学。 因此我整理了线性代数中常用的知识笔记，以及一些学习中对我有收获的资料，也便于自己复习： 知乎上的讨论：如何理解线性代数？ 科普类视频：线性代数的本质 据说很好的教材，自己也还没看：Linear Algebra Done Right CSDN上关于矩阵的理解，适合Review：理解矩阵 Jon Shlens大神写的PCA tutorial：Tutorial on Principal Component Analysis This GitBook notes are maintained by zealscott. 资源 Introduction to Linear Algebra, Fifth Edition 学线性代数主要的参考书，Strang 教授也算是网红了，讲课讲得十分浅显易懂，网上有配套的video，强烈推荐。 线性代数2 清华马辉老师的线性代数慕课，讲法比较传统，但课件很清晰，不太需要看video也能看懂。 这主要是针对相似矩阵、SVD、PCA、伪逆等矩阵论的内容，是传统线性代数的很好补充。 数值线性代数 这本书主要介绍解的问题，以及在现实中如何求解大型系数矩阵的逆、特征值以及一些迭代的方法。 @Last updated at 1/22/2021 "},"subspace.html":{"url":"subspace.html","title":"矩阵的四个基本子空间","keywords":"","body":" 矩阵的四个基本子空间贯穿整个线性代数，包含了矩阵的秩、维数、基等重要概念。 定义及性质 设AAA为m×nm\\times nm×n矩阵，则： 列空间（Column space） C(A)={y∈Rm∣y=Ax}C(A) = \\{y\\in R^m|y = Ax\\}C(A)={y∈Rm∣y=Ax} 行空间（Row space） C(AT)={y∈Rn∣y=ATx}C(A^T) = \\{y\\in R^n|y = A^Tx\\}C(AT)={y∈Rn∣y=ATx} 零空间（Nullspace） N(A)={x∈Rn∣Ax=0}N(A) = \\{x\\in R^n|Ax = 0\\}N(A)={x∈Rn∣Ax=0} 左零空间（Left nullspace） N(AT)={x∈Rm∣ATx=0}N(A^T) = \\{x\\in R^m| A^Tx = 0\\}N(AT)={x∈Rm∣ATx=0} 基 C(A)C(A)C(A)：化为行阶梯矩阵，主元对应的AAA的列为基。 C(AT)C(A^T)C(AT)：化为行阶梯矩阵，主元对应的UUU的行为基。 N(A)N(A)N(A)：基础解系为基。 N(AT)N(A^T)N(AT)：EA=U0EA = U_0EA=U0​，EEE的r+1→mr+1\\to mr+1→m行为基。 证明： 可将矩阵A→U0=(IF00)A\\to U_0 = \\begin{pmatrix}I & F \\\\\\\\ 0 & 0\\end{pmatrix}A→U0​=⎝⎛​I0​F0​⎠⎞​，前rrr行有主元，后m−rm-rm−r行是零向量。 即存在可逆矩阵EEE, EA=U0EA=U_0EA=U0​，且(u1T...u1T)\\begin{pmatrix}u_1^T\\\\\\\\ ...\\\\\\\\ u_1^T\\end{pmatrix}⎝⎜⎜⎜⎜⎛​u1T​...u1T​​⎠⎟⎟⎟⎟⎞​。 则ur+1TA=0,...,umTA=0u_{r+1}^TA = 0,...,u_m^TA = 0ur+1T​A=0,...,umT​A=0，根据定义，即ur+1,...umu_{r+1},...u_mur+1​,...um​是N(AT)N(A^T)N(AT)的一组基。 例：求解矩阵的四个线性子空间 A=(135070001213519)→U0=(135070001200000),E=(100010−1−11)A = \\begin{pmatrix}1 & 3 &5 & 0 &7 \\\\\\\\ 0 &0 & 0 & 1 &2 \\\\\\\\ 1&3 & 5 &1 &9 \\end{pmatrix}\\to U_0=\\begin{pmatrix}1 & 3 &5 & 0 &7 \\\\\\\\ 0 &0 & 0 & 1 &2 \\\\\\\\ 0&0 & 0 &0 &0 \\end{pmatrix},E = \\begin{pmatrix}1 & 0 &0 \\\\\\\\ 0 &1 & 0 \\\\\\\\ -1&-1 & 1 \\end{pmatrix}A=⎝⎜⎜⎜⎜⎛​101​303​505​011​729​⎠⎟⎟⎟⎟⎞​→U0​=⎝⎜⎜⎜⎜⎛​100​300​500​010​720​⎠⎟⎟⎟⎟⎞​,E=⎝⎜⎜⎜⎜⎛​10−1​01−1​001​⎠⎟⎟⎟⎟⎞​ 行空间 s1=c1[13507]T,s2=c2[00012]Ts_1 = c_1\\begin{bmatrix}1 &3 & 5 &0&7 \\end{bmatrix}^T, s_2 = c_2\\begin{bmatrix}0 &0 & 0 &1&2 \\end{bmatrix}^Ts1​=c1​[1​3​5​0​7​]T,s2​=c2​[0​0​0​1​2​]T 列空间 s1=c1[101]T,s2=c2[011]Ts_1 = c_1\\begin{bmatrix}1 &0 & 1 \\end{bmatrix}^T, s_2 = c_2\\begin{bmatrix}0 &1 & 1 \\end{bmatrix}^Ts1​=c1​[1​0​1​]T,s2​=c2​[0​1​1​]T 零空间 s1=c1[−31000]Ts_1 = c_1\\begin{bmatrix}-3 &1 & 0 &0&0 \\end{bmatrix}^Ts1​=c1​[−3​1​0​0​0​]T s2=c2[−50100]Ts_2 = c_2\\begin{bmatrix}-5 &0 & 1 &0&0 \\end{bmatrix}^Ts2​=c2​[−5​0​1​0​0​]T s3=c3[−7−2001]Ts_3 = c_3\\begin{bmatrix}-7 &-2 & 0 &0&1 \\end{bmatrix}^Ts3​=c3​[−7​−2​0​0​1​]T 左零空间 s1=c1[−1−11]Ts_1 = c_1\\begin{bmatrix}-1 &-1 & 1 \\end{bmatrix}^Ts1​=c1​[−1​−1​1​]T 维数 维数（dimension）是基中向量的个数，并且可以证明，任何两个基中向量个数一样多（反证法）。 直观感觉不难得到，当将矩阵AAA化简为U0U_0U0​后，行空间和列空间的维数都等于主元的个数，也就等于矩阵的秩rrr。 而零空间的维数就等于基础解系的个数，因此为列数减去秩。 同理，左零空间为AAA的转置的基础解系的个数，因此等于ATA^TAT的列数减去秩。因此不难得到如下等式： dimC(A)=rdim C(A) = rdimC(A)=r dimC(AT)=rdimC(A^T) = rdimC(AT)=r dimN(A)=n−rdimN(A) = n-rdimN(A)=n−r dimN(AT)=m−rdimN(A^T) = m-rdimN(AT)=m−r 为什么dimC(A)=dimC(AT)=rdim C(A) = dimC(A^T) =rdimC(A)=dimC(AT)=r? 行空间维数是矩阵的主元(pivot)的个数，而当矩阵AAA消元转换为EA=REA=REA=R(简化行阶梯矩阵)，就是非零行的个数，也就是前rrr行，因此维数为rrr。 列空间维数是在消元之后，矩阵的列数减去自由变量的个数，由定义可知，自由变量为非主元的个数，因此列空间维数也等于主元的个数rrr。 因此，我们可以得到：独立列向量的个数等于独立行向量的个数。 维数公式 设VVV是一个向量空间，W1,W2W_1,W_2W1​,W2​是两个子空间，则W1∪W2W_1\\cup W_2W1​∪W2​和W1+W2W_1 + W_2W1​+W2​是VVV的子空间，但W1∪W2W_1\\cup W_2W1​∪W2​一般不是子空间。它们满足以下关系： dimW1+dimW2=dim(W1∪W2)+dim(W1+W2)dimW_1 + dimW_2 = dim(W_1\\cup W_2)+dim(W1+W2)dimW1​+dimW2​=dim(W1​∪W2​)+dim(W1+W2) 可以使用离散数学中的鸽巢原理证明，并学会应用求解W1∪W2W_1\\cup W_2W1​∪W2​和W1+W2W_1 + W_2W1​+W2​。 "},"subspace property.html":{"url":"subspace property.html","title":"基本子空间的正交性及性质","keywords":"","body":" 基本子空间中有着更加特殊和精确的关系，由此可以引出向量空间的正交性及投影等问题。 正交性及正交补 定义：设SSS和TTT是RnR^nRn的两个子空间（subspace），如果对于∀V∈S,w∈T,vTw=0\\forall V\\in S, w\\in T, v^Tw=0∀V∈S,w∈T,vTw=0，则SSS垂直于TTT（S is perpendicular to T），并且，这个定义是对称的，即SSS垂直于TTTTTT垂直于SSS。记做S⊥TS\\perp TS⊥T。也可以说SSS和TTT是正交的（S and T are orthogonal）。 几个常见结论 设A=B1B2A = B_1B_2A=B1​B2​，其中B1B_1B1​是n×rn\\times rn×r 矩阵，B2B_2B2​是r×nr\\times nr×n矩阵，后两矩阵秩都为rrr，则AAA是一个n×nn \\times nn×n 矩阵，且r(A)=rr(A) = rr(A)=r。 AAA的每一列是B1B_1B1​的列向量的线性组合，因此C(A)⊂C(B1)C(A)\\subset C(B_1)C(A)⊂C(B1​)。 AAA的每一列是B2B_2B2​的行向量的线性组合，因此C(AT)⊂C(B2T)C(A^T)\\subset C(B_2^T)C(AT)⊂C(B2T​)。 B1B_1B1​是列满秩，则存在可逆n×nn\\times nn×n矩阵E1E_1E1​，E1B1=(Ir 0)TE_1B_1 = (I_r\\space 0)^TE1​B1​=(Ir​ 0)T。 B2B_2B2​是行满秩，则存在可逆n×nn\\times nn×n矩阵E2E_2E2​，B2E2=(Ir 0)B_2E_2 = (I_r\\space 0)B2​E2​=(Ir​ 0)。 C(A)=C(AE2)=C(B1(Ir 0))=C(B1)C(A) = C(AE_2)=C(B_1(I_r\\space 0)) = C(B_1)C(A)=C(AE2​)=C(B1​(Ir​ 0))=C(B1​)。因此，dimC(A)=dimC(B1)dimC(A) = dimC(B_1)dimC(A)=dimC(B1​)，即r(A)=r(B1)=rr(A) = r(B_1) = rr(A)=r(B1​)=r。 若AAA的列向量线性无关，则ATAA^TAATA为可逆方阵。 AAA列满秩 => Ax=0Ax = 0Ax=0只有零解 => ATAx=0A^TAx = 0ATAx=0 只有零解 => ATAA^TAATA列满秩。 又因为ATAA^TAATA是n×nn\\times nn×n方阵，因此为可逆矩阵。 若S∩T≠{0}S\\cap T \\neq\\{0\\}S∩T≠{0}，则∃v∈S∩T,vTv≠0\\exists v \\in S\\cap T,v^Tv\\neq 0∃v∈S∩T,vTv≠0。因此SSS和TTT不正交。 命题：设SSS和TTT是RnR^nRn中的两个子空间，且dimS+dimT>ndimS + dimT > ndimS+dimT>n，则SSS和TTT不正交。 若AAA是n×nn\\times nn×n矩阵，并且A2=0A^2 = 0A2=0，则r≤n/2r\\le n/2r≤n/2。 由题意可知，∵A×A=0,∴C(A)∈N(A)\\because A\\times A = 0, \\therefore C(A)\\in N(A)∵A×A=0,∴C(A)∈N(A)。 ∴r≤n−r⇒r≤n/2\\therefore r\\le n-r\\Rightarrow r\\le n/2∴r≤n−r⇒r≤n/2。 子空间的正交性 定理：设AAA是 n×nn\\times nn×n矩阵，则C(A)C(A)C(A)和N(AT)N(A^T)N(AT)正交，C(AT)C(A^T)C(AT)和N(A)N(A)N(A)正交。 设α∈N(AT)\\alpha \\in N(A^T)α∈N(AT)，则αTA=0\\alpha^T A = 0αTA=0。 因此α\\alphaα 和 AAA的全部列向量垂直。可以得到N(AT)⊥C(A)N(A^T)\\perp C(A)N(AT)⊥C(A)。 将AAA 换成ATA^TAT，可以得到C(AT)⊥N(A)C(A^T)\\perp N(A)C(AT)⊥N(A)。 四个子空间还存在着如下的关系： N(AT)+C(A)=Rm,C(A)+N(AT)=RnN(A^T)+ C(A) = R^m, C(A)+N(A^T) = R^nN(AT)+C(A)=Rm,C(A)+N(AT)=Rn 我们说C(A)C(A)C(A)是N(AT)N(A^T)N(AT)在RmR^mRm上的正交补，C(AT)C(A^T)C(AT)是N(A)N(A)N(A)在RnR^nRn上的正交补。 定义：设V⊂RnV\\subset R^nV⊂Rn是一个子空间，VVV在RnR^nRn中的正交补定义为集合 {w∈Rn∣vTw=0,∀v∈V}\\{w\\in R^n |v^Tw = 0,\\forall v\\in V\\}{w∈Rn∣vTw=0,∀v∈V} 子空间的性质 若AAA对称，即A=ATA = A^TA=AT，则C(A)=C(AT)C(A) = C(A^T)C(A)=C(AT)，因此C(A)⊥N(A)C(A) \\perp N(A)C(A)⊥N(A)。 ATAA^TAATA为对称阵，且N(A)=N(ATA)N(A) = N(A^TA)N(A)=N(ATA)， C(AT)=C(ATA)C(A^T)= C(A^TA)C(AT)=C(ATA)。 Ax=0⇒ATAx=0⇒N(A)⊆N(ATA)Ax = 0 \\Rightarrow A^TAx= 0 \\Rightarrow N(A) \\subseteq N(A^TA)Ax=0⇒ATAx=0⇒N(A)⊆N(ATA) ATAx=0⇒xTATAx=0⇒Ax=0⇒N(ATA)⊆N(A)A^TAx= 0 \\Rightarrow x^TA^TAx= 0 \\Rightarrow Ax = 0 \\Rightarrow N(A^TA)\\subseteq N(A)ATAx=0⇒xTATAx=0⇒Ax=0⇒N(ATA)⊆N(A) ⇒N(A)=N(ATA)\\Rightarrow N(A ) = N(A^TA)⇒N(A)=N(ATA) 若Ax=bAx= bAx=b有解，则Ax=bAx= bAx=b在C(AT)C(A^T)C(AT)中有唯一解。 存在性：设Ax=bAx= bAx=b有解，则b∈C(A)b\\in C(A)b∈C(A)。又因为C(A)=C(AAT)C(A) = C(AA^T)C(A)=C(AAT)，因此b∈C(AAT)b\\in C(AA^T)b∈C(AAT) ∴∃y∈Rm⇒AATy=b\\therefore \\exists y \\in R^m \\Rightarrow AA^Ty = b∴∃y∈Rm⇒AATy=b letxr=ATy⇒Axr=b∴xr∈C(AT)let x_r = A^Ty \\Rightarrow Ax_r = b \\therefore x_r \\in C(A^T)letxr​=ATy⇒Axr​=b∴xr​∈C(AT) 唯一性（反证法）：若xr1x_r^1xr1​，xr2∈C(AT),and Axr1=b=Axr2x_r^2\\in C(A^T), and\\space Ax_r^1 = b = Ax_r^2xr2​∈C(AT),and Axr1​=b=Axr2​ ∴A(xr1−xr2)=0⇒xr1−xr2∈N(A)\\therefore A(x_r^1-x_r^2) = 0\\Rightarrow x_r^1-x_r^2\\in N(A)∴A(xr1​−xr2​)=0⇒xr1​−xr2​∈N(A) ∵xr1,xr2∈C(AT)∴xr1,xr2∈C(AT)∩N(A)={0}\\because x_r^1, x_r^2\\in C(A^T) \\therefore x_r^1, x_r^2\\in C(A^T)\\cap N(A) = \\{0\\}∵xr1​,xr2​∈C(AT)∴xr1​,xr2​∈C(AT)∩N(A)={0} ∴xr1=xr2\\therefore x_r^1=x_r^2∴xr1​=xr2​ "},"project.html":{"url":"project.html","title":"向量投影","keywords":"","body":" 向量投影是线性代数中很重要的应用，用于找到向量到目标投影空间的投影向量。基本子空间中有着更加特殊和精确的关系，由此可以引出向量空间的正交性及投影等问题。这是下一节线性回归的基础。 Ax=bAx=bAx=b有解时 当计算线性方程组Ax=bAx=bAx=b 有解时， bbb就在C(A)C(A)C(A)的子空间中，则Ax=bAx= b Ax=b在C(AT)C(A^T)C(AT)中有唯一解。我们考虑xxx的投影。 设α∈Rn\\alpha \\in \\mathbb {R}^nα∈Rn是Ax=bAx= bAx=b的解，则α=αr+αn,αr∈C(AT),αn∈N(A)\\alpha = \\alpha_r + \\alpha_n, \\alpha_r \\in C(A^T), \\alpha_n \\in N(A) α=αr​+αn​,αr​∈C(AT),αn​∈N(A)。则： αr\\alpha _rαr​ 是α\\alphaα 在C(AT)C(A^T)C(AT)的投影。 αn\\alpha _nαn​ 是α\\alphaα 在N(A)N(A)N(A)的投影。 Ax=bAx=bAx=b无解时 当计算线性方程组 Ax=bAx=bAx=b 时， 它可能是无解的，此时我们可以考虑求 x^∈Rn\\hat{x} \\in \\mathbb{R}^{n} x^∈Rn，使得|| Ax^−b A \\hat{x} - b Ax^−b || 最小或极小？ 这就意味着当 b∉C(A)b \\notin C(A) b∉C(A) 时，我们需要求解 C(A)C(A)C(A) 上距离 bbb 最近的点 Ax^A \\hat{x}Ax^ ， 它就是bbb 在 C(A)C(A)C(A) 上的投影点。 这对于我们理解最小二乘法很有帮助，具体请参考下一章。 以三维空间为例，目标投影空间可能是线，也可能是面。 投影的实质就是找一个函数，从而使得 P(B)=bP(B) = bP(B)=b ，也就找到了 BBB 在某一维度的映射。 类似的，在线性代数中，我们需要找到投影矩阵 PPP ，使得 Pb∈C(A)Pb \\in C(A)Pb∈C(A) 。 投影矩阵 PPP 投影矩阵 PPP ，顾名思义，就是利用矩阵 PPP ，将向量 bbb 投影到所需的”空间“中，设投影点为 ppp，则误差向量 e=b−pe = b - pe=b−p。 在直线上的投影 求 bbb 在直线 aaa 上的投影向量 ppp. 已知 p+e=b,e⊥a,p=ta(t∈R) p + e = b, e \\perp a , p = ta (t \\in \\mathbb{R}) p+e=b,e⊥a,p=ta(t∈R) ∴e⊥a→aT(b−ta)=0→t=aTbaTa(a≠0)\\therefore e \\perp a \\rightarrow a^T(b - ta) = 0 \\rightarrow t = \\frac{a^Tb}{a^Ta} (a \\ne 0)∴e⊥a→aT(b−ta)=0→t=aTaaTb​(a≠0) 即 bbb 在直线 aaa 上的投影向量为 (aTbaTa)a=p (\\frac{a^Tb}{a^Ta} ) a = p (aTaaTb​)a=p. (a，b表示相应列向量) 投影向量p=(aTbaTa)a=aTaaTa)bp = (\\frac{a^Tb}{a^Ta} ) a = \\frac{a^Ta}{a^Ta} ) b p=(aTaaTb​)a=aTaaTa​)b 我们称 aTaaTa \\frac{a^Ta}{a^Ta}aTaaTa​为投影矩阵 PPP. 在平面上的投影 给定 v∈R3v \\in \\mathbb{R}^3v∈R3 ，求 vvv 在平面 π=C(A)\\pi= C(A)π=C(A) 上的投影 ppp . 令 α1,α2\\alpha_1, \\alpha_2α1​,α2​ 是平面 π\\piπ 上两无关向量，即 π=C(A) \\pi = C(A)π=C(A) 的一组基。 令p=Ax^p = A\\hat{x}p=Ax^，则 e=v−Ax^e = v - A\\hat{x}e=v−Ax^ 垂直于平面 π\\piπ ，即其属于AAA 的左零空间。 ∴AT(AX^−v)=0\\therefore A^T(A\\hat{X} - v) = 0∴AT(AX^−v)=0， 即 x^ \\hat{x}x^ 是 ATAx=ATvA^TAx = A^TvATAx=ATv 的解。 ∵A\\because A∵A 的列向量线性无关，即 ATAA^TAATA 是可逆矩阵 ∴x^=(ATA)−1ATv→p=A(ATA)−1ATv\\therefore \\hat{x} = (A^TA)^{-1}A^Tv \\rightarrow p = A(A^TA)^{-1}A^Tv∴x^=(ATA)−1ATv→p=A(ATA)−1ATv. 我们称 A(ATA)−1AT A(A^TA)^{-1}A^T A(ATA)−1AT 为投影矩阵 PPP. 一般情形 AAA 为 m×nm \\times nm×n 矩阵，设 b∈Rmb \\in \\mathbb{R}^mb∈Rm，求 bbb 在 C(A)C(A)C(A) 上的投影 ppp ? p∈C(A)⟺∃x^∈Rn,Ax^=pp \\in C(A) \\Longleftrightarrow \\exists \\hat{x} \\in \\mathbb{R}^n, A \\hat{x} = pp∈C(A)⟺∃x^∈Rn,Ax^=p。 ∵e=b−p⊥C(A)↔e∈N(AT)\\because e = b - p \\perp C(A) \\leftrightarrow e \\in N(A^T)∵e=b−p⊥C(A)↔e∈N(AT) ∴ATe=⇒AT(b−Ax^)=0.⟹p=Ax^=A(ATA)−1ATb\\therefore A^T e= \\Rightarrow A^T(b - A \\hat{x}) = 0. \\Longrightarrow p = A\\hat{x} = A(A^TA)^{-1}A^Tb∴ATe=⇒AT(b−Ax^)=0.⟹p=Ax^=A(ATA)−1ATb 这里需要注意一点：ATAx=ATbA^TAx = A^TbATAx=ATb 总有解（无论 AAA 是否列满秩） 这是因为C(AT)=C(ATA),ATb∈C(AT)=C(ATA)C(A^T) = C(A^TA), A^Tb \\in C(A^T) = C(A^TA)C(AT)=C(ATA),ATb∈C(AT)=C(ATA)，所以总能找到这样的 x^\\hat{x}x^ 使得 x^=A(ATA)−1AT\\hat{x} = A(A^TA)^{-1}A^Tx^=A(ATA)−1AT。 投影矩阵 PP P的性质 若AAA 的列向量线性无关（列满秩），则矩阵 ATAA^TAATA 可逆，投影矩阵 P=A(ATA)−1AT P = A(A^TA)^{-1}A^T P=A(ATA)−1AT 满足 P2=P,PT=PP^2=P, P^T = PP2=P,PT=P 从直观上，向量 bbb 经过一次投影到平面AAA 上后再经过相同的一次投影仍然在平面AAA 上，因此投影矩阵 P2P^2P2 和 PPP 的效果是一样的，因此P2=PP^2=PP2=P 。 数学推理： P2=(A(ATA)−1AT)(A(ATA)−1AT))=A(ATA)−1(ATA)(ATA)−1AT=A(ATA)−1AT=PP^2 = (A(A^TA)^{-1}A^T)(A(A^TA)^{-1}A^T)) = A(A^TA)^{-1}(A^TA)(A^TA)^{-1}A^T = A(A^TA)^{-1}A^T = PP2=(A(ATA)−1AT)(A(ATA)−1AT))=A(ATA)−1(ATA)(ATA)−1AT=A(ATA)−1AT=P C(P)=N(I−P),N(P)=C(I−P)C(P) = N(I-P), N(P) = C(I-P)C(P)=N(I−P),N(P)=C(I−P) ∵P2=P\\because P^2 = P∵P2=P ∴P(I−P)=0⟹C(I−P)⊂N(P)\\therefore P(I-P)=0 \\Longrightarrow C(I-P) \\subset N(P)∴P(I−P)=0⟹C(I−P)⊂N(P) 设 α∈N(P)\\alpha \\in N(P)α∈N(P)，则 Pα=0⟹α=(I−P)αP\\alpha = 0 \\Longrightarrow \\alpha = (I-P) \\alphaPα=0⟹α=(I−P)α ∴α∈C(I−P)⟹N(P)⊂C(I−P)\\therefore \\alpha \\in C(I-P) \\Longrightarrow N(P) \\subset C(I-P) ∴α∈C(I−P)⟹N(P)⊂C(I−P) 综上：N(P)=C(I−P)N(P) = C(I-P)N(P)=C(I−P) 同理C(P)=N(I−P)C(P) = N(I-P)C(P)=N(I−P) "},"Least squares.html":{"url":"Least squares.html","title":"最小二乘法","keywords":"","body":" 最小二乘法大家都很熟悉了，今天以向量投影的角度重新认识它。 引入 回到解方程组Ax=bAx = bAx=b。 若Ax=bAx = bAx=b 有解，则b∈C(A)b\\in C(A)b∈C(A)。 若Ax=bAx = bAx=b 有解，则b∉C(A)b\\notin C(A)b∉C(A)，转化为问题求：x^\\hat{x}x^使得||Ax^−bA\\hat{x} - bAx^−b||最小，即minx∈Rn∣∣Ax^−b∣∣min_{x\\in R^n}||A\\hat{x}-b||minx∈Rn​∣∣Ax^−b∣∣的最小值点。 由上一讲可知，最小值其实就是e=b−Ax^e = b- A\\hat xe=b−Ax^，即误差向量。在空间中表示为bbb 在C(A)C(A)C(A)上的投影。 因此，我们可以求得投影向量p=Ax^p = A\\hat xp=Ax^，然后根据e⊥C(A)e \\perp C(A)e⊥C(A)得到法方程组：ATAx^=ATbA^TA\\hat x= A^TbATAx^=ATb。 法方程组有几个重要的性质： 法方程组总有解（无论A是否列满秩）。 ATAx^=ATbA^TA\\hat x = A^TbATAx^=ATb的解可能有无数多个，但p=Ax^p = A\\hat xp=Ax^唯一。 直线拟合 首先我们来看最常见的直线拟合。 我们想得到目标直线y^=a+bx,ei=yi−y^i\\hat y = a + bx, e_i = y_i - \\hat y_iy^​=a+bx,ei​=yi​−y^​i​。 给定数据{(x1,y1,...(xn,yn)}\\{(x_1,y_1,...(x_n,y_n)\\}{(x1​,y1​,...(xn​,yn​)}。寻找直线y=C+Dxy=C+Dxy=C+Dx，使得误差最小: E(C,D)=[y1−(C+Dx1)]2+....+[yn−(C+Dn)]2E(C,D)=[y_1-(C+Dx_1)]^2+ .... +[y_n-(C+D_n)]^2E(C,D)=[y1​−(C+Dx1​)]2+....+[yn​−(C+Dn​)]2 即向量(y1−(C+Dx1)...yn−(C+Dxn))\\begin{pmatrix}y_1-(C+Dx_1)\\\\\\\\ ...\\\\\\\\ y_n-(C+Dx_n)\\end{pmatrix}⎝⎜⎜⎜⎜⎛​y1​−(C+Dx1​)...yn​−(C+Dxn​)​⎠⎟⎟⎟⎟⎞​的长度最小。 令A=(1 x1...... 1xn)A = \\begin{pmatrix}1 & \\ x_1 \\\\\\\\...& ...\\\\\\\\\\ 1& x_n \\end{pmatrix}A=⎝⎜⎜⎜⎜⎛​1... 1​ x1​...xn​​⎠⎟⎟⎟⎟⎞​，b=[y1...yn]b = \\begin{bmatrix}y_1\\\\ ...\\\\ y_n \\end{bmatrix}b=⎣⎡​y1​...yn​​⎦⎤​，x^=b=[C^D^]\\hat x = b = \\begin{bmatrix}\\hat C\\\\ \\hat D\\end{bmatrix}x^=b=[C^D^​]。即求解x^\\hat xx^ 使得∣∣b−Ax^∣∣||b-A\\hat{x}||∣∣b−Ax^∣∣最小。 利用之前的结论，ATAx^=ATbA^TA\\hat x= A^TbATAx^=ATb，带入即可得： C^=y‾−D^x‾, D^=∑i=1n(xi−x‾)(yi−y‾)∑i=1n(xi−x‾)\\hat C = \\overline y - \\hat D \\overline x, \\space \\hat D = \\frac{\\sum\\limits_{i=1}^{n}(x_i - \\overline x)(y_i - \\overline y)}{\\sum\\limits_{i=1}^{n} (x_i - \\overline x)}C^=y​−D^x, D^=i=1∑n​(xi​−x)i=1∑n​(xi​−x)(yi​−y​)​ 直线y=C^+D^x y = \\hat C + \\hat Dxy=C^+D^x称为最小二成直线。 因此，我们只需要求法方程组，即可求得直线的所有参数。 微积分 曲线拟合与直线类似，只是多了几个参数而已，在此不做介绍。 我们现在可以说明法方程组也来自微积分。令： f(x1,...,xn)=∣∣Ax=b∣∣2=(Ax−b)T(Ax−b)f(x_1,...,x_n) = || Ax = b||^2=(Ax-b)^T(Ax-b)f(x1​,...,xn​)=∣∣Ax=b∣∣2=(Ax−b)T(Ax−b) 则∂f∂X=(∂f∂x1...∂f∂xn)=2ATAX−2ATb\\frac{\\partial f}{\\partial X} = \\begin{pmatrix} \\frac{\\partial f}{\\partial x_1} \\\\\\\\...\\\\\\\\ \\frac{\\partial f}{\\partial x_n} \\end{pmatrix} = 2A^TAX - 2A^Tb∂X∂f​=⎝⎜⎜⎜⎜⎛​∂x1​∂f​...∂xn​∂f​​⎠⎟⎟⎟⎟⎞​=2ATAX−2ATb。 若x^\\hat xx^ 满足minx∈Rn∣∣Ax^−b∣∣min_{x\\in R^n}||A\\hat{x}-b||minx∈Rn​∣∣Ax^−b∣∣，则∂f∂X\\frac{\\partial f}{\\partial X}∂X∂f​一定是极值点。因此可得：ATAx^=ATbA^TA\\hat x= A^TbATAx^=ATb。 "},"gram-schmidit.html":{"url":"gram-schmidit.html","title":"Gram-Schmidit正交化","keywords":"","body":" 上一讲我们学习了最小二乘法，主要就是求解ATAx=ATbA^TAx = A^TbATAx=ATb这个方程，我们能不能想办法使得这个方程越简单越好呢？。 引言 如果矩阵的列向量互相正交，若长度都为一，则称为标准正交阵，若满秩，即QQQ为方阵，那么我们称这个矩阵为正交矩阵（orthogonal matrix）。标准正交阵有很多很好的性质： QTQ=IQ^TQ=IQTQ=I，不要求QQQ为方阵 如果QQQ为方阵，则QT=Q−1Q^T = Q^{-1}QT=Q−1。 QxQxQx是保持长度的变换 ∣∣Qx∣∣2=(Qx)T(Qx)=xTQTQx=xTx=∣∣x∣∣2||Qx||^2 =(Qx)^T(Qx) = x^TQ^TQx = x^Tx = ||x||^2 ∣∣Qx∣∣2=(Qx)T(Qx)=xTQTQx=xTx=∣∣x∣∣2 QQQ不改变向量点积。 Qx×Qy=(Qx)TQy=xTQTQy=xTyQx\\times Qy = (Qx)^TQy=x^TQ^TQy = x^TyQx×Qy=(Qx)TQy=xTQTQy=xTy 反射矩阵 设uuu是一列向量，uTu=1u^Tu = 1uTu=1。 令Q=In−2uuT,u∈RnQ = I_n - 2uu^T, u\\in R^nQ=In​−2uuT,u∈Rn。QQQ为一个反射矩阵(refection matrix)。 QT=I−2uuT=Q, QTQ=I−4uuT+4uuT=IQ^T = I - 2uu^T = Q, \\space Q^TQ = I - 4uu^T + 4uu^T = IQT=I−2uuT=Q, QTQ=I−4uuT+4uuT=I Qu=u−2uuTu=−uQu = u - 2uu^Tu = -uQu=u−2uuTu=−u 可以感性地认为uuu在QQQ上“没有动”，类似于镜面。 投影与正交 在上一讲中，我们推导了向量投影的公式，里面有ATAA^TAATA的形式，如果用QQQ来代替AAA，那么可以重新推导结论： 投影矩阵P=Q(QTQ)−1QT=QQTP = Q(Q^TQ)^{-1}Q^T = QQ^TP=Q(QTQ)−1QT=QQT 投影向量p=Pb=QQTbp = Pb=QQ^Tbp=Pb=QQTb 我们可以进一步仔细观察投影向量： p=QQTb=[q1...qn][q1T...qnT]b=[q1...qn][q1Tb...qnTb]=∑i=1n(qiqiT)bp = QQ^Tb = \\begin{bmatrix}q_1 &... &q_n \\end{bmatrix} \\begin{bmatrix}q_1^T \\\\\\\\...\\\\\\\\ q_n^T \\end{bmatrix}b = \\begin{bmatrix}q_1 &... &q_n \\end{bmatrix}\\begin{bmatrix}q_1^Tb \\\\\\\\...\\\\\\\\ q_n^Tb \\end{bmatrix} = \\sum \\limits _{i=1}^{n}(q_iq^T_i)bp=QQTb=[q1​​...​qn​​]⎣⎢⎢⎢⎢⎡​q1T​...qnT​​⎦⎥⎥⎥⎥⎤​b=[q1​​...​qn​​]⎣⎢⎢⎢⎢⎡​q1T​b...qnT​b​⎦⎥⎥⎥⎥⎤​=i=1∑n​(qi​qiT​)b 可以发现，其实向量bbb到矩阵C(A)C(A)C(A)的投影，本质上可以分为bbb到每个正交向量qiq_iqi​的投影之和。 这是一个十分优美和谐的关系，投影之后彼此之间依然是正交，没有任何冗余。 Gram Schmidt正交化 由此我们想到，标准正交阵有这么好的形式，而每个子空间都有无数个基，那么是不是可以将每个基都表示称标准正交基的形式呢？理论上当然可以，但如何进行变换呢？Gram Schmidt正交化是一种很好的迭代方法。 直接先给出定理： 设α1,α2,...,αk\\alpha _1,\\alpha_2,...,\\alpha_k α1​,α2​,...,αk​相互正交，v∈L{α1,α2,...,αk}v\\in L\\{\\alpha _1,\\alpha_2,...,\\alpha_k \\}v∈L{α1​,α2​,...,αk​},则： v=α1Tvα1Tα1α1+...+αkTvαkTαkαkv =\\frac{\\alpha_1^Tv}{\\alpha_1^T\\alpha_1}\\alpha_1+...+\\frac{\\alpha_k^Tv}{\\alpha_k^T\\alpha_k}\\alpha_k v=α1T​α1​α1T​v​α1​+...+αkT​αk​αkT​v​αk​ 特别的，若α1,α2,...,αk\\alpha _1,\\alpha_2,...,\\alpha_k α1​,α2​,...,αk​标准正交，则： v=(α1Tv)α1+...+(αkTv)αkv =(\\alpha_1^Tv)\\alpha_1+...+(\\alpha_k^Tv)\\alpha_kv=(α1T​v)α1​+...+(αkT​v)αk​ 就相当于把vvv投影到L{α1,α2,...,αk}L\\{\\alpha _1,\\alpha_2,...,\\alpha_k \\}L{α1​,α2​,...,αk​}这个子空间中，等于分解到每个正交向量的投影之和。 可以利用这个定理，很容易的求出正交向量，这里给出另一种方法，可以边正交化边标准化。 设eie_iei​为误差向量，viv_i vi​为原始向量，qiq_iqi​即为所求 e1=v1=w1,q1=v1∣∣v1∣∣e_1 = v_1 = w_1,q_1 = \\frac{v_1}{||v_1||}e1​=v1​=w1​,q1​=∣∣v1​∣∣v1​​ e2=v2−(q1Tv2)q1=w2,q2=w2∣∣w2∣∣e_2 = v_2 - (q_1^Tv_2)q_1 = w_2,q_2 = \\frac{w_2}{||w_2||}e2​=v2​−(q1T​v2​)q1​=w2​,q2​=∣∣w2​∣∣w2​​ ek=vk−(q1Tvk)q1−...−(qk1Tvk)qk−1=wk,qk=vk∣∣vk∣∣e_k = v_k - (q_1^Tv_k)q_1 - ... - (q^T_{k_1}v_k)q_{k-1}= w_k,q_k = \\frac{v_k}{||v_k||}ek​=vk​−(q1T​vk​)q1​−...−(qk1​T​vk​)qk−1​=wk​,qk​=∣∣vk​∣∣vk​​ QR分解 通过Gram Schmidt正交化，我们知道任何子空间的基AAA都可以转化为标准正交基QQQ，那会很自然的想到，AAA和QQQ之间到底有什么样的关系呢？其实关系已经蕴含在Gram Schmidt的定理中了： a1=(q1Ta1)q1a_1=(q_1^T a_1)q_1a1​=(q1T​a1​)q1​ a2=(q1Ta2)q1+(q2Ta2)q2a_2=(q_1^T a_2)q_1 + (q_2^Ta_2)q_2a2​=(q1T​a2​)q1​+(q2T​a2​)q2​ a3=(q1Ta3)q1+(q2Ta3)q2+(q2Ta3)q3a_3=(q_1^T a_3)q_1 + (q_2^Ta_3)q_2+(q_2^Ta_3)q_3a3​=(q1T​a3​)q1​+(q2T​a3​)q2​+(q2T​a3​)q3​ an=(q1Tan)q1+(q2Tan)q2+...+(qnTan)qna_n=(q_1^T a_n)q_1 + (q_2^Ta_n)q_2+...+(q^T_na_n)q_nan​=(q1T​an​)q1​+(q2T​an​)q2​+...+(qnT​an​)qn​ 总结为矩阵形式： A=[a1a2...an]=[q1q2...qn][q1Ta1q1Ta2...q1Tan0q2Ta2...q2Tan............00...qnTan]A = \\begin{bmatrix}a1 &a_2 & ... & a_n\\end{bmatrix} = \\begin{bmatrix}q_1 &q_2 & ... & q_n\\end{bmatrix}\\begin{bmatrix} q_1 ^T a_1& q_1^Ta_2 &... &q_1^Ta_n \\\\\\\\ 0 &q_2^Ta_2 & ... & q_2^Ta_n\\\\\\\\ ... & ... &... & ...\\\\\\\\ 0 &0 & ... & q_n^Ta_n\\end{bmatrix}A=[a1​a2​​...​an​​]=[q1​​q2​​...​qn​​]⎣⎢⎢⎢⎢⎢⎢⎢⎢⎡​q1T​a1​0...0​q1T​a2​q2T​a2​...0​............​q1T​an​q2T​an​...qnT​an​​⎦⎥⎥⎥⎥⎥⎥⎥⎥⎤​ Q=[q1q2...qn],  R=[q1Ta1q1Ta2...q1Tan0q2Ta2...q2Tan ............00...qnTan]Q =\\begin{bmatrix}q_1 &q_2 & ... & q_n\\end{bmatrix},\\space \\space R = \\begin{bmatrix}q_1^T a_1& q_1^Ta_2 &... &q_1^Ta_n \\\\\\\\ 0 &q_2^Ta_2 & ... & q_2^Ta_n\\\\\\ ... & ... &... & ...\\\\\\\\ 0 &0 & ... & q_n^Ta_n\\end{bmatrix}Q=[q1​​q2​​...​qn​​],  R=⎣⎢⎢⎢⎢⎢⎢⎡​q1T​a1​0 ...0​q1T​a2​q2T​a2​...0​............​q1T​an​q2T​an​...qnT​an​​⎦⎥⎥⎥⎥⎥⎥⎤​ 应用 若A,BA,BA,B都是正交矩阵，则ABABAB也是正交矩阵 ATA=E  BTB=EA^TA = E \\space \\space B^TB=EATA=E  BTB=E (AB)TAB=BTATAB=BTEB=E(AB)^TAB = B^TA^TAB = B^TEB =E(AB)TAB=BTATAB=BTEB=E 若AAA是可逆方阵，则QRQRQR分解是唯一的。 若Am×nA_{m\\times n}Am×n​列满秩，有QR分解A=QRA = QRA=QR，b∉C(A)b \\notin C(A)b∉C(A)，设bbb在C(A)C(A)C(A)上的投影为p,e=b−pp,e= b-pp,e=b−p，则(A,b)(A,b)(A,b)也是列满秩，其QR分解为： (A,b)=(Q,e∣∣e∣∣)(Rα0∣∣e∣∣),α=QTb(A,b) = (Q,\\frac {e}{||e||})\\begin{pmatrix} R& \\alpha \\\\\\\\ 0 & ||e||\\end{pmatrix}, \\alpha = Q^Tb(A,b)=(Q,∣∣e∣∣e​)⎝⎛​R0​α∣∣e∣∣​⎠⎞​,α=QTb "},"determinant.html":{"url":"determinant.html","title":"行列式","keywords":"","body":" 大部分国内的线性代数都是从行列式开始讲起，这里只列出基本性质方便回顾。 行列式的几何意义 行列式中的行或列向量所构成的超平行多面体的有向面积或体积 坐标系变换下的图形面积或体积的伸缩因子，即变换矩阵AAA 行列式的一般性质 ∣In∣=det(In)=1|I_n| = det(I_n)=1∣In​∣=det(In​)=1 设A=(α1,...,αn),B=(α1,...αi−1,kαi,αi+1,...αn)A = (\\alpha_1,...,\\alpha_n),B = (\\alpha_1,...\\alpha_{i-1},k\\alpha_i,\\alpha_{i+1},...\\alpha_n)A=(α1​,...,αn​),B=(α1​,...αi−1​,kαi​,αi+1​,...αn​),则det(B)=k×det(A)det(B) = k\\times det(A)det(B)=k×det(A) 设A=A=(α1,...,αn),A′=(α1,...,αi′,...αn),B=(α1,...αi+αi′,..,αn)A = A = (\\alpha_1,...,\\alpha_n),A^{'} = (\\alpha_1,...,\\alpha_i^{'},...\\alpha_n),B = (\\alpha_1,...\\alpha_{i}+\\alpha_i^{'},..,\\alpha_n)A=A=(α1​,...,αn​),A′=(α1​,...,αi′​,...αn​),B=(α1​,...αi​+αi′​,..,αn​),则det(B)=det(A)+det(A′)det(B) = det(A)+det(A^{'})det(B)=det(A)+det(A′) det(A)=det(AT)det(A) = det(A^T)det(A)=det(AT) 任意交换AAA的两列得到A′A^{'}A′，则det(A)=−det(A′)det(A) = -det(A^{'})det(A)=−det(A′)。 推论 若AAA的两行（列）成比例，则det(A)=0det(A) = 0det(A)=0 将AAA的某一行（列）乘上一个倍数加到另外一列（行），得到矩阵A′A^{'}A′，则det(A)=det(A′)det(A) = det(A^{'})det(A)=det(A′) 若AAA是一个方阵，则det(A)≠0⇔Adet(A) \\neq 0 \\Leftrightarrow Adet(A)≠0⇔A可逆 设A,BA,BA,B是两个nnn阶方阵，则∣AB∣=∣A∣×∣B∣|AB| = |A| \\times |B|∣AB∣=∣A∣×∣B∣ ∣A+B∣≠∣A∣+∣B∣,∣kA∣≠k∣A∣|A+B| \\neq |A|+|B|,|kA| \\neq k|A|∣A+B∣≠∣A∣+∣B∣,∣kA∣≠k∣A∣ 设A=(aij)nA = (a_{ij})_nA=(aij​)n​为nnn阶矩阵，AijA_{ij}Aij​为∣A∣|A|∣A∣中元素aija_{ij}aij​的代数余子式，则称矩阵A⋆A^{\\star}A⋆为AAA的伴随矩阵： A⋆=(A11A12...A1nA21A22...A2n............An1An2...Ann)TA^{\\star} = \\begin{pmatrix}A_{11} &A_{12} &... &A_{1n} \\\\\\\\ A_{21}&A_{22} &... &A_{2n} \\\\\\\\ ... &... &... &... \\\\\\\\ A_{n1} &A_{n2} &... &A_{nn} \\end{pmatrix}^TA⋆=⎝⎜⎜⎜⎜⎜⎜⎜⎜⎛​A11​A21​...An1​​A12​A22​...An2​​............​A1n​A2n​...Ann​​⎠⎟⎟⎟⎟⎟⎟⎟⎟⎞​T 不难得到： AA⋆=∣A∣IAA^{\\star} = |A|IAA⋆=∣A∣I。 因此： A−1=1∣A∣A⋆A^{-1} = \\frac {1}{|A|}A^{\\star}A−1=∣A∣1​A⋆ 当AAA为奇异矩阵时，不难得到AA⋆=∣A∣I=zero matrixAA^{\\star} = |A|I =zero \\space matrixAA⋆=∣A∣I=zero matrix。因此，A⋆A^{\\star}A⋆的每一列都在AAA的零空间中。 行列式的计算 直接利用公式计算 使用代数余子式（algebraic complement）计算 令Cij=(−1)i+jdet(Mij)C_{ij} = (-1)^{i+j}det(M_{ij})Cij​=(−1)i+jdet(Mij​)，则：det(A)=ai1Ci1+ai2Ci2+...+ainCindet(A) = a_{i1}C_{i1}+a_{i2}C_{i2}+...+a_{in}C_{in}det(A)=ai1​Ci1​+ai2​Ci2​+...+ain​Cin​ 综合利用消元法和降阶法 典型例题：计算Vandermonde行列式 证明∣λIm−AB∣=λm−n∣λIn−BA∣|\\lambda I_m -AB| = \\lambda^{m-n}|\\lambda I_n - BA|∣λIm​−AB∣=λm−n∣λIn​−BA∣ 求逆矩阵 设A=(aij)n×nA = (a_{ij})_{n\\times n}A=(aij​)n×n​可逆，构造如下矩阵，称为AAA的伴随矩阵(adjoint of A)： adj(A)=(C11C12...C1nC21C22...C2n............Cn1Cn2...Cnn)Tadj(A) = \\begin{pmatrix}C_{11} &C_{12} &... &C_{1n} \\\\\\\\ C_{21}&C_{22} &... &C_{2n} \\\\\\\\ ... &... &... &... \\\\\\\\ C_{n1} &C_{n2} &... &C_{nn} \\end{pmatrix}^Tadj(A)=⎝⎜⎜⎜⎜⎜⎜⎜⎜⎛​C11​C21​...Cn1​​C12​C22​...Cn2​​............​C1n​C2n​...Cnn​​⎠⎟⎟⎟⎟⎟⎟⎟⎟⎞​T A−1=adj(A)∣A∣A^{-1} = \\frac {adj(A)}{|A|}A−1=∣A∣adj(A)​ r(A)=n⇒r(adj(A))=nr(A ) = n \\Rightarrow r(adj(A)) = nr(A)=n⇒r(adj(A))=n r(A)=n−1⇒A×(adj(A))=0r(A ) = n-1 \\Rightarrow A\\times (adj(A)) = 0r(A)=n−1⇒A×(adj(A))=0，因此adj(A)adj(A)adj(A)的列属于AAA的零空间。而dimN(A)=1⇒r(adj(A))=1dim N(A) = 1 \\Rightarrow r(adj(A)) = 1dimN(A)=1⇒r(adj(A))=1 r(A)≤n−2⇒Ar(A) \\le n-2 \\Rightarrow Ar(A)≤n−2⇒A的任意n-1阶子矩阵都不可逆⇒Cij=0→adj(A)=0\\Rightarrow C_{ij} = 0 \\rightarrow adj(A) = 0⇒Cij​=0→adj(A)=0 外积 给定两个向量u=(u1u2u3),v=(v1v2v3),u×v=(u2v3−u3v2u3v1−u1v3u1v2−u2v1)u=\\begin{pmatrix}u_1\\\\\\\\u_2 \\\\\\\\u_3 \\end{pmatrix},v=\\begin{pmatrix}v_1\\\\\\\\v_2 \\\\\\\\v_3 \\end{pmatrix},u\\times v = \\begin{pmatrix}u_2v_3 - u_3v_2\\\\\\\\u_3v_1-u_1v_3 \\\\\\\\ u_1v_2-u_2v_1 \\end{pmatrix}u=⎝⎜⎜⎜⎜⎛​u1​u2​u3​​⎠⎟⎟⎟⎟⎞​,v=⎝⎜⎜⎜⎜⎛​v1​v2​v3​​⎠⎟⎟⎟⎟⎞​,u×v=⎝⎜⎜⎜⎜⎛​u2​v3​−u3​v2​u3​v1​−u1​v3​u1​v2​−u2​v1​​⎠⎟⎟⎟⎟⎞​ 若i,j,ki,j,ki,j,k为单位向量，则： ∣ijku1u2u3v1v2v3∣=(u2v3−u3v2)i+(u3v1−u1v3)j+(u1v2−u2v1)k\\begin{vmatrix}i & j & k\\\\\\\\ u_1 &u_2 &u_3 \\\\\\\\ v_1& v_2 &v_3 \\end{vmatrix} = (u_2v_3 - u_3v_2)\\textbf i + (u_3v_1 - u_1v_3)\\textbf{j}+ (u_1v_2 - u_2v_1)\\textbf k∣∣∣∣∣∣∣∣∣∣​iu1​v1​​ju2​v2​​ku3​v3​​∣∣∣∣∣∣∣∣∣∣​=(u2​v3​−u3​v2​)i+(u3​v1​−u1​v3​)j+(u1​v2​−u2​v1​)k 性质 u×v=−v×u→u×u=0u \\times v = -v \\times u \\rightarrow u\\times u = 0u×v=−v×u→u×u=0 (u1+u2)×v=u1×v+u2×v(u_1 + u_2) \\times v = u_1 \\times v + u_2 \\times v(u1​+u2​)×v=u1​×v+u2​×v "},"eigenvector.html":{"url":"eigenvector.html","title":"特征向量","keywords":"","body":" 特征值和特征向量在机器学习中有着很重要的应用，本文介绍一些相关的结论和证明，方便大家复习参考。 定义 特征向量与特征值 定义：对方阵AAA，若存在λ\\lambda λ和非零向量xxx，满足Ax=λxAx = \\lambda xAx=λx，则称λ\\lambdaλ为矩阵AAA的特征值（eigenvalue），xxx为AAA属于特征值λ\\lambdaλ的特征向量（eigenvector） Ax=λx⇒(A−λI)x=0Ax= \\lambda x \\Rightarrow (A - \\lambda I )x = 0Ax=λx⇒(A−λI)x=0 因此，我们可以认为满足这个方程的x∈N(A−λI)x \\in N(A- \\lambda I)x∈N(A−λI)，也就是说，xxx属于这个零空间。 我们知道，对于任意的λ\\lambdaλ，向量xxx总满足Ax=λxAx= \\lambda xAx=λx，但我们关心的是由非零向量xxx满足此方程的特殊的λ\\lambdaλ值。 因此， 不难得到以下推论： N(A−λI)N(A -\\lambda I) N(A−λI) 含非零向量 ⇔A−λ\\Leftrightarrow A - \\lambda ⇔A−λ不可逆 ⇔det(A−λI)=0\\Leftrightarrow det(A- \\lambda I ) = 0⇔det(A−λI)=0 特征方程 我们记det(A−λI)=0det(A- \\lambda I ) = 0det(A−λI)=0为矩阵AAA的特征方程（characteristic equation），AAA的特征值就是特征方程的解。 从直观理解上看，由于矩阵的乘法实际上是对向量进行坐标旋转变换，而Ax=λxAx = \\lambda xAx=λx表示了一种特殊的向量，它使得左乘AAA后的向量依然与xxx共线。 求解方法 计算特征多项式det(A−λI)det(A- \\lambda I ) det(A−λI)。 求特征方程det(A−λI)=0det(A- \\lambda I ) = 0det(A−λI)=0的解，即为特征值。 对每个特征值λ\\lambdaλ，求解其次线性方程组(A−λI)x=0(A- \\lambda I )x = 0(A−λI)x=0，其所有非零解即为属于λ\\lambdaλ的所有特征向量。 性质 矩阵AA A不可逆⇔A\\Leftrightarrow A⇔A有零特征值。 实对称矩阵的特征向量两两正交。 Ax1=λ1x1Ax2=λ2x2Ax_1 = \\lambda _1x_1 \\quad Ax_2 = \\lambda _2x_2Ax1​=λ1​x1​Ax2​=λ2​x2​ x2TAx1=λ1x2Tx1⇒(Ax2)Tx1=λ1x2Tx1x_2^TA x_1 = \\lambda _1 x_2^Tx_1 \\Rightarrow (Ax_2)^Tx_1 = \\lambda _1 x_2^Tx_1x2T​Ax1​=λ1​x2T​x1​⇒(Ax2​)Tx1​=λ1​x2T​x1​ λ2x2Tx1=λ1x2Tx1\\lambda _2 x_2^T x_1 = \\lambda _1 x_2^T x_1λ2​x2T​x1​=λ1​x2T​x1​ (λ1−λ2)x2Tx1=0⇒x2Tx1=0(\\lambda _1 - \\lambda_2) x_2^T x_1 = 0 \\Rightarrow x_2^T x_1 = 0(λ1​−λ2​)x2T​x1​=0⇒x2T​x1​=0 投影矩阵的特征值为0和1。 PPP是到子空间V⊂RnV \\subset R^nV⊂Rn的投影矩阵，其中p=Pb,b∈Vp = Pb ,b \\in Vp=Pb,b∈V 若b∈Vb\\in Vb∈V，则Pb=bPb = bPb=b 若b⊥Vb \\perp Vb⊥V，则Pb=0Pb = 0Pb=0 反射矩阵R=I−2uuTR = I - 2uu^TR=I−2uuT的特征值是1和-1。 若v⊥uv \\perp uv⊥u，则Rv=vRv = vRv=v 若v//uv // uv//u，则Rv=−vRv = -vRv=−v 上（下）三角矩阵的特征值为所有的对角元。 Markov矩阵A一定有特征值1（且为最大特征值）。 由于Markov矩阵的列项之和为1，那么每一列减去1，列项之和就变成0，一次你各行之间线性相关。即 (A−I)T(11...1)=0(A - I)^T\\begin{pmatrix}1 \\\\\\\\ 1\\\\\\\\ ...\\\\\\\\1 \\end{pmatrix} = 0(A−I)T⎝⎜⎜⎜⎜⎜⎜⎜⎜⎛​11...1​⎠⎟⎟⎟⎟⎟⎟⎟⎟⎞​=0 因此λ=1\\lambda = 1λ=1。 由代数学基本定理，任何复系数一元n次多项式方程在复数域上至少有一根(n≥1)，由此推出，n次复系数多项式方程在复数域内有且只有n个根（重根按重数计算），并且，虚根一定成对出现。 若λ\\lambda λ是矩阵AAA的特征值，则λ2\\lambda ^2λ2是A2A^2A2的特征值，λ+m\\lambda + m λ+m是A+mIA + mIA+mI的特征值。 设p(x)p(x)p(x)是关于xxx的多项式函数，则p(λ)p(\\lambda)p(λ)是矩阵p(A)p(A)p(A)的一个特征值。 若AAA可逆，则1λ\\frac{1}{\\lambda}λ1​为A−1A^{-1}A−1的一个特征值。 Ax=λx⇒x=A−1Ax=A−1λx=λA−1xAx = \\lambda x \\Rightarrow x = A^{-1}Ax = A^{-1}\\lambda x = \\lambda A^{-1}xAx=λx⇒x=A−1Ax=A−1λx=λA−1x A−1x=1λxA^{-1}x = \\frac{1}{\\lambda} xA−1x=λ1​x 设nnn阶矩阵A=(aij)A = (a_{ij})A=(aij​)有nnn个特征值，可能重复，则 λ1+...+λn=a11+a22+...+ann=trA\\lambda _1 + ...+ \\lambda_n = a_{11} + a_{22} + ... + a{nn} = tr Aλ1​+...+λn​=a11​+a22​+...+ann=trA λ1...λn=det(A)\\lambda_1 ...\\lambda_n = det(A)λ1​...λn​=det(A) 矩阵互异特征值对应的特征向量线性无关。 当AAA的所有特征值均小于1时，E−AE-AE−A可逆。 参考资料 马尔科夫矩阵 矩阵的特征值和特征向量 行列式的本质 "},"diagonalize.html":{"url":"diagonalize.html","title":"矩阵的对角化","keywords":"","body":" 本文主要讲矩阵对角化的证明及应用。 矩阵对角化条件 定义一：若存在可逆矩阵SSS，使得S−1ASS^{-1}ASS−1AS为对角矩阵，则称为矩阵AAA是可对角化的（diagonalized）。 设n×nn\\times nn×n矩阵有nnn个线性无关的特征向量x1,...,xnx_1,...,x_nx1​,...,xn​，令S=(x1,...,xn)S =(x_1,...,x_n)S=(x1​,...,xn​)，则： AS=A(x1,...,xn)=(λ1x1,...,λnxn)=(x1,...,xn)(λ1...λn)AS = A(x_1,...,x_n) = (\\lambda _1 x_1,...,\\lambda_n x_n ) = (x_1,...,x_n)\\begin{pmatrix}\\lambda_1 & & \\\\\\\\ & ... & \\\\\\\\ & & \\lambda_n\\end{pmatrix}AS=A(x1​,...,xn​)=(λ1​x1​,...,λn​xn​)=(x1​,...,xn​)⎝⎜⎜⎜⎜⎛​λ1​​...​λn​​⎠⎟⎟⎟⎟⎞​ AS=SΛ⇒S−1AS=ΛAS = S\\Lambda \\Rightarrow S^{-1}AS = \\LambdaAS=SΛ⇒S−1AS=Λ A 定义二：n×nn \\times nn×n矩阵AAA可对角化的充要条件是AAA有nnn个线性无关的特征向量。 那么什么样的方阵有线性无关的特征向量呢？ 定义三：λ1,..,λn\\lambda_1,..,\\lambda_nλ1​,..,λn​是矩阵AAA的互异特征值，x1,...,xnx_1,...,x_nx1​,...,xn​是相应的特征向量，则x1,...,xnx_1,...,x_nx1​,...,xn​线性无关。 可利用vandermonde行列式证明 可用反证法证明 同一个特征值对应的特征向量不一定都线性无关。 定义四：若n×nn\\times nn×n矩阵有nnn个互异的特征值，则矩阵可以对角化。 但若矩阵有相同的特征值，也可能可以对角化。 思考 矩阵可对角化和矩阵可逆有什么关系吗？ 没有明显关系。 若矩阵可对角化，不一定可逆。 例如，全一矩阵（实对称矩阵）可对角化，但不可逆。因为特征值为0在可对角化中是允许的。 若矩阵可逆，不一定可对角化。 例如，将单位矩阵的任意非零元变为1，则依然可逆，但不可对角化。 若nnn阶矩阵AAA与BBB相似，则AAA与BBB特征多项式相同。 相似矩阵特征值相同。 相似矩阵行列式相同。 具有相同的可逆性。 几何重数与代数重数 定义：设det(A−λI)=(λ1−λ)n1...(λk−λ)nkdet(A - \\lambda I) = (\\lambda_1 - \\lambda)^{n_1} ... (\\lambda_k - \\lambda)^{n_k}det(A−λI)=(λ1​−λ)n1​...(λk​−λ)nk​，称nin_ini​为特征值λi\\lambda _iλi​的代数重数（algebraic multiplicity），记做AM(λi)=niAM(\\lambda_i) = n_iAM(λi​)=ni​，称dimN(A−λiI)dimN(A-\\lambda_iI)dimN(A−λi​I)为特征值λi\\lambda _iλi​的几何重数（geometric multiplicity），记做GM(λi)=dimN(A−λ+iI)GM(\\lambda_i) = dimN(A-\\lambda+i I)GM(λi​)=dimN(A−λ+iI)。 从直观上看，代数重数就是对应的特征值的次数，几何重数是特征向量的维数，探究的就是特征值和特征向量之间的关系。 任意复方阵相似于上三角阵，且对角元为上三角矩阵的特征值。 GM(λ)≤AM(λ)\\boldsymbol {GM(\\lambda) \\le AM(\\lambda)}GM(λ)≤AM(λ) 由定理2，AAA相似于上三角矩阵TTT，则AAA和TTT有相同的特征值，且对于任意特征值λi\\lambda _iλi​，GMA(λi)=GMT(λi)GM_A(\\lambda_i) = GM_T(\\lambda_i)GMA​(λi​)=GMT​(λi​)。 因此，不妨设AAA是上三角阵，即A=(a11...ann)A =\\begin{pmatrix}a_{11} & & \\\\\\\\ & ... & \\\\\\\\ & & a_{nn}\\end{pmatrix} A=⎝⎜⎜⎜⎜⎛​a11​​...​ann​​⎠⎟⎟⎟⎟⎞​。 因此A−λiIA-\\lambda _i IA−λi​I为对角线上对应的特征值为0，但这一行不一定为0（最多矩阵的特征值少1），因此新的矩阵r(A−λiI)≥n−AM(λi)r(A-\\lambda _i I) \\ge n - AM(\\lambda_i)r(A−λi​I)≥n−AM(λi​) 所以GM(λi)=n−r(A−λiI)≤AM(λi)GM(\\lambda_i) = n - r(A - \\lambda_i I) \\le AM(\\lambda_i)GM(λi​)=n−r(A−λi​I)≤AM(λi​)。 若复方阵AAA可对角化⇔\\Leftrightarrow ⇔对任意特征值λi\\lambda_iλi​，GM(λi)=AM(λi)GM(\\lambda_i) = AM(\\lambda_i)GM(λi​)=AM(λi​)。 因为若GM(λi)=AM(λi)GM(\\lambda_i) = AM(\\lambda_i)GM(λi​)=AM(λi​)，则矩阵有nnn个线性无关的特征向量。 矩阵对角化判断 求出矩阵的所有特征值。 对于每个特征值，计算特征向量，并检查r(A−λiI)=n−AM(λi)r(A-\\lambda _i I) = n - AM(\\lambda_i)r(A−λi​I)=n−AM(λi​)是否成立。 若都成立，则计算特征向量（基础解系）。 最后将特征向量与特征值对应起来，就可以写出P−1AP=ΛP^{-1}AP= \\LambdaP−1AP=Λ。 注意：使矩阵对角化的特征向量不是唯一的（可以乘上常数倍）。 矩阵对角化的应用 可快速计算AkA^kAk。 可计算Markov过程中的平稳分布π\\piπ。 可得到方程：πP=ππ1=1\\pi P = \\pi \\quad \\pi 1 = 1πP=ππ1=1。 计算Fibonacci数列。 差分方程uk+1=Auku_{k+1} = Au_{k}uk+1​=Auk​描述的离散动力系统的长期行为 设AAA可对角化，即存在可逆矩阵S=(x1,...,xn)S=(x_1,...,x_n)S=(x1​,...,xn​)，使得S−1AS=ΛS^{-1 }A S = \\LambdaS−1AS=Λ 设S−1u0=(c1,...,cn)TS^{-1} u_0 = (c_1,...,c_n)^TS−1u0​=(c1​,...,cn​)T,即u0=c1x1+...+cnxnu_0 = c_1x_1 + ... +c_nx_nu0​=c1​x1​+...+cn​xn​。 uk=Aku0=SΛkS−1u0=c1λ1kx1+...+cnλnkxnu_k = A^ku_0 = S\\Lambda ^kS^{-1}u_0 = c_1\\lambda_1^kx_1 + ... + c_n\\lambda_n^kx_nuk​=Aku0​=SΛkS−1u0​=c1​λ1k​x1​+...+cn​λnk​xn​ 可以看出，uku_kuk​的增长因子λik\\lambda_i^kλik​支配，因此系统的稳定性依赖于AAA的特征值。 当所有特征值∣λi∣1|\\lambda_i|∣λi​∣1时，是稳定的； 当所有特征值∣λi∣≤1|\\lambda_i|\\le1∣λi​∣≤1时，是中性稳定的； 当至少有一个特征值∣λi∣>1|\\lambda_i|>1∣λi​∣>1时，是不稳定的； 同时对角化 定理：若AAA、BBB有相同的特征向量矩阵PPP，使得P−1AP=Λ1,P−1BP=Λ2P^{-1}AP= \\Lambda_1,P^{-1}BP= \\Lambda _2P−1AP=Λ1​,P−1BP=Λ2​，则AB=BAAB = BAAB=BA。 逆命题也成立：若AAA、BBB都可对角化，并且AB=BAAB = BAAB=BA，则AAA、BBB可同时对角化。 "},"application.html":{"url":"application.html","title":"对角矩阵在微分方程中的应用","keywords":"","body":" 本节将矩阵的特征值与微分方程联系在一起，从另一个角度更好地了解特征值。 在差分方程中的应用 首先回顾由差分方程uk+1=Au]ku_{k+1} = Au]_{k}uk+1​=Au]k​描述的离散动力系统的长期行为，即k⇒∞k\\Rightarrow \\infty k⇒∞时解的性质。 设AAA可对角化，即存在可逆矩阵S=(x1,...,xn)S=(x_1,...,x_n)S=(x1​,...,xn​)，使得S−1AS=ΛS^{-1 }A S = \\LambdaS−1AS=Λ为对角阵。 设S−1u0=(c1,...,cn)TS^{-1} u_0 = (c_1,...,c_n)^TS−1u0​=(c1​,...,cn​)T,即u0=c1x1+...+cnxnu_0 = c_1x_1 + ... +c_nx_nu0​=c1​x1​+...+cn​xn​。 uk=Aku0=SΛkS−1u0=c1λ1kx1+...+cnλnkxnu_k = A^ku_0 = S\\Lambda ^kS^{-1}u_0 = c_1\\lambda_1^kx_1 + ... + c_n\\lambda_n^kx_nuk​=Aku0​=SΛkS−1u0​=c1​λ1k​x1​+...+cn​λnk​xn​ 可以看出，uku_kuk​的增长因子λik\\lambda_i^kλik​支配，因此系统的稳定性依赖于AAA的特征值。 当所有特征值∣λi∣1|\\lambda_i|∣λi​∣1时，是稳定的； 当所有特征值∣λi∣≤1|\\lambda_i|\\le1∣λi​∣≤1时，是中性稳定的； 当至少有一个特征值∣λi∣>1|\\lambda_i|>1∣λi​∣>1时，是不稳定的； 因此，Markov过程是中性稳定的，Fibonacci数列是不稳定的。 引言 设关于t的向量值可导函数u=u(t)=(u1(t)....un(t))u = u(t) = \\begin{pmatrix}u_1(t) \\\\\\\\ .... \\\\\\\\ u_n(t)\\end{pmatrix}u=u(t)=⎝⎜⎜⎜⎜⎛​u1​(t)....un​(t)​⎠⎟⎟⎟⎟⎞​，满足： dudx=Au\\frac{\\mathrm{d} u}{\\mathrm{d} x} = Audxdu​=Au 其中A=(aij)A = (a_{ij})A=(aij​)为nnn阶常数矩阵，求解u=u(t)u = u(t)u=u(t) 若A=(λ1...λn)A =\\begin{pmatrix}\\lambda_1 & & \\\\\\\\ & ... & \\\\\\\\ & & \\lambda_n\\end{pmatrix} A=⎝⎜⎜⎜⎜⎛​λ1​​...​λn​​⎠⎟⎟⎟⎟⎞​为对角阵， 则duidx=λiui\\frac{\\mathrm{d} u_i}{\\mathrm{d} x} = \\lambda_i u_idxdui​​=λi​ui​ 因此可解得u=u(t)=(eλ1tc1...eλntcn)u = u(t) = \\begin{pmatrix}e^{\\lambda_1t}c_1\\\\\\\\... \\\\\\\\ e^{\\lambda_nt}c_n\\end{pmatrix}u=u(t)=⎝⎜⎜⎜⎜⎛​eλ1​tc1​...eλn​tcn​​⎠⎟⎟⎟⎟⎞​ 由于每个方程都是独立的，这类方程被称为解耦的（uncoupled） 那么对于一般的矩阵AAA，如何求解呢？ 可以将非解耦方程转化为解耦方程求解 AAA可对角化情形 设dudt=Au\\frac{\\mathrm{d} u}{\\mathrm{d} t} = Audtdu​=Au有形如eλtxe^{\\lambda t}xeλtx的解（为什么要这样假设？），其中λ\\lambdaλ为数，xxx为向量，则： Ax=λxAx = \\lambda xAx=λx 因此，AAA的每个特征值λ\\lambdaλ及特征向量xxx都会给出dudt=Au\\frac{\\mathrm{d} u}{\\mathrm{d} t} = Audtdu​=Au的一个解u=λtxu = ^{\\lambda t}xu=λtx。 因此，求解步骤为： dudt=Au=SΛS−1u\\frac{\\mathrm{d} u}{\\mathrm{d} t} = Au = S\\Lambda S^{-1}udtdu​=Au=SΛS−1u d(S−1u)dt=Λ(S−1u)\\frac{\\mathrm{d} (S^{-1}u)}{\\mathrm{d} t} =\\Lambda (S^{-1}u)dtd(S−1u)​=Λ(S−1u) S−1u=(eλ1tc1...eλntcn)S^{-1}u = \\begin{pmatrix}e^{\\lambda_1t}c_1\\\\\\\\ ...\\\\\\\\ e^{\\lambda_nt}c_n\\end{pmatrix}S−1u=⎝⎜⎜⎜⎜⎛​eλ1​tc1​...eλn​tcn​​⎠⎟⎟⎟⎟⎞​ u(t)=c1eλ1tx1+...+cneλntxn,u(0)=c1x1+...+cnxnu(t) = c_1e^{\\lambda_1t}x_1 + ... + c_ne^{\\lambda_n t}x_n, u(0) = c_1x_1+...+c_nx_nu(t)=c1​eλ1​tx1​+...+cn​eλn​txn​,u(0)=c1​x1​+...+cn​xn​ 这样，其实我们就使用对角化将非解耦的方程转化为解耦方程，方便求解。 设u=u1(t)u = u_1(t)u=u1​(t)和u=u2(t)u = u_2(t)u=u2​(t)是齐次线性微分方程组dudt=Au\\frac{\\mathrm{d} u}{\\mathrm{d} t} = Audtdu​=Au的解，则他们的线性组合u=c1u1(t)+c2u2(t)u = c_1u_1(t) + c_2u_2(t)u=c1​u1​(t)+c2​u2​(t)也是此方程组的解，其中c1c_1c1​和c2c_2c2​是任意常数。 dudt=An×nu\\frac{\\mathrm{d} u}{\\mathrm{d} t} = A_{n\\times n}udtdu​=An×n​u的解集是一个nnn维向量空间。 若AAA可对角化，则方程组的通解为u(t)=c1eλ1tx1+...+cneλntxnu(t) = c_1e^{\\lambda_1 t}x_1 + ... +c_ne^{\\lambda_n t}x_nu(t)=c1​eλ1​tx1​+...+cn​eλn​txn​ AAA不可对角化时 若AAA不可对角化，设GM(λ)AM(λ)GM(\\lambda ) GM(λ)AM(λ)。若有相同n个λ\\lambdaλ，只有一个特征向量，则这个特征值对应的解为：c1eλtx+....+cntn−1eλtxc_1e^{\\lambda t} x + ....+c_nt^{n-1}e^{\\lambda t}xc1​eλtx+....+cn​tn−1eλtx。 矩阵的指数函数 回顾ex=1+x+x22!+...+xnn!+...e^x = 1+x+\\frac{x^2}{2!}+...+\\frac{x^n}{n!}+...ex=1+x+2!x2​+...+n!xn​+... 因此可使用eAxe^{Ax}eAx带入，可得： d(eAt)dt=AeAt\\frac{\\mathrm{d} (e^{At})}{\\mathrm{d} t} = Ae^{At}dtd(eAt)​=AeAt 而我们需要求的微分方程组dudt=Au\\frac{\\mathrm{d} u}{\\mathrm{d} t} = Audtdu​=Au，因此u(t)=eAtu(0)u(t) = e^{At}u(0)u(t)=eAtu(0)。 矩阵的指数函数性质： 若Λ=(λ1...λn)\\Lambda = \\begin{pmatrix}\\lambda_1 & & \\\\\\\\ & ... & \\\\\\\\ & & \\lambda_n\\end{pmatrix}Λ=⎝⎜⎜⎜⎜⎛​λ1​​...​λn​​⎠⎟⎟⎟⎟⎞​, 则eΛt=(eλ1t...eλnt)e^{\\Lambda t}= \\begin{pmatrix}e^{\\lambda_1t} & & \\\\\\\\& ...& \\\\\\\\ & & e^{\\lambda_n t}\\end{pmatrix}eΛt=⎝⎜⎜⎜⎜⎛​eλ1​t​...​eλn​t​⎠⎟⎟⎟⎟⎞​ 若AB=BAAB= BAAB=BA，则eA+B=eA⋅eBe^{A+B} = e^A \\cdot e^BeA+B=eA⋅eB，特别的，(eA)−1=e−A(e^A)^{-1} = e^{-A}(eA)−1=e−A。 若存在可逆矩阵PPP,使得A=PBP−1A = PBP^{-1}A=PBP−1，则eAt=PeBtP−1e^{At} = P e ^{Bt} P^{-1}eAt=PeBtP−1。 因此，若AAA可对角化，由定理一可知： u(t)=eAtu(0)=SeΛtS−1u(0)=(x1,...,xn)(eλ1t...eλnt)(c1...cn)u(t) = e^{At}u(0) = Se^{\\Lambda t} S^{-1} u(0) = (x_1,...,x_n)\\begin{pmatrix}e^{\\lambda_1t} & & \\\\\\\\ & ...& \\\\\\\\ & & e^{\\lambda_n t}\\end{pmatrix}\\begin{pmatrix}c_1\\\\\\\\... \\\\\\\\ c_n\\end{pmatrix}u(t)=eAtu(0)=SeΛtS−1u(0)=(x1​,...,xn​)⎝⎜⎜⎜⎜⎛​eλ1​t​...​eλn​t​⎠⎟⎟⎟⎟⎞​⎝⎜⎜⎜⎜⎛​c1​...cn​​⎠⎟⎟⎟⎟⎞​ =c1eλ1tx1+...+cneλntxn = c_1e^{\\lambda_1t}x_1 + ... + c_ne^{\\lambda_n t}x_n=c1​eλ1​tx1​+...+cn​eλn​txn​ AAA二阶常系数线性微分方程 假设eλte^{\\lambda t}eλt是方程的解，则可以得特征方程， 若λ1,λ2\\lambda_1,\\lambda_2λ1​,λ2​为实数，则方程的通解为： y=c1eλ1t+c2eλ2ty = c_1 e^{\\lambda_1 t} + c_2e^{\\lambda_2 t}y=c1​eλ1​t+c2​eλ2​t 若λ1,λ2\\lambda_1,\\lambda_2λ1​,λ2​为共轭负数，即λ1=α+iβ,λ2=α−iβ\\lambda_1 = \\alpha + i\\beta,\\lambda_2 = \\alpha - i \\betaλ1​=α+iβ,λ2​=α−iβ，则方程的通解为： y=eαt(c1cosβt+c2sinβt)y = e^{\\alpha t}(c_1cos\\beta t + c_2 sin\\beta t)y=eαt(c1​cosβt+c2​sinβt) 也可以使用矩阵表示为dudx=Au\\frac{\\mathrm{d} u}{\\mathrm{d} x} = Audxdu​=Au。 若AAA有相同特征值，则不能对角化（为什么？），可使用第一种方法，但要注意，若有nnn重根，则解为t0eλt,....,tn−1eλtt^0e^{\\lambda t},....,t^{n-1}e^{\\lambda t}t0eλt,....,tn−1eλt。 微分方程的稳定性 我们知道若AAA可对角化，则dudx=Au\\frac{\\mathrm{d} u}{\\mathrm{d} x} = Audxdu​=Au有通解： u(t)=c1eλ1tx1+...+cneλntxnu(t) = c_1e^{\\lambda_1t}x_1 + ... + c_ne^{\\lambda_n t}x_nu(t)=c1​eλ1​tx1​+...+cn​eλn​txn​ 若所有的实数λi0\\lambda_i λi​0，则解是稳定的； 若所有的实数λi≤0\\lambda_i \\le 0λi​≤0，则解是中性稳定的； 若至少有一个的实数特征值λi0\\lambda_i λi​0，则解是不稳定的 "},"symmetric matrices.html":{"url":"symmetric matrices.html","title":"实对称矩阵","keywords":"","body":"定理 实对称矩阵的特征值都是实数。 ∵xˉTAx=λxˉTx=xˉTAˉTx=(Ax)ˉTx=λˉxˉTx\\because \\bar x^T Ax = \\lambda \\bar x^T x = \\bar x^T \\bar A^T x = \\bar {(Ax)}^T x = \\bar \\lambda \\bar x^T x∵xˉTAx=λxˉTx=xˉTAˉTx=(Ax)ˉ​Tx=λˉxˉTx ∴(λ−λˉ)xˉTx=0\\therefore (\\lambda - \\bar \\lambda )\\bar x^T x = 0∴(λ−λˉ)xˉTx=0 实对称矩阵的属于不同特征值的特征向量相互正交。 ∵yTAx=λyTx=yTATx=(Ay)Tx=uyTx\\because y^T Ax = \\lambda y^T x = y^T A^T x = (Ay )^T x = uy^Tx∵yTAx=λyTx=yTATx=(Ay)Tx=uyTx ∴(λ−u)yTx=0\\therefore (\\lambda - u) y^T x = 0∴(λ−u)yTx=0 任何实对称矩阵正交相似于对角阵，即存在正交阵QQQ，使得QTAQQ^TAQQTAQ为对角阵。 因此，我们求一个实对称矩阵的特征值和特征向量，并将同一个特征值的多个特征向量进行正交化，对所有特征向量进行单位化，就得到了正交阵QQQ。 谱分解： A=QΛQT=(q1,...,qn)(λ1...λn)(q1T...qnT)A = Q \\Lambda Q^T = (q_1, ...,q_n)\\begin{pmatrix}\\lambda_1 & & \\\\\\\\ &... &\\\\ \\\\ & & \\lambda_n\\end{pmatrix}\\begin{pmatrix}q_1^T\\\\\\\\... \\\\\\\\ q_n^T\\end{pmatrix}A=QΛQT=(q1​,...,qn​)⎝⎜⎜⎜⎜⎛​λ1​​...​λn​​⎠⎟⎟⎟⎟⎞​⎝⎜⎜⎜⎜⎛​q1T​...qnT​​⎠⎟⎟⎟⎟⎞​ ∴A=λ1q1q1T+...+λnqnqnT\\therefore A = \\lambda_1 q_1 q_1^T + ... + \\lambda_n q_n q_n^T∴A=λ1​q1​q1T​+...+λn​qn​qnT​ 注意：Pj=qjqjTP_j = q_jq_j^TPj​=qj​qjT​为投影矩阵，因此，任意实对称矩阵可以表示为秩为1 的投影矩阵的和。 Schur定理：任意一个复方阵AAA酉相似与上三角阵，即存在酉矩阵U(UˉTU=UUˉT=I)U(\\bar U^T U = U \\bar U^T = I)U(UˉTU=UUˉT=I)，使得UˉTAU=T\\bar U^T AU = TUˉTAU=T为上三角阵。（酉矩阵类似于实数域中的正交阵） 其他结论 设AAA是nnn阶实对称矩阵，λ1,...,λn\\lambda_1,...,\\lambda_nλ1​,...,λn​为AAA的全部特征值，则存在实数c>0c > 0c>0满足对于任意的x,∣xTAx∣≤cxTxx,|x^TAx| \\le cx^Txx,∣xTAx∣≤cxTx。 设λmax\\lambda_{max}λmax​是实对称矩阵AAA的最大特征值，则AAA的对角线元素aii≤λmaxa_{ii} \\le \\lambda_{max}aii​≤λmax​。 实对称矩阵的正特征值数与主元数相同（也就是说，其特征值符号个数与主元符号个数一致）。 "},"positive definite matrix.html":{"url":"positive definite matrix.html","title":"正定矩阵理解及推导","keywords":"","body":"引言 定义：特征值全是正数的实对称矩阵为正定矩阵（positive definite matrix）。 类似的，若实对称矩阵的特征值均非负，则为半正定矩阵（positive semidefinite matrix）。 可能用到的概念 主子式 定义：在nnn阶行列式中任选kkk行，再取相应的kkk列，将行列交汇处元素组成新的矩阵行列式，称为nnn阶行列式的一个kkk阶主子式。 顺序主子式（the k-th leading principal minor） 定义：在nnn阶行列式中由第1,...,k1,...,k1,...,k行和第1,...,k1,...,k1,...,k列所确定的主子式称为kkk阶顺序主子式。直观上看就是矩阵中左上方的子矩阵。 实对称矩阵AAA正定的充要条件 注意，这里的所有进行判别的矩阵都是实对称矩阵。 以下条件都是判别实对称矩阵是否正定的充要条件。 AAA的所有特征值λi\\lambda_iλi​均为正。 xTAx>0x^TAx > 0xTAx>0对所有非零向量xxx都成立。 AAA的所有顺序主子式都是正的。 AAA的所有主元（无行交换）都是正的。 存在列满秩矩阵RRR，使得A=RTRA=R^TRA=RTR. AAA的所有主子式都是正的。 证明 (1) => (2) 对实对称矩阵AAA，存在正交阵QQQ，使得A=QΛQRA=Q\\Lambda Q^RA=QΛQR。 因此，对任意非零向量xxx： xTAx=xTQΛQTx=yTΛy=λ1y12+...+λnyn2>0x^TAx = x^TQ\\Lambda Q^Tx = y^T\\Lambda y=\\lambda_1y_1^2 + ... + \\lambda_ny_n^2 > 0xTAx=xTQΛQTx=yTΛy=λ1​y12​+...+λn​yn2​>0 其中y=QTx=(y1,...,yn)≠0y = Q^Tx = (y_1,...,y_n) \\ne 0y=QTx=(y1​,...,yn​)≠0 (2) => (1) 因为AAA为实对称矩阵，因此一定可以对角化A=QλQTA = Q\\lambda Q^TA=QλQT ∵xTAx>0∴xTQΛQTx>0\\because x^TAx > 0 \\quad \\therefore x^TQ\\Lambda Q^Tx > 0∵xTAx>0∴xTQΛQTx>0 令y=QTxy = Q^Txy=QTx，因此yΛyT>0⇒∑λiyi2=0y\\Lambda y^T > 0\\Rightarrow \\sum \\lambda_iy_i^2 = 0yΛyT>0⇒∑λi​yi2​=0 ∵∀y≠0s.t∑λiyi2=0\\because \\forall y \\ne 0 \\quad s.t \\quad \\sum \\lambda_iy_i^2 = 0∵∀y≠0s.t∑λi​yi2​=0 λi=0\\lambda_i = 0λi​=0 (2) => (3) 由(2) => (1) => det(A)=λ1...λn>0det(A) = \\lambda_1 ...\\lambda_n > 0det(A)=λ1​...λn​>0 xTAx=(xkT0)(Ak∗∗∗)(xk0)=xkTAxk>0x^TAx = \\begin{pmatrix}x_k^T & 0\\end{pmatrix}\\begin{pmatrix}A_k &* \\\\\\\\ * & *\\end{pmatrix} \\begin{pmatrix}x_k\\\\\\\\0 \\end{pmatrix} = x^T_k A x_k > 0 xTAx=(xkT​​0​)⎝⎛​Ak​∗​∗∗​⎠⎞​⎝⎛​xk​0​⎠⎞​=xkT​Axk​>0 ∴det(xkT)det(Ak)det(kk)=det(Ak)>0\\therefore det (x_k^T)det(A_k)det(k_k) = det(A_k) > 0∴det(xkT​)det(Ak​)det(kk​)=det(Ak​)>0 (3) => (4) 顺序主子式与主元有直接关系，第kkk个主元： dk=det(Ak)detAk(k−1)>0d_k = \\frac{det(A_k)}{detA_k(k-1)} > 0dk​=detAk​(k−1)det(Ak​)​>0 其中AkA_kAk​是第kkk个顺序主子矩阵（the k-th leading principal submatrix)。 (4) => (2) 由对称矩阵的Gauss消元法得LDU分解：A=LDLTA = LDL^TA=LDLT，其中对角阵的对角元为AAA的主元： D=diag(d1,...,dn)D = diag (d_1,...,d_n)D=diag(d1​,...,dn​) 则对任意非零向量： xTAx=xTLDLTx=yTDy=d1y12+...+dnyn2>0x^TAx = x^TLDL^Tx = y^TDy = d_1y_1^2 + ...+ d_ny_n^2> 0xTAx=xTLDLTx=yTDy=d1​y12​+...+dn​yn2​>0 (2) => (5) A=LDLT=LDDLT=(DLT)T(DLT)=RTRA = LDL^T = L\\sqrt {D} \\sqrt {D} L^T = ( \\sqrt {D} L^T)^T ( \\sqrt {D} L^T) = R^TRA=LDLT=LD​D​LT=(D​LT)T(D​LT)=RTR (5) => (2) 设A=RTRA = R^TRA=RTR，则对任意非零向量xxx: xTAx=xTRTRx=(Rx)T(Rx)=∣∣Rx∣∣2>0x^TAx = x^TR^TRx = (Rx )^T(Rx) = ||Rx||^2 > 0xTAx=xTRTRx=(Rx)T(Rx)=∣∣Rx∣∣2>0 (6) => (2) (6) => (3) => (2) (2) => (6) 对kkk阶主子矩阵Ai1,...,ikA_{i1,...,ik}Ai1,...,ik​，任取x=(x1,...,xn)≠0x = (x_1,...,x_n) \\ne 0x=(x1​,...,xn​)≠0，使其除xi1,...,xikx_{i1},...,x_{ik}xi1​,...,xik​的其余分量全为0，则 xTAx=(xi1,...,xik)Ai1,...ik(xi1...xik)>0x^TAx = (x_{i1},...,x_{ik})A_{i1,...ik}\\begin{pmatrix}x_{i1}\\\\\\\\... \\\\\\\\ x_{i_k}\\end{pmatrix} > 0xTAx=(xi1​,...,xik​)Ai1,...ik​⎝⎜⎜⎜⎜⎛​xi1​...xik​​​⎠⎟⎟⎟⎟⎞​>0 ∴det(Ai1,...ik)>0\\therefore det (A_{i1,...ik}) > 0∴det(Ai1,...ik​)>0 判断 因此，我们可以用以上充要条件来判断矩阵是否正定。常用的判断方法有： 看顺序主子式是否都大于0 Gauss消元后主元是否都大于0 看特征值是否都大于0 找任意一个向量计算xTAxx^TAxxTAx是否大于0 找A=LDLTA = LDL^TA=LDLT分解，看R=DLTR = \\sqrt {D} L^TR=D​LT是否满秩 正定矩阵的常见性质 正定矩阵一定可逆。（行列式大于0） 设A,BA,BA,B为正定矩阵，则A+BA+BA+B也为正定矩阵。 设AAA为正定矩阵，则存在矩阵C，使得A=C2A = C^2A=C2。 证明：AAA为正定矩阵，则存在正交矩阵QQQ，使得: A=QΛQT=(QΛQT)(QΛQT)=C2A = Q\\Lambda Q^T = (Q\\sqrt{\\Lambda}Q^T) (Q\\sqrt{\\Lambda}Q^T) = C^2A=QΛQT=(QΛ​QT)(QΛ​QT)=C2 设AAA为正定矩阵，则矩阵A2A^2A2和A−1A^{-1}A−1也正定。 设AAA为正定矩阵，矩阵CCC可逆，则B=CTACB = C^TACB=CTAC也正定。 半正定矩阵 充要条件 AAA的所有特征值λi\\lambda_iλi​均非负。 xTAx≥0x^TAx \\ge 0xTAx≥0对所有向量XXX成立。 存在矩阵RRR，使得A=RTRA =R^TRA=RTR（RRR可能不是可逆阵）。 AAA的所有主子式均非负。（注意，不是所有顺序主子式） "},"quadratic form.html":{"url":"quadratic form.html","title":"二次型与函数极值","keywords":"","body":" 这一节我们将看见，如何将数值函数用矩阵表示，并使用正定矩阵来指示函数的极值。 二次型 定义：对nnn维实向量xxx及nnn阶实对称矩阵AAA，称以下数值函数为一个实二次型（quadratic form），为一个二次齐次多项式。 f(x)=xTAx=∑i=1n∑j=1naijxixjf(x) = x^TAx = \\sum\\limits_{i =1}^n \\sum\\limits_{j =1}^na_{ij}x_ix_jf(x)=xTAx=i=1∑n​j=1∑n​aij​xi​xj​ 对nnn维复向量xxx以及nnn阶复矩阵AAA且A=AˉT(Hermitian)A = \\bar A^T(Hermitian)A=AˉT(Hermitian)，则称f(x)=xˉTAxf(x ) = \\bar x^T Axf(x)=xˉTAx为复二次型。 若nnn阶矩阵DDD为对角阵，则称二次型为对角型的： f(x)=xTDx=∑i=1ndiixi2f(x) = x^TDx = \\sum\\limits_{i =1}^n d_{ii}x_i^2f(x)=xTDx=i=1∑n​dii​xi2​ 任何二次型总可以经过坐标变换x=Qyx = Qyx=Qy变为对角型的，这是因为对实对称矩阵AAA，总存在正交阵QQQ，使得QTAQ=Λ=diag(λ1,...,λn)Q^TAQ = \\Lambda = diag(\\lambda_1,...,\\lambda_n)QTAQ=Λ=diag(λ1​,...,λn​)。 ∴f(x)=xTQΛQTx=yTΛy=∑i=1nλiyi2\\therefore f(x) = x^TQ\\Lambda Q^Tx = y^T\\Lambda y = \\sum\\limits _{i=1}^n\\lambda_iy_i^2∴f(x)=xTQΛQTx=yTΛy=i=1∑n​λi​yi2​ 二次型的分类 一个二次型f(x)=xTAxf(x) = x^TAxf(x)=xTAx是： 正定的，若对所有x≠0x \\ne 0x≠0，有f(x)>0f(x) > 0f(x)>0; 负定的，若对所有x≠0x \\ne 0x≠0，有f(x)0f(x) f(x)0; 不定的，若f(x)f(x)f(x)既有正值，也有负值; 半正定的，若对所有x≠0x \\ne 0x≠0，有f(x)≥0f(x) \\ge 0f(x)≥0; 半负定的，若对所有x≠0x \\ne 0x≠0，有f(x)≤0f(x) \\le 0f(x)≤0; 性质及定理 主轴定理： 设AAA是一个nnn阶实对称矩阵，则存在正交变换x=Qyx = Qyx=Qy，使得二次型变为对角型的二次型： xTAx=yTΛy=∑λiyi2x^TAx = y^T\\Lambda y = \\sum \\lambda_iy_i^2xTAx=yTΛy=∑λi​yi2​ 推论： 若AAA为nnn阶正定矩阵，则xTAx=1x^TAx = 1xTAx=1 表示中心在原点，主轴沿着AAA的特征值方向，半长轴相应为1λ1,...1λn\\frac{1}{\\sqrt{\\lambda_1}},...\\frac{1}{\\sqrt{\\lambda_n}}λ1​​1​,...λn​​1​的椭球面，其中λ1,...λn\\lambda_1,...\\lambda_nλ1​,...λn​为AAA的特征值。 设AAA为nnn阶实对称矩阵，则二次型f(x)=xTAxf(x) = x^TAxf(x)=xTAx是： 正定的 AAA的所有特征值都是正数； 负定的 AAA的所有特征值都是负数； 不定的 AAA的特征值既有负数，也有正数； 矩阵的合同 若两个矩阵A,BA,BA,B，若存在nnn阶可逆矩阵CCC，使得： CTAC=BC^TAC = BCTAC=B 则称矩阵AAA和BBB合同(congruent) 主轴定理可表述为：任何实对称矩阵正交合同与对角阵。 事实上，实对称矩阵不限于正交合同，其他代换（如LDU分解）也可合同与对角阵。 惯性定理： 实对称矩阵AAA与矩阵CTACC^TACCTAC具有相同数目的正特征值，负特征值和零特征值。 在函数极值中的应用 这里不给出证明，当我们使用一阶导为0求得稳定点之后，将函数转化为二次型，可根据二次型的性质判断是极小值还是极大值。 二次型矩阵（Hessian矩阵）： Hessianf(x0,y0)=(∂2f∂x2(x0,y0)∂2f∂x∂y(x0,y0)∂2f∂x∂y(x0,y0)∂2f∂y2(x0,y0))Hessian_f(x_0,y_0) =\\begin{pmatrix}\\frac{\\partial^2 f}{\\partial x^2} (x_0,y_0)&\\frac{\\partial^2 f}{\\partial x\\partial y} (x_0,y_0)\\\\\\\\ \\frac{\\partial^2 f}{\\partial x\\partial y}(x_0,y_0)& \\frac{\\partial^2 f}{\\partial y^2} (x_0,y_0)\\end{pmatrix} Hessianf​(x0​,y0​)=⎝⎜⎛​∂x2∂2f​(x0​,y0​)∂x∂y∂2f​(x0​,y0​)​∂x∂y∂2f​(x0​,y0​)∂y2∂2f​(x0​,y0​)​⎠⎟⎞​ 若二次型负定，则f(x,y)f(x,y) f(x,y)在(x0,y0)(x_0,y_0)(x0​,y0​)达到极大值。 若二次型正定，则f(x,y)f(x,y) f(x,y)在(x0,y0)(x_0,y_0)(x0​,y0​)达到极小值。 若二次型不定，则f(x,y)f(x,y) f(x,y)在(x0,y0)(x_0,y_0)(x0​,y0​)不是极值。 "},"pagerank.html":{"url":"pagerank.html","title":"PageRank问题建模","keywords":"","body":"问题提出 PageRank的核心思想就是： 如果一个网页被很多其他网页链接到的话说明这个网页比较重要，也就是PageRank值会相对较高 如果一个PageRank值很高的网页链接到一个其他的网页，那么被链接到的网页的PageRank值会相应地因此而提高 因此，我们希望计算出每个网站的PR值，通过这个值来反映网站的重要程度，进而对网站排序。 这样，我们就可以对这个问题进行如下建模和猜想： 假设nnn是所有可访问网页的数目，此数值非常大，定义n×nn\\times nn×n为网页链接矩阵G=(gij)∈Rn×nG = (g_{ij})\\in R^{n\\times n}G=(gij​)∈Rn×n，若从网页jjj有一个链接到网页iii，则gij=1g_{ij} = 1gij​=1，否则为0。矩阵GGG有如下特点： GGG是大规模系数矩阵； 第jjj列非零向量的位置表示了从网页jjj链接出去的所有网页； 第iii行非零向量的位置表示了所有链接到网页iii的网页； GGG中非零向量的数目为整个网络中存在的超链接的数目； ri=∑jgijr_i = \\sum _j g_{ij}ri​=∑j​gij​，表示第iii个网站的入度； cj=∑igijc_j = \\sum_i g_ijcj​=∑i​gi​j，表示第jjj个网站的出度； 建模 为了解决这个问题，我们想象一个随机浏览网页的人，当他到达C网页后： 假定他有一定概率点击超链接（ppp）到达另一个网页。即，若网页iii在网页jjj的链接上，概率可以表示为： p⋅1/ci+(1−p)⋅1/np \\cdot 1/c_i + (1 - p) \\cdot 1/np⋅1/ci​+(1−p)⋅1/n 假定他有一个确定的概率会输入网址直接跳转到一个随机的网页，若网页iii不在网页jjj的链接上，概率可以表示为： (1−p)⋅1/n(1-p)\\cdot 1/n(1−p)⋅1/n 由于网页iii是否在网页jjj上由gijg_{ij}gij​决定，因此网页jjj到iii的转移概率为： aij=gij[p⋅1/ci+(1−p)⋅1/n]+(1−gij)[(1−p)⋅1/n]=pgijcj+1−pna_{ij} = g_{ij }[p \\cdot 1/c_i + (1 - p) \\cdot 1/n] + (1 - g_{ij})[(1-p)\\cdot 1/n]= \\frac{pg_{ij}}{c_j} + \\frac {1-p }{n}aij​=gij​[p⋅1/ci​+(1−p)⋅1/n]+(1−gij​)[(1−p)⋅1/n]=cj​pgij​​+n1−p​ 应该注意的是，若Cj=0C_j = 0Cj​=0意味着gij=0g_{ij} = 0gij​=0,则aij=1/na_{ij} = 1/naij​=1/n。任意两个网页之间的转移概率形成了一个转移矩阵AAA，设DDD为各个网页出度的导数构成的nnn阶对角阵，eee是全为1的nnn维向量，则： A=pGD+1−pneeTA = pGD + \\frac {1-p}{n}ee^TA=pGD+n1−p​eeT 设xi(k)x_i^{(k)}xi(k)​表示时刻kkk浏览网页iii的概率，其中∑xi(k)=1\\sum x_i^{(k)} = 1∑xi(k)​=1，那么下一刻浏览到网页iii的概率为∑j=1nxi(k)\\sum _{j = 1}^n x_i^{(k)}∑j=1n​xi(k)​,此时浏览整个网页的概率分布为x(k+1)=Ax(k)x^{(k+1)} = Ax^{(k)} x(k+1)=Ax(k)。 当这个过程无线进行下去，达到极限情况，即网页访问概率x(k)x^{(k)}x(k)收敛到一个极限值，这个极限向量x(k)x^{(k)}x(k)为网页的PageRank，满足Ax=xAx = xAx=x，且∑i=1nxi=1\\sum _{i = 1}^n x_i = 1∑i=1n​xi​=1。 参考资料 PageRank算法--从原理到实现 "},"norm.html":{"url":"norm.html","title":"范数与矩阵条件数","keywords":"","body":"向量范数 对于实向量xxx，下面给出几种常见的范数： 1-范数： ∣∣x∣∣1=∑i=1n∣xi∣||x||_1 = \\sum _{i = 1}^n |x_i|∣∣x∣∣1​=i=1∑n​∣xi​∣ 2-范数： ∣∣x∣∣2=(∑i=1n∣xi∣2)12=(xTx)12||x||_2 = (\\sum _{i = 1}^n |x_i|^2)^{\\frac{1}{2}} = (x^Tx)^{\\frac{1}{2}}∣∣x∣∣2​=(i=1∑n​∣xi​∣2)21​=(xTx)21​ ∞\\infty∞-范数： ∣∣x∣∣∞=max1≤i≤n∣xi∣||x||_{\\infty} = max_{1\\le i \\le n} |x_i|∣∣x∣∣∞​=max1≤i≤n​∣xi​∣ 由此我们可以定义p-范数为： ∣∣x∣∣2=(∑i=1n∣xi∣p)1p,p≥1||x||_2 = (\\sum _{i = 1}^n |x_i|^p)^{\\frac{1}{p}},p\\ge1∣∣x∣∣2​=(i=1∑n​∣xi​∣p)p1​,p≥1 向量范数的等价性 设∣∣x∣∣s||x||_s∣∣x∣∣s​ 和 ∣∣x∣∣t||x||_t∣∣x∣∣t​为RnR^nRn上任意两种向量范数，则存在常量c1,c2>0c_1,c_2 > 0 c1​,c2​>0，使得对一切x∈Rnx \\in R^nx∈Rn有： c1∣∣x∣∣s≤∣∣x∣∣t≤c2∣∣x∣∣sc_1||x||_s \\le ||x||_t \\le c_2 ||x||_sc1​∣∣x∣∣s​≤∣∣x∣∣t​≤c2​∣∣x∣∣s​ 矩阵范数 在以上基础上，实际使用的矩阵范数还满足以下相容性条件： ∀A∈Rn×n,x∈Rn,∣∣Ax∣∣≤∣∣A∣∣ ∣∣x∣∣\\forall A\\in R^{n\\times n},x\\in R^n ,||Ax|| \\le ||A|| \\space||x||∀A∈Rn×n,x∈Rn,∣∣Ax∣∣≤∣∣A∣∣ ∣∣x∣∣ 定义矩阵的算子范数为，这衡量了线性变换中对xxx伸缩的最大倍数。 ∣∣A∣∣v=max⁡x≠0∣∣Ax∣∣v∣∣x∣∣v||A||_v = \\max\\limits_{x\\ne 0} \\frac {||Ax||_v}{||x||_v}∣∣A∣∣v​=x≠0max​∣∣x∣∣v​∣∣Ax∣∣v​​ 我们需要在证明算子范数满足矩阵范数的条件（自己验证） 矩阵AAA的算子范数为: 1-范数： ∣∣A∣∣1=max⁡1≤j≤n∑i=1n∣aij∣||A||_1 = \\max _{1\\le j\\le n}\\sum_{i=1}^n |a_{ij}|∣∣A∣∣1​=1≤j≤nmax​i=1∑n​∣aij​∣ 2-范数： ∣∣A∣∣2=λmax⁡(ATA),表示ATA的最大特征值||A||_2 = \\sqrt{\\lambda_{\\max}(A^TA)}, \\text{表示} A^TA\\text{的最大特征值}∣∣A∣∣2​=λmax​(ATA)​,表示ATA的最大特征值 ∞\\infty∞-范数： ∣∣A∣∣∞=max1≤i≤n∑j=1n∣aij∣||A||_{\\infty} = max_{1\\le i \\le n} \\sum_{j = 1}^n|a_{ij}|∣∣A∣∣∞​=max1≤i≤n​j=1∑n​∣aij​∣ 矩阵条件数 矩阵条件数是衡量非奇异矩阵的敏感程度，也就是方程Ax=bAx = bAx=b中ΔA\\Delta AΔA、Δb\\Delta bΔb的变化对矩阵的影响程度；我们不加证明的说明一下几个定理。 条件数定义： cond=∣∣Δx∣∣/∣∣x∣∣∣∣Δb∣∣/∣∣b∣∣cond = \\frac{||\\Delta x||/||x||}{||\\Delta b||/||b||}cond=∣∣Δb∣∣/∣∣b∣∣∣∣Δx∣∣/∣∣x∣∣​ 设AAA为非奇异矩阵，则矩阵的条件数为： cond(A)v=∣∣A∣∣v∣∣A−1∣∣=max⁡x≠0∣∣Ax∣∣∣∣x∣∣/min⁡x≠0∣∣Ax∣∣∣∣x∣∣cond (A)_v = ||A||_v ||A^{-1}||=\\max\\limits _{x \\ne 0} \\frac{||Ax||}{||x||} / \\min\\limits _{x \\ne 0} \\frac {||Ax||}{||x||}cond(A)v​=∣∣A∣∣v​∣∣A−1∣∣=x≠0max​∣∣x∣∣∣∣Ax∣∣​/x≠0min​∣∣x∣∣∣∣Ax∣∣​ 根据条件数的定义，可以推导其和矩阵条件数的关系（考虑方程右边扰动）： ∵A(x+Δx)=b+Δb\\because A(x +\\Delta x) = b + \\Delta b∵A(x+Δx)=b+Δb AΔx=Δb⇒Δx=A−1Δb⇒∣∣Δx∣∣≤∣∣A−1∣∣ ∣∣Δb∣∣A \\Delta x = \\Delta b \\Rightarrow \\Delta x = A^{-1} \\Delta b \\Rightarrow ||\\Delta x || \\le ||A^{-1} ||\\space ||\\Delta b||AΔx=Δb⇒Δx=A−1Δb⇒∣∣Δx∣∣≤∣∣A−1∣∣ ∣∣Δb∣∣ Ax=b⇒∣∣b∣∣≤∣∣A∣∣ ∣∣x∣∣Ax = b \\Rightarrow ||b || \\le ||A|| \\space ||x||Ax=b⇒∣∣b∣∣≤∣∣A∣∣ ∣∣x∣∣ ∴cond=∣∣Δx∣∣/∣∣x∣∣∣∣Δb∣∣/∣∣b∣∣=∣∣Δx∣∣ ∣∣b∣∣∣∣Δb∣∣ ∣∣x∣∣≤∣∣A−1∣∣ ∣∣Δb∣∣ ∣∣A∣∣ ∣∣x∣∣∣∣Δb∣∣ ∣∣x∣∣=∣∣A∣∣ ∣∣A−1∣∣\\therefore cond = \\frac{||\\Delta x||/||x||}{||\\Delta b||/||b||} = \\frac{||\\Delta x||\\space ||b||}{||\\Delta b||\\space||x||}\\le \\frac{||A^{-1}|| \\space ||\\Delta b|| \\space ||A|| \\space|| x||}{||\\Delta b|| \\space ||x||} = ||A|| \\space ||A^{-1}||∴cond=∣∣Δb∣∣/∣∣b∣∣∣∣Δx∣∣/∣∣x∣∣​=∣∣Δb∣∣ ∣∣x∣∣∣∣Δx∣∣ ∣∣b∣∣​≤∣∣Δb∣∣ ∣∣x∣∣∣∣A−1∣∣ ∣∣Δb∣∣ ∣∣A∣∣ ∣∣x∣∣​=∣∣A∣∣ ∣∣A−1∣∣ 矩阵的条件数为误差传递的上限，可衡量矩阵的敏感性 奇异矩阵的条件数为无穷大，因此cond(A)cond(A)cond(A)越大，越接近于奇异矩阵。 直观的来看，矩阵的条件数反映了矩阵的奇异程度，相对于行列式只能反映是否为奇异矩阵，是一个更好的度量方式。 矩阵的谱半径 设实矩阵A∈Rn×nA\\in R^{n\\times n}A∈Rn×n的特征值为λi\\lambda_iλi​，称ρ\\rhoρ为AAA的谱半径： ρ(A)=max⁡1≤i≤n∣λi∣\\rho (A) = \\max\\limits_{1\\le i\\le n}|\\lambda_i|ρ(A)=1≤i≤nmax​∣λi​∣ 注意，这里的谱半径是指模长（二范数），对于实数来说就是绝对值，对于复数来说是模长。 谱半径的大小不超过任何一种算子范数。 圆盘定理 ∣λ−akk∣≤∑j=1,j≠kn∣akj∣|\\lambda - a_{kk} |\\le \\sum\\limits_{j =1,j \\ne k } ^n |a_{kj}|∣λ−akk​∣≤j=1,j≠k∑n​∣akj​∣ 直观的来看，在平面中，AAA的每个特征值都属于AAA的格什戈林圆盘中 可以用圆盘定理估计矩阵的特征值范围。 幂法 在矩阵AAA的特征值中，模最大的特征值称为主特征值，也叫“第一特征值”。对应的特征向量为主特征向量。 主特征值可能不唯一（正数负数复数）。 这里注意谱半径和主特征值的区别 谱半径是针对实矩阵而言，计算出来的是特征值的模长（一定大于零）； 主特征值是模长最大的那个特征值（对于复数来说不一样） 如果矩阵有唯一主特征值，则能通过幂法计算出主特征值和特征向量。幂法的计算过程是，首先任取一非零向量v0∈Rnv_0 \\in R^nv0​∈Rn，再迭代计算 vk=Avk−1v_k = Av_{k-1}vk​=Avk−1​ 根据vkv_kvk​求出主特征值和特征向量。 lim⁡k→∞vkλ1k=x1\\lim\\limits_{k \\rightarrow \\infty } \\frac {v_k}{\\lambda_1 ^k} = x_1k→∞lim​λ1k​vk​​=x1​ lim⁡k→∞(vk+1)j(vk)j=λ1\\lim\\limits_{k \\rightarrow \\infty } \\frac {(v_{k+1})_ j}{(v_{k})_j } = \\lambda_1k→∞lim​(vk​)j​(vk+1​)j​​=λ1​ 如果模最大的特征值是重根且非亏损(代数重数等于几何重数)的话幂法适用，但是一旦出现亏损就容易出问题。 幻方矩阵的最大特征值为行和，即为n(n2+1)2\\frac {n(n^2+1)}{2}2n(n2+1)​。 "},"svd.html":{"url":"svd.html","title":"SVD分解","keywords":"","body":" 本节在共轭转置的基础上介绍奇异值和奇异值分解，为严格证明过程。 谱分解 共轭转置 矩阵AAA的共轭转置AHA^HAH（又称Hermite共轭、Hermite转置）定义为： AH=(Aˉ)T=ATˉA^H = (\\bar A) ^T = \\bar {A^T}AH=(Aˉ)T=ATˉ 酉矩阵 设U∈Cn×nU \\in C^{n\\times n}U∈Cn×n阶复方阵，若UHU=IU^HU = IUHU=I，则称UUU是酉矩阵。 Hermite矩阵 设A∈Cn×nA\\in C^{n\\times n}A∈Cn×n，如果AH=AA^H = AAH=A，那么AAA为Hermite矩阵； 如果AH=−AA^H = - AAH=−A，则AAA为反Hermite矩阵。 Schur定理 任何一个nnn阶复矩阵都酉相似于一个上三角矩阵，则存在一个nnn阶酉矩阵UUU和一个nnn阶上三角矩阵RRR使得： UHAU=RU^HAU = RUHAU=R 其中RRR的对角元是AAA的特征值。 正规矩阵 设A∈Cn×nA \\in C^{n\\times n}A∈Cn×n，如果： AAH=AHAAA^H = A^HAAAH=AHA 则称AAA为正规矩阵。 可以证明，对角矩阵，Hermite矩阵，反Hermite矩阵，酉矩阵都是正规矩阵。 酉相似条件 nnn阶矩阵AAA酉相似于一个对角矩阵的充分必要条件为AAA是正规矩阵。 因此，若AAA是nnn阶Hermite矩阵，则AAA必酉相似与实对角矩阵，即存在nnn阶酉矩阵UUU使得： UHAU=ΛU^HAU = \\LambdaUHAU=Λ 因为AH=AA^H = AAH=A，则ΛH=Λ\\Lambda ^H = \\LambdaΛH=Λ，因此Λ\\LambdaΛ是实对角矩阵。 谱分解 Hermite的谱分解式 由上文可知，若AAA为Hermite矩阵，则： UHAU=ΛU^HAU = \\LambdaUHAU=Λ 奇异值分解 奇异值定义 设A∈Cn×nA \\in C^{n\\times n}A∈Cn×n，如果存在非负实数σ\\sigmaσ和非零向量u∈Cn,v∈Cmu\\in C^n,v\\in C^mu∈Cn,v∈Cm，使得： Au=σv,AHv=σuAu = \\sigma v , A^H v = \\sigma uAu=σv,AHv=σu 则称σ\\sigmaσ 为AAA的奇异值，uuu和vvv分别称为AAA对应于奇异值σ\\sigmaσ的右奇异向量和左奇异向量。 AHAu=σAHv=σ2uA^H A u = \\sigma A^H v = \\sigma ^2 uAHAu=σAHv=σ2u 因此σ2\\sigma ^2σ2是AHAA^HAAHA的特征值，也是AAHAA^HAAH的特征值，而uuu和vvv分别是AHAA^HAAHA和AAHAA^HAAH对应于σ2\\sigma ^2σ2的特征向量。 引理 设A∈Cm×nA \\in C^{m\\times n}A∈Cm×n，则 rank(AHA)=rank(AAH)=rank(A)rank(A^HA) = rank(AA^H ) = rank(A)rank(AHA)=rank(AAH)=rank(A) 设A∈Cm×nA \\in C^{m\\times n}A∈Cm×n，则 AHAA^HAAHA与AAHAA^HAAH的特征值均为非负实数 AHAA^HAAHA与AAHAA^HAAH的非零特征值相同，并且非零特征值个数等于rank(A)rank(A)rank(A) 定理 设AAA是正规矩阵，则AAA的奇异值为AAA的特征值的模。 设AAA是m×nm\\times nm×n矩阵，且rank(A)=rrank(A) = rrank(A)=r，则存在mmm阶酉矩阵UUU和nnn阶酉矩阵VVV使得： UHAV=(∑000)U^H AV = \\begin{pmatrix}\\sum &0 \\\\\\\\0 & 0\\end{pmatrix}UHAV=⎝⎛​∑0​00​⎠⎞​ ∑=diag(σ1,...,σr)\\sum = diag(\\sigma_1,...,\\sigma_r)∑=diag(σ1​,...,σr​)，且σ1≥...≥σr>0\\sigma_1 \\ge ...\\ge \\sigma_r > 0σ1​≥...≥σr​>0为矩阵AAA的奇异值 这个式子就被称为奇异值分解。 证明 易得AHAA^HAAHA为Hermite矩阵，AHAA^HAAHA的特征值λ2≥λ2≥...>0\\lambda^2\\ge\\lambda^2\\ge...>0λ2≥λ2≥...>0 由Schur定理可得，存在nnn阶酉矩阵，使得： UH(AHA)V=(∑2000)U^H(A^HA)V =\\begin{pmatrix}\\sum^2 &0 \\\\\\\\0 & 0\\end{pmatrix} UH(AHA)V=⎝⎛​∑20​00​⎠⎞​ 将VVV分解为V=(V1,V2),V1=Cn×r,V2=Cn×(n−r)V = (V_1,V_2),V_1 = C^{n\\times r},V_2 = C^{n\\times(n-r)}V=(V1​,V2​),V1​=Cn×r,V2​=Cn×(n−r) 重写上式为： AHA(V1,V2)=(V1,V2)(∑2000)A^HA(V_1,V_2)= (V_1,V_2)\\begin{pmatrix}\\sum^2 &0 \\\\\\\\0 & 0\\end{pmatrix} AHA(V1​,V2​)=(V1​,V2​)⎝⎛​∑20​00​⎠⎞​ {AHAV1=V1∑2⇒V1HAHAV1=∑2⇒(AV1∑−1)H(AV1∑−1)=IAHAV2=0⇒V2HAHAV2=0⇒(AV2)H(AV2)=0\\left \\{ \\begin{array}{c}A^HAV_1 = V_1 \\sum^2 \\Rightarrow V_1^HA^HAV_1 =\\sum^2 \\Rightarrow (AV_1\\sum^{-1})^H (AV_1\\sum^{-1}) = I\\\\ A^HAV_2 = 0 \\Rightarrow V_2^HA^HAV_2 = 0 \\Rightarrow (AV_2)^H(AV_2) =0\\end{array}\\right. {AHAV1​=V1​∑2⇒V1H​AHAV1​=∑2⇒(AV1​∑−1)H(AV1​∑−1)=IAHAV2​=0⇒V2H​AHAV2​=0⇒(AV2​)H(AV2​)=0​ 因此，AV2=0,U1=AV1∑−1,AV_2 = 0,U_1 = AV_1\\sum^{-1},AV2​=0,U1​=AV1​∑−1,则U1U_1U1​是酉矩阵：U1HU1=IU_1^HU_1 = IU1H​U1​=I。 因此U1U_1U1​的前rrr列两两正交且为单位向量，将其扩充为CmC^mCm的标准正交基，U2=(ur+1,...,um)U_2 = (u_{r+1},...,u_m)U2​=(ur+1​,...,um​) 则U=(U1,U2)U = (U_1,U_2)U=(U1​,U2​)是mmm阶酉矩阵，U1HU1=I,U2HU1=0U_1^HU_1 = I,U_2^HU_1 = 0U1H​U1​=I,U2H​U1​=0 UH(AHA)V=UH(AV1,AV2)=(U1HU2H)(U1∑,0)=(∑2000)U^H(A^HA)V = U^H (AV_1,AV_2) = \\begin{pmatrix}U_1^H\\\\\\\\U_2^H \\end{pmatrix} (U_1\\sum,0) = \\begin{pmatrix}\\sum^2 &0 \\\\\\\\0 & 0\\end{pmatrix} UH(AHA)V=UH(AV1​,AV2​)=⎝⎛​U1H​U2H​​⎠⎞​(U1​∑,0)=⎝⎛​∑20​00​⎠⎞​ 因此： A=U(∑2000)VHA = U\\begin{pmatrix}\\sum^2 &0 \\\\\\\\0 & 0\\end{pmatrix} V^HA=U⎝⎛​∑20​00​⎠⎞​VH VVV为AHAA^HAAHA的r个非零特征值对应的特征向量并单位化 UUU为AAHAA^HAAH的r个非零特征值对应的特征向量并单位化 奇异值分解的几何意义 我们观察SVD这个式子： A=U∑VTA = U\\sum V^TA=U∑VT 我们知道，若对一个向量乘以正交矩阵，相当于对其进行旋转变换（不改变长度和比例），而乘以一个对角矩阵，则相当于对其进行伸缩变换，因此，我们对线性变换X→AXX \\rightarrow AXX→AX，XXX为单位元上的点，其线性变化可以表示为： 一般的，设秩为rrr的m×nm\\times nm×n矩阵AAA有SVD:A=U∑VTA = U\\sum V^TA=U∑VT，从RnR^nRn到RmR^mRm的线性变换X→AXX \\rightarrow AXX→AX可以看成是以下三步的复合： RnR^nRn中的旋转X→VTXX \\rightarrow V^TXX→VTX RnR^nRn中的向量VTXV^TXVTX的前rrr个分量做伸缩，其余分量变为零： VTX→∑VTXV^TX \\rightarrow \\sum V^TXVTX→∑VTX 再在RmR^mRm中做旋转∑VTX→U∑VTX\\sum V^TX \\rightarrow U\\sum V^TX∑VTX→U∑VTX SVD的性质和本质 正交矩阵UUU的前rrr列是C(A)C(A)C(A)的一组标准正交基。 正交矩阵UUU的后m−rm-rm−r列是N(AT)N(A^T)N(AT)的一组标准正交基。 正交矩阵VVV的前rrr列是C(AT)C(A^T)C(AT)的一组标准正交基。 正交矩阵VVV的后n−rn-rn−r列是N(A)N(A)N(A)的一组标准正交基。 设∣λ∣max|\\lambda|_{max}∣λ∣max​是矩阵的特征值的模长最大值，则： σ1≥∣λ∣max,σ1≥∣aij∣\\sigma_1 \\ge |\\lambda |_{max},\\sigma_1 \\ge |a_{ij}|σ1​≥∣λ∣max​,σ1​≥∣aij​∣ 即最大奇异值大于等于特征值模长的最大值，也大于等于矩阵的元素 矩阵AAA列满秩 ⇔\\Leftrightarrow ⇔AAA的奇异值均非零 思考 对于正定对称矩阵而言，奇异值分解和对角化相同 特征值分解必须要求AAA为方阵，而奇异值分解不需要 AHAA^HAAHA或AAHAA^HAAH的特征值为AAA的奇异值的平方。 我们可以根据对AHAA^HAAHA和AAHAA^HAAH求特征值和特征向量，从而得到VVV、UUU、∑\\sum∑。 "},"pca.html":{"url":"pca.html","title":"理解PCA","keywords":"","body":"基本思想 降维是机器学习中很常见的一种思维方式，一般来说，可以通过线性投影和非线性映射进行。 PCA是一种简单的线性映射，当考虑降维时，我们一般有两种思路： 找到d-维仿射变换子空间，在合适的投影下，新的投影点与原先的投影点就接近。也就是说，在新投影下能最大限度的保持原数据的特征。 找到d-位投影，尽可能多的保留数据的变动（方差）。 我们将会从这两个思路分别进行求解，可以看到，这两个目标实际上等价。 定义 首先定义一些常用的量 样本均值 μn=1n∑n=1nxi\\mu_n = \\frac{1}{n}\\sum\\limits_{n = 1}^{n}x_iμn​=n1​n=1∑n​xi​ 样本协方差 ∑n=1n−1∑i=1n(xi−μi)(xi−μi)T\\sum_n = \\frac{1}{n-1}\\sum\\limits_{i=1}^{n}(x_i - \\mu_i)(x_i - \\mu_i)^Tn∑​=n−11​i=1∑n​(xi​−μi​)(xi​−μi​)T 其中xix_ixi​ 为数据样本（列向量），因此可以得到X=(x1,...,xn)X = (x_1,...,x_n)X=(x1​,...,xn​)为p×np\\times np×n矩阵，因此，写成矩阵的形式为 ∑n=1n−1(X−μn1)(X−μ1)T\\sum_n = \\frac{1}{n-1}(X - \\mu_n1)(X - \\mu1)^Tn∑​=n−11​(X−μn​1)(X−μ1)T 直观理解 首先，让我们用不是很严格的数学公式来直观理解PCA。 我们很常见的思想是使得协方差矩阵的方差尽可能大（保留更多有效信息），而让协方差尽可能的小（防止数据冗余），在协方差矩阵中则表现为对角矩阵DDD。 我们令经过d-维基VVV变换后的新坐标为yyy，因此可得： D=yyT=Vx(Vx)T=VxxTVT=V∑nVT \\begin{aligned} D &=y y^{T} \\\\ &=V x(V x)^{T} \\\\ &=V x x^{T} V^{T} \\\\ &=V \\sum_{n} V^{T} \\end{aligned} D​=yyT=Vx(Vx)T=VxxTVT=Vn∑​VT​ 这个式子有着特殊的含义。其中，DDD是新的协方差矩阵（对角矩阵），而∑n\\sum_n∑n​则是原始数据的协方差矩阵，VVV则是d-维正交基。 因此，这个式子可以理解为：对协方差矩阵∑n\\sum_n∑n​，找一个VVV，使得其转变为对角矩阵。而协方差矩阵是实对称矩阵，一定能够对角化，证明了这一点的完备性。 因此，我们只需要对协方差矩阵进行对角化，然后求出其对应的特征向量，即为新坐标下的正交基VVV。对y=Vxy = Vxy=Vx进行坐标变换则求到了新坐标下的PCA坐标。 PCA是最佳的仿射变换拟合 我们要对每个近似xix_ixi​近似（由仿射变换的定义）： xi≈μ+∑j=1dβijvjx_i \\approx \\mu + \\sum\\limits_{j= 1}^{d} \\beta_i^jv_jxi​≈μ+j=1∑d​βij​vj​ 其中，Vp×d=(v1,..,vd)V_{p\\times d} = (v_1,..,v_d)Vp×d​=(v1​,..,vd​)为d-维子空间中的标准正交基，μ∈Rp\\mu \\in R^pμ∈Rp是平移量，βj\\beta_jβj​为在基vjv_jvj​下的系数，βji\\beta_j^iβji​为βj\\beta_jβj​的第iii个分量那么上式可以写成： xi=μ+Vβix_i = \\mu + V\\beta_ixi​=μ+Vβi​ 由于其中的VVV由标准正交基组成，因此VTV=1V^TV = 1VTV=1. 用平方误差来衡量拟合效果，即要求出： min⁡μ,V,βi.VTV=1∑i=1n∣∣xi−(μ+Vβi)∣∣2\\min\\limits_{\\mu,V,\\beta_i.V^TV=1} \\sum\\limits_{i=1}^n||x_i - (\\mu + V\\beta_i)||^2μ,V,βi​.VTV=1min​i=1∑n​∣∣xi​−(μ+Vβi​)∣∣2 求μ\\muμ的最优值 首先对μ\\muμ求偏导，可以得到： ∑i=1n(xi−(μ+Vβi))=0⇒(∑i=1nxi)−nμ−V(∑i=1nβi)=0\\sum_{i=1}^n(x_i - (\\mu + V\\beta_i)) = 0 \\Rightarrow (\\sum_{i=1}^n x_i) - n\\mu - V(\\sum_{i=1}^n \\beta_i) = 0i=1∑n​(xi​−(μ+Vβi​))=0⇒(i=1∑n​xi​)−nμ−V(i=1∑n​βi​)=0 由于μ\\muμ和β\\betaβ之间没有关系，不失一般性我们可以假设∑βi=0\\sum \\beta_i = 0∑βi​=0，因此可以解出： μ∗=1n∑i=1nxi=μn\\mu^* = \\frac{1}{n}\\sum_{i=1}^{n}x_i = \\mu_nμ∗=n1​i=1∑n​xi​=μn​ 因此，μ\\muμ的最优值就是样本均值μ∗\\mu^*μ∗。 这样，我们可以将原始式子化简为： min⁡μ,V,βi.VTV=1∑i=1n∣∣xi−(μn+Vβi)∣∣2\\min\\limits_{\\mu,V,\\beta_i.V^TV=1} \\sum\\limits_{i=1}^n||x_i - (\\mu_n + V\\beta_i)||^2μ,V,βi​.VTV=1min​i=1∑n​∣∣xi​−(μn​+Vβi​)∣∣2 求βi\\beta_iβi​的最优值 注意到，βi\\beta_iβi​之间是无耦合的影响的最小值，因此，对于原始式子，可以分别解出βi\\beta_iβi​： min⁡βi∣∣xi−μn−Vβi∣∣2=min⁡βi∣∣xi−μn−∑j=1dβijvj∣∣2\\min\\limits_{\\beta_i}||x_i - \\mu_n - V\\beta_i||^2 = \\min\\limits_{\\beta_i}||x_i - \\mu_n - \\sum\\limits_{j=1}^d\\beta_i^jv_j||^2 βi​min​∣∣xi​−μn​−Vβi​∣∣2=βi​min​∣∣xi​−μn​−j=1∑d​βij​vj​∣∣2 由于VVV是标准正交基，对βi\\beta_iβi​求偏导： βij=vjT(xi−μn)⇒βi=VT(xi−μn)\\beta_i^j = v_j^T(x_i - \\mu_n)\\Rightarrow \\beta_i = V^T(x_i - \\mu _n)βij​=vjT​(xi​−μn​)⇒βi​=VT(xi​−μn​) 因此式子可以化简为： min⁡VTV=1∑i=1n∣∣(xi−μn)−VVT(xi−μn)∣∣2\\min\\limits_{V^TV = 1} \\sum\\limits_{i= 1 } ^n ||(x_i - \\mu_n) - VV^T(x_i - \\mu_n)||^2VTV=1min​i=1∑n​∣∣(xi​−μn​)−VVT(xi​−μn​)∣∣2 求VVV的最优值 由∣∣x∣∣2=x,x>||x||^2 = ∣∣x∣∣2=x,x>和VTV=1V^TV = 1VTV=1，可以得到： ∥(xi−μn)−VVT(xi−μn)∥2=[(xi−μn)−VVT(xi−μn)]T[(xi−μn)−VVT(xi−μn)]=(xi−μn)T(xi−μn)−(xi−μn)TVVT(xi−μn)−(xi−μn)TVVT(xi−μn)+(xi−μn)TVV=2(xi−μn)T(xi−μn)−2(xi−μn)TVVT(xi−μn) \\begin{aligned} \\left\\|\\left(x_{i}-\\mu_{n}\\right)-V V^{T}\\left(x_{i}-\\mu_{n}\\right)\\right\\|^{2} &=\\left[\\left(x_{i}-\\mu_{n}\\right)-V V^{T}\\left(x_{i}-\\mu_{n}\\right)\\right]^{T}\\left[\\left(x_{i}-\\mu_{n}\\right)-V V^{T}\\left(x_{i}-\\mu_{n}\\right)\\right] \\\\ &=\\left(x_{i}-\\mu_{n}\\right)^{T}\\left(x_{i}-\\mu_{n}\\right)-\\left(x_{i}-\\mu_{n}\\right)^{T} V V^{T}\\left(x_{i}-\\mu_{n}\\right)-\\left(x_{i}-\\mu_{n}\\right)^{T} V V^{T}\\left(x_{i}-\\mu_{n}\\right)+\\left(x_{i}-\\mu_{n}\\right)^{T} V V \\\\ &=2\\left(x_{i}-\\mu_{n}\\right)^{T}\\left(x_{i}-\\mu_{n}\\right)-2\\left(x_{i}-\\mu_{n}\\right)^{T} V V^{T}\\left(x_{i}-\\mu_{n}\\right) \\end{aligned} ∥∥​(xi​−μn​)−VVT(xi​−μn​)∥∥​2​=[(xi​−μn​)−VVT(xi​−μn​)]T[(xi​−μn​)−VVT(xi​−μn​)]=(xi​−μn​)T(xi​−μn​)−(xi​−μn​)TVVT(xi​−μn​)−(xi​−μn​)TVVT(xi​−μn​)+(xi​−μn​)TVV=2(xi​−μn​)T(xi​−μn​)−2(xi​−μn​)TVVT(xi​−μn​)​ 由于(xi−μn)T(xi−μn)(x_i - \\mu_n)^T(x_i - \\mu_n)(xi​−μn​)T(xi​−μn​)与VVV无关，因此等价于求： max⁡VTV=1∑i=1n(xi−μn)TVVT(xi−μn) \\max _{V^{T} V=1} \\sum_{i=1}^{n}\\left(x_{i}-\\mu_{n}\\right)^{T} V V^{T}\\left(x_{i}-\\mu_{n}\\right) VTV=1max​i=1∑n​(xi​−μn​)TVVT(xi​−μn​) 化简原式可得： ∑i=1n(xi−μn)TVVT(xi−μn)=∑i=1n[VT(xi−μn)]T[VT(xi−μn)] \\sum_{i=1}^{n}\\left(x_{i}-\\mu_{n}\\right)^{T} V V^{T}\\left(x_{i}-\\mu_{n}\\right)=\\sum_{i=1}^{n}\\left[V^{T}\\left(x_{i}-\\mu_{n}\\right)\\right]^{T}\\left[V^{T}\\left(x_{i}-\\mu_{n}\\right)\\right] i=1∑n​(xi​−μn​)TVVT(xi​−μn​)=i=1∑n​[VT(xi​−μn​)]T[VT(xi​−μn​)] 由矩阵的迹的性质可得： yTy=Tr(yyT)y^Ty = Tr(yy^T)yTy=Tr(yyT) 因此，将原始化简的式子等价于求： max⁡VTV=1∑i=1n(xi−μn)TVVT(xi−μn)=max⁡VTV=1(n−1)Tr(VT∑nV)\\max\\limits _{V^TV=1}\\sum\\limits_{i=1}^n (x_i - \\mu_n)^TVV^T(x_i - \\mu_n) =\\max\\limits _{V^TV=1} (n-1)Tr(V^T\\sum_nV) VTV=1max​i=1∑n​(xi​−μn​)TVVT(xi​−μn​)=VTV=1max​(n−1)Tr(VTn∑​V) 即： max⁡VTV=1Tr(VT∑nV)\\max\\limits _{V^TV=1} Tr(V^T\\sum_nV)VTV=1max​Tr(VTn∑​V) 即，我们最后要求的标准正交基为使得协方差矩阵的迹最大；这等价于求协方差矩阵的特征值，并按照从大到小排列。 PCA保留最大方差 我们的第二个目标是要保留数据最大变化的d-维投影。可以写出全方差为： Total Variance(Xn)=1n∑∣∣xi−μn∣∣2=1n∑i=1n∣∣xi−1n∑i=1nxi∣∣2\\text{Total Variance} (X_n) = \\frac{1}{n} \\sum\\limits||x_i- \\mu_n||^2 = \\frac {1}{n} \\sum\\limits_{i=1}^n||x_i - \\frac{1}{n}\\sum\\limits_{i=1}^n x_i||^2Total Variance(Xn​)=n1​∑∣∣xi​−μn​∣∣2=n1​i=1∑n​∣∣xi​−n1​i=1∑n​xi​∣∣2 因此，我们要向最大化投影以后的方差，即VTxiV^Tx_iVTxi​的方差： max⁡VTV=1∑i=1n∣∣VTxi−1n∑i=1nVTxi∣∣2\\max\\limits _{V^TV=1}\\sum\\limits_{i=1}^n ||V^Tx_i - \\frac{1}{n}\\sum\\limits_{i=1}^n V^Tx_i||^2 VTV=1max​i=1∑n​∣∣VTxi​−n1​i=1∑n​VTxi​∣∣2 根据之前的结论： ∑i=1n∣∣VTxi−1n∑i=1nVTxi∣∣2=∑i=1n∣∣VT(xi−μn)∣∣2=(n−1)Tr(VT∑nV)\\sum\\limits_{i=1}^n ||V^Tx_i - \\frac{1}{n}\\sum\\limits_{i=1}^n V^Tx_i||^2 =\\sum\\limits_{i=1}^n ||V^T(x_i - \\mu_n)||^2= (n-1)Tr(V^T\\sum_nV) i=1∑n​∣∣VTxi​−n1​i=1∑n​VTxi​∣∣2=i=1∑n​∣∣VT(xi​−μn​)∣∣2=(n−1)Tr(VTn∑​V) 表明主成分VVV可以通过下式解决： max⁡VTV=1Tr(VT∑nV)\\max\\limits_{V^TV = 1}Tr(V^T\\sum_nV) VTV=1max​Tr(VTn∑​V) 这样，两种不同的度量方法就等价求协方差矩阵的前ddd个特征值。 参考资料 如何通俗地讲解「仿射变换」这个概念 奇异值的物理意义是什么 Tutorial on Principal Component Analysis "},"svd understanding.html":{"url":"svd understanding.html","title":"SVD通俗理解","keywords":"","body":" 前面已经对SVD进行了推导，但自己一直理解不够深入，知道看了Strang教授的视频才恍然大悟。 思考 对于对称矩阵，我们知道，可以分解为A=QΛQTA = Q\\Lambda Q^TA=QΛQT，这是很美妙和对称的式子，但对于一般的矩阵，我们怎么能得到类似的式子呢？ 我们的目标是想要找到两组不同的正交矩阵（UUU，VVV）和对角矩阵Λ\\LambdaΛ，来表示AAA。 因此，SVD就是对于任意矩阵的“对角化”过程。 子空间 这里，我们回到四个基本子空间。我们可以在行空间（row space）中找到一组标准正交基（这很容易），将其进行映射后（通过AAA），转化为列空间（column space）中的标准正交基。也就是说，在行空间中的V1V_1V1​，通过AV1AV_1AV1​转化为列空间中的U1U_1U1​： AV1=σ1U1AV_1 = \\sigma_1 U_1 AV1​=σ1​U1​ 其中σ1\\sigma_1σ1​为伸缩因子。 将所有行空间和列空间中的标准正交基写成矩阵的形式： A(V1,...,Vr)=(U1,...,Ur)diag(σ1,...,σr)A(V_1,...,V_r) = (U_1,...,U_r)diag(\\sigma_1,...,\\sigma_r)A(V1​,...,Vr​)=(U1​,...,Ur​)diag(σ1​,...,σr​) 其中，rrr表示矩阵的秩。 我们很容易将其扩充为整个行空间和列空间： A(V1,...,Vr,Vr+1,....Vm)=(U1,...,Ur,Ur+1,...,Un)diag(σ1,...,σr,0,...,0)A(V_1,...,V_r,V_{r+1},....V_m) = (U_1,...,U_r,U_{r+1},...,U_n)diag(\\sigma_1,...,\\sigma_r,0,...,0)A(V1​,...,Vr​,Vr+1​,....Vm​)=(U1​,...,Ur​,Ur+1​,...,Un​)diag(σ1​,...,σr​,0,...,0) 其中，扩充的基向量来源于零空间和左零空间（这很容易）。 回到SVD 这样，我们整理一下就得到： AV=U∑A V=U\\sum AV=U∑ A=U∑V−1=U∑VTA = U\\sum V^{-1} = U\\sum V^T A=U∑V−1=U∑VT 这就是SVD分解：我们需要在行空间和列空间中找到两组不同的基，并且这两组基可以通过AAA相互转换。 然而，这还不够。我们不知道如何求得UUU和VVV。最常见的想法就是：我们把一个变量消去，只保留一个变量，这样就容易求解了。 幸运的是，这很容易，考虑： ATA=V∑TUTU∑V=V∑2VT=Vdiag(σ12,...)VTA^TA = V\\sum^TU^TU\\sum V = V\\sum^2V^T = V diag(\\sigma_1^2,...)V^TATA=V∑T​UTU∑V=V∑2​VT=Vdiag(σ12​,...)VT 我们发现，在ATAA^TAATA这个对称矩阵中，VVV就是其特征向量，而它的所有非零特征向量都是正的，因此这个矩阵是半正定的。 可以对AATAA^TAAT同样进行求解求得UUU。 我们发现，尽管AAA是任意矩阵，但ATAA^TAATA和AATAA^TAAT很特殊，并且可以通过求其的特征向量来对AAA进行奇异值分解。 实际上，ATAA^TAATA和AATAA^TAAT还有更为特殊的关系（特征值相同等等），严格的推导可以参考我这篇博客。 总结 其实SVD没什么特别的，就是我们对于实对称矩阵的推广。 经过分析，我们发现在列空间和行空间中找到一组基，可以使得任意矩阵分解成A=U∑VTA = U\\sum V^T A=U∑VT的形式。 并且，求解UUU和VVV并不复杂，与AATAA^TAAT和ATAA^TAATA有关。 在求解时，先求AATAA^TAAT的特征值和特征向量，其特征向量单位化后就是UUU的前r列，再将其扩充到左零空间；同样，求ATAA^TAATA的特征向量，单位化后就是VVV的前r列，再将其扩充到零空间；填充∑\\sum∑，即可求解。 "},"transform.html":{"url":"transform.html","title":"线性变换与基变换","keywords":"","body":"每一个矩阵都可以看作是线性变换，矩阵乘法也是由线性变换的复合引出的。 线性变换 理解 线性变换是一种映射，对于向量来说，就是线性空间到线性空间的映射。这里不严格给出线性变换的定义，但举例来说，投影变换、反射变换、不定积分等都可以看做是线性变换。 与线性变换相对的是仿射变换，例如： T(x)=Ax+x0T(x)= Ax + x_0T(x)=Ax+x0​ 就是一个仿射变换，可以通俗的理解为对现象变换AxAxAx加上了一个偏移量x0x_0x0​。 性质 由线性变换的性质，我们可以得到： T(0)=0,T(−x)=−xT(0) = 0,T(-x)= -xT(0)=0,T(−x)=−x T(c1x1+c2x2+...+cnxn)=c1T(x1)+c2T(x2)+...+cnT(xn)T(c_1x_1 + c_2 x_2 +...+c_nx_n) = c_1T(x_1)+c_2T(x_2) +...+ c_nT(x_n)T(c1​x1​+c2​x2​+...+cn​xn​)=c1​T(x1​)+c2​T(x2​)+...+cn​T(xn​) 若x1,...,xnx_1,...,x_nx1​,...,xn​线性相关，则T(x1),...T(xn)T(x_1),...T(x_n)T(x1​),...T(xn​)线性相关。 即线性变换保持向量空间的线性关系。 例如，线性变换总是把直线变成直线，把三角形变成三角形，把平行四边形变成平行四边形。。。 线性变换的矩阵表示 我们想用一个矩阵来表示一个向量中所有线性空间中的变换，也就是用矩阵来描述这个线性变换。 设VVV和WWW分别是数域上nnn维、mmm维向量空间，T:V→WT: V \\rightarrow WT:V→W是VVV到WWW的线性变换。 在VVV中取一组基v1,...,vnv_1,...,v_nv1​,...,vn​，则对于任意的vvv,可以用基表示为v=c1v1,...,cnvnv = c_1v_1,...,c_nv_nv=c1​v1​,...,cn​vn​，这也就是vvv在这组基下的坐标。 因此，T(v)=c1T(v1)+...+cnT(vn)T(v) = c_1T(v_1)+...+c_nT(v_n)T(v)=c1​T(v1​)+...+cn​T(vn​)。我们可以发现，要求这个线性空间中任意向量的线性变化，只需要知道基的变换即可。 因此，我们可以在WWW中取一组基w1,...,wmw_1,...,w_mw1​,...,wm​，则得到基的线性变换为： 称m×nm\\times nm×n矩阵AAA为线性变换TTT在VVV中给定基v1,....,vnv_1,....,v_nv1​,....,vn​和WWW中给定基w1,...,wmw_1,...,w_mw1​,...,wm​下的矩阵表示。 线性变换与矩阵之间的关系 线性变换的唯一性 对于一个线性变换σ\\sigmaσ，在确定了一组基后，对应于唯一的矩阵AAA。 而一个矩阵AAA在一组基下，也对应唯一一个线性变换σ\\sigmaσ。 可逆线性变换 设σ∈L(V,V)\\sigma \\in L(V,V)σ∈L(V,V)为可逆线性变换，且σ\\sigmaσ在VVV的某一组基下的矩阵为AAA，则σ−1\\sigma^{-1}σ−1在这组基下的矩阵为A−1A^{-1}A−1。 例子 设线性变换t:R3→R2t:R^3 \\to R^2 t:R3→R2定义为t(x,y,z)=(x+y,y−z)t(x,y,z) = (x+y,y-z)t(x,y,z)=(x+y,y−z)，线性变换σ:R2→R2\\sigma:R^2\\to R^2 σ:R2→R2定义为σ(u,v)=(2u−v,u)\\sigma(u,v) = (2u-v,u)σ(u,v)=(2u−v,u)，求线性变换σt:R3→R2\\sigma t:R^3\\to R^2σt:R3→R2在R3R^3 R3与R2R^2R2标准基下的矩阵。 注意到： σt(x,y,z)=σ(t(x,y,z))=σ(x+y,y−z)=(2x+y+z,x+y)\\sigma t (x,y,z) = \\sigma (t(x,y,z)) = \\sigma (x+y,y-z) = (2x+y+z,x+y)σt(x,y,z)=σ(t(x,y,z))=σ(x+y,y−z)=(2x+y+z,x+y) 因此在R3R^3R3的标准基e1,e2,e3e_1,e_2,e_3e1​,e2​,e3​与R2R^2R2的标准基δ1,δ2\\delta_1,\\delta_2δ1​,δ2​下有： σt(e1)=σt(1,0,0)=(2,1)=2δ1+δ2\\sigma t (e_1)= \\sigma t(1,0,0) = (2,1) = 2\\delta_1+\\delta _2σt(e1​)=σt(1,0,0)=(2,1)=2δ1​+δ2​ σt(e2)=σt(0,1,0)=(1,1)=δ1+δ2\\sigma t (e_2)= \\sigma t(0,1,0) = (1,1) = \\delta_1+\\delta _2σt(e2​)=σt(0,1,0)=(1,1)=δ1​+δ2​ σt(e3)=σt(0,0,1)=(1,0)=δ1\\sigma t (e_3)= \\sigma t(0,0,1) = (1,0) = \\delta_1σt(e3​)=σt(0,0,1)=(1,0)=δ1​ 因此： 又因为： 验证可得： AB=CAB=CAB=C 这就是线性变换的复合。 基变换 我们可以将基变换理解为特殊的线性变换，因为基变换其实是可逆线性变换，也就是说，AAA始终是可逆矩阵。 设σ\\sigmaσ是恒同变换，则： 则恒同变换σ\\sigmaσ在两组基下的矩阵表示PPP与VVV的这两组基之间的基变换矩阵。 线性变换在不同基下的矩阵 我们发现，线性变换与基的选取有关：同一个线性变换在不同基下的矩阵表示不相同。 因此，我们希望找出线性变换与基无关的性质，或者说，找出线性变换的矩阵表示如何随着基的改变而改变。 对于这样一个变换，我们既可以通过BBB矩阵直接得到，也可以通过基变换PPP，在新基上用AAA矩阵变换，最后回到原来的基上来表示，因此可以得到： B=PAP−1B = PAP^{-1}B=PAP−1 我们发现，对于同样一个线性变化，在不同基下的变换矩阵时相似的，同时，可逆矩阵PPP表示这个基变换矩阵。 这是个很好的性质，我们因此可以理解对角化A=SΛS−1A = S\\Lambda S^{-1}A=SΛS−1和奇异值分解A=U∑VTA = U\\sum V^TA=U∑VT，在此不再赘述，可以参考目录。 参考资料 线性代数(2) "}}