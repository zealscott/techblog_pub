
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <title>spark编程练习 · Distribution System</title>
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.0.0">
        <meta name="author" content="zealscott">
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-disqus/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-katex-plus/katex.min.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-back-to-top-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search-pro/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-expandable-chapters/expandable-chapters.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="spark-recap.html" />
    
    
    <link rel="prev" href="spark1.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    
    
        
        <li>
            <a href="https://tech.zealscott.com" target="_blank" class="custom-link">Homepage</a>
        </li>
    
    

    
    <li class="divider"></li>
    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" >
            
                <span>
            
                    
                    Notes
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="../notes/Distribution-File-System-DFS.html">
            
                <a href="../notes/Distribution-File-System-DFS.html">
            
                    
                    Distribution File System DFS
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="../notes/mapreduce.html">
            
                <a href="../notes/mapreduce.html">
            
                    
                    MapReduce处理系统
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3" data-path="../notes/mrcoding.html">
            
                <a href="../notes/mrcoding.html">
            
                    
                    MapReduce编程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4" data-path="../notes/RPC-and-serialization.html">
            
                <a href="../notes/RPC-and-serialization.html">
            
                    
                    RPC And Serialization
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.5" data-path="../notes/spark.html">
            
                <a href="../notes/spark.html">
            
                    
                    Spark 处理框架
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.6" data-path="../notes/sparkcoding.html">
            
                <a href="../notes/sparkcoding.html">
            
                    
                    Spark 编程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.7" data-path="../notes/yarn.html">
            
                <a href="../notes/yarn.html">
            
                    
                    Yarn 资源管理框架
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.8" data-path="../notes/zookeeper.html">
            
                <a href="../notes/zookeeper.html">
            
                    
                    ZooKeeper 元数据管理系统
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.9" data-path="../notes/pregel.html">
            
                <a href="../notes/pregel.html">
            
                    
                    分布式图处理系统--Pregel
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.10" data-path="../notes/flink.html">
            
                <a href="../notes/flink.html">
            
                    
                    批流融合系统--Flink
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.11" data-path="../notes/beam.html">
            
                <a href="../notes/beam.html">
            
                    
                    批流融合系统--展望
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.12" data-path="../notes/ps.html">
            
                <a href="../notes/ps.html">
            
                    
                    机器学习系统--Parameter Server
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.13" data-path="../notes/graphlab.html">
            
                <a href="../notes/graphlab.html">
            
                    
                    机器学习系统--GraphLab
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.14" data-path="../notes/mahout.html">
            
                <a href="../notes/mahout.html">
            
                    
                    机器学习系统--mahout
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.15" data-path="../notes/stream.html">
            
                <a href="../notes/stream.html">
            
                    
                    流计算系统概述
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" >
            
                <span>
            
                    
                    Lab
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="rpc.html">
            
                <a href="rpc.html">
            
                    
                    RPC model in Java
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="hadoop.html">
            
                <a href="hadoop.html">
            
                    
                    hadoop安装与配置
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="hadoop1.html">
            
                <a href="hadoop1.html">
            
                    
                    hadoop编程实践（一）
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="hadoop2.html">
            
                <a href="hadoop2.html">
            
                    
                    hadoop编程实践（二）
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="hadoop-coding.html">
            
                <a href="hadoop-coding.html">
            
                    
                    hadoop编程练习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.6" data-path="hadoop-recap.html">
            
                <a href="hadoop-recap.html">
            
                    
                    Hadoop 编程总结
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.7" data-path="spark-installation.html">
            
                <a href="spark-installation.html">
            
                    
                    spark安装与配置
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.8" data-path="spark1.html">
            
                <a href="spark1.html">
            
                    
                    spark编程实践
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.3.9" data-path="spark2.html">
            
                <a href="spark2.html">
            
                    
                    spark编程练习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.10" data-path="spark-recap.html">
            
                <a href="spark-recap.html">
            
                    
                    Spark 编程总结
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.11" data-path="docker1.html">
            
                <a href="docker1.html">
            
                    
                    使用 Docker 配置 hadoop/spark
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.12" data-path="docker2.html">
            
                <a href="docker2.html">
            
                    
                    使用 docker 搭建 spark(2.3.1) 集群
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.13" data-path="zookeeper.html">
            
                <a href="zookeeper.html">
            
                    
                    ZooKeeper配置及简单使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.14" data-path="yarn.html">
            
                <a href="yarn.html">
            
                    
                    Yarn框架下的系统部署
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.15" data-path="storm-installation.html">
            
                <a href="storm-installation.html">
            
                    
                    Storm部署与运行
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.16" data-path="storm-coding.html">
            
                <a href="storm-coding.html">
            
                    
                    Storm编程练习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.17" data-path="storm-summary.html">
            
                <a href="storm-summary.html">
            
                    
                    Storm 编程总结
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.18" data-path="sparksteaming.html">
            
                <a href="sparksteaming.html">
            
                    
                    SparkSteaming使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.19" data-path="flink-installation.html">
            
                <a href="flink-installation.html">
            
                    
                    Flink安装及使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.20" data-path="flink1.html">
            
                <a href="flink1.html">
            
                    
                    Flink编程练习（一）
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.21" data-path="flink2.html">
            
                <a href="flink2.html">
            
                    
                    Flink编程练习（二）
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.22" data-path="graph-in-hadoop.html">
            
                <a href="graph-in-hadoop.html">
            
                    
                    常用图算法实现--Hadoop
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.23" data-path="graph-in-spark.html">
            
                <a href="graph-in-spark.html">
            
                    
                    常用图算法实现--Spark
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.24" data-path="graph-in-flink.html">
            
                <a href="graph-in-flink.html">
            
                    
                    常用图算法实现--Flink
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.25" data-path="giraph.html">
            
                <a href="giraph.html">
            
                    
                    Giraph配置及使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.26" data-path="flink-iteration.html">
            
                <a href="flink-iteration.html">
            
                    
                    Flink迭代小记
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" >
            
                <span>
            
                    
                    Recap
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="../recap/fundamental-of-distributed-system.html">
            
                <a href="../recap/fundamental-of-distributed-system.html">
            
                    
                    分布式系统基础
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2" data-path="../recap/batch-system.html">
            
                <a href="../recap/batch-system.html">
            
                    
                    批处理系统
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3" data-path="../recap/management-system.html">
            
                <a href="../recap/management-system.html">
            
                    
                    支持数据管理的底层系统
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.4" data-path="../recap/streaming-system.html">
            
                <a href="../recap/streaming-system.html">
            
                    
                    流处理系统
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5" data-path="../recap/flink.html">
            
                <a href="../recap/flink.html">
            
                    
                    批流融合系统
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.6" data-path="../recap/graph.html">
            
                <a href="../recap/graph.html">
            
                    
                    图处理系统
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.7" data-path="../recap/ml.html">
            
                <a href="../recap/ml.html">
            
                    
                    机器学习系统
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.8" data-path="../recap/summary.html">
            
                <a href="../recap/summary.html">
            
                    
                    总结与对比
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >spark编程练习</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="map">Map</h1>
<p>&#x73ED;&#x7EA7;&#x5B66;&#x751F;&#x6210;&#x7EE9;&#x7684;&#x968F;&#x673A;&#x751F;&#x6210;</p>
<ul>
<li>&#x8F93;&#x5165;&#xFF1A;&#x672C;&#x73ED;&#x540C;&#x5B66;&#x7684;&#x5B66;&#x53F7;</li>
<li>&#x8F93;&#x51FA;&#xFF1A;&lt;&#x5B66;&#x53F7;&#xFF0C;&#x6210;&#x7EE9;&gt;</li>
</ul>
<h2 id="&#x6570;&#x636E;&#x51C6;&#x5907;">&#x6570;&#x636E;&#x51C6;&#x5907;</h2>
<ol>
<li><p>&#x9996;&#x5148;&#x9700;&#x8981;&#x4E00;&#x4E2A;<code>stuID.csv&#x6587;&#x4EF6;</code>&#xFF0C;&#x6BCF;&#x4E00;&#x5217;&#x4E3A;&#x4E00;&#x4E2A;&#x5B66;&#x53F7;&#xFF1A;</p>
<ul>
<li><img src="../images/spark41.png" alt="spark41"></li>
</ul>
</li>
<li><p>&#x7136;&#x540E;&#x5C06;&#x6587;&#x4EF6;&#x653E;&#x5165;<code>HDFS</code>&#x4E2D;&#xFF1A;</p>
<pre><code class="lang-shell">hdfs dfs put stuID.csv input
</code></pre>
</li>
</ol>
<h2 id="&#x7F16;&#x5199;&#x7A0B;&#x5E8F;">&#x7F16;&#x5199;&#x7A0B;&#x5E8F;</h2>
<pre><code class="lang-java"><span class="hljs-keyword">import</span> org.apache.spark.SparkConf;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.*;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.function.Function;

<span class="hljs-keyword">import</span> java.util.ArrayList;
<span class="hljs-keyword">import</span> java.util.List;
<span class="hljs-keyword">import</span> java.util.Random;

<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">StuScore</span> </span>{

    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> Random rand = <span class="hljs-keyword">new</span> Random();

    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>{
        SparkConf conf = <span class="hljs-keyword">new</span> SparkConf().setAppName(<span class="hljs-string">&quot;StuScore&quot;</span>);
        JavaSparkContext sc = <span class="hljs-keyword">new</span> JavaSparkContext(conf);
        String logFile = <span class="hljs-string">&quot;hdfs:///user/hadoop/input/stuID.csv&quot;</span>;
        JavaRDD&lt;String&gt; stuID = sc.textFile(logFile);

        JavaRDD&lt;String&gt; stuScore = stuID.map(
                <span class="hljs-keyword">new</span> Function&lt;String, String&gt;() {
                    <span class="hljs-meta">@Override</span>
                    <span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">call</span><span class="hljs-params">(String s)</span> <span class="hljs-keyword">throws</span> Exception </span>{
                        String tmp  =  s + <span class="hljs-string">&quot; &quot;</span> +  String.valueOf( rand.nextInt(<span class="hljs-number">100</span>) +<span class="hljs-number">1</span>);
                        <span class="hljs-keyword">return</span> tmp;
                    }
                }
        );

  stuScore.saveAsTextFile(<span class="hljs-string">&quot;hdfs:///user/hadoop/output/spark/StuRandomScore&quot;</span>);
    }
}
</code></pre>
<h3 id="&#x6CE8;&#x610F;&#x70B9;">&#x6CE8;&#x610F;&#x70B9;</h3>
<ol>
<li>&#x6CE8;&#x610F;&#x5728;&#x7528;Spark&#x8FDE;&#x63A5;HDFS&#x65F6;&#xFF0C;&#x9700;&#x8981;&#x6307;&#x660E;&#x5B8C;&#x6574;&#x8DEF;&#x5F84;&#xFF0C;&#x5982;<code>/user/hadoop</code>&#xFF0C;&#x4E0D;&#x80FD;&#x50CF;hadoop&#x4E00;&#x6837;&#x7701;&#x7565;&#x3002;</li>
<li>&#x4F7F;&#x7528;<code>map</code>&#x51FD;&#x6570;&#x5C06;&#x5176;transform&#x5230;&#x53E6;&#x4E00;&#x4E2A;RDD&#x662F;&#x5E38;&#x7528;&#x7684;&#x64CD;&#x4F5C;&#x65B9;&#x5F0F;&#x3002;</li>
</ol>
<h2 id="&#x8FD0;&#x884C;">&#x8FD0;&#x884C;</h2>
<h3 id="&#x672C;&#x5730;&#x8FD0;&#x884C;">&#x672C;&#x5730;&#x8FD0;&#x884C;</h3>
<p>&#x9996;&#x5148;&#x786E;&#x4FDD;&#x5DF2;&#x7ECF;&#x6253;&#x5F00;&#x4E86;HDFS&#xFF0C;&#x5728;<code>target</code>&#x76EE;&#x5F55;&#x4E0B;&#xFF0C;&#x63D0;&#x4EA4;&#x4F5C;&#x4E1A;&#xFF1A;</p>
<pre><code>spark-submit --class StuScore StuScore-1.0.jar
</code></pre><p>&#x67E5;&#x770B;&#x7ED3;&#x679C;</p>
<pre><code>hdfs dfs -cat output/spark/StuRandomScore/*
</code></pre><h3 id="&#x96C6;&#x7FA4;&#x4E0A;&#x8FD0;&#x884C;">&#x96C6;&#x7FA4;&#x4E0A;&#x8FD0;&#x884C;</h3>
<p>&#x540C;&#x6837;&#xFF0C;&#x9700;&#x8981;&#x5C06;HDFS&#x5730;&#x5740;&#x66F4;&#x6539;&#x4E3A;&#x96C6;&#x7FA4;&#x7684;&#x5730;&#x5740;&#xFF0C;&#x4F8B;&#x5982;&#xFF1A;</p>
<blockquote>
<p>hdfs:///user/hadoop/input/stuID.csv =&gt; hdfs://10.11.6.91:9000/user/hadoop7/input/stuID.csv</p>
</blockquote>
<p>&#x63D0;&#x4EA4;&#x4F5C;&#x4E1A;&#x5E76;&#x8FD0;&#x884C;&#xFF1A;</p>
<pre><code class="lang-shell">spark-submit  --class StuScore StuScore-1.0.jar
</code></pre>
<p>&#x67E5;&#x770B;&#x8FD0;&#x884C;&#x7ED3;&#x679C;</p>
<pre><code>hdfs dfs -cat output/spark/StuRandomScore/*
</code></pre><h1 id="reducebykey">reduceByKey</h1>
<h2 id="&#x95EE;&#x9898;">&#x95EE;&#x9898;</h2>
<p>&#x6C42;&#x5E73;&#x5747;&#x6210;&#x7EE9;&#xFF1A;&#x5C06;&#x5168;&#x73ED;&#x540C;&#x5B66;&#x6BCF;&#x9694;5&#x53F7;&#x5206;&#x4E3A;&#x4E00;&#x7EC4;&#xFF0C;&#x6C42;&#x6BCF;&#x7EC4;&#x7684;&#x5E73;&#x5747;&#x6210;&#x7EE9;</p>
<p>&#x8F93;&#x5165;&#xFF1A; &lt;&#x5B66;&#x53F7;&#xFF0C;&#x6210;&#x7EE9;&gt;</p>
<p>&#x8F93;&#x51FA;&#xFF1A;&lt;&#x7EC4;&#x53F7;&#xFF0C;&#x5E73;&#x5747;&#x5206;&gt;</p>
<h2 id="&#x6570;&#x636E;&#x51C6;&#x5907;">&#x6570;&#x636E;&#x51C6;&#x5907;</h2>
<ol>
<li><p>&#x9996;&#x5148;&#x9700;&#x8981;&#x4E00;&#x4E2A;<code>score.csv&#x6587;&#x4EF6;</code>&#xFF0C;&#x6BCF;&#x4E00;&#x5217;&#x4E3A;&#x5B66;&#x53F7;&#x548C;&#x5B66;&#x751F;&#x6210;&#x7EE9;&#xFF1A;</p>
<ul>
<li><img src="../images/spark42.png" alt="spark42"></li>
</ul>
</li>
<li><p>&#x7136;&#x540E;&#x5C06;&#x6587;&#x4EF6;&#x653E;&#x5165;<code>HDFS</code>&#x4E2D;&#xFF1A;</p>
<pre><code class="lang-shell">hdfs dfs put score.csv input
</code></pre>
</li>
</ol>
<h2 id="&#x7F16;&#x5199;&#x7A0B;&#x5E8F;">&#x7F16;&#x5199;&#x7A0B;&#x5E8F;</h2>
<pre><code class="lang-java"><span class="hljs-keyword">import</span> org.apache.spark.SparkConf;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.*;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.function.Function;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.function.Function2;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.function.PairFunction;
<span class="hljs-keyword">import</span> scala.Tuple2;


<span class="hljs-keyword">import</span> java.util.Iterator;
<span class="hljs-keyword">import</span> java.util.Random;

<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">AVGScore</span> </span>{
    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> Integer groupSize = <span class="hljs-number">5</span>;

    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>{
        SparkConf conf = <span class="hljs-keyword">new</span> SparkConf().setAppName(<span class="hljs-string">&quot;AVGScore&quot;</span>);
        JavaSparkContext sc = <span class="hljs-keyword">new</span> JavaSparkContext(conf);
        sc.setLogLevel(<span class="hljs-string">&quot;WARN&quot;</span>); <span class="hljs-comment">//http://stackoverflow.com/questions/27781187/how-to-stop-messages-displaying-on-spark-console</span>

        String logFile = <span class="hljs-string">&quot;hdfs:///user/hadoop/input/score.csv&quot;</span>;

        JavaRDD&lt;String&gt; fileRDD = sc.textFile(logFile);


        <span class="hljs-comment">/**
         * map string to (id, score) and convert to (group_id, (score,1))
         * reduceByKey =&gt; (group_id,(sumScore, count)
         * and then mapValues to avg score
         */</span>

        JavaPairRDD&lt;Integer, Double&gt; stuScore = fileRDD.mapToPair(
                line -&gt; <span class="hljs-keyword">new</span> Tuple2&lt;&gt;(
                        (Integer.parseInt(line.split(<span class="hljs-string">&quot;,&quot;</span>)[<span class="hljs-number">0</span>]) + <span class="hljs-number">1</span> )/<span class="hljs-number">5</span>, <span class="hljs-keyword">new</span> Tuple2&lt;&gt;(Double.parseDouble(line.split(<span class="hljs-string">&quot;,&quot;</span>)[<span class="hljs-number">1</span>]),<span class="hljs-number">1</span>)))
                .reduceByKey(
                        (x,y) -&gt; <span class="hljs-keyword">new</span> Tuple2&lt;&gt;(x._1 + y._1,x._2+y._2))
                .mapValues(x -&gt; x._1/x._2);

        stuScore.saveAsTextFile(<span class="hljs-string">&quot;hdfs:///user/hadoop/output/spark/AVGscore&quot;</span>);
    }
}

<span class="hljs-comment">//&#x53C2;&#x8003; : https://blog.csdn.net/gx304419380/article/details/79455833</span>
</code></pre>
<h3 id="&#x6CE8;&#x610F;&#x70B9;">&#x6CE8;&#x610F;&#x70B9;</h3>
<ul>
<li>&#x6C42;&#x5E73;&#x5747;&#x503C;&#x6709;&#x5F88;&#x591A;&#x79CD;&#x65B9;&#x6CD5;&#xFF0C;&#x8FD9;&#x91CC;&#x9009;&#x62E9;&#x7684;&#x662F;reduceByKey&#xFF0C;&#x6548;&#x7387;&#x8F83;&#x9AD8;&#xFF0C;&#x66F4;&#x591A;&#x65B9;&#x6CD5;<a href="https://blog.csdn.net/gx304419380/article/details/79455833" _target="blank">&#x53C2;&#x8003;&#x8FD9;&#x91CC;</a>&#x3002;</li>
<li>&#x591A;&#x4F7F;&#x7528;Lambda&#x51FD;&#x6570;&#xFF0C;&#x7B80;&#x5355;&#x76F4;&#x89C2;&#x3002;</li>
</ul>
<h2 id="&#x8FD0;&#x884C;">&#x8FD0;&#x884C;</h2>
<h3 id="&#x672C;&#x5730;&#x8FD0;&#x884C;">&#x672C;&#x5730;&#x8FD0;&#x884C;</h3>
<p>&#x8FD0;&#x884C;&#x7A0B;&#x5E8F;</p>
<pre><code class="lang-shell">spark-submit --class AVGScore AVGScore-1.0.jar
</code></pre>
<p>&#x67E5;&#x770B;&#x7ED3;&#x679C;&#xFF0C;&#x540C;&#x65F6;&#x67E5;&#x770B;&#x884C;&#x53F7;&#xFF1A;</p>
<pre><code class="lang-shell">hdfs dfs -cat output/spark/AVGscore/* | wc -l
</code></pre>
<p><img src="../images/spark43.png" alt="spark43"></p>
<h3 id="&#x96C6;&#x7FA4;&#x4E0A;&#x8FD0;&#x884C;">&#x96C6;&#x7FA4;&#x4E0A;&#x8FD0;&#x884C;</h3>
<p>&#x9700;&#x8981;&#x5C06;HDFS&#x5730;&#x5740;&#x66F4;&#x6539;&#x4E3A;&#x96C6;&#x7FA4;&#x7684;&#x5730;&#x5740;&#xFF0C;&#x4F8B;&#x5982;&#xFF1A;</p>
<blockquote>
<p>hdfs:///user/hadoop/input/score.csv =&gt; hdfs://10.11.6.91:9000/user/hadoop7/input/score.csv</p>
</blockquote>
<p>&#x63D0;&#x4EA4;&#x4F5C;&#x4E1A;&#x5E76;&#x8FD0;&#x884C;&#xFF1A;</p>
<pre><code class="lang-shell">spark-submit --master spark://10.11.6.91:7077 --class AVGScore AVGScore-1.0.jar
</code></pre>
<p>&#x67E5;&#x770B;&#x7ED3;&#x679C;</p>
<pre><code class="lang-shell">hdfs dfs -cat output/spark/AVGscore/*
</code></pre>
<p><img src="../images/spark44.png" alt="spark44"></p>
<h1 id="natural-join">Natural join</h1>
<h2 id="&#x6570;&#x636E;&#x51C6;&#x5907;">&#x6570;&#x636E;&#x51C6;&#x5907;</h2>
<p>&#x6709;&#x4E24;&#x4E2A;&#x6587;&#x4EF6;</p>
<ol>
<li><p>person.txt</p>
<blockquote>
<p>1 Aaron 210000</p>
<p>2 Abbott 214000
3 Abel 221000
4 Abner 215000
5 Abraham 226000
6 Adair 225300
7 Adam 223800
8 Addison 224000
9 Adolph 223001</p>
</blockquote>
</li>
<li><p>address.txt</p>
<blockquote>
<p>210000 Nanjing
214000 Wuxi
221000 Xuzhou
213000 Changzhou</p>
</blockquote>
</li>
</ol>
<p>&#x8981;&#x6C42;&#x4EE5;code&#x4E3A;&#x8FDE;&#x63A5;&#x5C5E;&#x6027;&#xFF0C;&#x5339;&#x914D;&#x51FA;person&#x4E2D;&#x6BCF;&#x4E2A;&#x4EBA;&#x6240;&#x5728;&#x7684;&#x4F4D;&#x7F6E;&#x4FE1;&#x606F;&#xFF1B;&#x6BCF;&#x6761;&#x8BB0;&#x5F55;&#x5404;&#x4E2A;&#x5B57;&#x6BB5;&#x4E4B;&#x95F4;&#x4EE5;&#x7A7A;&#x683C;&#x4E3A;&#x5206;&#x9694;&#x7B26;&#x3002;</p>
<h2 id="&#x7F16;&#x5199;&#x7A0B;&#x5E8F;">&#x7F16;&#x5199;&#x7A0B;&#x5E8F;</h2>
<pre><code class="lang-java"><span class="hljs-keyword">import</span> org.apache.commons.lang.StringUtils;
<span class="hljs-keyword">import</span> org.apache.hadoop.hdfs.protocol.DirectoryListing;
<span class="hljs-keyword">import</span> org.apache.spark.SparkConf;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.JavaPairRDD;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.JavaRDD;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.JavaSparkContext;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.function.Function;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.function.PairFunction;
<span class="hljs-keyword">import</span> scala.Tuple2;

<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">NaturalJoin</span> </span>{


    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String args[])</span> </span>{
        SparkConf conf = <span class="hljs-keyword">new</span> SparkConf().setAppName(<span class="hljs-string">&quot;NaturalJoin&quot;</span>);
        JavaSparkContext sc = <span class="hljs-keyword">new</span> JavaSparkContext(conf);
        sc.setLogLevel(<span class="hljs-string">&quot;WARN&quot;</span>); <span class="hljs-comment">//http://stackoverflow.com/questions/27781187/how-to-stop-messages-displaying-on-spark-console</span>


        String addFile = <span class="hljs-string">&quot;hdfs:///user/hadoop/input/address.txt&quot;</span>;
        String personFile = <span class="hljs-string">&quot;hdfs:///user/hadoop/input/person.txt&quot;</span>;


        <span class="hljs-comment">/***
         * return code,city
         */</span>
        JavaPairRDD&lt;Integer, String&gt; addRDD = sc.textFile(addFile).mapToPair(
                line -&gt; <span class="hljs-keyword">new</span> Tuple2&lt;&gt;(
                        Integer.parseInt(line.split(<span class="hljs-string">&quot; &quot;</span>)[<span class="hljs-number">0</span>]), line.split(<span class="hljs-string">&quot; &quot;</span>)[<span class="hljs-number">1</span>]));

        <span class="hljs-comment">/**
         * return return code,{ id + name }
         */</span>
        JavaPairRDD&lt;Integer, String&gt; personRDD = sc.textFile(personFile).mapToPair(
                <span class="hljs-keyword">new</span> PairFunction&lt;String, Integer, String&gt;() {
                    <span class="hljs-meta">@Override</span>
                    <span class="hljs-function"><span class="hljs-keyword">public</span> Tuple2&lt;Integer, String&gt; <span class="hljs-title">call</span><span class="hljs-params">(String s)</span> <span class="hljs-keyword">throws</span> Exception </span>{
                        String[] splitLines = StringUtils.split(s, <span class="hljs-string">&quot; &quot;</span>);
                        <span class="hljs-keyword">if</span> (splitLines.length &lt; <span class="hljs-number">3</span>)
                            <span class="hljs-keyword">return</span> <span class="hljs-keyword">null</span>;
                        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> Tuple2&lt;&gt;(Integer.parseInt(splitLines[<span class="hljs-number">2</span>]), splitLines[<span class="hljs-number">0</span>] + splitLines[<span class="hljs-number">1</span>]);
                    }
                }
        );

        <span class="hljs-comment">/**
         * return code, [{id + name}, city]
         */</span>
        JavaPairRDD&lt;Integer, Tuple2&lt;String,String&gt;&gt; resultRDD = personRDD.join(addRDD);

        resultRDD.saveAsTextFile(<span class="hljs-string">&quot;hdfs:///user/hadoop/output/spark/NaturalJoin&quot;</span>);
    }
}
</code></pre>
<h3 id="&#x6CE8;&#x610F;&#x70B9;">&#x6CE8;&#x610F;&#x70B9;</h3>
<ul>
<li>&#x672C;&#x64CD;&#x4F5C;&#x6BD4;&#x8F83;&#x7E41;&#x7410;&#xFF0C;&#x9700;&#x8981;&#x5148;&#x751F;&#x6210;<code>JavaPairRDD</code>&#xFF0C;&#x518D;&#x4F7F;&#x7528;<code>Join</code>&#xFF0C;&#x672A;&#x6765;&#x53EF;&#x4EE5;&#x5C1D;&#x8BD5;&#x4F7F;&#x7528;<code>DataFrame</code>&#x6267;&#x884C;&#x3002;</li>
</ul>
<h2 id="&#x8FD0;&#x884C;">&#x8FD0;&#x884C;</h2>
<h3 id="&#x672C;&#x5730;&#x8FD0;&#x884C;">&#x672C;&#x5730;&#x8FD0;&#x884C;</h3>
<p>&#x8FD0;&#x884C;&#x7A0B;&#x5E8F;&#x5E76;&#x67E5;&#x770B;&#x7ED3;&#x679C;</p>
<pre><code class="lang-shell"> spark-submit --class NaturalJoin NaturalJoin-1.0.jar 
 hdfs dfs -cat output/spark/NaturalJoin/*
</code></pre>
<h3 id="&#x96C6;&#x7FA4;&#x4E0A;&#x8FD0;&#x884C;">&#x96C6;&#x7FA4;&#x4E0A;&#x8FD0;&#x884C;</h3>
<p>&#x9700;&#x8981;&#x5C06;HDFS&#x5730;&#x5740;&#x66F4;&#x6539;&#x4E3A;&#x96C6;&#x7FA4;&#x7684;&#x5730;&#x5740;&#xFF0C;&#x4F8B;&#x5982;&#xFF1A;</p>
<blockquote>
<p>hdfs:///user/hadoop/input/address.txt =&gt; hdfs://10.11.6.91:9000/user/hadoop7/input/address.txt </p>
</blockquote>
<p>&#x63D0;&#x4EA4;&#x4F5C;&#x4E1A;&#x5E76;&#x8FD0;&#x884C;&#xFF1A;</p>
<pre><code class="lang-shell">spark-submit --master spark://10.11.6.91:7077 --class NaturalJoin NaturalJoin-1.0.jar
</code></pre>
<p>&#x67E5;&#x770B;&#x7ED3;&#x679C;</p>
<pre><code class="lang-shell">hdfs dfs -cat output/spark/NaturalJoin/*
</code></pre>
<p><img src="../images/spark45.png" alt="spark45"></p>
<h1 id="kmeans">Kmeans</h1>
<h2 id="&#x6570;&#x636E;&#x51C6;&#x5907;">&#x6570;&#x636E;&#x51C6;&#x5907;</h2>
<p>&#x8F93;&#x5165;&#x6570;&#x636E;&#xFF08;<code>k-means.dat</code>&#xFF09;&#xFF1A;</p>
<blockquote>
<p>4,400
96,826
606,776
474,866
400,768
2,920
356,766
36,687
-26,824</p>
</blockquote>
<ul>
<li>&#x7B2C;&#x4E00;&#x884C;&#x6807;&#x660E;K&#x7684;&#x503C;&#x548C;&#x6570;&#x636E;&#x4E2A;&#x6570;N, &#x5747;&#x4E3A;&#x6574;&#x5F62;, &#x7531;&quot;,&quot;&#x9694;&#x5F00; (&#x5982; 3,10 &#x8868;&#x793A;K=3, N=10)&#x3002;</li>
<li>&#x4E4B;&#x540E;N&#x884C;&#x4E2D;&#x6BCF;&#x884C;&#x4EE3;&#x8868;&#x4E00;&#x4E2A;&#x4E8C;&#x7EF4;&#x5411;&#x91CF;, &#x5411;&#x91CF;&#x5143;&#x7D20;&#x5747;&#x4E3A;&#x6574;&#x5F62;, &#x7531;&quot;,&quot;&#x9694;&#x5F00; (&#x5982; 1,2 &#x8868;&#x793A;&#x5411;&#x91CF;(1, 2))&#x3002;</li>
</ul>
<p>&#x8F93;&#x51FA;: K&#x884C;, &#x6BCF;&#x884C;&#x662F;&#x4E00;&#x4E2A;&#x805A;&#x7C7B;&#x56FE;&#x5FC3;&#x7684;&#x4E8C;&#x7EF4;&#x5411;&#x91CF;, &#x5411;&#x91CF;&#x5143;&#x7D20;&#x5747;&#x4E3A;&#x6D6E;&#x70B9;&#x578B; (&#x5982; 1.1,2.3)&#x3002;</p>
<h2 id="&#x7F16;&#x5199;&#x7A0B;&#x5E8F;">&#x7F16;&#x5199;&#x7A0B;&#x5E8F;</h2>
<h3 id="kmeansjava">Kmeans.java</h3>
<pre><code class="lang-java"><span class="hljs-keyword">import</span> org.apache.spark.api.java.JavaPairRDD;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.JavaRDD;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.JavaSparkContext;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.function.Function2;
<span class="hljs-keyword">import</span> scala.Serializable;
<span class="hljs-keyword">import</span> scala.Tuple2;

<span class="hljs-keyword">import</span> java.util.ArrayList;
<span class="hljs-keyword">import</span> java.util.List;

<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Kmeans</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">KmeansInterface</span>, <span class="hljs-title">Serializable</span> </span>{

    <span class="hljs-comment">// every point has a cluster number and point(x,y)</span>
    <span class="hljs-keyword">private</span> List&lt;Tuple2&lt;Integer, Point&gt;&gt; oldCenterList = <span class="hljs-keyword">new</span> ArrayList&lt;&gt;();
    <span class="hljs-keyword">private</span> List&lt;Tuple2&lt;Integer, Point&gt;&gt; newCenterList = <span class="hljs-keyword">new</span> ArrayList&lt;&gt;();
    <span class="hljs-keyword">private</span> <span class="hljs-keyword">double</span> threshold = <span class="hljs-number">0.000001</span>;


    <span class="hljs-comment">/**
     * <span class="hljs-doctag">@param</span> point
     * <span class="hljs-doctag">@return</span> cluster belonged
     * <span class="hljs-doctag">@Method</span> get the closest cluster for the point
     */</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">findClosest</span><span class="hljs-params">(Point point)</span> </span>{
        <span class="hljs-keyword">int</span> argmin = -<span class="hljs-number">1</span>;
        <span class="hljs-keyword">double</span> minimalDistance = Double.MAX_VALUE;
        <span class="hljs-keyword">for</span> (Tuple2&lt;Integer, Point&gt; i : oldCenterList) {
            <span class="hljs-keyword">double</span> distance = point.EuclideanDis(i._2);
            <span class="hljs-keyword">if</span> (distance &lt; minimalDistance) {
                minimalDistance = distance;
                argmin = i._1;
            }
        }
        <span class="hljs-keyword">return</span> argmin;
    }


    <span class="hljs-comment">/**
     * <span class="hljs-doctag">@param</span> outFile string
     * <span class="hljs-doctag">@Method</span> save center to txt
     */</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">saveToFile</span><span class="hljs-params">(String outFile, JavaSparkContext sc)</span> </span>{
        List&lt;String&gt; outCenterList = <span class="hljs-keyword">new</span> ArrayList&lt;&gt;();
<span class="hljs-comment">//        format center points</span>
        <span class="hljs-keyword">for</span> (Tuple2&lt;Integer, Point&gt; tmp : newCenterList) {
            outCenterList.add(String.valueOf(tmp._2.getX()) + <span class="hljs-string">&quot; &quot;</span> + String.valueOf(tmp._2.getY()));
        }

        JavaRDD&lt;String&gt; center = sc.parallelize(outCenterList);
        center.saveAsTextFile(outFile);
    }


    <span class="hljs-comment">/**
     * <span class="hljs-doctag">@return</span> False for not stable
     * <span class="hljs-doctag">@Method</span> compare two cluster center with threshold
     */</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">boolean</span> <span class="hljs-title">clusterCompare</span><span class="hljs-params">()</span> </span>{

        <span class="hljs-keyword">for</span> (Tuple2&lt;Integer, Point&gt; oldCenter : oldCenterList) {
            <span class="hljs-keyword">int</span> clusterNum = oldCenter._1;
            <span class="hljs-keyword">for</span> (Tuple2&lt;Integer, Point&gt; newCenter : newCenterList) {
                <span class="hljs-keyword">if</span> (newCenter._1 == clusterNum) {
                    <span class="hljs-keyword">double</span> dis = oldCenter._2.EuclideanDis(newCenter._2);
                    <span class="hljs-keyword">if</span> (dis &gt; threshold)
                        <span class="hljs-keyword">return</span> <span class="hljs-keyword">false</span>;
                    <span class="hljs-keyword">break</span>;
                }
            }
        }
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">true</span>;
    }


    <span class="hljs-comment">/**
     * <span class="hljs-doctag">@param</span> kmeansRDD
     * <span class="hljs-doctag">@return</span> init pointsRDD
     * <span class="hljs-doctag">@Method</span> prepare Points RDD and select clusters randomly
     */</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> JavaPairRDD&lt;Integer, Point&gt; <span class="hljs-title">Prepare</span><span class="hljs-params">(JavaRDD&lt;String&gt; kmeansRDD)</span> </span>{
        <span class="hljs-comment">// get the number of cluster</span>
        String fisrtLine = kmeansRDD.first();
        <span class="hljs-keyword">int</span> clusterCount = Integer.parseInt(fisrtLine.split(<span class="hljs-string">&quot;,&quot;</span>)[<span class="hljs-number">0</span>]);

<span class="hljs-comment">//        filter first line and convert to &lt;Point,clusternum&gt;, init set all cluster number 1</span>
        JavaPairRDD&lt;Integer, Point&gt; pointsRDD = kmeansRDD.filter(line -&gt; !line.equals(fisrtLine)).mapToPair(
                line -&gt; {
                    String[] splitLine = line.split(<span class="hljs-string">&quot;,&quot;</span>);
                    <span class="hljs-keyword">double</span> X = Double.parseDouble(splitLine[<span class="hljs-number">0</span>]);
                    <span class="hljs-keyword">double</span> Y = Double.parseDouble(splitLine[<span class="hljs-number">1</span>]);
                    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> Tuple2&lt;&gt;(<span class="hljs-number">0</span>, <span class="hljs-keyword">new</span> Point(X, Y));
                }
        );

<span class="hljs-comment">//       init center list</span>
        oldCenterList.addAll(pointsRDD.take(clusterCount));

        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; clusterCount; i++) {
            Tuple2&lt;Integer, Point&gt; tmp = oldCenterList.get(i);
            oldCenterList.set(i, <span class="hljs-keyword">new</span> Tuple2&lt;&gt;(i, tmp._2));
        }

        newCenterList.addAll(oldCenterList);

        <span class="hljs-keyword">return</span> pointsRDD;

    }


    <span class="hljs-comment">/**
     * <span class="hljs-doctag">@param</span> pointsRDD to cluster
     * <span class="hljs-doctag">@return</span> new classify PointsRDD
     * <span class="hljs-doctag">@method</span> cluster and update new cluster center
     */</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> JavaPairRDD&lt;Integer, Point&gt; <span class="hljs-title">cluster</span><span class="hljs-params">(JavaPairRDD&lt;Integer, Point&gt; pointsRDD)</span> </span>{

        JavaPairRDD&lt;Integer, Point&gt; newPointsRDD = pointsRDD.mapToPair(
                kv -&gt; <span class="hljs-keyword">new</span> Tuple2&lt;&gt;(findClosest(kv._2), kv._2)
        );

        JavaPairRDD&lt;Integer, Point&gt; newClusterRDD = newPointsRDD
                .mapValues(
                        value -&gt; <span class="hljs-keyword">new</span> Tuple2&lt;&gt;(value, <span class="hljs-number">1</span>))
                .reduceByKey(
                        <span class="hljs-keyword">new</span> Function2&lt;Tuple2&lt;Point, Integer&gt;, Tuple2&lt;Point, Integer&gt;, Tuple2&lt;Point, Integer&gt;&gt;() {
                            <span class="hljs-meta">@Override</span>
                            <span class="hljs-function"><span class="hljs-keyword">public</span> Tuple2&lt;Point, Integer&gt; <span class="hljs-title">call</span><span class="hljs-params">(Tuple2&lt;Point, Integer&gt; value1, Tuple2&lt;Point, Integer&gt; value2)</span> <span class="hljs-keyword">throws</span> Exception </span>{
                                Point tmp = <span class="hljs-keyword">new</span> Point(value1._1.getX() + value2._1.getX(), value1._1.getY() + value2._1.getY());
                                <span class="hljs-keyword">int</span> count = value1._2 + value2._2;
                                <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> Tuple2&lt;&gt;(tmp, count);
                            }
                        }
                ).mapValues(
                        v -&gt; <span class="hljs-keyword">new</span> Point(v._1.getX() / v._2, v._1.getY() / v._2)
                );

        oldCenterList.clear();
        oldCenterList.addAll(newCenterList);
        <span class="hljs-comment">// convert to list to store</span>
        newCenterList.clear();
        newCenterList.addAll(newClusterRDD.collect());

        <span class="hljs-keyword">return</span> newPointsRDD;
    }

}
</code></pre>
<h3 id="kmeansrunjava">kmeansRun.java</h3>
<pre><code class="lang-java"><span class="hljs-keyword">import</span> org.apache.spark.SparkConf;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.JavaPairRDD;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.JavaRDD;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.JavaSparkContext;
<span class="hljs-keyword">import</span> scala.Tuple2;

<span class="hljs-keyword">import</span> java.util.ArrayList;
<span class="hljs-keyword">import</span> java.util.List;

<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">kmeansRun</span> </span>{

    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String args[])</span> </span>{
        Kmeans kmeans = <span class="hljs-keyword">new</span> Kmeans();

        SparkConf conf = <span class="hljs-keyword">new</span> SparkConf().setAppName(<span class="hljs-string">&quot;Kmeans&quot;</span>);
        JavaSparkContext sc = <span class="hljs-keyword">new</span> JavaSparkContext(conf);

        String kmeansFile = <span class="hljs-string">&quot;hdfs://10.11.6.91:9000/user/hadoop7/input/k-means.dat&quot;</span>;
        String outFile = <span class="hljs-string">&quot;hdfs://10.11.6.91:9000/user/hadoop7/output/spark/kmeans&quot;</span>;

        <span class="hljs-keyword">int</span> counter = <span class="hljs-number">1</span>, maxIteration = <span class="hljs-number">500</span>;
        <span class="hljs-keyword">boolean</span> result = <span class="hljs-keyword">false</span>;

        JavaRDD&lt;String&gt; kmeansRDD = sc.textFile(kmeansFile).cache();

<span class="hljs-comment">//        init centerList and Points RDD</span>
        JavaPairRDD&lt;Integer, Point&gt; PointsRDD = kmeans.Prepare(kmeansRDD);

        <span class="hljs-keyword">while</span> (!result &amp;&amp; counter &lt; maxIteration) {
            PointsRDD = kmeans.cluster(PointsRDD);

            result = kmeans.clusterCompare();
            System.out.println(<span class="hljs-string">&quot;*******KMEANS finished iteration:&gt;&gt; &quot;</span> + counter + <span class="hljs-string">&quot; || means stable: &quot;</span> + result);
            counter++;
        }

        kmeans.saveToFile(outFile,sc);

    }
}
</code></pre>
<h3 id="&#x6CE8;&#x610F;&#x4E8B;&#x9879;">&#x6CE8;&#x610F;&#x4E8B;&#x9879;</h3>
<ul>
<li>&#x5C06;&#x7C7B;&#x6210;&#x5458;&#x51FD;&#x6570;&#x7684;&#x58F0;&#x660E;&#x548C;&#x5B9A;&#x4E49;&#x5206;&#x5F00;&#x5199;&#xFF0C;&#x7528;interface&#x6765;&#x5B9A;&#x4E49;&#x62BD;&#x8C61;&#x51FD;&#x6570;&#x3002;</li>
<li>&#x5728;&#x5FAA;&#x73AF;&#x8FC7;&#x7A0B;&#x4E2D;&#xFF0C;&#x867D;&#x7136;&#x53D8;&#x91CF;&#x540D;&#x6CA1;&#x6709;&#x6539;&#x53D8;&#xFF0C;&#x4F46;&#x53EA;&#x662F;&#x6307;&#x5411;&#x90A3;&#x4E00;&#x4E2A;RDD&#xFF0C;&#x800C;&#x6BCF;&#x6B21;&#x5FAA;&#x73AF;RDD&#x90FD;&#x5728;&#x53D8;&#x5316;&#x3002;</li>
</ul>
<h2 id="&#x8FD0;&#x884C;">&#x8FD0;&#x884C;</h2>
<h3 id="&#x672C;&#x5730;&#x8FD0;&#x884C;">&#x672C;&#x5730;&#x8FD0;&#x884C;</h3>
<p>&#x8FD0;&#x884C;&#x7A0B;&#x5E8F;</p>
<pre><code class="lang-shell">spark-submit --class kmeansRun Kmeans-1.0.jar 2&gt;&amp;1 | grep &quot;KMEANS finished iteration:&quot;
</code></pre>
<p><img src="../images/spark46.png" alt="spark46"></p>
<p>&#x67E5;&#x770B;&#x7ED3;&#x679C;</p>
<pre><code class="lang-shell">hdfs dfs -cat output/spark/kmeans/*
</code></pre>
<p><img src="../images/spark47.png" alt="spark47"></p>
<h3 id="&#x96C6;&#x7FA4;&#x4E0A;&#x8FD0;&#x884C;">&#x96C6;&#x7FA4;&#x4E0A;&#x8FD0;&#x884C;</h3>
<p>&#x9700;&#x8981;&#x5C06;HDFS&#x5730;&#x5740;&#x66F4;&#x6539;&#x4E3A;&#x96C6;&#x7FA4;&#x7684;&#x5730;&#x5740;&#xFF0C;&#x4F8B;&#x5982;&#xFF1A;</p>
<blockquote>
<p>hdfs:///user/hadoop/input/k-means.dat =&gt; hdfs://10.11.6.91:9000/user/hadoop7/input/k-means.dat</p>
</blockquote>
<p>&#x63D0;&#x4EA4;&#x4F5C;&#x4E1A;&#x5E76;&#x8FD0;&#x884C;&#xFF1A;</p>
<pre><code>spark-submit --master spark://10.11.6.91:7077 --class kmeansRun Kmeans-1.0.jar 2&gt;&amp;1 | grep &quot;KMEANS finished iteration:&quot;
</code></pre><p><img src="../images/spark48.png" alt="spark48"></p>
<p>&#x67E5;&#x770B;&#x7ED3;&#x679C;&#xFF1A;</p>
<p><img src="../images/spark49.png" alt="spark49"></p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="spark1.html" class="navigation navigation-prev " aria-label="Previous page: spark编程实践">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="spark-recap.html" class="navigation navigation-next " aria-label="Next page: Spark 编程总结">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"spark编程练习","level":"1.3.9","depth":2,"next":{"title":"Spark 编程总结","level":"1.3.10","depth":2,"path":"project/spark-recap.md","ref":"project/spark-recap.md","articles":[]},"previous":{"title":"spark编程实践","level":"1.3.8","depth":2,"path":"project/spark1.md","ref":"project/spark1.md","articles":[]},"dir":"ltr"},"config":{"plugins":["github","disqus","katex-plus","ga","back-to-top-button","-lunr","-search","search-pro","expandable-chapters"],"ignores":["node_modules","_book"],"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"disqus":{"shortName":"techzealscott","useIdentifier":false},"github":{"url":"https://github.com/scottdyt"},"search-pro":{},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"katex-plus":{},"back-to-top-button":{},"ga":{"token":"UA-116370175-1","configuration":"auto"},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false},"expandable-chapters":{}},"theme":"default","author":"zealscott","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"sortedBy":" ","variables":{},"title":"Distribution System","links":{"sidebar":{"Homepage":"https://tech.zealscott.com"}},"gitbook":"*"},"file":{"path":"project/spark2.md","mtime":"2021-01-27T07:18:29.225Z","type":"markdown"},"gitbook":{"version":"3.0.0","time":"2021-03-04T09:58:50.487Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-github/plugin.js"></script>
        
    
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/URI.js/1.16.1/URI.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-disqus/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-ga/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-back-to-top-button/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search-pro/jquery.mark.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search-pro/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-expandable-chapters/expandable-chapters.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/buttons.js"></script>
        
    

    </body>
</html>

