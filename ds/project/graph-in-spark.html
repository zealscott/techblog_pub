
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <title>常用图算法实现--Spark · Distribution System</title>
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.0.0">
        <meta name="author" content="zealscott">
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-disqus/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-katex-plus/katex.min.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-back-to-top-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search-pro/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-expandable-chapters/expandable-chapters.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="graph-in-flink.html" />
    
    
    <link rel="prev" href="graph-in-hadoop.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    
    
        
        <li>
            <a href="https://tech.zealscott.com" target="_blank" class="custom-link">Homepage</a>
        </li>
    
    

    
    <li class="divider"></li>
    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" >
            
                <span>
            
                    
                    Notes
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="../notes/Distribution-File-System-DFS.html">
            
                <a href="../notes/Distribution-File-System-DFS.html">
            
                    
                    Distribution File System DFS
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="../notes/mapreduce.html">
            
                <a href="../notes/mapreduce.html">
            
                    
                    MapReduce处理系统
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3" data-path="../notes/mrcoding.html">
            
                <a href="../notes/mrcoding.html">
            
                    
                    MapReduce编程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4" data-path="../notes/RPC-and-serialization.html">
            
                <a href="../notes/RPC-and-serialization.html">
            
                    
                    RPC And Serialization
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.5" data-path="../notes/spark.html">
            
                <a href="../notes/spark.html">
            
                    
                    Spark 处理框架
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.6" data-path="../notes/sparkcoding.html">
            
                <a href="../notes/sparkcoding.html">
            
                    
                    Spark 编程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.7" data-path="../notes/yarn.html">
            
                <a href="../notes/yarn.html">
            
                    
                    Yarn 资源管理框架
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.8" data-path="../notes/zookeeper.html">
            
                <a href="../notes/zookeeper.html">
            
                    
                    ZooKeeper 元数据管理系统
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.9" data-path="../notes/pregel.html">
            
                <a href="../notes/pregel.html">
            
                    
                    分布式图处理系统--Pregel
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.10" data-path="../notes/flink.html">
            
                <a href="../notes/flink.html">
            
                    
                    批流融合系统--Flink
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.11" data-path="../notes/beam.html">
            
                <a href="../notes/beam.html">
            
                    
                    批流融合系统--展望
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.12" data-path="../notes/ps.html">
            
                <a href="../notes/ps.html">
            
                    
                    机器学习系统--Parameter Server
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.13" data-path="../notes/graphlab.html">
            
                <a href="../notes/graphlab.html">
            
                    
                    机器学习系统--GraphLab
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.14" data-path="../notes/mahout.html">
            
                <a href="../notes/mahout.html">
            
                    
                    机器学习系统--mahout
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.15" data-path="../notes/stream.html">
            
                <a href="../notes/stream.html">
            
                    
                    流计算系统概述
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" >
            
                <span>
            
                    
                    Lab
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="rpc.html">
            
                <a href="rpc.html">
            
                    
                    RPC model in Java
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="hadoop.html">
            
                <a href="hadoop.html">
            
                    
                    hadoop安装与配置
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="hadoop1.html">
            
                <a href="hadoop1.html">
            
                    
                    hadoop编程实践（一）
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="hadoop2.html">
            
                <a href="hadoop2.html">
            
                    
                    hadoop编程实践（二）
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="hadoop-coding.html">
            
                <a href="hadoop-coding.html">
            
                    
                    hadoop编程练习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.6" data-path="hadoop-recap.html">
            
                <a href="hadoop-recap.html">
            
                    
                    Hadoop 编程总结
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.7" data-path="spark-installation.html">
            
                <a href="spark-installation.html">
            
                    
                    spark安装与配置
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.8" data-path="spark1.html">
            
                <a href="spark1.html">
            
                    
                    spark编程实践
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.9" data-path="spark2.html">
            
                <a href="spark2.html">
            
                    
                    spark编程练习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.10" data-path="spark-recap.html">
            
                <a href="spark-recap.html">
            
                    
                    Spark 编程总结
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.11" data-path="docker1.html">
            
                <a href="docker1.html">
            
                    
                    使用 Docker 配置 hadoop/spark
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.12" data-path="docker2.html">
            
                <a href="docker2.html">
            
                    
                    使用 docker 搭建 spark(2.3.1) 集群
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.13" data-path="zookeeper.html">
            
                <a href="zookeeper.html">
            
                    
                    ZooKeeper配置及简单使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.14" data-path="yarn.html">
            
                <a href="yarn.html">
            
                    
                    Yarn框架下的系统部署
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.15" data-path="storm-installation.html">
            
                <a href="storm-installation.html">
            
                    
                    Storm部署与运行
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.16" data-path="storm-coding.html">
            
                <a href="storm-coding.html">
            
                    
                    Storm编程练习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.17" data-path="storm-summary.html">
            
                <a href="storm-summary.html">
            
                    
                    Storm 编程总结
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.18" data-path="sparksteaming.html">
            
                <a href="sparksteaming.html">
            
                    
                    SparkSteaming使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.19" data-path="flink-installation.html">
            
                <a href="flink-installation.html">
            
                    
                    Flink安装及使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.20" data-path="flink1.html">
            
                <a href="flink1.html">
            
                    
                    Flink编程练习（一）
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.21" data-path="flink2.html">
            
                <a href="flink2.html">
            
                    
                    Flink编程练习（二）
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.22" data-path="graph-in-hadoop.html">
            
                <a href="graph-in-hadoop.html">
            
                    
                    常用图算法实现--Hadoop
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.3.23" data-path="graph-in-spark.html">
            
                <a href="graph-in-spark.html">
            
                    
                    常用图算法实现--Spark
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.24" data-path="graph-in-flink.html">
            
                <a href="graph-in-flink.html">
            
                    
                    常用图算法实现--Flink
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.25" data-path="giraph.html">
            
                <a href="giraph.html">
            
                    
                    Giraph配置及使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.26" data-path="flink-iteration.html">
            
                <a href="flink-iteration.html">
            
                    
                    Flink迭代小记
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" >
            
                <span>
            
                    
                    Recap
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="../recap/fundamental-of-distributed-system.html">
            
                <a href="../recap/fundamental-of-distributed-system.html">
            
                    
                    分布式系统基础
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2" data-path="../recap/batch-system.html">
            
                <a href="../recap/batch-system.html">
            
                    
                    批处理系统
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3" data-path="../recap/management-system.html">
            
                <a href="../recap/management-system.html">
            
                    
                    支持数据管理的底层系统
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.4" data-path="../recap/streaming-system.html">
            
                <a href="../recap/streaming-system.html">
            
                    
                    流处理系统
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5" data-path="../recap/flink.html">
            
                <a href="../recap/flink.html">
            
                    
                    批流融合系统
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.6" data-path="../recap/graph.html">
            
                <a href="../recap/graph.html">
            
                    
                    图处理系统
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.7" data-path="../recap/ml.html">
            
                <a href="../recap/ml.html">
            
                    
                    机器学习系统
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.8" data-path="../recap/summary.html">
            
                <a href="../recap/summary.html">
            
                    
                    总结与对比
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >常用图算法实现--Spark</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="pagerank">PageRank</h1>
<h2 id="&#x6570;&#x636E;&#x51C6;&#x5907;">&#x6570;&#x636E;&#x51C6;&#x5907;</h2>
<p>&#x8FB9;&#xFF1A;</p>
<pre><code>1 2
1 15
2 3
2 4
2 5
2 6
2 7
3 13
4 2
5 11
5 12
6 1
6 7
6 8
7 1
7 8
8 1
8 9
8 10
9 14
9 1
10 1
10 13
11 12
11 1
12 1
13 14
14 12
15 1
</code></pre><p>&#x7F51;&#x9875;&#xFF1A;</p>
<pre><code>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</code></pre><p>&#x5C06;&#x8FD9;&#x4E24;&#x4E2A;&#x6587;&#x4EF6;&#x653E;&#x5165;HDFS&#xFF1A;</p>
<pre><code class="lang-shell">hdfs dfs -mkdir input/PageRank
hdfs dfs -put links.txt input/PageRank
hdfs dfs -put pages.txt input/PageRank
</code></pre>
<h2 id="&#x7F16;&#x5199;&#x7A0B;&#x5E8F;">&#x7F16;&#x5199;&#x7A0B;&#x5E8F;</h2>
<pre><code class="lang-java"><span class="hljs-keyword">import</span> org.apache.spark.SparkConf;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.*;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.function.Function;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.function.PairFunction;
<span class="hljs-keyword">import</span> scala.Tuple2;

<span class="hljs-keyword">import</span> <span class="hljs-keyword">static</span> java.lang.Math.abs;


<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">PageRank</span> </span>{
    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">int</span> MaxIteration = <span class="hljs-number">100</span>;
    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">double</span> DAMPENING_FACTOR = <span class="hljs-number">0.85</span>;
    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">double</span> EPSILON = <span class="hljs-number">0.0001</span>;

    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>{
        SparkConf conf = <span class="hljs-keyword">new</span> SparkConf().setAppName(<span class="hljs-string">&quot;PageRank&quot;</span>);
        JavaSparkContext sc = <span class="hljs-keyword">new</span> JavaSparkContext(conf);
        sc.setLogLevel(<span class="hljs-string">&quot;WARN&quot;</span>);

        String linksFile = <span class="hljs-string">&quot;hdfs:///user/hadoop/input/PageRank/links.txt&quot;</span>;
        String pagesFile = <span class="hljs-string">&quot;hdfs:///user/hadoop/input/PageRank/pages.txt&quot;</span>;
        String rankFile = <span class="hljs-string">&quot;hdfs:///user/hadoop/output/Graph/SparkPageRank&quot;</span>;

        <span class="hljs-comment">/**
         *  neighborRDD: (from, s)
         *  linksRDD: tuple (from, [to,1/m])
         *  pageRDD: vertex
         *  pageRankRDD: (point, 1/n)
         */</span>


        JavaPairRDD&lt;Integer, Integer&gt; neighborRDD = sc.textFile(linksFile)
                .mapToPair(
                        line -&gt; <span class="hljs-keyword">new</span> Tuple2&lt;&gt;(
                                Integer.parseInt(line.split(<span class="hljs-string">&quot; &quot;</span>)[<span class="hljs-number">0</span>]), <span class="hljs-number">1</span>))
                .reduceByKey((x, y) -&gt; x + y);

        JavaPairRDD&lt;Integer, Tuple2&lt;Integer, Integer&gt;&gt; linksRDD = sc.textFile(linksFile)
                .mapToPair(
                        line -&gt; <span class="hljs-keyword">new</span> Tuple2&lt;&gt;(
                                Integer.parseInt(line.split(<span class="hljs-string">&quot; &quot;</span>)[<span class="hljs-number">0</span>]),
                                Integer.parseInt(line.split(<span class="hljs-string">&quot; &quot;</span>)[<span class="hljs-number">1</span>])
                        ))
                .join(neighborRDD);

        JavaRDD&lt;Integer&gt; pagesRDD = sc.textFile(pagesFile).map(line -&gt; Integer.parseInt(line));
        <span class="hljs-keyword">long</span> pageCount = pagesRDD.count();
        JavaPairRDD&lt;Integer, Double&gt; pageRankRDD = pagesRDD.mapToPair(
                vertex -&gt; <span class="hljs-keyword">new</span> Tuple2&lt;&gt;(vertex, <span class="hljs-number">1.0</span> / pageCount)
        );

        <span class="hljs-keyword">int</span> count = <span class="hljs-number">0</span>;
        <span class="hljs-keyword">while</span> (count &lt; MaxIteration) {
            JavaPairRDD&lt;Integer, Double&gt; NewPageRankRDD = linksRDD.join(pageRankRDD)
                    .mapToPair(
                            <span class="hljs-keyword">new</span> PairFunction&lt;Tuple2&lt;Integer, Tuple2&lt;Tuple2&lt;Integer, Integer&gt;, Double&gt;&gt;, Integer, Double&gt;() {
                                <span class="hljs-meta">@Override</span>
                                <span class="hljs-function"><span class="hljs-keyword">public</span> Tuple2&lt;Integer, Double&gt; <span class="hljs-title">call</span><span class="hljs-params">(Tuple2&lt;Integer, Tuple2&lt;Tuple2&lt;Integer, Integer&gt;, Double&gt;&gt; ans)</span> <span class="hljs-keyword">throws</span> Exception </span>{
<span class="hljs-comment">//                               // [ toNode, fraction * rank]</span>
                                    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> Tuple2&lt;&gt;(ans._2._1._1, ans._2._2/ans._2._1._2);
                                }
                            })
                    .reduceByKey((v1, v2) -&gt; v1 + v2)
                    .mapValues(
                            <span class="hljs-keyword">new</span> Function&lt;Double, Double&gt;() {
                                <span class="hljs-keyword">double</span> dampening = DAMPENING_FACTOR;
                                <span class="hljs-keyword">double</span> randomJump = (<span class="hljs-number">1</span> - DAMPENING_FACTOR) / pageCount;

                                <span class="hljs-meta">@Override</span>
                                <span class="hljs-function"><span class="hljs-keyword">public</span> Double <span class="hljs-title">call</span><span class="hljs-params">(Double value)</span> <span class="hljs-keyword">throws</span> Exception </span>{
                                    value = value * dampening + randomJump;
                                    <span class="hljs-keyword">return</span> value;
                                }
                            }
                    );
            count++;
            JavaPairRDD&lt;Integer, Tuple2&lt;Double, Double&gt;&gt; compare = pageRankRDD.join(NewPageRankRDD).filter(each -&gt; abs(each._2._1 - each._2._2) &gt; EPSILON);
            <span class="hljs-keyword">if</span> (compare.isEmpty() || count &gt; MaxIteration)
                <span class="hljs-keyword">break</span>;
            pageRankRDD = NewPageRankRDD;

        }

        pageRankRDD.saveAsTextFile(rankFile);

    }
}
</code></pre>
<p>&#x601D;&#x8DEF;&#xFF1A;</p>
<ol>
<li>&#x5168;&#x90E8;&#x4F7F;&#x7528;Lambda&#x8868;&#x8FBE;&#x5F0F;&#x8FDB;&#x884C;&#xFF0C;&#x9996;&#x5148;&#x9700;&#x8981;&#x627E;&#x5230;&#x6240;&#x6709;&#x7684;&#x8FB9;&#x7684;&#x6761;&#x6570;&#xFF0C;&#x521D;&#x59CB;&#x5316;Rank&#x503C;</li>
<li>&#x7136;&#x540E;&#x4F7F;&#x7528;Join&#x8FDB;&#x884C;&#x5408;&#x5E76;&#xFF0C;&#x5E76;&#x8BA1;&#x7B97;&#x4E0B;&#x4E00;&#x8F6E;Rank</li>
<li>&#x4F7F;&#x7528;<code>DAMPENING_FACTOR</code>&#x8FDB;&#x884C;&#x968F;&#x673A;&#x8DF3;&#x8F6C;</li>
</ol>
<h2 id="&#x8FD0;&#x884C;">&#x8FD0;&#x884C;</h2>
<pre><code>spark-submit  --class PageRank PageRank-1.0.jar
hdfs dfs -cat output/Graph/SparkPageRank/*
</code></pre><p>&#x7ED3;&#x679C;&#x4E3A;&#xFF1A;</p>
<p><img src="../images/graph8.png" alt="graph8"></p>
<h1 id="connectedcomponents">ConnectedComponents</h1>
<h2 id="&#x6570;&#x636E;&#x51C6;&#x5907;">&#x6570;&#x636E;&#x51C6;&#x5907;</h2>
<p>&#x63D0;&#x4F9B;&#x57FA;&#x672C;&#x6570;&#x636E;&#x96C6;&#xFF0C;&#x4E0E;PageRank&#x4E00;&#x6837;&#xFF0C;&#x6307;&#x5B9A;&#x9876;&#x70B9;&#x548C;&#x8FB9;</p>
<h3 id="verticestxt">vertices.txt</h3>
<p>&#x51C6;&#x5907;&#x4E00;&#x4E9B;&#x9876;&#x70B9;&#xFF0C;&#x4F8B;&#x5982;1-16</p>
<h3 id="edgestxt">edges.txt</h3>
<p>&#x51C6;&#x5907;&#x4E00;&#x4E9B;&#x8FDE;&#x63A5;&#x8FB9;&#xFF1A;</p>
<pre><code>1 2
2 3
2 4
3 5
6 7
8 9
8 10
5 11
11 12
10 13
9 14
13 14
1 15
16 1
</code></pre><p>&#x5C06;&#x8FD9;&#x4E24;&#x4E2A;&#x6587;&#x4EF6;&#x653E;&#x5165;HDFS&#xFF1A;</p>
<pre><code class="lang-shell">hdfs dfs -mkdir input/ConnectedComponents
hdfs dfs -put edges.txt input/ConnectedComponents
hdfs dfs -put vertices.txt input/ConnectedComponents
</code></pre>
<h2 id="&#x7F16;&#x5199;&#x7A0B;&#x5E8F;">&#x7F16;&#x5199;&#x7A0B;&#x5E8F;</h2>
<pre><code class="lang-java"><span class="hljs-keyword">import</span> org.apache.spark.SparkConf;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.JavaPairRDD;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.JavaSparkContext;
<span class="hljs-keyword">import</span> scala.Tuple2;

<span class="hljs-keyword">import</span> <span class="hljs-keyword">static</span> java.lang.StrictMath.min;

<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ConnectedComponents</span> </span>{

    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">int</span> MaxIteration = <span class="hljs-number">100</span>;

    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>{
        SparkConf conf = <span class="hljs-keyword">new</span> SparkConf().setAppName(<span class="hljs-string">&quot;ConnectedComponents&quot;</span>);
        JavaSparkContext sc = <span class="hljs-keyword">new</span> JavaSparkContext(conf);
        sc.setLogLevel(<span class="hljs-string">&quot;WARN&quot;</span>);

        String edgesFile = <span class="hljs-string">&quot;hdfs:///user/hadoop/input/ConnectedComponents/edges.txt&quot;</span>;
        String verticesFile = <span class="hljs-string">&quot;hdfs:///user/hadoop/input/ConnectedComponents/vertices.txt&quot;</span>;
        String outFile = <span class="hljs-string">&quot;hdfs:///user/hadoop/output/Graph/SparkConnectedComponents&quot;</span>;


        <span class="hljs-comment">/**
         * edgesRDD: [x,y]
         * componentsRDD: [x,x] init
         */</span>

        JavaPairRDD&lt;Integer, Integer&gt; edgesRDD = sc.textFile(edgesFile)
                .mapToPair(
                        line -&gt; <span class="hljs-keyword">new</span> Tuple2&lt;&gt;(
                                Integer.parseInt(line.split(<span class="hljs-string">&quot; &quot;</span>)[<span class="hljs-number">0</span>]),
                                Integer.parseInt(line.split(<span class="hljs-string">&quot; &quot;</span>)[<span class="hljs-number">1</span>])
                        )
                );

        JavaPairRDD&lt;Integer, Integer&gt; componentsRDD = sc.textFile(verticesFile)
                .mapToPair(
                        line -&gt; <span class="hljs-keyword">new</span> Tuple2&lt;&gt;(Integer.parseInt(line), Integer.parseInt(line))
                );

        <span class="hljs-keyword">int</span> count = <span class="hljs-number">0</span>;

        <span class="hljs-keyword">while</span> (count &lt; MaxIteration) {
            JavaPairRDD&lt;Integer, Integer&gt; newcomponentsRDD = componentsRDD.join(edgesRDD)
                    .mapToPair(
                            x -&gt; <span class="hljs-keyword">new</span> Tuple2&lt;&gt;(x._2._2, x._2._1)
                    )
                    .reduceByKey(
                            (v1, v2) -&gt; min(v1, v2)
                    );

            JavaPairRDD&lt;Integer, Tuple2&lt;Integer, Integer&gt;&gt; filterRDD = newcomponentsRDD.join(componentsRDD)
                    .filter(
                            each -&gt; each._2._1 &lt; each._2._2
                    );

            <span class="hljs-keyword">if</span> (filterRDD.isEmpty())
                <span class="hljs-keyword">break</span>;

            <span class="hljs-comment">// update to componentsRDD</span>
            componentsRDD = componentsRDD.leftOuterJoin(newcomponentsRDD).
                    mapValues(
                            v -&gt; min(v._1, v._2.orElse(v._1))
                    );

            count++;
        }

        componentsRDD.saveAsTextFile(outFile);
    }
}
</code></pre>
<p>&#x601D;&#x8DEF;&#xFF1A;</p>
<ol>
<li>&#x9996;&#x5148;&#x9700;&#x8981;&#x5C06;&#x6BCF;&#x4E2A;&#x70B9;&#x6620;&#x5C04;&#x6210;&#x81EA;&#x5DF1;&#x7684;&#x5F3A;&#x8FDE;&#x901A;&#x5206;&#x652F;</li>
<li>&#x6BCF;&#x6B21;&#x8FED;&#x4EE3;&#xFF0C;&#x66F4;&#x65B0;&#x4E0E;&#x81EA;&#x5DF1;&#x76F8;&#x8FDE;&#x7684;&#x70B9;&#x7684;&#x5F3A;&#x8FDE;&#x901A;&#x5206;&#x652F;&#xFF0C;&#x53D6;&#x6700;&#x5C0F;&#x503C;</li>
<li>&#x4F7F;&#x7528;&#x5DE6;&#x8FDE;&#x63A5;&#x66F4;&#x65B0;&#x539F;&#x59CB;&#x7684;&#x5F3A;&#x8FDE;&#x901A;&#x5206;&#x652F;</li>
</ol>
<h2 id="&#x8FD0;&#x884C;">&#x8FD0;&#x884C;</h2>
<pre><code>spark-submit  --class ConnectedComponents ConnectedComponents-1.0.jar
hdfs dfs -cat output/Graph/SparkConnectedComponents/*
</code></pre><p>&#x67E5;&#x770B;&#x7ED3;&#x679C;&#xFF1A;</p>
<p><img src="../images/graph9.png" alt="graph9"></p>
<h1 id="singlesourceshortestpaths">SingleSourceShortestPaths</h1>
<h2 id="&#x6570;&#x636E;&#x51C6;&#x5907;">&#x6570;&#x636E;&#x51C6;&#x5907;</h2>
<p>&#x9996;&#x5148;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x51C6;&#x5907;&#x8FB9;&#x548C;&#x70B9;</p>
<p>&#x8FB9;&#xFF1A;</p>
<pre><code>1 2 12.0
1 3 13.0
2 3 23.0
3 4 34.0
3 5 35.0
4 5 45.0
5 1 51.0
</code></pre><p>&#x70B9;&#xFF1A;</p>
<pre><code>1
2
3
4
5
</code></pre><p>&#x5C06;&#x8FD9;&#x4E24;&#x4E2A;&#x6587;&#x4EF6;&#x653E;&#x5165;HDFS&#xFF1A;</p>
<pre><code class="lang-shell">hdfs dfs -mkdir input/SingleSourceShortestPaths
hdfs dfs -put edges.txt input/SingleSourceShortestPaths
hdfs dfs -put vertices.txt input/SingleSourceShortestPaths
</code></pre>
<h2 id="&#x7F16;&#x5199;&#x7A0B;&#x5E8F;">&#x7F16;&#x5199;&#x7A0B;&#x5E8F;</h2>
<pre><code class="lang-java"><span class="hljs-keyword">import</span> org.apache.spark.SparkConf;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.JavaPairRDD;
<span class="hljs-keyword">import</span> org.apache.spark.api.java.JavaSparkContext;
<span class="hljs-keyword">import</span> scala.Tuple2;

<span class="hljs-keyword">import</span> javax.validation.constraints.Max;

<span class="hljs-keyword">import</span> <span class="hljs-keyword">static</span> java.lang.StrictMath.min;

<span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SingleSourceShortestPaths</span> </span>{
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">int</span> sourceVerticeID = <span class="hljs-number">1</span>;
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">int</span> MaxIteration = <span class="hljs-number">100</span>;

    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>{
        SparkConf conf = <span class="hljs-keyword">new</span> SparkConf().setAppName(<span class="hljs-string">&quot;ConnectedComponents&quot;</span>);
        JavaSparkContext sc = <span class="hljs-keyword">new</span> JavaSparkContext(conf);
        sc.setLogLevel(<span class="hljs-string">&quot;WARN&quot;</span>);

        String edgesFile = <span class="hljs-string">&quot;hdfs:///user/hadoop/input/SingleSourceShortestPaths/edges.txt&quot;</span>;
        String verticesFile = <span class="hljs-string">&quot;hdfs:///user/hadoop/input/SingleSourceShortestPaths/vertices.txt&quot;</span>;
        String outFile = <span class="hljs-string">&quot;hdfs:///user/hadoop/output/Graph/SparkSingleSourceShortestPaths&quot;</span>;

        <span class="hljs-comment">/**
         * edgesRDD: [from, to, dis ]
         * verticesRDD: [vertice, dis]
         */</span>


        JavaPairRDD&lt;Integer, Tuple2&lt;Integer, Double&gt;&gt; edgesRDD = sc.textFile(edgesFile)
                .mapToPair(
                        line -&gt; {
                            <span class="hljs-keyword">int</span> from = Integer.parseInt(line.split(<span class="hljs-string">&quot; &quot;</span>)[<span class="hljs-number">0</span>]);
                            <span class="hljs-keyword">int</span> to = Integer.parseInt(line.split(<span class="hljs-string">&quot; &quot;</span>)[<span class="hljs-number">1</span>]);
                            <span class="hljs-keyword">double</span> dis = Double.parseDouble(line.split(<span class="hljs-string">&quot; &quot;</span>)[<span class="hljs-number">2</span>]);
                            <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> Tuple2&lt;&gt;(from, <span class="hljs-keyword">new</span> Tuple2&lt;&gt;(to, dis));
                        }
                );

        JavaPairRDD&lt;Integer, Double&gt; verticesRDD = sc.textFile(verticesFile)
                .mapToPair(
                        line -&gt; {
                            <span class="hljs-keyword">int</span> vertice = Integer.parseInt(line);
                            <span class="hljs-keyword">if</span> (vertice == sourceVerticeID)
                                <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> Tuple2&lt;&gt;(vertice, <span class="hljs-number">0.0</span>);
                            <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> Tuple2&lt;&gt;(vertice, Double.POSITIVE_INFINITY);
                        }
                );

        <span class="hljs-keyword">int</span> count = <span class="hljs-number">0</span>;
        <span class="hljs-keyword">while</span> (count &lt; MaxIteration) {
            <span class="hljs-comment">// get new dis</span>
            JavaPairRDD&lt;Integer, Double&gt; newVerticesRDD = verticesRDD
                    .join(edgesRDD)
                    .mapToPair(
                            line -&gt; {
                                <span class="hljs-keyword">if</span> (line._2._1 != Double.POSITIVE_INFINITY)
                                    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> Tuple2&lt;&gt;(line._2._2._1, line._2._1 + line._2._2._2);
                                <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> Tuple2&lt;&gt;(line._2._2._1, Double.POSITIVE_INFINITY);
                            }
                    ).reduceByKey(
                            (v1, v2) -&gt; min(v1, v2));

            JavaPairRDD&lt;Integer, Tuple2&lt;Double, Double&gt;&gt; filterRDD = newVerticesRDD.join(verticesRDD)
                    .filter(
                            each -&gt; each._2._1 &lt; each._2._2);

            <span class="hljs-keyword">if</span> (filterRDD.isEmpty())
                <span class="hljs-keyword">break</span>;

            <span class="hljs-comment">// update to verticesRDD</span>
            verticesRDD = verticesRDD.leftOuterJoin(newVerticesRDD).
                    mapValues(
                            v -&gt; min(v._1, v._2.orElse(v._1)));
        }
        verticesRDD.saveAsTextFile(outFile);

    }
}
</code></pre>
<p>&#x601D;&#x8DEF;&#xFF1A;</p>
<ol>
<li>&#x9996;&#x5148;&#x9700;&#x8981;&#x521D;&#x59CB;&#x5316;&#x6BCF;&#x4E2A;&#x9876;&#x70B9;&#x7684;&#x8DDD;&#x79BB;&#xFF0C;&#x5C06;&#x539F;&#x59CB;&#x70B9;&#x8BBE;&#x7F6E;&#x4E3A;0&#xFF0C;&#x5176;&#x4F59;&#x8BBE;&#x7F6E;&#x4E3A;&#x65E0;&#x7A77;</li>
<li>&#x6BCF;&#x6B21;&#x8FED;&#x4EE3;&#x5F97;&#x5230;&#x65B0;&#x7684;&#x9876;&#x70B9;&#x8DDD;&#x79BB;&#xFF0C;&#x5E76;&#x4F7F;&#x7528;<code>reduceByKey</code>&#x6700;&#x5C0F;&#x5316;&#xFF0C;&#x6BD4;&#x8F83;&#x662F;&#x5426;&#x66F4;&#x65B0;</li>
<li>&#x7136;&#x540E;&#x5C06;&#x66F4;&#x65B0;&#x5F97;&#x5230;&#x7684;&#x9876;&#x70B9;&#x8DDD;&#x79BB;&#x52A0;&#x5165;&#x539F;&#x59CB;RDD&#x4E2D;</li>
</ol>
<h2 id="&#x8FD0;&#x884C;">&#x8FD0;&#x884C;</h2>
<pre><code>spark-submit  --class SingleSourceShortestPaths SingleSourceShortestPaths-1.0.jar
hdfs dfs -cat output/Graph/SparkSingleSourceShortestPaths/*
</code></pre><p>&#x67E5;&#x770B;&#x7ED3;&#x679C;&#xFF1A;</p>
<p><img src="../images/graph10.png" alt="graph10"></p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="graph-in-hadoop.html" class="navigation navigation-prev " aria-label="Previous page: 常用图算法实现--Hadoop">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="graph-in-flink.html" class="navigation navigation-next " aria-label="Next page: 常用图算法实现--Flink">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"常用图算法实现--Spark","level":"1.3.23","depth":2,"next":{"title":"常用图算法实现--Flink","level":"1.3.24","depth":2,"path":"project/graph-in-flink.md","ref":"project/graph-in-flink.md","articles":[]},"previous":{"title":"常用图算法实现--Hadoop","level":"1.3.22","depth":2,"path":"project/graph-in-hadoop.md","ref":"project/graph-in-hadoop.md","articles":[]},"dir":"ltr"},"config":{"plugins":["github","disqus","katex-plus","ga","back-to-top-button","-lunr","-search","search-pro","expandable-chapters"],"ignores":["node_modules","_book"],"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"disqus":{"shortName":"techzealscott","useIdentifier":false},"github":{"url":"https://github.com/scottdyt"},"search-pro":{},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"katex-plus":{},"back-to-top-button":{},"ga":{"token":"UA-116370175-1","configuration":"auto"},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false},"expandable-chapters":{}},"theme":"default","author":"zealscott","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"sortedBy":" ","variables":{},"title":"Distribution System","links":{"sidebar":{"Homepage":"https://tech.zealscott.com"}},"gitbook":"*"},"file":{"path":"project/graph-in-spark.md","mtime":"2021-01-27T07:19:54.518Z","type":"markdown"},"gitbook":{"version":"3.0.0","time":"2021-03-04T09:58:50.487Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-github/plugin.js"></script>
        
    
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/URI.js/1.16.1/URI.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-disqus/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-ga/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-back-to-top-button/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search-pro/jquery.mark.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search-pro/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-expandable-chapters/expandable-chapters.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/buttons.js"></script>
        
    

    </body>
</html>

