{"./":{"url":"./","title":"Introduction","keywords":"","body":"Advanced Database System This GitBook notes are maintained by zealscott. Syllabus Date Description Reading Project 2.19 Structure of Database LevelDB安装及使用 2.26 Introduction to LSM-tree Storage Model B tree historyLMDB architecture LevelDB基本接口 3.4 Memtable & In-memory Index SkipList解析 3.11/3.18 Handle Concurrency for In-memory Index A Lazy Concurrent List-Based Set Algorithm 并发链表 3.25 Storage Design of SStables SStable练习一 4.15 Data Compaction SStable练习二 4.15 Index & Storage for traditional database 使用gdb调试pg 4.24 SQL Execution Engine-Vocalno Model gdb跟踪pg源码 4.24 SQL Execution Engine-Operations 5.6 Introduction to Query Optimization 调试HashJoin 5.13 Introduction to Concurrency Control Protocols Isolation Level 基于时间戳的并发控制 5.20 Transaction Engine Lock table Raw Locking 基于锁的并发控制 5.27 Introduction to WAL logging 乐观并发控制 6.10 Raft/Paxos made simple 6.17 Raft /Basic paxos implementation 6.24 Introduction of NewSQL - TiDB as an Example Reading Material Books 《数据库系统实现》-- Hector Garcia-Molina, et al. leveldb 实现解析 Papers 存储 LSM-based Storage Techniques: A Survey(Chen Luo) Fault-tolerant precise data access on distributed log-structured merge-tree A Comparative Study of Secondary Indexing Techniques in LSM-based NoSQL Databases 查询-哈希Join Radix Join(Partitioned Join, https://15721.courses.cs.cmu.edu/spring2016/slides/11.pdf) Sort vs. Hash Revisited: Fast Join Implementation on Modern Multi-Core CPUs 并发控制、日志 Concurrency Control and Recovery (Michael J. Franklin) Cache-Conscious Concurrency Control of Main-Memory Indexes on Shared-Memory Multiprocessor Systems Raft In Search of an Understandable Consensus Algorithm (Extended Version) PolarFS: An Ultra-low Latency and Failure Resilient Distributed File System for Shared Storage Cloud Database 数据库与机器学习 Self-Driving Database Management Systems(CIDR17) @Last updated at 1/27/2021 "},"leveldb1.html":{"url":"leveldb1.html","title":"LevelDB 安装及使用","keywords":"","body":"环境安装 本项目基于Ubuntu 16.04.1 LTS，参考链接。 建议预留50G空间，根目录20G,boot 500m,swap 2到4G,其他的都给home 若使用虚拟机，建议使用sudo apt-get install gparted进行可视化分区及扩容（需要删除之前的wap分区） 安装Clion 官网下载 解压并安装，运行clion.sh启动 tar -xzvf clion-* ~/clion-2018.1.6/bin/clion.sh 导入代码 通过Clion导入项目代码，在打开界面选择：VCS -> Checkout from version control -Git 项目地址为：https://github.com/gexrior/leveldb 在根目录CMakeLists.txt文件中添加一行：add_definitions(\"-D NO_ALLOCA\") 编译项目 测试代码 编译运行/test/db_test.cc测试其读写功能 修改该测试文件代码为（实现删除操作）： #include \"leveldb/db.h\" #include #include using namespace std; using namespace leveldb; int main() { DB *db = nullptr; Options op; op.create_if_missing = true; Status status = DB::Open(op, \"testdb\", &db); assert(status.ok()); db->Put(WriteOptions(), \"001\", \"not world\"); string s; db->Get(ReadOptions(), \"001\", &s); cout Delete(WriteOptions(),\"001\"); delete db; return 0; } "},"leveldb2.html":{"url":"leveldb2.html","title":"LevelDB 基本接口","keywords":"","body":"基本接口 Put/Get 使用key进行插入或查询 //opening a database leveldb::DB* db; leveldb::Options options; options.create_if_missing = true; leveldb::Status status = leveldb::DB::Open(options, \"testdb\", &db); assert(status.ok()); std::string key1=\"book\"; std::string value1=\"algorithm\"; std::string value; db->Put(WriteOptions(),key1,value1); db->Get(ReadOptions(),key1,&value); std::cout Snapshot 可以查询历史版本的值，使用readoptions指定 std::string key1=\"fruit\"; std::string value1=\"apple\"; status=db->Put(leveldb::WriteOptions(),key1,value1); assert(status.ok()); leveldb::ReadOptions readoptions; readoptions.snapshot=db->GetSnapshot(); std::string value2=\"orange\"; status=db->Put(leveldb::WriteOptions(),key1,value2); assert(status.ok()); std::string value; //status=db->Get(leveldb::ReadOptions(),key1,&value); // snapshot status=db->Get(readoptions,key1,&value); assert(status.ok()); Writebatch 使用batch的方式进行写入，使用WriteBatch类进行write操作 std::string key2=\"fruit\"; std::string value2=\"apple\"; if (status.ok()) { leveldb::WriteBatch batch; batch.Delete(key1); batch.Put(key2, value); status = db->Write(leveldb::WriteOptions(), &batch); } 练习 从文件读入数据并写入数据库（Batch） std::string id, mail; std::ifstream inFile; leveldb::WriteBatch batch; inFile.open(\"/home/hadoop/Documents/data/PJ2/inputFile.csv\"); if (status.ok()) { while (getline(inFile, id, ',')) { // std::cout Write(leveldb::WriteOptions(), &batch); 通过Get接口获取读入数据库的指定属性ID号和邮箱 int fibonacci[1000]; fibonacci[0] = 0; fibonacci[1] = 1; fibonacci[2] = 1; for (int i = 2; fibonacci[i-1] Get(leveldb::ReadOptions(), std::to_string(fibonacci[i-1]), &mail); assert(status.ok()); std::cout "},"skiplist.html":{"url":"skiplist.html","title":"SkipList 解析","keywords":"","body":"levelDB使用skiplist作为索引，实现其实不难，但在levelDB中为了减少浪费空间，使用了variant32类型，具体细节可以参考这里。 这里是KV的内部结构： 因此，我们需要首先从key的指针位置找到internal key size，然后找到对应的user key，之后再用同样的方法找到value 使用GetVarint32Ptr函数可以方便的帮助我们偏移指针和找到key size，构造print函数为： template void SkipList::PrintTable() { uint32_t* value; for(int i = GetMaxHeight()-1; i >= 0;i--) { Node* tmp = head_->Next(i); printf(\"\\n-------------PRINT-------------\\n\"); while(tmp!=NULL) { uint32_t keylen = 1; uint32_t valuelen = 1; const char* keyPtr = GetVarint32Ptr(tmp->key,tmp->key+5,&keylen); const char* valuePtr = GetVarint32Ptr(keyPtr+keylen,keyPtr+keylen+5,&valuelen); char key[keylen] = {\"\"}; char value[valuelen] = {\"\"}; strncpy(key, keyPtr, keylen-8); strncpy(value, valuePtr, valuelen+1); key[keylen-8] = '\\0'; if (key[keylen-7] == '0') continue; // value[valuelen] = '\\0'; printf(\"%s:%s \\t\",key,value); tmp = tmp->Next(i); } } } 因此，当每次插入一个kv时，我们都打印当前skiplist 的结构。 "},"linkedlist.html":{"url":"linkedlist.html","title":"并发链表","keywords":"","body":" 实现支持并发安全的有序链表 C++并发 头文件 该头文主要声明了两个类, std::atomic 和 std::atomic_flag，另外还声明了一套 C 风格的原子类型和与 C 兼容的原子操作的函数。 该头文件主要声明了 std::thread 类，另外 std::this_thread 命名空间也在该头文件中。 该头文件主要声明了与互斥量(mutex)相关的类，包括 std::mutex 系列类，std::lock_guard, std::unique_lock, 以及其他的类型和函数。 该头文件主要声明了与条件变量相关的类，包括 std::condition_variable 和 std::condition_variable_any。 该头文件主要声明了 std::promise, std::package_task 两个 Provider 类，以及 std::future 和 std::shared_future 两个 Future 类，另外还有一些与之相关的类型和函数，std::async() 函数就声明在此头文件中。 这里主要使用和实现。 例子 根据线程执行的顺序，可以分为detach和join： #include #include using namespace std; void output(int i) { cout 执行命令：g++ -std=c++0x test.cpp -pthread -o test detach的结果为： join的结果为： 可以发现，detach方式，启动的线程自主在后台运行，当前的代码继续往下执行，不等待新线程结束。join方式，等待启动的线程完成，才会继续往下执行。 并发链表 这里使用lock coupling方法进行并发处理，简单来说: 对于Add操作，每次需要锁住当前插入节点和前驱节点 对于Remove操作，每次需要锁住删除节点和前驱节点 Contain操作需要锁吗？（可以不需要） 这其实是一种很严格的锁，每次操作从头往后遍历，处理每个节点时，其他线程都不能操作。 代码 Linkdedlist.h #ifndef LINKEDLIST_H // include guard #define LINKEDLIST_H #include #include #include #include #include using namespace std; class Node { public: Node *next_; mutex mutex_; int key_; int value_; Node() : next_(nullptr){}; Node(int key, int value) : next_(nullptr), key_(key), value_(value){}; }; void Add(Node *head, Node *node) { if (node == nullptr || head == nullptr) return; printf(\"Inserting %d ....\\n\", node->key_); // need to lock first head->mutex_.lock(); Node *prev = head; Node *current = head->next_; while (current != nullptr) { current->mutex_.lock(); if (node->key_ key_) { prev->next_ = node; node->next_ = current; printf(\"Interted %d success!\\n\", node->key_); current->mutex_.unlock(); prev->mutex_.unlock(); return; } else if (node->key_ == current->key_) { printf(\"Inserting %d failed! duplicated key\\n\", node->key_); current->mutex_.unlock(); prev->mutex_.unlock(); return; } else { prev->mutex_.unlock(); prev = current; current = current->next_; } } // insert to the last printf(\"Interted %d success to the last!\\n\", node->key_); prev->next_ = node; prev->mutex_.unlock(); } void Remove(Node *head, int key) { if (head == nullptr) return; printf(\"Romoving %d ....\\n\", key); head->mutex_.lock(); Node *prev = head; Node *current = head->next_; while (current != nullptr && current->key_ mutex_.lock(); prev->mutex_.unlock(); prev = current; current = current->next_; } if (current != nullptr && current->key_ == key) { // its important to lock current node to ensure delete safely current->mutex_.lock(); prev->next_ = current->next_; delete current; prev->mutex_.unlock(); printf(\"Romove %d success!\\n\", key); } else { prev->mutex_.unlock(); printf(\"Romove %d failed! Key not exited!\\n\", key); } return; } bool Contain(Node *head, int key) { if (head == nullptr) return false; Node *prev = head; Node *current = head->next_; while (current != nullptr) { // prev->mutex_.lock(); // current->mutex_.lock(); if (current->key_ == key) { // current->mutex_.unlock(); // prev->mutex_.lock(); return true; } else if (current->key_ mutex_.unlock(); // current->mutex_.unlock(); prev = current; current = current->next_; } else return false; } return false; } void Print(Node *head) { head->mutex_.lock(); ofstream fout(\"result.txt\"); fout next_; current != nullptr; current = current->next_) { fout key_ value_ mutex_.unlock(); fout Test.cpp #include #include #include #include \"LinkedList.h\" using namespace std; //test for add + remove thread void ARTest(Node *head, Node *node, int dlkey) { Add(head, node); Remove(head, dlkey); } //test for Remove + Add Thread void RATest(Node *head, Node *node, int dlkey) { Remove(head, dlkey); Add(head, node); } int main() { auto head = new Node(0, 0); //test for AddThreads vector AddThreads; for (int i = 0; i RemoveThreads; // for(int i = 0; i ARThreads; // for(int i = 0; i RAThreads; for (int i = 0; i 注意点 每次操作，需要首先锁住head头指针！！！ 需要判断是否已经存在同样的key。 运行 执行g++ -std=c++0x testList.cpp -pthread，结果保存在result.txt文件中 "},"sstable1.html":{"url":"sstable1.html","title":"SStable 练习","keywords":"","body":" 了解LevelDB block实现源码，并读取footer LevelDB Block类 构造函数 其中，对于block的构造函数，使用了explicit关键字，主要用于避免类型转换，参考这里。 构造函数用于插入数据并判断大小： Iterator 在block类中，还存在一个iter类，是nested classes，参考官网。 主要看ParseNextKey函数，迭代器重要任务就是解析出记录： 当为第一条记录时，共享部分为0， key_.append(p, non_shared);这行代码就是将第一条完整记录加在key_后面。 当不是第一条记录时，此时key_.resize(shared)；这行代码获取当前记录和上一条记录共享部分， key_.append(p, non_shared)；这行代码就获得非共享部分，凑成完整的记录。 最后，如果下一个key是在另一个group中，就将restart_index往下指。 此时这个迭代器的key_指向第一条记录的key，value_指向第一条记录的value。 Two Level Iterator类 如果要读取一个SStable文件的某个键值对，首先要读取data block，然后才是从这个data block中读取键值对。所以有两次迭代，即两个迭代器。 构造函数 读取第一个样本 经过SeekToFirst 、InitDataBlock 这两个函数之后，index_iter_指向index_block第一条记录，data_iter_指向第一个块的首位置 获取数据 先构造一个sst文件的Table类，然后构造出Table的迭代器，从迭代器就可以获取这个文件的任何键值（seek函数） 读取footer 结构 可以发现，footer一共有4个结构+magic number，每个结构最多10个字节，需要使用GetVarint64得到。 代码 首先需要创建一个SStable，然后通过指针指到footer，再依次读出里面的结构。 #include #include using namespace std; int getFileSize(const string &filename) { int size = 0; FILE* fp = nullptr; fp = fopen(filename.c_str(), \"r\"); if (nullptr == fp) { return size; } fseek(fp, 0L, SEEK_END); size = ftell(fp); fclose(fp); return size; } char* GetVarint64Ptr(char* p, const char* limit, uint64_t* value) { uint64_t result = 0; for (uint32_t shift = 0; shift (p)); p++; if (byte & 128) { // More bytes are present result |= ((byte & 127) (indexOffset)); fgets(index, static_cast(indexSize + 1), fp); // cout "},"sstable2.html":{"url":"sstable2.html","title":"SStable 练习二","keywords":"","body":"+++ title = \"SStable 练习二\" slug = \"sstable2\" tags = [\"database\"] date = \"2019-04-15T20:36:03+08:00\" description = \"读出SStable中的key,value\" +++ 安装snappy库: https://www.cnblogs.com/yankang/p/10636562.html 文件预览： table存储格式里面主要包括几个部分： datablock metablock metaindex block dataindex block footer footer部分是放在最末尾的，里面包含了dataindex block以及metaindex block的偏移信息，读取table时候从末尾读取 Data block组织形式 对于DiskTable(TableBuilder)就是不断地Add(Key,Value).当缓存的数据达到一定大小之后，就会调用Flush这样就形成了一个Block. 对于一个Block内部而言的话，restart point.所谓restart point就是为了解决 前缀压缩的问题的，所谓的restart point就是基准key。 假设我们顺序加入abcd,abce,abcf.我们以abcd为restart point的话，那么abce可以存储为 (3,e),abcf存储为(3,f). 对于restart point采用全量存储，而对于之后的部分采用增量存储。一个restart block可能存在多个restart point, 将这些restart point在整个table offset记录下来，然后放在data block最后面。每个data block尾部还有一个type和CRC32.其中type可以选择是否 需要针对这个data block进行snappy压缩，而CRC32是针对这个data block的校验。 data index block组织形式 data index block从不刷新直到Table构造完成之后才会刷新，所以对于一个table而言的话只有一个data index block. data index block添加的key/value是在data block形成的时候添加的 block trailer：每个block后面都会有5个字节的 trailer。1个字节的 type 表示 block 内的数据是 否进行了压缩（比如使用了 snappy 压缩），4 个字节的 crc 记录 block 数据的校验码。 block 在 sstable 中索引信息 offset/size,封装成 BlockHandle（table/format.h）使用,size 不包含 trailer。持久化时，offset/size 均采用 varint64 encode。 Block读取 block读取操作（ReadBlock() table/format.cc)： 有了一个 block 的 BlockHandle，即可定位到该 block 在 sstable 中的 offset 及 size,从而读取出具体的 block（ReadBlock()） 根据 BlockHandle，将 block 从 sstable 中读取出来（包含 trailer）。 可选校验 trailer 中的 crc(get 时由 ReadOption:: verify_checksums 控制，compact 时由 Option:: paranoid_checks 控制)。 根据 trailer 中的 type，决定是否要解压数据。 将数据封装成 Block（block.cc），解析出 restarts 集合以及数量。 代码 #include #include #if HAVE_SNAPPY #include #endif // HAVE_SNAPPY inline bool Snappy_GetUncompressedLength(const char* input, size_t length, size_t* result) { #if HAVE_SNAPPY return snappy::GetUncompressedLength(input, length, result); #else return false; #endif // HAVE_SNAPPY } inline bool Snappy_Uncompress(const char* input, size_t length, char* output) { #if HAVE_SNAPPY return snappy::RawUncompress(input, length, output); #else return false; #endif // HAVE_SNAPPY } using namespace std; int getFileSize(const string &filename) { int size = 0; FILE *fp = nullptr; fp = fopen(filename.c_str(), \"r\"); if (nullptr == fp) { return size; } fseek(fp, 0L, SEEK_END); size = ftell(fp); fclose(fp); return size; } char *GetVarint64Ptr(char *p, const char *limit, uint64_t *value) { uint64_t result = 0; for (uint32_t shift = 0; shift (p)); p++; if (byte & 128) { // More bytes are present,| or result |= ((byte & 127) (indexOffset)); fgets(index, static_cast(indexSize + 1), fp); //cout data = string(); result->cachable = false; result->heap_allocated = false; //char * handle; // Read the block contents as well as the type/crc footer. // See table_builder.cc for the code that built this structure. size_t n = indexSize; switch (index[n]) { case kNoCompression: // File implementation gave us pointer to some other data. // Use it directly under the assumption that it will be live // while the file is open. result->data = string(index, n); result->heap_allocated = false; result->cachable = false; // Do not double-cache cout data data = string(ubuf, ulength); result->heap_allocated = true; result->cachable = true; cout data "},"postgre.html":{"url":"postgre.html","title":"PostgreSQL 源码安装","keywords":"","body":"PostgresSQL 介绍、简史等信息可以参考http://www.postgres.cn/docs/10/ 前言部分 安装依赖库 在Ubuntu系统中安装： sudo apt-get install libreadline6 libreadline6-dev sudo apt-get install zlib1g-dev sudo apt-get install libssl-dev sudo apt-get install systemtap-sdt-dev sudo apt-get install firewalld make版本3.80或以上 make --version GCC编译器 GNU Readline库：它允许psql记住你输入的每个命令，这样就可以通过上下方向键快速输入之前的命令，默认开启，也可以通过编译参数--without-readline来禁止它，建议保留默认。 Zlib库 源代码包 源码包下载，下载地址 https://www.postgresql.org/ftp/source/ 版本postgresql 9.6.12 安装 解压缩 tar -zxvf postgresql-9.6.12.tar.gz cd postgresql-9.6.12 生成makefile文件 ./configure --prefix=/home/username/postgresql --enable-debug 其中--prefix是指定软件的安装路径，--with选项是指安装本文件依赖的库文件。如有不清楚可以自己学习下configure命令的相关参数 修改makefile.global 这里要注意的是，由于我希望后面能跟踪代码的运行路径，所以我要在编译configure的时候加上--enable-debug的选项，并且修改src/Makefile.global文件：CFLAGS = -g 其中参数\"-O2\"是编译器的优化选项，如果打开了，代码的执行顺序会改变，使得追踪起代码来比较困难。当然去除了优化选项，编译后的可执行文件会比较大，而且会比较慢，所以不太适合生产环境。所以切记这个操作仅仅是在学习的时候而设置的。 重新configure ./configure --prefix=/home/username/postgresql --with-perl --with-tcl --with-python --with-openssl --with-pam --without-ldap --with-libxml --with-libxslt --enable-thread-safety --with-wal-blocksize=16 --with-blocksize=16 --enable-dtrace --enable-debug （注释：命令解释参考http://www.postgres.cn/docs/9.6/install-procedure.html） 或者只指定debug ./configure --prefix=/home/username/postgresql --enable-dtrace --enable-debug 执行：make 安装：make install 配置环境变量 vi ~/.bashrc 插入：export PG_HOME=/home/username/postgresql、export PATH=PGHOME/bin:PG_HOME/bin:PGH​OME/bin:PATH source ~/.bash_profile 目录授权 mkdir /home/username/postgresql/data mkdir /home/username/postgresql/log 创建log文件： touch /home/username/postgresql/log/server.log sudo chown -R username:username /home/username/postgresql/ 启动 初始化 initdb -D /home/username/postgresql/data 执行完成后显示 pg_ctl -D /home/username/postgresql/data/ -l logfile start 提示表示成功 其中data目录下：base目录是表空间目录，global目录是相关全局变量目录, pg_hba.conf是访问控制配置文件，postgresql.conf是postgresql主配置文件 可选配置（可配可不配），在data目录下修改 修改pg_hba.conf。修改为如下（0.0.0.0/0表示信任来自所有id连接的客户端，加密方式才有md5）： 修改postgresql.conf。localhoat改为*，表示监听所有网络连接。 防火墙开放端口 sudo firewall-cmd --zone=public --add-port=5432/tcp --permanent sudo firewall-cmd --reload 启动PG pg_ctl -D /home/username/postgresql/data/ -l /home/username/postgresql/log/server.log start 连接： psql -d postgres Reference http://www.postgres.cn/docs/9.6/installation.html https://www.cnblogs.com/flying-tiger/p/5859393.html https://www.2cto.com/database/201805/748632.html http://www.postgres.cn/docs/10/ http://www.postgres.cn/docs/9.6/ 数据库的基本操作 第二和第三章 "},"gdb1.html":{"url":"gdb1.html","title":"GDB 调试 pg","keywords":"","body":"postgresql从最早20万行左右的代码量上升到近200万行，所以为了便于调试工作，需要大家在理解目录结构的基础上，按照流程跟踪调试代码 目录结构 首先进入postgresql的第一级目录 config文件夹主要放的是一些配置文件； contrib文件夹里放的是一些第三方的插件、扩展程序等，常用的有pg_standby、postgres_fdw这些； doc文件夹不用说放的是一些帮助文档和manuals； 最主要的是src目录，这里放置的是postgresql的源代码，也是我们调试和跟踪的主要文件目录；configure和Makefile这些是程序编译时要用的文件 进去src目录， 首先那几个Makefile文件什么的就不用多介绍了，主要看看这几个文件夹。 bin/ 放置了postgresql的unix命令，比如psql、initdb这些的源代码; backend/ postgresql后端程序的源代码; include/ 头文件; interfaces/ 前端相关的库的代码（包括pgsql的C语言库libpq）; makefiles/ 平台相关的make的设置文件; pl/ 存储过程语言的代码; port/ 平台移植相关的代码; template/ 平台相关的设置文件; test/ postgresql自带的各种测试脚本; timezone/ 时区相关的代码文件; tools/ 各种开发工具和文档; tutorial/ 各种相关教程。 可以看出比较核心的是backend、bin、interfaces这三个目录，其中backend对应后端（服务器端），剩下两个对应前端（客户端）。 Backend 对于我们的调试工作，大部分关注点集中在后端，即backend目录，在该目录下细分了好多目录： access/ 各种存储访问方法(在各个子目录下) common(共同函数)、gin (Generalized Inverted Index通用逆向索引) 、gist (Generalized Search Tree通用索引)、hash (哈希索引)、heap (heap的访问方法)、index (通用索引函数)、 nbtree (Btree函数)、transam (事务处理)、 bootstrap/ 数据库的初始化处理(initdb的时候) catalog/ 系统目录 commands/ SELECT/INSERT/UPDATE/DELETE以为的SQL文的处理 executor/ 执行器(访问的执行) foreign/ FDW(Foreign Data Wrapper)处理 lib/ 共同函数 libpq/ 前端/后端通信处理 main/ postgres的主函数 nodes/ 构文树节点相关的处理函数 optimizer/ 优化器 parser/ SQL构文解析器 port/ 平台相关的代码 postmaster/ postmaster的主函数 (常驻postgres) replication/ streaming replication regex/ 正则处理 rewrite/ 规则及视图相关的重写处理 snowball/ 全文检索相关（语干处理） storage/ 共享内存、磁盘上的存储、缓存等全部一次/二次记录管理(以下的目录)buffer/(缓存管理)、 file/(文件)、freespace/(Fee Space Map管理) ipc/(进程间通信)、large_object /(大对象的访问函数)、 lmgr/(锁管理)、page/(页面访问相关函数)、 smgr/(存储管理器) tcop/ postgres (数据库引擎的进程)的主要部分 tsearch/ 全文检索 utils/ 各种模块(以下目录) adt/(嵌入的数据类型)、cache/(缓存管理)、 error/(错误处理)、fmgr/(函数管理)、hash/(hash函数)、 init/(数据库初始化、postgres的初期处理)、mb/(多字节文字处理)、misc/(其他)、mmgr/(内存的管理函数)、 resowner/(查询处理中的数据(buffer pin及表锁)的管理)、sort/(排序处理)、time/(事务的 MVCC 管理) 利用gdb调试 既然要用gdb跟踪调试程序，我们首先要知道postgresql后端进程的pid，然后才能attach上进行调试（对gdb命令不熟悉的可以先自行百度下：参考URL：https://www.cnblogs.com/xsln/p/gdb_instructions1.html）。 要获取postgresql的pid，我们有两个办法。 方法一、使用ps命令查看 首先进入psql：psql -d postgres 然后查看：ps -ef | grep postgres 我们可以看到 那个[local] idle 提示的那个就是我们要的，可知进程pid为3098； 方法二、直接在进入postgresql后运行下面的查询语句：select pg_backend_pid(); 也可以得到进程的pid，方便快捷。 得到进程的pid后，我们就可以进入gdb调试了。 另开一个窗口，我们输入如下命令：sudo db postgres 3098 select命令 调试postgresql，我们先以最简单的SQL文作为例子演示如何调试跟踪代码。例如：select 1; 在这个状态下，可以接受gdb命令，这里，我们使用b命令在ExecResult处打上断点，再回到postgresql的窗口，执行SQL： 我们可以看到因为postgres进程已经暂停，SQL会卡在那里动不了，这也是我们的目的，不然怎么一步一步的调试呢？ 我们再回到gdb这边，运行c命令，程序就会继续执行下去，然后再断点处（ExecResult）停止。 （注释：c 是gdb中的断点（continue），具体解释见给的GDB URL中 三.11） 我们当然会很好奇执行路径上走过了哪些文件调用了哪些函数？ 好的，我们执行gdb的bt命令： （注释：bt 是gdb中的栈信息（backtrace），具体解释见给的GDB URL中 三.1） 这一大串就是我们梦寐以求的函数调用的堆栈了。这样从程序开始到ExecResult为止的函数调用都有了。既然说是“堆栈”，我们自然是要反着看的，比如，我们可以看到最早调用的是main函数，它在（at）main.c文件里，在main函数的第228行，调用了PostmasterMain函数，依次类推即可知道函数的调用路径。 知道了函数的调用路径，我们可以一步一步地看看这条语句是怎么走的了。 以postgresql9.6.12为例： #13 main.c 内： line99： 函数MemoryContextInit()启动必须的子系统error和memory管理系统; line110：函数set_pglocale_pgservice()获取并设置环境变量; line146~148: 函数init_locale初始化环境变量; line219~228：根据输入参数确定程序走向，这里进入了PostmasterMain(),跳转至postmaster.c文件。 #12#11#10#9 postmaster.c 内： 该文件中定义了后端的常驻进程\"postmaster\"所使用的主要函数接口和数据结构定义。postmaster接受前端的请求，建立新的backend进程。 line561~623：读取上下文信息和配置文件，完成初始化; line630~812：读取postmaster的参数; line930~1000：建立socket通信; line1100~1159：建立shared memory和semaphores以及堆栈和pipe，初始化子系统(stats collection、autovacuum); line1296：进入ServerLoop()函数,跳转至line1604; line1604:ServerLoop()函数入口。该函数循环监听端口上的连接请求; line1673~1699：判断是否有\"合法\"的连接请求，fork一个子进程去处理它，进入BackendStartup()函数，跳转至line3857; line3857：BackendStartup()函数入口。该函数负责开启一个新的backend进程; line3858~3914：做一些初始化准备(数据结构，开启和关闭一些必要的进程等等); line3917：进入BackendRun()函数，跳转至line4179; line4179：BackendRun()函数入口，该函数运行backend进程，主要干两件事：1.建立参数列表并初始化2.调用PostgresMain()函数; line4243：调用PostgresMain()函数，进入postgres.c文件. #8#7 postgres.c 文件内： 该文件定义了postgres后端的主要模块，相当于后端的main，并且负责后端进程的调度。 line3572：PostgresMain()函数入口。根据输入的dbname，username和输入参数建立一个会话; line3573~3801：初始化工作。开设初始化环境和默认参数，设置信号处理函数和其他参数，建立内存上下文，设置share buffer等等等等; line3825：进入POSTGRES的主处理循环,这个if语句主要用于判断输入处理是否有异常等; line3933：进入处理循环中。该循环监听新的查询请求并判断请求的类别; line4045：判断查询请求为simple query，调用exec_simple_query()函数,跳转至line884; line884：exec_simple_query()函数入口。该函数做一些初始化工作，建立一个transaction command，做简单的语法规则判断，分析重写，并为该查询建立查询计划，并返回查询结果; line1104：进入函数PortalRun()，进入pquery.c文件. #6#5 pquery.c 文件内： 该文件定义了postgres后端查询语句的代码。 line706：PortalRun()函数入口。该函数负责运行一个或一组查询; line786：进入PortalRunSelect()函数，跳转至line888; line888：PortalRunSelect()函数入口。该函数只能执行简单的SELECT查询操作; line942：进入ExecutorRun()函数，进入execMain.c文件. #4#3#2 execMain.c 文件内： 该文件给出了执行的四个接口函数，分别是ExecutorStart() ExecutorRun() ExecutorFinish() ExecutorEnd()。 line279：ExecutorRun()函数入口。该函数时执行模块的主要部分，它接受一个查询描述符并真正的执行一个查询语句; line285：进入standard_ExecutorRun()函数。跳转至line289; line289：standard_ExecutorRun()函数入口。它执行\"标准\"的查询; line337：进入ExecutePlan()函数，跳转至line1517; line1517：ExecutePlan()函数入口。还记得前面exec_simple_query()说的查询计划么？这里用上了，执行该查询计划。 line1541：进入查询计划执行的主循环; line1549：进入ExecProcNode()函数,进入execProcnode.c文件. #1 execProcnode.c 文件内： 该文件内提供了执行查询计划的调度函数，功能分别是： ExecInitNode()：初始化查询计划的节点以及其子查询计划; ExecProcNode()：通过执行查询计划获得元组; ExecEndNode()：关闭一个查询节点和它的子查询计划。 line367：ExecProcNode()函数入口; line385：进入ExecResult()函数，跳转至文件nodeResult.c. #0 nodeResult.c 文件内： 该文件主要为每个查询计划的节点提供支持。 line67：ExecResult()函数入口，该函数返回查询计划获得的元组。 这一段从#13到#0的函数调用简单分析 Join命令 CREATE TABLE t1( key integer not null, v1 varchar(10) ); CREATE TABLE t2( key integer not null, v2 varchar(10) ); INSERT INTO t1 VALUES (1, 'a'), (2, 'b'), (3, 'c'), (4, 'd'), (5, 'e'), (6, 'f'); INSERT INTO t2 VALUES (1, 'A'), (2, 'B'), (3, 'C'), (4, 'D'), (5, 'E'), (6, 'F'); 执行join命令： select * from t1 left join t2 on t1.key = t2.key gdb 设置断点的几种方式 方式1、根据函数名，查找符号（symbol）设置断点 此种方式最为简单，阅读源代码，了解函数如何调用，在需要暂停运行的函数入口进行断点设置。但并不是所有函数，任何时候都能设置断点的。比如优化后的静态函数，inline函数。在特定的情况下，通过函数名进行断点设置便不可为，而又需要查看运行时该函数的运行情况，这时就需要使用第二种方式。 例子：b func_name 方式2、根据代码行位置设置断点 当无法通过方式1进行设置断点，而又明确知道，程序运行到源代码文件中某个位置需要中断，则可通过在gdb中指定文件及代码位置进行断点设置。通过方式1和2，能解决绝大部分的跟踪问题，但是，在运行运行中，我们可能会碰到通过函数指针进行函数调用的情况，此时只知道函数指针的地址，就无法通过函数名或者代码行数进行 例子：b /src/codefile.cc:81。gdb将在运行到源码文件/src/codefile.cc的第81行中断 方式3、根据运行时的地址设置断点 此时有两种方式，一是通过直接指定地址进行，进行断点设置。二是通过print命令获得相关信息 例子1：b *0x5859c0。\"*\"号是必须加在地址前的，0x5859c0为函数指针的地址 例子2：展示变量内容 (gdb) p *thread_scheduler 在打印thread_scheduler变量的内容时，保存函数指针的变量add_connection的内容被打印出来，保活函数的指针和函数的名字，通过指针可使用b *0x5859c0进行断点设置；通过函数名可使用方式1进行断点设置 Reference 1.http://www.postgres.cn/docs/9.6/ 2.https://www.cnblogs.com/flying-tiger/p/5859393.html 3.https://www.cnblogs.com/xsln/p/gdb_instructions1.html 4.《PostgreSQL查询处理部分源码分析》 5.http://www.postgres.cn/docs/10/ 6.http://www.cnblogs.com/northhurricane/p/3860393.html 7.https://zhuanlan.zhihu.com/p/59452004 "},"gdb2.html":{"url":"gdb2.html","title":"GDB 跟踪 pg 源码","keywords":"","body":"PostgreSQL操作 进入psql：psql -d postgres restart server: pg_ctl -D /home/hadoop/postgresql/data/ -l /home/hadoop/postgresql/log/server.log restart 查看log信息： tailf /home/hadoop/postgresql/data/pg_log/**.csv 创建表 create table t1 (c1 int primary key, c2 int ); create index index1 on t1 (c2); insert into t1 SELECT generate_series(1,10000) as key, (random()*(10^3))::integer; 查看操作的log 使用GDB调试 看当前session的pid select pg_backend_pid(); 打断点 连接当前session sudo gdb postgres 2900 看查询流程 看parser tree continue到1037行看query tree continue到1041行看plan tree GDB调试Sequence Scan 首先对SeqNext函数打断点：b SeqNext Reference PG物理存储、数据结构介绍 http://rachbelaid.com/introduction-to-postgresphysical-storage/ 《PostgreSQl数据库内核分析》 《PostgreSQl查询引擎源码技术探析》 MySQL PG源码解析的blog:https://blog.51cto.com/yanzongshuai PG源码解析Executor: https://www.cnblogs.com/flying-tiger/p/6100794.html "},"hashjoin.html":{"url":"hashjoin.html","title":"调试 HashJoin","keywords":"","body":"建表 create table t1 (c1 int primary key, c2 int ); create table t2 (c1 int primary key, c2 int ); -- 插入测试数据 insert into t1 SELECT generate_series(1,10000) as key, (random()*(10^3))::integer; insert into t2 SELECT generate_series(1,10000) as key, (random()*(10^3))::integer; 查看查询计划： explain select * from t1,t2 where t1.c1 可以发现，在这个SQL语句的查询树中，lefttree对应的是SeqScan，righttree对应的是Hash，即左树(outer relation)为t2的顺序扫描运算生成的relation，右树(inner relation)为t1的索引扫描（Index Scan)运算生成的relation(在此relation上创建Hash Table) 源码解读 ExecHashJoinImpl函数把Hash Join划分为多个阶段/状态(有限状态机),保存在HashJoinState->hj_JoinState字段中,这些状态分别是分别为： HJ_BUILD_HASHTABLE：创建Hash表; HJ_NEED_NEW_OUTER：扫描outer relation,计算外表连接键的hash值,把相匹配元组放在合适的bucket中; HJ_SCAN_BUCKET：扫描bucket,匹配的tuple返回 HJ_FILL_OUTER_TUPLE：当前outer relation元组已耗尽，因此检查是否发出一个虚拟的外连接元组。 HJ_FILL_INNER_TUPLES：已完成一个批处理，但做的是右外连接/完全连接,填充虚拟连接元组 HJ_NEED_NEW_BATCH：开启下一批次 注意：在work_mem不足以装下Hash Table时,分批执行.每个批次执行时,会把outer relation与inner relation匹配(指hash值一样)的tuple会存储起来,放在合适的批次文件中(hashtable->outerBatchFile[batchno]),以避免多次的outer relation扫描 对于之前提到的SQL语句，有如下执行步骤 首先对t1表进行Index scan，建立Hash表（对应状态HJ_BUILD_HASHTABLE） 对每个Outer的Tuple，计算Hash值，放到合适的Bucket中（对应状态HJ_NEED_NEW_OUTER） 扫描Bucket，匹配Tuple（对应状态HJ_SCAN_BUCKET） 如果当前Tuple已经没有匹配了，转到状态HJ_FILL_OUTER_TUPLE 火山模型一定要返回一个tuple，如果hash值没有，则找下一个，因此每次计算hash值的次数不确定。 当成功放回一个tuple后，当前位置的指针也需要保留，因为不清楚是否对于当前key的join是否完全匹配。 GDB 首先对HashJoin打断点： b ExecHashJoin 然后每次next，查看node->hj_JoinState的变化过程 "},"lock.html":{"url":"lock.html","title":"基于锁的并发控制","keywords":"","body":" 实现基于2PL的事务处理原型 基本概念 Short duration lock 短锁 动作开始前申请锁，动作结束立即把锁释放 Long duration Lock 长锁 动作开始前申请锁，动作结束继续持有锁 2PL的思路 事务从锁的角度看分为加锁和解锁两个阶段 Growing 加锁阶段，事务只获取锁，不释放锁 Shrinking 解锁阶段，事务只能释放锁，不能加新锁 2pl变种：保守2pl、严格2pl 常见的实现方式 事务进行过程中加锁，事务结束后集体释放 这里只考虑事务结束后统一释放的情况 实现思路 加锁 获取数据项上已有的锁，判断与自己加的锁是否冲突 若不冲突 对数据项上mutex加锁，设置该数据上已有锁信息(owner)为自己加的锁 若冲突 将自己要加的锁(LockEntry)push到该数据的等待队列waitlist中 对该数据mutex加锁，然后阻塞，等待已有的锁释放 解锁 判断数据项上有无阻塞的锁请求（检查waitlist） 若没有 释放mutex上的锁，将数据上的锁owner置为无锁 再次检查waitlist，防止在释放锁的过程中有加锁操作被阻塞，从而使该锁请求不能得到响应 若有阻塞的锁请求 从waitlist中pop出头部的LockEntry，将owner置为该LockEntry 释放mutex上的锁 代码说明 本人完成的代码原型已经上传到GitHub。 代码结构 global.h：全局配置及变量 structure.h/.cpp：实验所用的数据结构定义及基本操作，采用的基础数据结构是hash map cc_lock.h/.cpp：基于锁的并发控制的实现 main.cpp：程序入口，测试程序的实现 全局变量 锁类型 enum lock_t {LOCK_EX, LOCK_SH, LOCK_NONE }; 三种锁类型，EX代表互斥锁，SH代表共享锁，NONE代表无锁 返回值 enum RC {RCOK, ERROR, FINISH, NOT_FOUND,ALREADY_EXIST }; 代表操作的结果类型，RCOK 正确，ERROR错误，NOT_FOUND数据项不存在，ALREADY_EXIST数据项已存在 并发策略 enum cc_type{CC_LOCK, CC_OCC, CC_TO}; 代表三种并发策略，LOCK 基于锁，OCC 乐观并发控制，TO基于时间戳 通过配置Engine的cc_type，指定所需的并发策略 数据结构 Engine 实验所用的datastore的引擎，实际上就是一个HashMap std::unordered_map data_map; Data 数据项 LockEntry 锁，包含属性有：锁类型，持有该锁的线程id 事务 通过开启多个线程，每个线程执行若干条对数据的操作，来模拟多个事务的并发。每个线程相当于一个事务 本实验模拟了4个事务 "},"timestamp.html":{"url":"timestamp.html","title":"基于时间戳的并发控制","keywords":"","body":"TO算法流程 维护若干时间戳 事务时间戳：以事务开始时间标识事务的先后顺序，表示为ts(T) 数据项读写时间戳：记录读写该数据的最新事务的时间戳，表示为r_ts(X), w_ts(X) 另每个数据项x有三个队列，分别为读队列dm_read(x)，写队列dm_write(x)，预写队列dm_pre(x)。min_R_ts(x)，min_P_ts(x)分别为读队列最小时间戳和预写队列最小时间戳。 同一事务后续的写失败导致之前的写撤销，引发一系列异常 所有写均不能直写数据，需先预写成功，再进行数据的修改 事务对某数据进行第一次读后，其他事务修改该数据，导致不可重复读 读操作copy出一份数据，后续对该数据的读都在该副本上操作 读操作 若读时间戳小于数据的写时间戳，ts(R) 若读时间戳大于预写队列的最小时间戳，ts(R)>min_P_ts(x)，则暂时不能执行，先缓存到dm_read(x)； 否则，则可以直接执行读操作。 预写操作 所有的写操作都先做预写，为了避免级联回滚，即pre_write 若预写时间戳小于数据的读或写时间戳，ts(P) 否则，缓存到预写队列dm_pre(x)中； 写操作 若写请求时间戳大于min_P_ts(x)或min_R_ts(x)，缓存到写请求队列dm_write(x)中 否则，直接执行 每执行一个写操作，min_P_ts(x)增大，执行小于该时间戳的读操作；相应的，min_R_ts(x)增大，执行小于该时间戳的写操作 其实相当于将读队列和预写队列的请求按时间戳从大到小依次执行 代码说明 本人完成的代码原型已经上传到GitHub。 代码结构 global.h：全局配置及变量 data_to.h/.cpp：基于时间戳的并发控制的算法 cc_to.h/.cpp：基于时间戳的读写操作实现 main.cpp：程序入口，测试程序的实现 算法实现 读操作 由cc_lock中get()实现，调用data_to中access()，请求类型为R_REQ 写操作 由cc_lock中update()实现，先调用access()，请求类型为P_REQ 若P_REQ执行成功，再调用access()，请求类型为W_REQ "},"positive.html":{"url":"positive.html","title":"乐观并发控制","keywords":"","body":"OCC三阶段 读阶段 所有更新操作缓冲在事务本地内存空间中，维护事务的写集 所有读取操作先访问事务本地内存空间，若不存在则从数据库中读取并可选地缓存在事务私有内存空间中，维护事务的读集 验证阶段（最关键的阶段） 检查待提交事务是否满足可串行化调度 写阶段（只读事务不需要） 事务私有内存中的更新数据写入数据库使其全局可见 验证过程 对事务TiT_i Ti​, TjT_jTj​ ,且 TiTjT_iTi​Tj​，则检查事务TjT_jTj​是否符合可串行化（即TiT_iTi​在TjT_jTj​之前完成），需满足如下三种条件之一： TiT_iTi​在TjT_jTj​开始读取阶段前完成写入阶段，即TiT_iTi​在TjT_jTj​之前提交 TiT_iTi​的写集与TjT_jTj​的读集不相交，且TiT_iTi​在TjT_jTj​开始写入阶段前完成写入阶段 TiT_iTi​的写集与TjT_jTj​的读集和写集都不相交，且TiT_iTi​在TjT_jTj​完成读取阶段前完成读取阶段 算法实现 算法流程 维护数据结构 每个事务的写集合wset，读集合rset 全局的活跃事务写集合列表active（活跃事务指已完成读阶段，正在进行验证阶段的事务） 全局的已提交事务写集合列表history 事务开始，读阶段 获取开始时间戳start_ts 事务结束，进入验证阶段 获取结束时间戳end_ts，活跃事务列表active，将自身加入active 验证事务start_ts和end_ts之间提交的事务的写集与该事务的读集是否相交 验证active中的写集与该事务的读集和写集是否相交 相交，则发现冲突，在临界区内将本事务从active中去除并中止待验证事务 不相交，则验证成功，执行写入阶段 在临界区内将本事务从active列表中去除 读操作 将读操作所读的数据加入事务的读集合rset 写操作 将写操作所写的数据加入事务的写集合wset 实现代码参考这里 "},"project.html":{"url":"project.html","title":"LevelDB 大作业","keywords":"","body":"Project说明 要求 对于给定数据集说明如下 只有 key,value 无其它字段 数量级在5万-50万之间 对于主键和非主键都存在过滤条件 给定id查询的范围，同时给出特定的Email，输出该Email对应的所有id 可以自行采取优化方案 数据集 Id(int, Increment) Email(string) 1 xiaoming@ecnu.cn 2 hong@ecnu.cn 3 xiaoming@ecnu.cn 4 wang@ecnu.cn … … 100 li@sjtu.cn 101 wang@sjtu.cn … … id为主键，Email为value，其中，id不重复，Email有重复 同一个学校后缀的邮箱放在一起 说明 过滤条件 主键和非主键都存在过滤条件 给定一个较大的id范围区间（涵盖多个不同的学校邮箱） 查询Email相同学校邮箱下的同一个人 输出格式 所有的Pair，他们具有相同的Email + Email 数据量 5W-50W之间 注意 导入之后会自动出发leveldb的compaction，所以存在memtable和sst都有需要查询结果的情况 实现 思路 首先可以使用最简单的scan进行查找输出 为了简单起见，在第一次载入数据后，再跑一遍程序，使得cmake-build-debug/mydb中的.log文件为空，此时所有数据都在sst中 然后想到如何对于主键进行过滤：在sstable中，每一个table会维护当前key中的值域范围，可以通过该metadata对其进行主键过滤 如何对非主键过滤？levelDB提供了布隆过滤器，可以用于非主键的过滤 最后，如何对得到的所有可能kv对根据query进行输出？由于levelDB没有join等复杂的算子，因此可以使用multiMap数据结构进行存储。 主键过滤 事实上，levelDB已经实现了对于sst的key值划分，但这是根据字典序进行排序的。对于我们这个题来说，key都是id，因此需要使用整数进行比较，需要我们重写comparator函数。 在util/comparator.cc文件中，已经实现了默认的key字典序比较函数，因此我们需要继承该函数： class MyComparatorImpl : public Comparator { public: MyComparatorImpl() {} virtual const char *Name() const { return \"leveldb.MyComparator\"; } virtual int Compare(const Slice &a, const Slice &b) const { // 用stio会导致level 1没有table，level 2两层table，不知道为啥 int a_data = std::stoi(a.ToString()); int b_data = std::stoi(b.ToString()); if (a_data 同时，在util/options.cc文件中，需要将默认的comparator函数换为我们自定义的函数，这样就实现了重载。 对每个sst，通过对比与query range的大小，即可实现将部分sst进行过滤。 测试函数： // find level min-max leveldb::Version *current = db2->GetCurrentVersion(); std::vector files_ = current->GetFiles(1); for (int i = 0; i number smallest.user_key().ToString() largest.user_key().ToString() 非主键过滤 非主键过滤是通过布隆过滤器实现的。在levelDB中，已经实现了主键的布隆过滤器，需要我们更改为非主键。 在table/table.cc文件中，仿照InternalGet函数，构造自己的布隆过滤器查询函数： // new method, to indicate whether the value is in this table bool Table::ValueInTable(const leveldb::Slice &value_) { Iterator *iiter = rep_->index_block->NewIterator(rep_->options.comparator); iiter->SeekToFirst(); bool flag = false; while (iiter->Valid()) { Slice handle_value = iiter->value(); FilterBlockReader *filter = rep_->filter; BlockHandle handle; if (filter != nullptr && handle.DecodeFrom(&handle_value).ok() && !filter->KeyMayMatch(handle.offset(), value_)) { // std::cout Next(); } // std::cout 同时，我们需要将默认的主键上的布隆过滤器改为非主键的，在table/table_builder.cc文件中修改124行，这里需要注意的是，需要将value变为slice类型才能作为参数传递，因此需要加入sequence满足slice约束 if (r->filter_block != nullptr) { // r->filter_block->AddKey(key); // 向布隆过滤器添加值 // 向布隆过滤器添加mail（value），而不是key uint64_t seq = 1; std::string tmp_value = value.ToString(); PutFixed64(&tmp_value, seq); r->filter_block->AddKey(Slice(tmp_value)); } 这样就实现了简单的对于非主键的过滤优化。 读取sst 那么，通过metadata选择了可能存在当前value的sst，如何对sst进行读取呢？ 一个简单的测试函数为（助教提供） int main() { // open a db leveldb::DB *db; leveldb::Options options; // options.comparator = myCom; options.create_if_missing = true; std::string dbname_ = \"../cmake-build-debug/mydb123\"; leveldb::Status status2 = leveldb::DB::Open(options, dbname_, &db); leveldb::Version *current = db->GetCurrentVersion(); std::vector files_ = current->GetFiles(0); std::string fname = leveldb::TableFileName(dbname_, files_[0]->number); leveldb::RandomAccessFile *file = nullptr; leveldb::Table *table = nullptr; leveldb::Env *env_ = options.env; env_->NewRandomAccessFile(fname, &file); leveldb::Table::Open(options, file, files_[0]->file_size, &table); leveldb::Iterator *result = table->NewIterator(leveldb::ReadOptions()); result->SeekToFirst(); while (result->Valid()) { leveldb::ParsedInternalKey ikey; leveldb::ParseInternalKey(result->key(), &ikey); std::cout value().ToString() Next(); } delete db; return 0; } 输出 可以使用multimap进行输出，不再赘述 总代码 本实验完成的总代码可参考这里。入口函数在test/FinalDemo.cc中。 "}}