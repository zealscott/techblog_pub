{"./":{"url":"./","title":"Introduction","keywords":"","body":"Data Management Systems This GitBook notes are maintained by zealscott. Syllabus Lecture Reading Material Hints Notes 1. coding - Creating Great Programmers with a Software Design Studio- Criteria for modularization 2.introduce to document database - Design Philosophy- A Technical Introduction to WiredTigerl- understand JSON Document-oriented DB:MongoBD(1) 3. Logging - Durability _- write-ahead logging - Linearizability introduction ,- Linearizability original paper 存储的正确性 4. Availability - Raft protocol (importent), - MongoDB Consensus internal (optional)- Triple modular redundancy High availability - fault tolerant 5. Design for document database - Data Modeling for Document Database- Rules of Thumb for MongoDB Schema Design- ORM 6. Data Model(relation database) - Network Model- Hierarchy Model (a bit similar to mongodb)- Original paper on relational model by Codd 1/2) - History of RDBMS at IBM, an interesting read- About Expressiveness) data model 7. SQL SQL(1)SQL(2)SQL(3) 8. RelationDB design 关系数据库的逻辑设计 9. Normalization 关系数据库规范化 8. Physical Design - 物化视图- 强函数依赖- B-Tree- 聚簇索引- 索引的设计- 存储过程（UDP） 10. Transaction - Compensating Transaction- MongoDB Transaction - SQL Transaction 11. Object Relational Mismatch - Object Relational Mismatch Problems- Two Camps of Opinions- Class first- Data first 12. Query Process 13. OLAP 14. Database Tuning - Database Tuning 1st Edition 15. Distributed DB 16. Transction in DDB 17. Scalability 18. NewSQL 19. Search engine 20. Indexing - Multidimensional Indexing- k-d tree- R-tree - KD Tree- Curse of dimension Lab Lab1: Installation of Mongodb Lab2: Mongodb interface in Java MongoDB java driver using maven and IDEA to install tour Lab3: Mongodb in docker Lab4: SQL in PostgreSQL Lab5: Complex SQL CRUD Lab6: Crete DB schema Lab7: hibernate Introduction hibernate with PostgreSQL Lab8: Superset Lab9: OLTP Benchmark Lab10: SQL practice Lab11: Database backup @Last updated at 1/27/2021 "},"notes/data model.html":{"url":"notes/data model.html","title":"Data Model","keywords":"","body":" What is a good data model? 数据模型 数据的逻辑组织方式（数据的基本结构和结构的语义） 文档模型（MongoDB 2000s） 关系模型（SQL DB 1970s~80s） 层次模型（IBM IMS 1960s） 网状模型（GE IDS 1960s） 数据模型决定了数据的访问形式（接口），因此决定了系统的功能性和易用性。 Schema 对数据库中数据的结构性描述 参照schema才能正确书写查询 一种数据库的元数据（Metadata） 描述数据库中有什么样的数据 Metadata:Data about data DataModel相当于Schema的Metadata，即MetaMetadata！ 表达能力 如何衡量数据模型的表达能力？ 数据本身能够表达什么信息？ 计算机能够理解的信息 查询能够满足哪些信息需求？ 表达能力的两个维度 表达能力的范围：能够满足哪些信息需求 上限为Turing Completeness 计算机的表达能力上界，数据库无法达到 表达的精简程度：用户描述需求是否方便 Prolog比Java更精简更强 DeclarativeLanguage（声明式程序设计语言） 相对于ProceduralLanguage（过程式语言） 表达更精简，只需要告诉程序要什么，而不是怎么要 例子 FirstOrder Logic Prolog SQL/CRUD 对DBMS的智能提出了更高要求！ 关系模型 关系 笛卡尔积的子集 单一的数据结构----关系 现实世界的实体以及实体间的各种联系均用关系来表示 逻辑结构----二维表 从用户角度，关系模型中数据的逻辑结构是一张二维表 建立在集合代数的基础上 结构 关系 D1×D2×…×DnD_1×D_2×…×D_nD1​×D2​×…×Dn​的子集叫作在域D1,D2,…,DnD_1, D_2,…,D_nD1​,D2​,…,Dn​上的关系，表示为R(D1,D2,…,Dn)R(D_1,D_2,…,D_n)R(D1​,D2​,…,Dn​) R：关系名 n：关系的目或度（Degree） 元组 关系中的每个元素是关系中的元组，通常用t表示。 单元关系与二元关系（n-ary） 当n=1时，称该关系为单元关系（Unaryrelation）或一元关系 当n=2时，称该关系为二元关系（Binaryrelation） 关系的表示 关系也是一个二维表，表的每行对应一个元组，表的每列对应一个域 属性 关系中不同列可以对应相同的域 为了加以区分，必须对每列起一个名字，称为属性（Attribute） n目关系必有n个属性 码 候选码（Candidatekey） 若关系中的某一属性组的值能唯一地标识一个元组，则称该属性组为候选码 简单的情况：候选码只包含一个属性 全码（All-key） 最极端的情况：关系模式的所有属性组是这个关系模式的候选码，称为全码（All-key） 主码 若一个关系有多个候选码，则选定其中一个为主码（Primarykey） 主码也可以由多个属性组成 主属性 候选码的诸属性称为主属性（Primeattribute） 不包含在任何侯选码中的属性称为非主属性（Non-Primeattribute）或非码属性（Non-keyattribute） 基本的关系性质 列是同质的（Homogeneous） 不同的列可出自同一个域 其中的每一列称为一个属性 不同的属性要给予不同的属性名 列的顺序无所谓,，列的次序可以任意交换 任意两个元组的候选码不能相同 行的顺序无所谓，行的次序可以任意交换 关系代数 关系代数是一种抽象的查询语言，它用对关系的运算来表达查询 关系代数 运算对象是关系 运算结果亦为关系 关系代数的运算符有两类：集合运算符和专门的关系运算符 传统的集合运算是从关系的“水平”方向即行的角度进行 专门的关系运算不仅涉及行而且涉及列 选择 选择运算是从关系R中选取使逻辑表达式F为真的元组，是从行的角度进行的运算 投影 投影操作主要是从列的角度进行运算 投影之后不仅取消了原关系中的某些列，而且还可能取消某些元组（避免重复行） 连接 等值连接 自然连接 去除冗余行 悬浮元祖（Dangling tuple） –两个关系R和S在做自然连接时，关系R中某些元组有可能在S中不存在公共属性上值相等的元组，从而造成R中这些元组在操作时被舍弃了，这些被舍弃的元组称为悬浮元组。 外连接（OuterJoin） 如果把悬浮元组也保存在结果关系中，而在其他属性上填空值(Null)，就叫做外连接 左外连接(LEFTOUTER JOIN或LEFTJOIN) 只保留左边关系R中的悬浮元组 右外连接(RIGHTOUTER JOIN或RIGHTJOIN) 只保留右边关系S中的悬浮元组 一般的连接操作是从行的角度进行运算 表达能力范围比较 "},"notes/document.html":{"url":"notes/document.html","title":"Document-oriented DB","keywords":"","body":" Introduce to Document-oriented Database: MongoBD. Conception Document -> Collection -> Database Example: MongoDB (using in Web App) using B-Tree as storage structure Object Oriented Programming Unifying programming model and data model Everything is treated as object Document like json, the key-value pair Document can be seen as object Collection a class of document can be seen as class Database some documents constitute a database usually for one application Interface Insert > db.foo.insert({\"bar\":\"bsd}) > db.foo.batchInsert([{\"_id\":0},{\"_id\":1},{\"_id\":2}]) Find Delete > db.foo.remove() > db.mailing.list.remove({\"opt-out\":true}) Update Useful link MongoDB CRUD Operations json A Technical Introduction to WiredTiger NoSQL Databases Explained Creating Great Programmers with a Software Design Studio - John Ousterhout (Stanford) "},"notes/SQL 1.html":{"url":"notes/SQL 1.html","title":"SQL(1) 单表查询","keywords":"","body":"SQL 1974 年诞生于 IBM System-R项目 前称SEQUEL （Structured English Query Language） 声明式查询语言，易用，取代关系演算 Relational Calculus -> Relational Algebra Relational -> Relational Algebra Function of SQL 数据查询（ DQL ） 数据定义（DDL） 数据增删改（ DML ） 数据访问控制（ DCL ） Table 在定义表时，对数据格式的要求较高，可以让数据访问的效率更高 Create Key words PRIMARY KEY 主码，列完整性约束条件 UNIQUE 取唯一值 为了遵守独立性原则，由数据库来确定数据关系 FOREIGN KEY 设F是基本关系 R的一个或组属性 ，但不是关系 R的码。如果 F与基本关系 S的主码 Ks相对应 ，则称 F是R的外码 基本关系 R称为 参照关系 （Referencing Relation） 基本关系 S称为 被参照关系 （Referenced Relation） 或目标关系 （Target Relation） 当被参照表中的元组删除时，我们有两个选择： 连带删除参照表中对应的元组 如果 参照表中对应的元组还存在，删除操作无效 Alter 是要修改的基本表 ADD子句用于增加新列、新的列级完整性约束条件和新的表级完整性约束条件 DROP COLUMN子句用于删除表中的列 如果指定了CASCADE短语，则自动删除引用了该列的其他对象 如果指定了RESTRICT短语，则如果该列被其他对象引用，关系数据库管理系统将拒绝删除该列 DROP CONSTRAINT子句用于删除指定的完整性约束条件 ALTER COLUMN子句用于修改原有的列定义，包括修改列名和数据类型 修改表的代价很大，要么修改整张表，要么不修改。 与MongoDB完全不同 Drop Select Key words 使用列别名改变查询结果的列标题: SELECT Sname NAME, 'Year of Birth:' BIRTH, 2014-Sage BIRTHDAY, LOWER(Sdept) DEPARTMENT FROM Student; DISTINCT 去掉表中重复的行 确定范围 BETWEEN … AND … NOT BETWEEN … AND … 确定集合 IN , NOT IN 字符匹配 [NOT] LIKE ‘’ [ESCAPE ‘ ’] 查询名字中第2个字为\"阳\"字的学生的姓名和学号 SELECT Sname,Sno FROM Student WHERE Sname LIKE '__阳%'; 涉及空值的查询 IS NULL或 IS NOT NULL IS不能用=代替 多重条件查询 AND和 OR来连接多个查询条件 AND的优先级高于OR Index 常用索引 B-Tree Hash Index 通常情况下，主码会由系统自动创建索引 人工使用Create Index指令创建任意索引 "},"notes/SQL 2.html":{"url":"notes/SQL 2.html","title":"SQL(2)--复杂查询","keywords":"","body":" 关系数据库的查询结果都是一个结果表（也是关系） 集聚函数 基本语法 统计元组个数 COUNT(*) 统计一列中值的个数 COUNT([DISTINCT|ALL]) 计算一列值的总和（此列必须为数值型） SUM([DISTINCT|ALL]) 计算一列值的平均值（此列必须为数值型） AVG([DISTINCT|ALL]) 求一列中的最大值和最小值 MAX([DISTINCT|ALL]) MIN([DISTINCT|ALL]) 例子 查询选修1号课程的学生最高分数 SELECTMAX(Grade) FROM SC WHERE Cno='1'; 查询学生201215012选修课程的总学分数 SELECT SUM(Ccredit) FROM SC,Course WHERE Sno='201215012' AND SC.Cno=Course.Cno; GROUP BY 子句 细化聚集函数的作用对象 如果未对查询结果分组，聚集函数将作用于整个查询结果 对查询结果分组后，聚集函数将分别作用于每个组 按指定的一列或多列值分组，值相等的为一组 HAVING短语与WHERE子句的区别： 作用对象不同 WHERE子句作用于基表或视图，从中选择满足条件的元组 HAVING短语作用于组，从中选择满足条件的组 WHERE子句不能使用聚合函数！ 例子 求各个课程号及相应的选课人数 SELECT Cno, COUNT(Sno) FROM SC GROUP BY Cno; 查询选修了3门以上课程的学生学号 SELECT Sno FROM SC GROUP BY Sno HAVING COUNT(*) >3; 查询平均成绩大于等于90分的学生学号和平均成绩 SELECT Sno, AVG(Grade) FROM SC GROUP BY Sno HAVING AVG(Grade)>=90; 这里只能使用HAVING，不能使用WHERE。 ORDER BY子句 可以按一个或多个属性列排序 优先级逐渐降低 升序：ASC; 降序：DESC; 缺省值为升序 对于空值，排序时显示的次序由具体系统实现来决定 例子 查询选修了3号课程的学生的学号及其成绩，查询结果按分数降序排列 SELECT Sno, Grade FROM SC WHERE Cno= ' 3 ' ORDER BY Grade DESC; 查询全体学生情况，查询结果按所在系的系号升序排列，同一系中的学生按年龄降序排列 SELECT * FROM Student ORDER BY Sdept, Sage DESC; 连接查询 连接查询：同时涉及两个以上的表的查询 连接条件或连接谓词：用来连接两个表的条件 一般格式： [.] [.] [.]BETWEEN [.]AND[.] 连接字段：连接谓词中的列名称 连接条件中的各连接字段类型必须是可比的，但名字不必相同 （非）等值连接查询 等值连接：连接运算符为=，这里与Join操作等价。 例子 查询每个学生及其选修课程的情况 SELECT Student.*, SC.* FROM Student, SC WHERE Student.Sno = SC.Sno; 一条SQL语句可以同时完成选择和连接查询，这时WHERE子句是由连接谓词和选择谓词组成的复合条件。 查询选修2号课程且成绩在90分以上的所有学生的学号和姓名 SELECT Student.Sno, Sname FROM Student, SC WHERE Student.Sno=SC.Sno AND SC.Cno=' 2 ' AND SC.Grade>90; 执行过程 嵌套循环法（NESTED-LOOP） 首先在表1中找到第一个元组，然后从头开始扫描表2，逐一查找满足连接件的元组，找到后就将表1中的第一个元组与该元组拼接起来，形成结果表中一个元组。 表2全部查找完后，再找表1中第二个元组，然后再从头开始扫描表2，逐一查找满足连接条件的元组，找到后就将表1中的第二个元组与该元组拼接起来，形成结果表中一个元组。 重复上述操作，直到表1中的全部元组都处理完毕 可以发现，等值连接的复杂度很高，为O(m* n)。 自身连接 自身连接：一个表与其自己进行连接 需要给表起别名以示区别 由于所有属性名都是同名属性，因此必须使用别名前缀 例子 查询每一门课的间接先修课（即先修课的先修课） SELECT FIRST.Cno, SECOND.Cpno FROM Course FIRST, Course SECOND WHERE FIRST.Cpno = SECOND.Cno; 外连接 外连接与普通连接的区别 普通连接操作只输出满足连接条件的元组 外连接操作以指定表为连接主体，将主体表中不满足连接条件的元组一并输出 左外连接 列出左边关系中所有的元组 右外连接 列出右边关系中所有的元组 例子 SELECT Student.Sno, Sname, Ssex, Sage, Sdept, Cno, Grade FROM Student LEFT OUT JOIN SC ON (Student.Sno=SC.Sno); 多表连接 两个以上的表进行连接。 MongoDB不提供这种操作： JOIN很慢 多级扩展能力差，代价太高 例子 查询每个学生的学号、姓名、选修的课程名及成绩 SELECT Student.Sno, Sname, Cname, Grade FROM Student, SC, Course /*多表连接*/ WHERE Student.Sno = SC.Sno AND SC.Cno = Course.Cno; 嵌套查询 一个SELECT-FROM-WHERE语句称为一个查询块 将一个查询块嵌套在另一个查询块的WHERE子句或HAVING短语的条件中的查询称为嵌套查询 上层的查询块称为外层查询或父查询 下层查询块称为内层查询或子查询 SQL语言允许多层嵌套查询 即一个子查询中还可以嵌套其他子查询 子查询的限制 不能使用ORDERBY子句 因为ORDER BY 结果为有序的，不满足关系的定义，只能作为最后的生成结果 带有IN谓词的子查询 查询与“刘晨”在同一个系学习的学声 SELECT Sno, Sname, Sdept FROM Student WHERE Sdept IN (SELECT Sdept FROM Student WHERE Sname= ' 刘晨 '); /*用自身连接表示*/ SELECT S1.Sno, S1.Sname,S1.Sdept FROM Student S1,Student S2 WHERE S1.Sdept = S2.Sdept AND S2.Sname = '刘晨'; 查询选修了课程名为“信息系统”的学生学号和姓名 SELECT Sno,Sname FROM Student WHERE Sno IN (SELECT Sno FROM SC WHERE Cno IN (SELECT Cno FROM Course WHERE Cname= '信息系统' ) ); /*用连接查询表示*/ SELECT Sno,Sname FROM Student,SC,Course WHERE Student.Sno = SC.Sno AND SC.Cno = Course.Cno AND Course.Cname='信息系统'; 带有比较运算符的子查询 当能确切知道内层查询返回单值时，可用比较运算符（>，=，）。 由于一个学生只可能在一个系学习，则可以用 = 代替IN ： SELECT Sno,Sname,Sdept FROM Student WHERE Sdept = (SELECT Sdept FROM Student WHERE Sname= '刘晨'); 注意，用比较运算符取嵌套，只能SELECT一个属性，且为数值类型。 不相关子查询 子查询的查询条件不依赖于父查询 由里向外逐层处理。即每个子查询在上一级查询处理之前求解，子查询的结果用于建立其父查询的查找条件。 相关子查询 子查询的查询条件依赖于父查询 首先取外层查询中表的第一个元组，根据它与内层查询相关的属性值处理内层查询，若WHERE子句返回值为真，则取此元组放入结果表 然后再取外层表的下一个元组 重复这一过程，直至外层表全部检查完为止 例子 找出每个学生超过他选修课程平均成绩的课程号 SELECT Sno, Cno FROM SC x WHERE Grade >= ( SELECT AVG(Grade) FROM SC y WHERE y.Sno = x.Sno ); /*用连接查询表示*/ SELECT First.Sno, First.Cno FROM SC First JOIN ( SELECT Sno, AVG(Grade) as A_Grade FROM SC GROUP BY Sno) SA ON First.Sno = SA.Sno WHERE First.Grade > SA.A_Grade 带有ANY（SOME）或ALL谓词的子查询 使用ANY或ALL谓词时必须同时使用比较运算 若子查询中不是唯一的，使用ANY/ALL可以使用比较运算符 语义为： > ANY 大于子查询结果中的某个值 >ALL 大于子查询结果中的所有值 >=ANY 大于等于子查询结果中的某个值 =ANY 等于子查询结果中的某个值 !=（或<>）ALL 不等于子查询结果中的任何一个值 例子 查询非计算机科学系中比计算机科学系任意一个学生年龄小的学生姓名和年龄 SELECT Sname,Sage FROM Student WHERE Sage ‘CS ' ; /*父查询块中的条件 */ /*用聚集函数实现*/ SELECT Sname,Sage FROM Student WHERE Sage ' CS '; 查询非计算机科学系中比计算机科学系所有学生年龄都小的学生姓名及年龄 SELECT Sname,Sage FROM Student WHERE Sage ' CS ’; /*用聚集函数实现*/ SELECT Sname,Sage FROM Student WHERE Sage ' CS '; 带有EXISTS谓词的子查询 EXISTS谓词 存在量词 带有EXISTS谓词的子查询不返回任何数据，只产生逻辑真值“true”或逻辑假值“false”。 若内层查询结果非空，则外层的WHERE子句返回真值 若内层查询结果为空，则外层的WHERE子句返回假值 由EXISTS引出的子查询，其目标列表达式通常都用* ，因为带EXISTS的子查询只返回真值或假值，给出列名无实际意义。 例子 查询所有选修了1号课程的学生姓名。 思路 本查询涉及Student和SC关系 在Student中依次取每个元组的Sno值，用此值去检查SC表 若SC中存在这样的元组，其Sno值等于此Student.Sno值，并且其Cno=‘1’，则取此Student.Sname送入结果表 SELECT Sname FROM Student WHERE EXISTS (SELECT * FROM SC WHERE Sno=Student.Sno AND Cno= ' 1 '); 查询没有选修1号课程的学生姓名。 SELECT Sname FROM Student WHERE NOT EXISTS (SELECT * FROM SC WHERE Sno = Student.Sno AND Cno='1'); 难点 不同形式的查询间的替换 一些带EXISTS或NOT EXISTS谓词的子查询不能被其他形式的子查询等价替换 所有带IN谓词、比较运算符、ANY和ALL谓词的子查询都能用带EXISTS谓词的子查询等价替换 查询与“刘晨”在同一个系学习的学生 可以用带EXISTS谓词的子查询替换 SELECT Sno,Sname,Sdept FROM Student S1 WHERE EXISTS 　 (SELECT * FROM Student S2 WHERE S2.Sdept = S1.Sdept AND S2.Sname = '刘晨'); 用EXISTS/NOT EXISTS实现全称量词（难点） 查询选修了全部课程的学生姓名 不存在一门课,这个学生没有选 SELECT Sname FROM Student WHERE NOT EXISTS (SELECT * FROM Course WHERE NOT EXISTS (SELECT * FROM SC WHERE Sno= Student.Sno AND Cno= Course.Cno ) ); "},"notes/SQL-3.html":{"url":"notes/SQL-3.html","title":"SQL(3)--视图与索引","keywords":"","body":" 介绍数据修改的SQL语句以及视图与索引 数据修改 三种修改方式： 修改某一个元组的值 /* 将学生201215121的年龄改为22岁 */ UPDATE Student SET Sage=22 WHERE Sno=' 201215121 '; 修改多个元组的值 /* 将所有学生的年龄增加1岁 */ UPDATE Student SET Sage= Sage+1; 带子查询的修改语句 /* 将计算机科学系全体学生的成绩置零 */ UPDATE SC SET Grade=0 WHERE Sno IN (SELECT Sno FROM Student WHERE Sdept= 'CS' ); 要求 关系数据库管理系统在执行修改语句时会检查修改操作是否破坏表上已定义的完整性规则 实体完整性 主码不允许修改（如果被外码参照） 用户定义的完整性 NOT NULL约束 UNIQUE约束 值域约束 删除数据 语句格式 DELETE FROM [WHERE ]; 功能 删除指定表中满足WHERE子句条件的元组 WHERE子句 指定要删除的元组 缺省表示要删除表中的全部元组，表的定义仍在字典中 删除方式 删除某一个元组的值 /* 删除学号为201215128的学生记录。 */ DELETE FROM Student WHERE Sno= '201215128'; 删除多个元组的值 /* 删除所有的学生选课记录 */ DELETE FROM SC; 带子查询的删除语句 /* 删除计算机科学系所有学生的选课记录。*/ DELETE FROM SC WHERE Sno IN (SELETE Sno FROM Student WHERE Sdept= 'CS') ; 空值 空值是一个很特殊的值，含有不确定性。对关系运算带来特殊的问题，需要做特殊的处理。 空值的产生 向SC表中插入一个元组，学生号是”201215126”，课程号是”1”，成绩为空。 INSERT INTO SC(Sno,Cno,Grade) VALUES('201215126 ','1',NULL); /*该学生还没有考试成绩，取空值*/ 或 INSERT INTO SC(Sno,Cno) VALUES(' 201215126 ','1'); /*没有赋值的属性，其值为空值*/ 将Student表中学生号为”201215200”的学生所属的系改为空值。 UPDATE Student SET Sdept = NULL WHERE Sno='201215200'; 空值的判断 判断一个属性的值是否为空值，用IS NULL或IS NOT NULL来表示。 /* 从Student表中找出漏填了数据的学生信息*/ SELECT * FROM Student WHERE Sname IS NULL OR Ssex IS NULL OR Sage IS NULL OR Sdept IS NULL; 空值的约束条件 属性定义（或者域定义）中 有NOT NULL约束条件的不能取空值 Primary Key不能为空值 加了UNIQUE限制的属性不能取空值 码属性不能取空值 空值的运算 空值与另一个值（包括另一个空值）的算术运算的结果为空值 空值与另一个值（包括另一个空值）的比较运算的结果为UNKNOWN。 有UNKNOWN后，传统二值（TRUE，FALSE）逻辑就扩展成了三值逻辑 无论判断结果是否为True，都不会返回空值 找出选修1号课程的不及格的学生。 SELECT Sno FROM SC WHERE Grade 查询结果不包括缺考的学生，因为他们的Grade值为null。 视图 虚表，是从一个或几个基本表（或视图）导出的表 只存放视图的定义，不存放视图对应的数据 基表中的数据发生变化，从视图中查询出的数据也随之改变 建立视图 CREATE VIEW [( [,]…)] AS [WITH CHECK OPTION]; 组成视图的属性列名：全部省略或全部指定 全部省略 由子查询中SELECT目标列中的诸字段组成 明确指定视图的所有列名 某个目标列是聚集函数或列表达式 多表连接时选出了几个同名列作为视图的字段 需要在视图中为某个列启用新的更合适的名字 关系数据库管理系统执行CREATE VIEW语句时只是把视图定义存入数据字典，并不执行其中的SELECT语句。 WITHCHECK OPTION 对视图进行UPDATE，INSERT和DELETE操作时要保证更新、插入或删除的行满足视图定义中的谓词条件（即子查询中的条件表达式） 在对视图查询时，按视图的定义从基本表中将数据查出。 建立信息系学生的视图 CREATE VIEW IS_Student AS SELECT Sno,Sname,Sage FROM Student WHERE Sdept= 'IS'; 基于多个基表的视图 建立信息系选修了1号课程的学生的视图（包括学号、姓名、成绩） CREATE VIEW IS_S1(Sno,Sname,Grade) AS SELECT Student.Sno,Sname,Grade FROM Student,SC WHERE Sdept= 'IS' AND Student.Sno=SC.Sno AND SC.Cno= '1'; 带表达式的视图 定义一个反映学生出生年份的视图。 CREATE VIEW BT_S(Sno,Sname,Sbirth) AS SELECT Sno,Sname,2014-Sage FROM Student; 分组视图 将学生的学号及平均成绩定义为一个视图 CREAT VIEW S_G(Sno,Gavg) AS SELECT Sno,AVG(Grade) FROM SC GROUP BY Sno; 删除视图 语句的格式 DROP VIEW [CASCADE]; 该语句从数据字典中删除指定的视图定义 如果该视图上还导出了其他视图，使用CASCADE级联删除语句，把该视图和由它导出的所有视图一起删除 删除基表时，由该基表导出的所有视图定义都必须显式地使用DROP VIEW语句删除 查询视图 用户角度 查询视图与查询基本表相同 关系数据库管理系统实现视图查询的方法 视图消解法（View Resolution） 进行有效性检查 转换成等价的对基本表的查询 执行修正后的查询 视图的作用 视图能够简化用户的操作 视图对重构数据库提供了一定程度的逻辑独立性 在新表上建立一个旧表视图。应用程序在旧表上的SQL可以保持不变。 视图能够对机密数据提供安全保护 适当的利用视图可以更清晰的表达查询 索引 建立索引的目的：加快查询速度 关系数据库管理系统中常见索引： 顺序文件上的索引 B+树索引 散列（hash）索引 位图索引 特点 B+树索引具有动态平衡的优点 HASH索引具有查找速度快的特点 建立索引 语句格式 CREATE [UNIQUE] [CLUSTER] INDEX ON ([][,[] ]…); ：要建索引的基本表的名字 索引：可以建立在该表的一列或多列上，各列名之间用逗号分隔 ：指定索引值的排列次序，升序：ASC，降序：DESC。缺省值：ASC UNIQUE：此索引的每一个索引值只对应唯一的数据记录 CLUSTER：表示要建立的索引是聚簇索引 修改索引 ALTER INDEX RENAME TO 删除索引 删除索引时，系统会从数据字典中删去有关该索引的描述。 DROP INDEX ; "},"notes/design.html":{"url":"notes/design.html","title":"关系数据库的逻辑设计","keywords":"","body":" 如何设计关系数据库？ 数据库设计流程 需求分析 了解用户需求，确定软件的基本功能。 概念模型设计 确定数据库需要记录哪些信息。 逻辑结构设计 确定数据的组织形式。 数据库物理设计 确定数据的存储方式、索引使用系统配置等。 数据库实施 安装 数据 库管理系统、创建、调试运行 。 数据库设计演进 根据需求的扩展与变化，对以上结果进行调整和变更 文档型数据库 对于文档型数据库，需要确定 数据库要记录那些对象 对象之间的关系以及文档结构（embedding or reference） 关系数据库 对于关系数据库，需要确定 数据库要记录那些实体和联系(ERD) 关系的基本定义 优化关系的定义 关系数据库设计基本概念 逻辑设计 只跟概念有关，与应用无– 概念模型、逻辑独立于应用 最小化对应用程序的依赖 物理设计 物理模型与应用相关 优化应用的性能 概念模型和物理模型 严格意义上，二者是两套模型 现实的 RDBMS RDBMS 很难区分（物理设计只是对逻辑的优化） ER图 E：Entity Entity（实体） R：Relationship（联系） 基本概念： 世界由实体组成。 实体由属性刻画。 实体之间存在联系。 实体可分类，别确定的属性。 组成 实体（ Entity Entity ） 现实世界中可以被标识的具体事物。 姚明（身份证号） 我的一辆福特汽车（牌号） 实体类（ Entity Type Entity TypeEntity Type ） 具有相同属性的实体集合。 人 联系（ Relationship） 现实世界中事物内部以及之间的联系，在 ER 图中反映为实 图中反映为实体内部的联系和实之间。 我和的银行账户之间联系； 联系类（ Relationship Type） 涉及特定实体类之间，并且具有相同属性的联系集合。 联系类的势（ Cardinality ） 一对联系（ 1:1 ） 人-身份证、夫妻 一对多联系（ 1:m/m:1 ）人 -出生地、父子 多对联系（ m:m ） 学生 -课 属性（ Attribute） 对于实体类（或联系类），属性是描述该对于实体（或联 系）的某种特征结构。 身高是人的一种属性。 对于实体（或联系），属性是描述该实体的某个特征的数据 姚明的身高为 2.29米。 属性的势（ Cardinality） 唯一属性（ 1:1 1:1） 人- 身份证号 单值属性（ m:1 ） 人- 生日、人 - 名字 多值属性（ 1:m/m:m） 人-技能、人 - 作品 表示方法 "},"notes/normalization.html":{"url":"notes/normalization.html","title":"关系数据库规范化","keywords":"","body":" 如何设计关系数据库的各个表，减少数据冗余？ 数据库范式化 目的 减少数据中重复和冗余 冗余带来的问题 额外的存储开销 语义不清晰 数据增删改的麻烦 程序员必须知道容易的存在 应用程序与数据库之间的关系复杂化 在关系数据库的理念中，好的模式设计应该避免冗余 性能问题应该交给物理层来解决 但对于实际问题中，很难做到 第一范式 只要满足关系的定义（笛卡尔积的子集），则满足第一范式 函数依赖 设R(U) 为属性集 U上的关系模式。 X，Y是U的子集。若对于 R(U) 的 任意一个在现实世界中可能的关系 r，r中不可能存在 两个元组中X上的属性值相上的属性值相 等，而在Y上的属性值不等，则称 Y函数依赖于 X， 记作 X->Y。 完全函数依赖 对于X，必须由其全部属性才能确定Y，则称为Y完全依赖于X。 键 设R(U) 为属性集 U上的关系模式。 X是U的子集。 如果 X->U，并且不存在 X的子集 X’ 使得 X’ ->U， 那么 X为R(U) 的键/码（key）。 在R(U)中可能存在多个键，我们人为指定其中的一个键为主键（primary key） 包含在任意一个键中的属性，称为主属性（primary attribute）。 第二范式 关系模式R满足第二范式，当且仅当，R满足第一范式，并且，R的每一个非主属性都完全依赖于R的每一个键。 若不是键，则不能决定其他属性。 第三范式 关系模式R满足第三范式，当且仅当，R中不存在这样的键X，属性组Y和非主属性Z，使得X->Y，Y->Z成立，且Y->X不成立。 即：若X是键，Y不是键，但Y能决定Z，则不满足第三范式。 满足第三范式的模式必满足第二范式。 BC范式 关系模式 R满足 BC 范式，当且仅对任意一个属性集 A，如果存在不属于A一个属性 X， 使得 X函数依赖于A，那么所有R的属性都函数依赖于A。 任何满足BC范式的关系模式都满足第三范式。 BCNF与第三范式的不同之处在于： 第三范式中不允许非主属性被另一个非主属性决定，但第三范式允许主属性被非主属性决定； 而在BCNF中，任何属性（包括非主属性和主属性）都不能被非主属性所决定。 "},"notes/storage.html":{"url":"notes/storage.html","title":"存储的正确性","keywords":"","body":" 如何保证数据的正确性和一致性？ 数据不会被恶意串改和删除（一般不在数据库中考虑） 在发生宕机、磁盘损坏或其他意外时，数据完好 在程序出错的情况下，数据不被损坏（很难补救） 如何衡量？ 一个CRUD操作成功，将永久性生效（Durability） 除了read，其余操会导致状态转移 任何一个CRUD操作都将被正确的执行 逻辑上不出错 原子性（Atomicity） 一个操作在瞬间完成 只有完成和未完成两种可能 主要关注两个问题 系统故障的干扰 其他CRUD操作的干扰 解决宕机问题 Logging/Journaling Undo日志 immediate modified 在写入磁盘前，记录当前状态的值 需要在数据之前到达磁盘 规则 每一次对数据的改动都要记录日志 日志记录必须在数据之前到达磁盘（WAL） 操作结束之前，所有的数据和日志必须到达磁盘 在\\之后表示这次操作成功 由于logging始终比真实的CRUD先，总是可以回到上一步操作 从后往前恢复 缺点 日志读写是顺序的，数据访问是随机的，操作结束之前必须将数据刷盘 内存缺失了写缓存的作用 Redo日志 deferred modified 每次记录这次CRUD操作后的值 规则 每一次对数据的改动都要记录日志 操作结束之前所有的日志必须到达磁盘 没有必要每一次都写进磁盘 数据到达磁盘后，需要在日志中记录 操作可以不需要 重放日志 从前往后恢复 需要设置checkpoint来减少重放日志的工作量 强制将之前的操作落盘 定时checkpoint，减少log的大小 在进行checkpoint时候，相应速度会变慢 缺点 若一个操作很长，则会占用很大的内存空间 操作结束之前不能将数据刷盘 Undo/Redo日志 规则 数据可以在任何时间到达磁盘 操作结束前或操作结束后 日志必须在数据之前到达磁盘 操作结束之前所有的日志必须到达磁盘 不受其他CRUD干扰 Linearizability All function calls have a linearization point at some instant between their invocation and their response. all functions appear to occur instantly at their linearization point, behaving as specified by the sequential definition. 保证无论谁先做谁后做，一定不会让系统confuse 通过加锁实现并发控制 二阶段加锁可以实现线性化 但当数据有多份时，若加锁，开销太大 "},"notes/availability.html":{"url":"notes/availability.html","title":"数据库的Availability","keywords":"","body":" High availability - fault tolerant Useful link Raft algorthem visualization of Raft original paper zh_cn version work using Redundancy and Replication to reach fault tolerant Raft key point leader control the whole process, interact with clients candidate if cannot receive heartbeat from leader, wait for a random timeout to be cadidate follower Leader election two timeout election timeout is the amount of time a follower waits until becoming a candidate. then it assumes there is no viable leader and begins an election to choose a new leader randomized to be between 150ms and 300ms. After the election timeout the follower becomes a candidate and starts a new election term sends out Request Vote messages to other nodes. heartbeat timeout leader sends heartbeat messages to all of the other servers to establish its authority and prevent new elections. Leader once get majority votes, leader begins sending out Append Entries messages to its followers. send in intervals specified by the heartbeat timeout if node cannot receive heartbeat, then become a candidate and re-election Requiring a majority of votes guarantees that only one leader can be elected per term. split vote if two or more candidates receive same votes The nodes will wait for a new election and try again. log replicate This is done by using the same Append Entries message that was used for heartbeats. committed The leader decides when it is safe to apply a log entry to the state machines; such an entry is called committed. Raft guarantees that committed entries are durable and will eventually be executed by all of the available state machines. once new entry committed leader executes command in its state machine ,return result to client leader notifies followers of committed entries in subsequent AppendEntries RPCs followers execute committed commands in their state machines "},"project/postgre1.html":{"url":"project/postgre1.html","title":"PostgreSQL配置与单表查询","keywords":"","body":"PostgreSQL 安装 Windows Linux 创建数据库和表 使用SQL语句，完成创建一个数据库，创建关系。 创建数据库scDB； create database scDB; 按要求创建四个表： Student(Sno,Sname,Ssex,Sage,Sdept) create table Student //学生表 ( Sno char(9) unique, Sname char(5) not null, Ssex char(2), Sage smallint, Sdept char(20), primary key(Sno) // 设置主码为学号 ); Course(Cno,Cname,Cpno,Ccredits) create table Course //课程表 ( Cno char(4), Cname char(20) not null, Cpno char(4), // 先修课程 Ccredits smallint, primary key(Cno), // 设置主码为课程编号 foreign key(Cpno) references Courese(Cno) // 约束条件，Cpno为外码，被参照表Course，被参照列为Cno ); SC(Sno,Cno,Grade) create table SC //学生选课表 ( Sno char(9), Cno char(4), Grade smallint, foreign key(Sno) references Student(Sno), // 约束条件，Cpno为外码，被参照表Course，被参照列为Cno foreign key(Cno) references Course(Cno) ); 注意，执行SQL脚本时，Postgre不能识别大小写，必须添加双引号，如果有中文，则使用GB 2312格式保存： 执行脚本，注意，在Windows下，路径要使用正斜杠 查看表，注意，若有大小写，也要加引号： 简单单表查询 运行脚本 查看表，其中S是供应商表，P为零件表，J为工程项目表，SPJ是供应情况表 课上习题 找出所有供应商的姓名和所在城市 select sno,sname from s; 找出所有零件的名称，颜色，重量 select pname,color,weight from p; 找出工程项目J2使用的各种零件的名称及数量 SELECT spj.qty,p.pname FROM spj, p WHERE spj.pno = p.pno and spj.jno='J2'; 找出上海厂商供应的所有零件号码 SELECT distinct spj.pno FROM spj, s WHERE s.sno = spj.sno and s.city='上海'; 找出使用上海产的零件的工程号码 SELECT distinct spj.jno FROM spj, s WHERE s.sno = spj.sno and s.city='上海'; 找出没有使用天津产的零件的工程号码 SELECT distinct spj.jno FROM spj, s WHERE s.sno = spj.sno and s.city<>'天津'; 把所有红色零件的颜色改成蓝色 UPDATE p SET color = '蓝' WHERE color = '红' ; 由S5供给J4的零件P6改为由S3供应，请做出必要的修改： UPDATE spj SET sno = 'S3' WHERE sno = 'S5' and jno = 'J4' and pno ='P6' ; 从供应商关系中删除S2的记录，并从供应情况关系中删除相应的记录 DELETE FROM spj WHERE sno = 'S2'; DELETE FROM s WHERE sno = 'S2'; 请将（S2，J6，P4,200）插入供应情况关系 INSERT INTO s VALUES ('S2', '盛锡', 10 ,'北京'); INSERT INTO spj VALUES ('S2', 'P4', 'J6' ,200); 操作 数据库命令 \\password 设置密码 \\q 退出 \\h 查看SQL命令的解释，比如\\h select \\e 打开文本编辑器。 \\conninfo 列出当前数据库和连接的信息。 \\\\? 查看psql命令列表 \\du 列出所有用户。 \\i yourPath 运行sql脚本 数据库查询时使用单引号 \\l 列出所有数据库 \\c [database_name] 连接其他数据库 \\d 列出当前数据库的所有表格 \\d [table_name] 列出某一张表格的结构 drop database db; 删除一个数据库 drop table table_name; 删除一个表 "},"project/postgre2.html":{"url":"project/postgre2.html","title":"使用PostgreSQL进行复杂查询","keywords":"","body":" SQL复杂查询与视图 数据说明 现在有一个spj数据库，其中有四个表，分别为： S P J SPJ 供应商代码表 零件表 工程项目表 供应情况表 SQL查询 创建视图 将零件表P表与供应情况SPJ表、供应商S表结合，得到零件与供应商的关系： CREATE VIEW P_S AS SELECT P.PNO,PNAME,COLOR,WEIGHT,S.SNO,JNO,QTY,SNAME,STATUS,CITY FROM P LEFT JOIN SPJ ON P.PNO = SPJ.PNO LEFT JOIN S ON SPJ.SNO = S.SNO; 可以得到： 操作 在零件表的视图中找出weight SELECT DISTINCT PNAME FROM P_S WHERE WEIGHT 查询供应商表中城市为北京的供应商姓名(SNAME) SELECT DISTINCT SNAME FROM S WHERE CITY = '北京'; 在零件表中查询平均重量在15以上的零件名字和零件代码（PNO） SELECT DISTINCT PNAME,PNO FROM P_S WHERE PNAME IN ( SELECT DISTINCT PNAME FROM P_S GROUP BY PNAME HAVING AVG(WEIGHT) > 15); 查询全体供应商的姓名（SNAME）和状态(STATUS) SELECT DISTINCT SNAME,STATUS FROM P_S; 查询所有weight在13到20岁（含13和20）的零件代码（PNO）、零件名（PNAME）和颜色(COLOR) SELECT DISTINCT PNO,PNAME,COLOR FROM P_S WHERE WEIGHT >= 13 AND WEIGHT 查询所有“螺”开头的的零件代码（PNO）和零件名（PNAME） SELECT DISTINCT PNO,PNAME FROM P_S WHERE PNAME like '螺%' 查询所有零件的平均重量 SELECT DISTINCT PNAME,AVG(WEIGHT) FROM P_S GROUP BY PNAME; 查询同在“天津”的工程项目名（JNAME） SELECT JNAME FROM J WHERE CITY = '天津'; 查询在“精益”供应商下的零件，且质量小于15的零件详细信息 SELECT PNO,PNAME,COLOR,WEIGHT,JNO,QTY FROM P_S WHERE SNAME = '精益'; "},"project/jbdc.html":{"url":"project/jbdc.html","title":"JBDC","keywords":"","body":"使用说明 下载JAR包 从这里下载合适的JAR包，并加入IDEA的路径中。 连接数据库 /** * @method getConn() 获取数据库的连接 * @return Connection */ public Connection getConn() { String driver = \"org.postgresql.Driver\"; String url = \"jdbc:postgresql://localhost:5432/spj\"; String username = \"postgres\"; String password = \"postgres\"; Connection conn = null; try { Class.forName(driver); // classLoader,加载对应驱动 conn = DriverManager.getConnection(url, username, password); } catch (ClassNotFoundException e) { e.printStackTrace(); } catch (SQLException e) { e.printStackTrace(); } return conn; CRUD 在进行CRUD中，一种方法是将变量和SQL语句写在一起组成String直接执行，另一种更好的方法是使用PreparedStatement。 PreparedStatement是预编译的，并且直观容易修改，对于批量处理可以大大提高效率。 Update /** * @method update(Student student) 更改表中数据 * @return int 成功更改表中数据条数 */ public int update(S s) { Connection conn = getConn(); int i = 0; String sql = \"update S set sname= ? where sno=? \"; PreparedStatement pstmt; try { pstmt = (PreparedStatement) conn.prepareStatement(sql); pstmt.setString(1,s.getSname()); pstmt.setString(2,s.getSno()); i = pstmt.executeUpdate(); System.out.println(\"resutl: \" + i); pstmt.close(); conn.close(); } catch (SQLException e) { e.printStackTrace(); } return i; } Delete /** * @method delete(Student student) 删除表中数据 * @return int 成功删除表中数据条数 */ public int delete(String no) { Connection conn = getConn(); int i = 0; String sql = \"delete from S where sno=?\"; PreparedStatement pstmt; try { pstmt = (PreparedStatement) conn.prepareStatement(sql); pstmt.setString(1,no); i = pstmt.executeUpdate(); System.out.println(\"resutl: \" + i); pstmt.close(); conn.close(); } catch (SQLException e) { e.printStackTrace(); } return i; } Insert /** * @method insert(Student student) 往表中插入数据 * @return int 成功插入数据条数 */ public int insert(S s) { Connection conn = getConn(); int i = 0; String sql = \"insert into s (sno,sname,status,city) values(?,?,?,?)\"; PreparedStatement pstmt; try { pstmt = (PreparedStatement) conn.prepareStatement(sql); pstmt.setString(1, s.getSno()); pstmt.setString(2, s.getSname()); pstmt.setString(3, s.getStatus()); pstmt.setString(4, s.getCity()); i = pstmt.executeUpdate(); pstmt.close(); conn.close(); } catch (SQLException e) { e.printStackTrace(); } return i; } Select /** * * @method Integer SelectCity(String City) 查询城市 * @return Integer 查询并打印表中数据 */ public void SelectCity(String City){ Connection conn = getConn(); String sql = \"select * from S where city = ? \"; PreparedStatement pstmt; try { pstmt = (PreparedStatement) conn.prepareStatement(sql); pstmt.setString(1,City); ResultSet rs = pstmt.executeQuery(); int col = rs.getMetaData().getColumnCount(); System.out.println(\"============================\"); // 打印每一列 while (rs.next()) { for (int i = 1; i "},"project/hibernate.html":{"url":"project/hibernate.html","title":"Hibernate使用","keywords":"","body":"创建项目 创建一个HibernateTest项目 在依赖中添加postgresql的JAR包 修改hibernate.cfg.xml org.postgresql.Driver jdbc:postgresql://localhost:5432/Game2 postgres 1234 true true update --> 这里连接了Game2的数据库 连接数据库 添加PostgreSQL 写入用户名和密码，注意，红框中写数据库名字 在持久化中，添加我们需要的表： 这里需要指定Package，指定我们之前创建的entity 这样，我们会发现其自动帮我们新建了一个Trade的实体类： 但注意，没有帮我们添加构造函数，需要自己添加。 同时，在cfg文件中，发现其自动添加了mapping关系： 运行 这里需要额外注意的是，hibernate默认不区分大小写，如果表名或者column有大小写区分，需要用转义符自己更改 创建HibernateSessionFactory： import entity.PlayerEntity; import org.hibernate.Session; import org.hibernate.SessionFactory; import org.hibernate.Transaction; import org.hibernate.boot.MetadataSources; import org.hibernate.boot.registry.StandardServiceRegistry; import org.hibernate.boot.registry.StandardServiceRegistryBuilder; import org.hibernate.cfg.Configuration; import java.util.List; public class HibernateSessionFactory { public static void main(String[] args) { //创建配置对象(读取配置文档) Configuration config = new Configuration().configure(); //创建会话工厂对象 SessionFactory sessionFactory = config.buildSessionFactory(); //会话对象 Session session = sessionFactory.openSession(); //这是开启Session的操作 session.beginTransaction(); PlayerEntity player1 = new PlayerEntity(); player1.setCoin(10); player1.setUserName(\"scott\"); //这正是把数据放入一级缓存session中的操作 session.save(player1); //此处才是真正与数据库交互的语句 session.getTransaction().commit(); session.close(); } } 这样直接运行会报错： java.lang.ClassNotFoundException: javax.xml.bind.JAXBException 原因是JAXB API是java EE 的API，因此在java SE 9.0 中不再包含这个 Jar 包。java 9 中引入了模块的概念，默认情况下，Java SE中将不再包含java EE 的Jar包。而在 java 6/7 / 8 时关于这个API 都是捆绑在一起的。 因此，需要手动添加以下Jar包到lib： javax.activation-1.2.0.jar jaxb-api-2.3.0.jar jaxb-core-2.3.0.jar jaxb-impl-2.3.0.jar 这样运行后，在数据库查看： 成功！ Debug 在shell中，如果选择的column有大小写区分，需要添加双引号 在shell中，如果需要添加字符串，需要添加单引号 Hibernate5中表字段大小写探讨 JAXBE错误 Hibernate增删查改操作 "},"project/many to many.html":{"url":"project/many to many.html","title":"Hibernate多对多关系","keywords":"","body":" 使用注解用Hibernate自动创建多对多数据表 之前我们用hibernate连接已经创建的数据表，并避免了直接写SQL语言。 同样，对于多对多的关系映射，我们可以直接在程序中定义这种对象的关系，然后JPA会自动帮助我们创建表和相关关系。 创建项目 与之前一样，创建Hibernate项目。 需要额外注意，JDK9以上需要添加JPA额外的包才不会报错，具体请参考这里。 同时，将Postgres的JAR包加入lib。 设置xml 设置hibernate.cfg.xml，注意，由于我们对象对应的表在该数据库中不存在，因此要添加自动创建表的设置 org.postgresql.Driver jdbc:postgresql://localhost:5432/stu postgres xxx true update true update --> 项目结构 我们以老师和学生多对多的关系举例 学生 package Entity; import javax.persistence.*; import java.io.Serializable; import java.util.Date; import java.util.Set; @Entity //@Table(name = \"t_student\") //@SequenceGenerator(name = \"SEQ_STUDENT\", sequenceName = \"SEQ_STUDENT\") public class Student implements Serializable { private static final long serialVersionUID = 2524659555729848644L; private Long id; private String name; private Date birthday; private int sex; private String address; private Set teacherList; private Integer a; @Id @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = \"id\", nullable = false, precision = 22, scale = 0) public Long getId() { return id; } public void setId(Long id) { this.id = id; } @Column(name = \"name\") public String getName() { return name; } public void setName(String name) { this.name = name; } @Temporal(TemporalType.DATE) @Column(name = \"birthday\") public Date getBirthday() { return birthday; } public void setBirthday(Date birthday) { this.birthday = birthday; } @Column(name = \"sex\") public int getSex() { return sex; } public void setSex(int sex) { this.sex = sex; } @Column(name = \"address\") public String getAddress() { return address; } public void setAddress(String address) { this.address = address; } @ManyToMany(cascade = CascadeType.ALL) @JoinTable(name = \"t_teacher_student\", joinColumns = @JoinColumn(name = \"stu_id\",referencedColumnName=\"id\"), inverseJoinColumns = @JoinColumn(name = \"teacher_id\",referencedColumnName =\"id\")) public Set getTeacherList() { return teacherList; } public void setTeacherList(Set teacherList) { this.teacherList = teacherList; } } 老师 package Entity; import Entity.Student; import javax.persistence.*; import java.io.Serializable; import java.util.Set; @Entity //@Table(name = \"t_teacher\") //@SequenceGenerator(name = \"SEQ_TEACHER\", sequenceName = \"SEQ_TEACHER\") public class Teacher implements Serializable { private static final long serialVersionUID = 2297316923535111793L; private Long id; private String name; private int sex; private Set studentList; @Id // @GeneratedValue(strategy = GenerationType.SEQUENCE, generator = \"SEQ_TEACHER\") @GeneratedValue(strategy = GenerationType.IDENTITY) @Column(name = \"id\", nullable = false, precision = 22, scale = 0) public Long getId() { return id; } public void setId(Long id) { this.id = id; } @Column(name = \"name\") public String getName() { return name; } public void setName(String name) { this.name = name; } @Column(name = \"sex\") public int getSex() { return sex; } public void setSex(int sex) { this.sex = sex; } @ManyToMany(mappedBy = \"teacherList\", cascade = CascadeType.ALL) public Set getStudentList() { return studentList; } public void setStudentList(Set studentList) { this.studentList = studentList; } } Main import Entity.Student; import Entity.Teacher; import org.hibernate.HibernateException; import org.hibernate.Session; import org.hibernate.SessionFactory; import org.hibernate.cfg.Configuration; import java.util.HashSet; import java.util.Set; public class Main { public static void main(final String[] args) throws Exception { //创建配置对象(读取配置文档) Configuration config = new Configuration().configure(); //创建会话工厂对象 SessionFactory sessionFactory = config.buildSessionFactory(); //会话对象 Session session = sessionFactory.openSession(); //这是开启Session的操作 session.beginTransaction(); Student s = new Student(); s.setName(\"小猪\"); Teacher t = new Teacher(); t.setName(\"小李\"); Set t_set = new HashSet(); t_set.add(t); s.setTeacherList(t_set); session.save(s); //此处才是真正与数据库交互的语句 session.getTransaction().commit(); session.close(); } } 运行 运行后，打印SQL语句，发现hibernate帮我们创建了表，并添加了数据 在shell中查看数据： 参考 hibernate多对多关系 理解JPA注解@GeneratedValue "},"project/superset.html":{"url":"project/superset.html","title":"Superset使用","keywords":"","body":"安装 本实验在win10环境下完成。 配置 请务必安装了VS（安装了C++依赖包），且使用x64 Native Tools Command Prompt for VS 2017运行以下命令： 安装虚拟环境virtualenv（需要安装Python，并配置环境变量） pip install virtualenv 使用virtualenv。先在E盘建立e:\\superset目录 md superset cd superset 激活 # 创建虚拟环境 virtualenv env # 激活，启用虚拟环境（必须要用反斜杆） env\\Scripts\\activate 会发现前面有（env）字样： 安装之前，需要单独安装安装sasl。不装这个包，可能superset安装会不成功。下载地址 现在开始安装superset pip install superset 初始化与使用 # 创建管理员帐号 fabmanager create-admin --app superset # 初始化数据库 (windows下，先进入到 Python安装目录（或者virtualEnv的虚拟目录）下，lib\\site-packages\\superset\\bin下) Python superset db upgrade # 加载例子(后续操作都需要在lib\\site-packages\\superset\\bin下) Python superset load_examples # 初始化角色和权限 Python superset init # 启动服务，端口 8088, 使用 -p 更改端口号。 Python superset runserver -d 使用浏览器，打开localhost:8088即可看到登录页面。 参考 使用docker搭建superset Superset的安装配置及基础使用手册 "},"project/oltp.html":{"url":"project/oltp.html","title":"OLTPBenchmark配置及OLTP性能调优","keywords":"","body":"安装依赖 PostgreSQL 首先安装PostgreSQL，本测试系统为Ubuntu，请参考这里。 您可以通过psql像scott用户sudo一样运行单个命令来完成此操作，如下所示： psql -h 127.0.0.1 -d postgres -U scott -p 5432 这会将你直接登录到Postgres中，而不需要中间的bashshell。 同样，您可以键入以下命令退出交互式Postgres会话： \\q Ant的配置 首先通过通过Linux下的wget指令获取到最新的Ant包： wget http://mirrors.cnnic.cn/apache//ant/binaries/apache-ant-1.10.5-bin.tar.gz 然后通过tar指令解压Ant包中的内容： tar zxvf apache-ant-1.10.5-bin.tar.gz 最后根据解压后内容配置系统的环境变量 -->需要修改当前用户下的 .bash_profile文件中的配置：vim ~/.bash_profile #set Java environment export JAVA_HOME=/usr/local/jdk export JRE_HOME={% math_inline %}{JAVA_HOME}/jre export CLASSPATH=.:{% endmath_inline %}{JAVA_HOME}/lib:{% math_inline %}{JRE_HOME}/lib export ANT_HOME=/usr/local/apache-ant export PATH={% endmath_inline %}PATH:{% math_inline %}{ANT_HOME}/bin:{% endmath_inline %}{JAVA_HOME}/bin 然后执行ant： 安装成功！ OLTPBenchmark编译 首先git到本地： git clone https://github.com/oltpbenchmark/oltpbench 然后进入该目录，使用ant进行编译。 OLTPBenchmark 修改配置 编译好了，进入config： cd config/ 里面有很多样例，我们这里选择sample_pgtpcc_config.xml进行postgreSQL的性能测试： 修改内容为（标准测试）： postgres org.postgresql.Driver jdbc:postgresql://localhost:5432/tpcc_test #连接信息 postgres #用户名 postgres #密码 TRANSACTION_READ_COMMITTED #隔离级别 1 #数据库的scale factor，在TPCC里面可以理解为warehouse的数量 30 # #指定多个工作的任务，也可以包含两个工作任务（TP和AP的任务） 30 #执行的时间 4000 #峰值多少（考虑到对其他工作任务的影响） true #工作负载类型 44,44,4,4,4 负载分配 NewOrder Payment OrderStatus Delivery StockLevel 然后首先根据这个配置文件新建表： ./oltpbenchmark -b tpcc -c config/sample_pgtpcc_config.xml --create=true --load=true 可以在pg中查看表： 测试 ./oltpbenchmark -b tpcc -c config/sample_pgtpcc_config.xml --execute=true -s 5 -o outputfile 这里-s表示每隔5s输出到-o中 然后在results/outputfile.res中查看结果： 性能调优 修改配置 打开pg终端，输入SHOW config_file;查看config文件的位置： 打开该文件，并对以下配置进行修改： Parameter Meanings Optimization Strategy shared_buffers 数据库服务器将使用的共享内存缓冲区大小，该缓冲区为所有连接共用。从磁盘读入的数据（主要包括表和索引）都缓存在这里。 提高该值可以减少数据库的磁盘IO。 work_mem 声明内部排序和哈希操作可使用的工作内存大小。该内存是在开始使用临时磁盘文件之前使用的内存数目。数值以kB为单位的，缺省是 1024 (1MB)。请注意对于复杂的查询，可能会同时并发运行好几个排序或者哈希操作，每个都会使用这个参数声明的这么多内存，然后才会开始求助于临时文件。同样，好几个正在运行的会话可能会同时进行排序操作。因此使用的总内存可能是 work_mem 的好几倍。ORDER BY, DISTINCT 和mergejoin都要用到排序操作，而哈希操作在哈希连接、哈希聚集和以哈希为基础的 IN 子查询处理中都会用到。该参数是会话级参数。 执行排序操作时，会根据work_mem的大小决定是否将一个大的结果集拆分为几个小的和 work_mem差不多大小的临时文件写入外存。显然拆分的结果是导致了IO，降低了排序的速度。因此增加work_mem有助于提高排序的速度。通常设置时可以逐渐调大，知道数据库在排序的操作时不会有大量的写文件操作即可。该内存每个连接一份，当并发连接较多时候，该值不宜过大。 effective_cache_size 优化器假设一个查询可以使用的最大内存（包括pg使用的和操作系统缓存），和shared_buffer等内存无关，只是给优化器生成计划使用的一个假设值。 设置稍大，优化器更倾向使用索引扫描而不是顺序扫描，建议的设置为可用空闲内存的25%，这里的可用空闲内存指的是主机物理内存在运行pg时得空闲值。 maintenance_work_mem 这里定义的内存只是在CREATE INDEX, VACUUM等时用到，因此用到的频率不高，但是往往这些指令消耗比较多的资源，因此应该尽快让这些指令快速执行完毕。 在数据库导入数据后，执行建索引等操作时，可以调大，比如512M。 wal_buffers 日志缓冲区，日志缓冲区的大小。 两种情况下要酌情调大：1.单事务的数据修改量很大，产生的日志大于wal_buffers，为了避免多次IO，调大该值。 2.系统中并发小数据量修改的短事务较多，并且设置了commit_delay，此时wal_buffers需要容纳多个事务（commit_siblings个）的日志，调大该值避免多次IO。 commit_delay 事务提交后，日志写到wal_buffer上到wal_buffer写到磁盘的时间间隔。 如果并发的非只读事务数目较多，可以适当增加该值，使日志缓冲区一次刷盘可以刷出较多的事务，减少IO次数，提高性能。需要和commit_sibling配合使用。 commit_siblings 触发commit_delay等待的并发事务数，也就是系统的并发活跃事务数达到了该值事务才会等待commit_delay的时间才将日志刷盘，如果系统中并发活跃事务达不到该值，commit_delay将不起作用，防止在系统并发压力较小的情况下事务提交后空等其他事务。 应根据系统并发写的负载配置。例如统计出系统并发执行增删改操作的平均连接数，设置该值为该平均连接数。 fsync 设置为on时，日志缓冲区刷盘时，需要确认已经将其写入了磁盘，设置为off时，由操作系统调度磁盘写的操作，能更好利用缓存机制，提高IO性能。 该性能的提高是伴随了数据丢失的风险，当操作系统或主机崩溃时，不保证刷出的日志是否真正写入了磁盘。应依据操作系统和主机的稳定性来配置。 autovacuum 事务提交后，日志写到wal_buffer上到wal_buffer写到磁盘的时间间隔。 如果并发的非只读事务数目较多，可以适当增加该值，使日志缓冲区一次刷盘可以刷出较多的事务，减少IO次数，提高性能。需要和commit_sibling配合使用。 bgwriter_delay 后台写进程的自动执行时间 后台写进程的作用是将shared_buffer里的脏页面写回到磁盘，减少checkpoint的压力，如果系统数据修改的压力一直很大，建议将该时间间隔设置小一些，以免积累的大量的脏页面到checkpoint，使checkpoint时间过长（checkpoint期间系统响应速度较慢）。 当然，缓冲区和内存越大越好，但要考虑到机器的性能，因此是一个tradeoff。 重新测试 需要重启postgresql，执行pg_ctl reload 在Windows下进行性能测试 参考这里 修改配置 首先修改run下面postgres.properties的配置文件，将数据库和用户名密码指定为本地。 新增表 在当前目录中输入（在Windows中需要使用.bat文件，Linux中需要.sh文件）： .\\runSQL.bat postgres.properties sqlTableCreates 自动创建用于测试的九张表 查看数据库中是否新建： 新增数据 .\\loadData.bat postgres.properties numWarehouses 10 numWarehouse指的是仓库数（具体含义见上篇博文），默认为1，导入9张表的数据大小大概70多M，当 numWarehouse为10时，数据大小可以近似当作1GB数据。 创建成功： 为基础表创建必要的索引: .\\runSQL.bat postgres.properties sqlIndexCreates 测试 运行runBenchmark.bat借助GUI程序测试数据库 .\\runBenchmark.bat postgres.properties 不要忘记设置图形界面的仓库数时要与第4步中设置的数量相符；此外，测试的结果报告除了显示在图形界面有显示以外，还在run/reports目录下有备份，随时可以查阅 Control-Database:配置所要链接的数据库，默认会读取之前我们修改的配置文件，故此处不用动 Control-Terminals:配置终端数，仓库数，是否显示Debug信息，指定测试时间以及每终端事务等，需要将仓库数设置为10 Control-Weights:配置TPC-C测试中五中事务的比重（界面中只要配置4种），一般按默认比例测试即可 Control-Controls:控制器设置，点击Create Terminals创建一个终端；点击Start Transaction开始基准测试，点击Stop Transaction停止基准测试 在测试中若出现错误，则应该是线程冲突，一般不用理会 注意 测试完后在界面下方会显示简要的测试结果，包括平均tpmC值（每分钟执行的事务数），当前tpmC值，内存使用情况等等；出结果以后尽量记录下来，以为之后如果乱点界面按钮的话，测试结果将会被重写（感觉是一个bug）； 运行过程中如果想要修改终端数等参数，最好关闭GUI界面，重新运行runBenchmark.bat 测试结果 优化 修改postgresql.conf配置信息，在windows上找该配置文件。 需要将所有的测试数据删除，并重启pg。 重复之前的操作，需要重新load数据，创建索引，并测试，得到结果为： "},"project/sql.html":{"url":"project/sql.html","title":"SQL练习","keywords":"","body":"建表： drop table Student; drop table Course; drop table Teacher; drop table SC; -- 学生表 Student create table Student(SId varchar(10),Sname varchar(10),Sage date,Ssex varchar(10)); insert into Student values('01' , '赵雷' , '1990-01-01' , '男'); insert into Student values('02' , '钱电' , '1990-12-21' , '男'); insert into Student values('03' , '孙风' , '1990-12-20' , '男'); insert into Student values('04' , '李云' , '1990-12-06' , '男'); insert into Student values('05' , '周梅' , '1991-12-01' , '女'); insert into Student values('06' , '吴兰' , '1992-01-01' , '女'); insert into Student values('07' , '郑竹' , '1989-01-01' , '女'); insert into Student values('09' , '张三' , '2017-12-20' , '女'); insert into Student values('10' , '李四' , '2017-12-25' , '女'); insert into Student values('11' , '李四' , '2012-06-06' , '女'); insert into Student values('12' , '赵六' , '2013-06-13' , '女'); insert into Student values('13' , '孙七' , '2014-06-01' , '女'); -- 科目表 Course create table Course(CId varchar(10),Cname varchar(10),TId varchar(10)); insert into Course values('01' , '语文' , '02'); insert into Course values('02' , '数学' , '01'); insert into Course values('03' , '英语' , '03'); -- 教师表 Teacher create table Teacher(TId varchar(10),Tname varchar(10)); insert into Teacher values('01' , '张三'); insert into Teacher values('02' , '李四'); insert into Teacher values('03' , '王五'); -- 成绩表 SC create table SC(SId varchar(10),CId varchar(10),score decimal(18,1)); insert into SC values('01' , '01' , 80); insert into SC values('01' , '02' , 90); insert into SC values('01' , '03' , 99); insert into SC values('02' , '01' , 70); insert into SC values('02' , '02' , 60); insert into SC values('02' , '03' , 80); insert into SC values('03' , '01' , 80); insert into SC values('03' , '02' , 80); insert into SC values('03' , '03' , 80); insert into SC values('04' , '01' , 50); insert into SC values('04' , '02' , 30); insert into SC values('04' , '03' , 20); insert into SC values('05' , '01' , 76); insert into SC values('05' , '02' , 87); insert into SC values('06' , '01' , 31); insert into SC values('06' , '03' , 34); insert into SC values('07' , '02' , 89); insert into SC values('07' , '03' , 98); 插入数据库 \\i C:/Users/scott/Desktop/Class.sql 习题 查询课程名称为「数学」，且分数低于 60 的学生姓名和分数 SELECT sname,score FROM Student, (SELECT sid,score FROM SC,Course WHERE Course.cname = '数学' AND Course.cid = SC.cid AND SC.score 查询本月份过生日的同学名单 SELECT sname FROM Student WHERE EXTRACT(month from sage) = EXTRACT(month FROM CURRENT_DATE); 查询下个月过生日的学生名单 SELECT sname FROM Student WHERE EXTRACT(month from sage) = EXTRACT(month from (CURRENT_DATE + INTERVAL '1 MONTH')); 查询有数学成绩的学生信息 SELECT sname,sage,ssex FROM Student, (SELECT sid FROM SC,Course WHERE Course.cname = '数学' AND Course.cid = SC.cid) t WHERE (t.sid = Student.sid); 成绩不重复，查询选修「张三」老师所授课程的学生中，成绩最高的学生信息及其成绩 SELECT sname, sage,ssex,score FROM Student, (SELECT sid,score FROM Teacher,Course,SC WHERE Teacher.tname = '张三' AND Teacher.tid = Course.tid AND Course.cid = SC.cid ) t WHERE t.sid = Student.sid ORDER BY score DESC LIMIT 1; 查询没有学全部课程（语数外）的学生的信息 SELECT sname, sage,ssex FROM Student, (SELECT sid,cname,cname FROM Course,SC WHERE Course.cid = SC.cid )t WHERE t.sid = Student.sid GROUP BY Student.sid,sname,sage,ssex HAVING COUNT(*) 统计各科成绩各分数段人数：课程名称，课程编号，[100-85]，[85-70]，[70-60]，[60-0] 及所占百分比 SELECT cname,cid, a as \"[100-85]\",round(a::numeric/(a+b+c+d),2)*100 || '%' as ratio, b as \"[85-70]\", round(b::numeric/(a+b+c+d),2)*100 || '%' as ratio, c as \"[70-60]\", round(c::numeric/(a+b+c+d),2)*100 || '%' as ratio, d as \"[60-0]\",round(d::numeric/(a+b+c+d),2)*100 || '%' as ratio FROM (SELECT cname,Course.cid as cid, count(case when score >=85 then 1 end) as a, count(case when score >=70 and score = 60 and score 查询平均成绩大于等于 80(且单科大于70) 的同学的学生编号和学生姓名和平均成绩 SELECT SC.sid,sname,round(AVG(score),2) as avgScore FROM SC, (SELECT sid,sname FROM Student WHERE NOT EXISTS (SELECT * FROM SC WHERE SC.sid = Student.sid AND score = 80 首先使用NOT EXISTS进行相关子查询，查询到单科成绩大于70分的同学id和名字（没有成绩的同学也在里面），然后再求平均数。 查询两门及其以上不及格课程的同学的学号，姓名及其平均成绩 SELECT Student.sid,sname,round(AVG(score),2) as avgScore FROM Student,SC WHERE Student.sid = SC.sid GROUP BY Student.sid,sname HAVING COUNT(case when score =2; 查询每门课程的平均成绩，结果按平均成绩降序排列，平均成绩相同时，按课程编号升序排列 SELECT SC.cid as cid,Course.cname as cname,round(AVG(score),2) as avgScore FROM Course,SC WHERE Course.cid = SC.cid GROUP BY SC.cid,Course.cname ORDER BY AVG(score) DESC, SC.cid; 查询有一门成绩大于90(且没有挂科: >= 60) 的同学的学生编号和学生姓名和平均成绩 SELECT Student.sid,sname,round(AVG(score),2) as avgScore FROM Student,SC WHERE Student.sid = SC.sid GROUP BY Student.sid,sname HAVING COUNT(case when score 90 then 1 end) =1; 查询各科成绩前三名的记录 select * from sc where ( select count(*) from sc as a where sc.cid = a.cid and sc.score 这里使用了相关子查询，相当于两层循环 "},"project/backup.html":{"url":"project/backup.html","title":"数据库备份","keywords":"","body":"SQL dump Backup-SQL Dump Dump方法是生成含有SQL命令的文本文件。通过系统中自带的pg_dump指令可以将指定库中的表及其表中的数据以SQL指令的形式dump到一个文件中 pg_dump -hlocalhost -U postgres -p 5432 -d spj -f \"D:/test.dmp\" 这个命令可以在任意可以连接数据库的远程机器上运行，但他需要读表的权限，所以大多数是用superuser用户运行这个命令。连接指定的数据库可以使用-h host和-p port命令选项。默认的host是localhost或由PGHOST环境变量指定。使用-U选项设置连接数据库的用户。 查看生成的dmp文件： Restore create database newspj psql -h localhost -U postgres -d newspj -f \"D:/test.dmp\" 文件系统级备份 一个备份的策略是直接拷贝PostgreSQL的存储文件 tar -cf backup.tar /usr/local/pgsql/data 注意点： 数据库服务必须关闭，才能得到有用的备份。一个折中的办法是阻止所有连接。在恢复数据前也要关闭服务。 如果你已经查看了数据库文件系统的目录结构，你可能想尝试备份和恢复某个特定的表或库。这是不行的，因为没有提交日志文件，这些目录中的信息是不能用的，pg_clog/*包含所有事务的提交状态。一个表文件只有和这些提交状态信息一起才能使用。当然只恢复一个表文件和关联的pg_clog数据也是不行的，因为数据库的其他表都不可用了。所以文件系统备份必须整体备份数据库。 连续归档 思想 在任何时候，PostgreSql在pg_xlog/目录中维护一个写日志(WAL)。日志文件记录了数据库的每次修改。这个日志的主要目的是崩溃安全：如果系统崩溃了，数据库可以通过从上次的检查点“回放”日志来恢复数据库。然而我们可以用日志做备份的第三种策略。你可以混合一个文件系统级别的备份和WAL文件备份。如果需要恢复，我们先恢复文件系统备份，再回放WAL的内容，使数据库恢复到当前状态。 增量备份的思想，每次先备份归档文件（基础备份），再备份WAL文件（这时候只需要备份在备份时产生的WAL文件和之后的WAL，之前的WAL数据会被删掉） 操作 设置WAL归档 在postgresql.conf文件中修改： wal_level = archive archive_mode = on # allows archiving to be done archive_command = 'copy \"%p\" \"D:\\%f\"' 需要重新启动PostgreSQL 创建基础备份 最简单的基础备份方法是使用pg_basebackup工具。生成基础备份需要大量的时间，且在备份过程会影响系统性能。但是，如果你运行服务时禁止了full_page_writes，你可能注意到在运行备份时性能下降了。每次创建备份后都会删除之前的WAL日志，开始归档备份期间及后续的WAL日志信息。 pg_basebackup -D backup -h localhost -U postgres -Ft -z -P 利用备份恢复 参考这里 Reference Backup and Restore 利用pg_basebackup 命令进行热备份和恢复 "},"recap/Distributed DB.html":{"url":"recap/Distributed DB.html","title":"Recap: Distributed DB","keywords":"","body":"数据库扩展能力 提高扩展能力 scale up 高性能关系数据库产品 昂贵/扩展能力有限/使用简单 scale out 更多的计算机，增加节点 性价比高/扩展能力强/实现困难 若系统能做到scale out，是否自然能做到scale up？（不能） Scale out 应用层扩展（分库/分表的扩展模式） 与应用相关，不是数据库内部的事情 优点：不需要修改数据库内核 问题 负载不均 业务难以拆分 重点：查询分解 并行/分布式数据库 只有一个数据库，对用户透明 如何评价扩展性？ 加一倍的机器，效率是否能提高一倍 硬件资源的瓶颈：机器之间的通信 降低带宽的使用量，才能有更好的扩展性 架构设计 shared memory：可以访问其他计算机的内存/磁盘 任何内存/磁盘的读写都是通信 shared disk：共享磁盘 内存在本地读，磁盘通信 shared nothing（最强的）：每个进程只能访问本机的资源，可以与其他进程进行通信 在本地操作，使传输数据尽可能小（处理的中间结果） 但实现复杂，划分数据困难 如何划分数据 根据业务划分 Round-robin（轮询调度算法）：每次的请求都按照节点顺序依次分配 负载均衡 不适合点/范围查询 对顺序查询友好 Hash partitioning 对点查询/join友好 不适合范围查询/非key值查询 负载较为均衡 Range patitioning：根据key范围进行划分 对在key值上的范围查询友好 需要存储partition vector（不均衡的） 如何执行查询 关系代数的并行化 选择/投影/join都可以并行化 join的并行化 半连接（semi-join） 不需要传输完整的数据，减少消息传递的开销 先在key上做投影，只发送key给另一个table broadcasting join 对于小表而言，可以将其发送到另一个表的每一个节点 也可以先在局部做了排序后再发送（parallel external sort-merge） partitioned join 使用同样的hash函数，将两个table同样的key映射到一个机器做local join 分布式数据库事务 对比 分库/分表的扩展模式 缺点 数据难以拆分 事务处理困难 将事务拆分，能保证ACID吗？ 一般很难保证 由中间键（middleware）保证，需要DB与中间键配合，提供特殊的接口 并行/分布式数据库 优点 不需要拆分或子查询 SQL可以并行化 事务不需要中间层处理 缺点 实现复杂 节点之间通信很多 对应用透明，不会根据不同的查询来优化SQL，扩展性不一定好 分布式并发控制 如何实现分布式的可线性化： 需要保证每个节点的可线性化（local schedule） 需要保证全局的可线性化（global schedule） 保证每个节点的事务处理顺序都一样 实现方式 Locking Centralized 2PL 在单点维护所有的锁信息和锁管理器 会造成单点压力过大，扩展性差 但容易检测到死锁 Distributed 2PL 每个节点加锁，同时直接在该节点操作 扩展性更强，但不容易检测到死锁（需要结合多个节点信息） Atomicity and Durability Two - Phase commit（两节点提交） 主节点问所有的从节点是否准备好了commit，然后进行投票 每个节点有自己的日志，可以用来恢复 当主节点挂了，某些已经commit的从节点也挂了，这时候会blocking（不知道是否该提交），进行不下去了 3PC commit 主要用一个precommit来解决blocking的问题 在precommit之前挂掉，都可以回滚 其实就是让从节点知道了整个集群的信息 扩展性问题 通信的开销分为两部分 延迟 为了维护数据的一致性，弥补系统的不稳定，需要经常通信 分库/分表的扩展模式：扩展性更好（NoSQL使用） 并行/分布式数据库：没有考虑到业务逻辑，可能造成通信开销大 扩展能力的关键在于数据和负载的划分：依赖于数据的局部性 NoSQL为什么扩展性比SQL强？ 没有Join/没有事务 基本上没有跨节点操作 强迫用户层面去解决事务的问题 NoSQL的工具特点使得应用始终都在考虑扩展性问题 分布式数据库的折中点 CAP理论：任何一个分布式数据库只能在C（Consistency）/A（Availability）/P（Partitioning Tolerance）中兼顾两个。 对于分布式数据库来说，一定会面临P的问题，因此实际上是在C/A中进行选择 传统数据库 根据日志复制方式不同，可分为： eager：复制后再返回，属于CP lazy：返回后再复制，属于AP MongoDB 通过调节read concern和write concern实现 readConcern: { level: } local 直接返回数据，不保证该数据已经被写入多数节点 (AP) majority 返回已经被多数节点写入的数据(CP) { w: , j: , wtimeout: } w 0：不保证数据成功写入 1：保证单点已经收到写入请求 majority：保证大多数节点已经收到写入请求 j true：根据w设置的节点数，保证日志已经写入磁盘 j\\w 0 1 majority true 保证收到写入请求 保证主节点收到写入请求且日志写入磁盘 保证大部分节点收到写入请求且日志都写入磁盘 false 不保证收到写入请求 保证主节点收到请求但不保证日志持久化 保证大部分节点都收到写入请求但不保证日志都持久化 NewSQL 支持传统SQL的功能接口 支持更好的扩展性(Scale-out)（最主要） 支持分布式环境下的高可用 在低端高并行硬件(commodity hardware) 上部署 nA &sA 由于C/A我们都尽可能的想要，因此： Node Availability (nA) 通信故障发生时，任一节点都可用 Service Availability (sA) 通信故障发生时，部分节点不可用。但是，总有一部分节点可用。系统可以将用户自动切换到可用的节点。 服务不中断。 CnAP vs CsAP CnAP：只能在CP和nAP中二选一。 CsAP：在某种条件下，可以兼顾。 Raft /Paxos 若网络故障，但大部分节点没有故障，可以将故障的服务转移到majority上持续提供服务 数据的一致性可以保证（服务的高可用） Spanner是利用CsAP的NewSQL Spanner 事务 对于分布式事务处理，一般处理方法有： 并发控制： 2PL 原子性&容错：2PC 但加锁性能太差，因此在spanner中使用 multiversion & Timestamp ordering Timestamp-Based Protocols 每一个事务进入系统时给一个时间戳，在每个数据上维护两个时间戳，分别是： W-timestamp（Q）：执行写事务的最大时间戳 R-timestamp（Q）：执行读事务的最大时间戳 当执行读操作时， 若该事务时间戳小于W-timestamp，则回滚（已经有新事务写入）； 否则，读取该数据，并修改R-timestamp 当执行写操作时， 若该事务的时间戳小于R-timestamp，则回滚（已经有新事务读取了旧数据）； 若该事务的时间戳小于W-timestamp，则回滚（已经有新事务写入）； 否则，执行写事务，并将W-timestamp设置为当前时间戳 这种方法不会造成死锁，但会出现大量回滚（cascading roolback） 解决方法 写操作全部在事务的最后进行 所有的写操作都是原子的，在写操作进行时不会有事务执行 在读数据时等待数据commit 使用multiversion解决大量回滚的问题 multiversion schemes 每次写操作只是增加数据的一个新副本，且用时间戳进行标识 当进行操作时，总是找小于它的最大的W-timestamp的数据 当执行读操作时： 立即返回，且更新其R-timestamps 当执行写操作时： 若该时间戳小于R-timestamp，则回滚（本来后面的事务应该读这个事务的数据，但已经读了比它更老的数据） 若该时间戳等于W-timestamp，则重写内容 否则，增加一个数据的副本 区分两种事务： 只读事务 不加锁，可以直接读 读写事务 读全部加读锁（读最新的），写在commit时加写锁（代价于SQL中相同） "},"recap/RDBSM.html":{"url":"recap/RDBSM.html","title":"Recap: RDBSM","keywords":"","body":"数据库理解 为什么需要数据库？ 很多应用用场景有共同的需求，有必要抽象出来，单独成为一个系统 什么是一个好的数据管理系统？ 功能性 易用性 性能：处理数据的能力和容量 没有一个系统在各个方面都能做到完美 功能性强，会牺牲易用性 数据库最重要的是数据模型 关系数据库概述 关系模型 主要是为了数据管理的独立性（区别于网状db） 如何做到独立 数据库暴露给应用简单的接口，只需要表达需要什么（声明式语言） 接口为关系演算—>SQL语言 声明式语言，因此做到了app与dbsm的隔离性 表达能力 实际上决定了功能性 没有过程式语言强，可以达到一阶逻辑（fol）子集，比较强 关系代数表达式 输入关系（集合），产生关系（选择，投影，连接，聚集cout，max，sum） 存储的正确性 CRUD操作保证原子性 要么成功要么失败，没有中间状态 -> 用日志实现 其他CRUD在它之前或者之后 -> 可线性化 日志 Undo日志 记录修改之前的值 用start和commit包裹起来 日志需要在数据之前到达磁盘（WAL） 操作结束之前，所有的数据和日志必须到达磁盘（保证持久性），commit表示成功将所有数据写到磁盘 操作结束之前必须将数据刷盘 恢复时从新往后进行恢复数据 Redo日志 记录修改之后的值 操作结束之后，才能将数据写到磁盘，也就是说，在操作结束之前，只有日志写入了磁盘（顺序写效率高） 操作结束之前不能将数据刷盘(END之前) 数据到达磁盘后，需在日志中记录END Undo/Redo日志 克服了两者的缺点，数据可以在任何时间到达磁盘（操作结束前或之后） 但日志依然必须在数据之前到达磁盘 操作结束之前日志必须到达磁盘 日志恢复 若有commit，则表示日志已经全部写完，用Redo（可以更新这次的值了） 若没有commit，则表示日志都还没写完，用Undo（必须将数据还原为未更新的值） 可线性化 如何实现并发控制？通过加锁实现 可用性 如何实现 冗余节点(Redundancy) + 数据复制(Replication) 节点发生故障时，切换到(Failover)冗余节点 单机热备：无法做到，若两个节点之间的通讯断了，都认为自己是主节点，数据无法同步 Raft 状态：节点有Candidate/Follower/Leader三种状态（最初都是follower） Timeout election timeout：是follower等待转化为candidate的时间（150ms - 300ms） heartbeat timeout：每次leader发送AppendEntries的时间 任期（term） 每次都有一个任期（term）每个任期最多只有一个leader，有些任期可能因为选票瓜分导致没有leader。每一个服务器维护自己当前的任期，并在RPC时进行交换，若别人的任期大于自己的，则转为follower。 选主（Election） 集群通过心跳保持联系，若在随机等待的timeout中没有收到Leader的心跳，则自己变为candidate，向其他节点进行投票（不完整的log的follower一定不会变成leader） 若收到大部分的选票，则投票成功，则自己变为Leader，这时候将自己的log复制到从节点中 为了保证总是有leader被选出来，使用随机timeout的方式，若这个时间段中没有被选出来，则失败 Log replication client发送命令给leader，leader加入自己的log中，并将AppendEntries发送给followers 之后返回给leader且进行commit，并让follower进行commit 根据设置的参数，WriteConcern若为majority，则需要等到followers都commit之后才能返回给client 若有log不相同，则找到最近相同的log，从这里用AppendEntries将其覆盖 数据库设计 对应用的理解，对数据的需求 需求分析 概念模型设计 ER图 逻辑模型设计 范式，函数依赖，多值依赖（见书） 物理模型设计 Denoemalization 什么时候用索引 物化视图 关系模型 关系是笛卡尔积的子集，为二维表，每行对应一个元祖，每列对应一个域（不能重复） 候选码 某一属性值能唯一的标识一个元祖，任意两个候选码不能相同 全码 所有属性组是这个关系模型的候选码 主码 在候选码中选定一个 主属性 候选码的属性，其余为非主属性 外码 参照对象不一定是不同的关系 连接： 等值连接 自然连接：特殊的等值连接，会将公共属性只保留一个 外连接：保留悬浮元祖 一般连接 除法：需要右边的公共属性都在左边某些元祖中都存在的那些列 关系代数（并/差/交/投影/连接）-> 关系演算 -> SQL 范式化 第一范式 只要满足关系的定义（笛卡尔积的子集），则满足第一范式 函数依赖 若X的取值相等，则Y一定相等。记作 X->Y。 强函数依赖 X->Y是一个完全函数依赖，如果Y中的属性在实际中从来不变或者很少变化，则为强函数依赖 Y的冗余并不会带来太多的更新异常 弱函数依赖 若将关系R中的少数几个元祖去除之后，X->Y为一个函数依赖，则X->Y为一个弱函数依赖 若函数依赖涉及到的少数几个元祖可以单独作为一个关系 完全函数依赖 对于X，必须由其全部属性才能确定Y，则称为Y完全依赖于X。 键 设R(U) 为属性集 U上的关系模式。 X是U的子集。 如果 X->U，并且不存在 X的子集 X’ 使得 X’ ->U， 那么 X为R(U) 的键/码（key）。 在R(U)中可能存在多个键，我们人为指定其中的一个键为主键（primary key） 包含在任意一个键中的属性，称为主属性（primary attribute）。 代理键：主码越小，则BTree的n越大（同样空间中能存储的值越多），则查询效率越高，因此使用代理键id作为主属性 第二范式 关系模式R满足第二范式，当且仅当，R满足第一范式，并且，R的每一个非主属性都完全依赖于R的每一个键。 若不是键，则不能决定其他属性。 第三范式 关系模式R满足第三范式，当且仅当，R中不存在这样的键X，属性组Y和非主属性Z，使得X->Y，Y->Z成立，且Y->X不成立。 即：若X是键，Y不是键，但Y能决定Z，则不满足第三范式。 满足第三范式的模式必满足第二范式。 BC范式 关系模式 R满足 BC 范式，当且仅对任意一个属性集 A，如果存在不属于A一个属性 X， 使得 X函数依赖于A，那么所有R的属性都函数依赖于A。 任何满足BC范式的关系模式都满足第三范式。 BCNF与第三范式的不同之处在于： 第三范式中不允许非主属性被另一个非主属性决定，但第三范式允许主属性被非主属性决定； 而在BCNF中，任何属性（包括非主属性和主属性）都不能被非主属性所决定。 关系数据库内部实现 存储系统组织形式 页 选择-索引 btree 投影- 去重过程， 外部排序（扫描3遍） 连接 sortmerge，hash，index 复杂度用io来衡量 查询计划通过流水线的方式执行 查询执行过程 关系代数的表达式 -> 查询计划（解析） 查询计划 -> 最优查询计划（优化） 最优查询计划 -> 结果（查询执行） 有多个查询计划都可以完成同一个操作 不同的数据会导致查询计划的效率不同，不能说哪一个查询计划一定最好 若要实现优化，首先需要考虑影响数据访问的性能差异 至少需要考虑内存到磁盘的差异 这里复杂度主要用I/O来衡量 映射去重 在SELECT DISTINCT操作中经常出现 排序 由于数据无法完全放入内存，因此考虑MergeSort 边合并边去重 至少需要将数据完整扫描三遍 首先在创建排序子表时需要读入每个块进入内存排序 将各排序子表写入磁盘 从子表中读入每个块进行归并排序（直接输出） 散列 使用M个缓冲区将其划分为大致相等的M-1个桶（最后一个用于装入数据库的buffer） 将每一个桶和缓冲区联系起来，每次来一个块，将元组进行散列到不同的缓冲区中（缓冲区保存目前为止见过的每个元祖的一个副本） 将每个桶都写入磁盘 再读入每个桶的数据，用另外的哈希算法写入内存，保存每个元祖的副本，即可去重 至少需要将数据完整扫描三遍I/O 连接 嵌套循环（Nested loop） 基本思想：拿一个元祖（S），扫描另一个集合（R） 可以优化成拿尽可能多的元祖（外层循环S）一起扫描 B(S)+B(S)B(R)M−1=B(S)M−1(M−1+B(R))B(S) + \\frac{B(S)B(R)}{M-1} = \\frac{B(S)}{M-1}(M-1 + B(R))B(S)+M−1B(S)B(R)​=M−1B(S)​(M−1+B(R)) 外层循环S需要全部放到内存中一次(B(S)B(S)B(S))，加上有多少次内层循环 内层循环需要M−1+B(R)M-1+B(R)M−1+B(R)，一共需要B(S)M−1\\frac{B(S)}{M-1}M−1B(S)​ 当两个数组都很大时，大致相当于B(R)B(S)M\\frac{B(R)B(S)}{M}MB(R)B(S)​ 合并排序 对两个集合的元组分别使用两阶段多路归并排序 再归并排好序的两个集合 一般情况下磁盘I/O为：3×(B(R)+B(S))3\\times (B(R) + B(S))3×(B(R)+B(S)) 散列连接 用连接属性作为散列关键字，再对对应桶进行连接 3×(B(R)+B(S))3\\times (B(R) + B(S))3×(B(R)+B(S))，需要每一对桶中至少有一个能全部放入缓冲区中 利用索引 当R表很小时，索引很好 当S表很小时，则与嵌套循环类似（外层循环都可以直接放入内存） 查询执行 批处理 依次执行每个操作，将一个操作在所有数据上执行完之后再执行下一个操作 以表为传递 流水线 逐个数据上执行所有操作 筛选出的元组一个个被传递（并行） 火山模型 每个数据库操作都使用共同的接口（open(),next(),close()） 查询优化 基于规则的优化 聚簇索引/物化视图/hash join 基于代价的优化 估算每个查询的I/O代价 选择/join 查询改写 删除多余的DISTINCT 子查询效率较低，尽量使用join 尽量避免使用存放中间结果的表（中间表没有办法优化） 相关子查询改写 索引 B-Tree：多值查询可以加速（若为多值索引），可以进行单值的范围查询加速 Hash Table：多值查询可以加速，不能进行范围查询 聚簇索引：数据就存在索引的叶子结点，数据存储方式按照索引排列（会溢出，随着数据增加会变差） 事务处理 什么是事务 事务就是一段线性的程序 acid性质 原子性（Atomicity） 一个事务要么没有开始，要么全部完成，使用日志实现 一致性（Consistency） 注意，这里的数据正确指符合约束（非零/主码） 隔离性（Isolation） 多个事务不会互相破坏，指的是并发控制 持久性（Durability） 事务一旦提交成功，对数据的修改不会丢失，使用日志实现 事务的实现 如何保证原子性/持久性（AD）：日志（undo，redo，undo+redo） 如何保证隔离性（I）：并发控制（加锁，时间戳，有效性验证） 可串行化调度 并发事务的正确性原则: 调度产生的结果与一次执行一个事务所产生的结果相同。 并不保证先后顺序 冲突可串行化 一个比可串行化更严格的条件 商用系统中的调度器采用 可以通过移动非冲突的动作变成线性化调度 冲突 对于调度中一对连续的动作，如果它们的顺序交换， 结果将改变。 冲突的条件: 涉及同一个数据库元素 并且至少有一个是写操作的动作 冲突等价的调度: 如果S1能通过一系列的非冲突交换变成S2（线性化调度），则S1 、S2 是冲突等价的调度。 冲突可串行化: 一个调度是冲突可串行化的，如果它和某些串行调度是冲突等价的。 若一个调度是冲突可串行化，则一定是可串行化的调度 例子参考PPT 如何实现冲突的可串行化？ 先全部加锁，再依次释放 两阶段锁 在每个事务中，所有加锁请求先于解锁请求 访问数据前申请锁 事务结束后将锁一齐释放 理解 冲突可串行化调度是可串行化调度的充分条件，不是必要条件。还有不满足冲突可串行化条件的可串行化调度。 两阶段锁协议是冲突可串行化的充分条件，不是必要条件。 在这里，Y的写顺序没有改变，而X的写顺序发生了改变，没有办法转换为串行调度，但不影响最终结果。 例如，若两个事务对索引进行更新，属于冲突，但可以交换顺序，不满足冲突可串行化，但可以串行化。 线性化vs串行化 可串行化与时间无关 可线性化在可串行化的基础上加入时间限制，要求更高 可线性化优势 能保证逻辑的正确性（先操作的一定先发生） 数据库很难保证可串行化（事务），操作能保证可线性化 事务的使用 begin comit 中间不能与用户交互 如何减小锁对性能的影响 尽量少加锁 多使用共享锁（读锁），少使用排他锁（写锁） 共享锁：多个事务可对同一数据重复申请加读锁 排他锁：一旦事务T对数据A加上了X锁，只允许T对其进行读写 使用更细粒度的锁 表级锁 vs 行级锁 事务做到尽可能的简短，减少阻塞 调优及备份 数据库调优 触发点：数据库性能⽆法满足应用负载 响应时间明显延⻓，甚⾄不响应 事务回滚增加，导致⼤量任务失败 确认数据库为性能瓶颈 诊断点 关键查询是否被⾼高效执⾏? 找到关键查询 频繁被用户使用/执行过程消耗较多资源 了解查询的执⾏⽅式 查询计划 排查询执⾏过程中的性能问题 系统组件是否有效地利用了硬件资源? 缓冲区管理器/磁盘碎片/锁管理器/日志管理器 硬件资源是否足够？ 物理设计调整/查询改写/系统调参 备份 数据备份（backup） 预防错误或灾难 可以处理更多错误，例如误操作（已提交的事务需要撤回） 利用Replication机制可以实现更精确的恢复 Replication 实现高可用 在一定程度上也可以起到备份的作用 无法撤销已提交的事务（检查点之前到日志可能被删除） 备份时将全量数据进行复制，后面可以进行恢复。 存档（Archiving）是将旧的数据移除数据库系统，转移到线下设备。 OLAP OLTP 查询和更新，对现实世界状态数据的存储 如状态信息/查询余额 OLAP 主要是查询，分析和发现知识 历史流水 数据模型 Data Cube dimensions/facts 主要操作 slicing/dicing Roll Up/Drill Down 数据仓库系统 提供data cube的各种操作 MOLAP Multidimensional OLAP 直接存一个cube 一般会提前计算各种数据指标 查询非常快速 空间浪费严重（稀疏性），没办法扩展到高维 ROLAP Relational OLAP 可以扩展到高维，空间存放合理，避免稀疏性问题 但性能不佳，需要格外指定索引 SQL语句没办产生subtotoal 提供CUBE操作 数据模式 由于很多数据有多个维度和属性，不能直接全部存在一个表中（冗余/宽表） 使用范式化技术，将表分为dimension table 和fact table dimension table 一般不会有太多行，但会有很多列 一般只会查找，不会修改 存储现实世界的某些物体 fact table 一般非常多的行，列不会很多 不断增加，但一般不会修改 存储衡量某个事件的过程 "},"recap/SQL.html":{"url":"recap/SQL.html","title":"Recap: SQL","keywords":"","body":"易错点 视图是虚表，观察到的数据反映的是实际基本表中的数据 索引最主要的副作用是维护的代价（更新索引），而不是增加存储空间的消耗 GROUP BY 会去重 只有GROUP BY中的属性列（或者聚合函数）才能出现在SELECT中 查询得到的结果不再是关系，因为有可能有重复 嵌套查询不能有ORDER BY 关系 试述关系模型的三个组成部分。 关系模型由关系数据结构、关系操作集合和关系完整性约束三部分组成 为什么外部码属性的值也可以为空?什么情况下才可以为空? 实体完整性规则是指若属性 A 是基本关系 R 的主属性，则属性 A 不能取空值。 即属性 F（外码） 本身不是主属性，则可以取空值，否则不能取空值。 试述等值连接与自然连接的区别和联系。 连接运算符是“=”的连接运算称为等值连接。它是从关系 R 与 S 的广义笛卡尔积中选取 A，B 属性值相等的那些元组 自然连接是一种特殊的等值连接，它要求两个关系中进行比较的分量必须是相同的属性组，并且在结果中把重复的属性列去掉。 SQL SQL的数据定义包括模式定义，表定义，视图和索引 模式（schema）实际上是一个命名空间 查询 单表查询 查询时，可以对列进行简单运算（大小写更改，加减），也可以指定别名（直接在列名后面写别名） 选择表中的若干元祖 确定范围 Sage between 20 and 30 确定集合 Sdept in ('cs','ff') 字符匹配 Like % 表示任意长度的字符串 a%b 表示以a开头，b结尾的任意长度的字符串 _ 代表任意单个字符 聚集函数 where语句中不能使用聚集函数作为表达式 只能用于group by 和 having having作用于组，where作用于基本表和视图 连接操作 等值连接 在目标中重复的属性列去掉为自然连接 自身连接 需要给表取别名FIRST，SECOND 外连接 左连接、右连接 将悬浮元祖保存在结果关系中 嵌套操作 子查询 相关子查询 子查询的查询条件依赖于父查询 例如大于自己的平均成绩的元祖 使用IN进行嵌套 带有EXISTS谓词的子查询 不返回任何数据，只产生逻辑真值，因此其目标列表表达式通常都用*代替 集合查询 参加集合操作的割裂结果的列数必须相同，对应的数据类型也必须相同 UNION 会自动去掉重复元祖 INTERSECT EXCEPT 派生表的查询 子查询不仅可以出现在WHERE子句中，还可以出现在FROM子句中，这时子查询生成的临时派生表称为主查询的查询对象。 注意，通过FROM子句生成派生表时，一定要为派生关系指定一个别名。 数据更新 插入操作时，字符串要用单引号括起来。 若没有指明插入的属性名，则每个字段都必须存在，即使为NULL，也要显示的写出来。 插入子查询的结果 INSERT INTO Dept_Age(Sdept,Avg_age) SELECT Sdept,AVG(Sage) FROM Student GROUP BY Sdept; 修改数据 UPDATE student SET Sage=22 WHERE Sno = '...' 视图 WITH CHECK OPTION 在视图创建时使用，表示对视图进行UPDATE、INSERT、DELETE操作要保证行满足视图定义中的谓词条件 组成视图的属性列名全部省略或全部指定 有聚合函数时必须全部指定 视图可以建立在一个或多个表上，也可以建立在视图上 视图消解 关系数据库系统执行对视图的查询步骤 检查有效性 检查查询中涉及的表、视图是否存在，如果存在，把定义的子查询和用户的查询结合起来，转换成等价的对基本表的查询，然后再执行修正了的查询 有时候不能直接转换，例如WHERE语句中不能使用聚集函数 视图更新 并不是所有的视图都可以更新 基本表的行列子集视图一般是可以更新的 若视图的属性来自集合函数、表达式，则该视图肯定是不可更新的 对视图的更新都要转换为基本表的更新，因为有些视图的更新不能唯一有意义的转换为基本表的更新，因此并不能更新 视图的作用 简化用户的操作 使用户能以多种角度看待同一数据 对重构数据库提供了一定程度的逻辑独立性 表属性改变时，只需要改变视图，应用程序SQL语句不用修改 视图能够对机密数据提供安全保护 可以更清晰的表达查询 "},"recap/NoSQL.html":{"url":"recap/NoSQL.html","title":"Recap: NoSQL","keywords":"","body":"NOSQL数据库 主要是文档数据库（mongoDB） SQL缺陷 隔离程度低，需要程序员写逻辑 过于庞大和复杂 范式化无法做到，schema难看 设计思想 想要与应用做更好的结合，对应于json，object 更易于使用 扩展能力：由于功能简单，很好的扩展性（no join，no transaction，只能交给应用，如何在nosql上做transaction） 接口 CRUD 高可用 replication 多版本的一致性，共识协议 raft，service availability write，read concern OOP Object-Relational Impedance Mismatch OO与DB有各自的数据模型，两种模型之间存在差异 常常使用ORM工具 帮助用户建立/管理/维护对象和关系之间的映射 实际上将关系有所改变 主码变得没有意义（代理键） 对象中的属性也可能是对象（也形成一种关系） 缺陷 映射关系的标注和维护不简单 无法代替复杂查询和数据库管理（索引） 数据库设计过程 需求分析 OO 对每个对象设计一个文档 概念模型设计 逻辑模型设计 物理模型设计（是否可以embedding，denormalization） 操作原子性（需要了解） 日志 锁 可线性化 NoSQL的事务功能 现状 NoSQL数据库通常不支持事务! 只保证单个操作的原子性。 MongoDB的Multi-document Transaction 只限于单节点。（不是分布式） 原因 事务的性能得不到保证。 把数据一致性的问题交给应用来解决 事务的ACID vs 操作的原子性： 事务 过程未知，只能使用通用并发控制手段，如2PL; 粒度和时间不可控，可以很大。 操作 过程已知，可以为其定制并发控制手段，访问数据的方式已知，可以进行优化 粒度小，时间短。 数据一致性问题 Embedding 将经常被同时更新的字段放在统一文档中，与文档数据库的设计理念相同 同步标记 标记打开说明同步工作未完成，下次启动时重新操作 需要满足幂等性质 操作一次和多次的结果是一样的 消息队列 可能使用数据库之外的其他系统实现 每条消息都是原子的，同一个消息队列中的消息串行执行，不同消息队列中保证不会有冲突 依然需要满足幂等性质 若不满足幂等性质的操作（转账等），使用类似于事务处理的机制 日志 时间戳 补偿事务 使用操作系统的同步机制 锁 信号 原子操作（CAS） "},"recap/Extra.html":{"url":"recap/Extra.html","title":"Recap: Extra","keywords":"","body":"Search Engine 数据 结构化数据 可用作数据库管理的数据 可利用结构进行关系演算 json/html 非结构化数据 文本 图片 音频 查询 数据库的查询 精确 快速 功能多样 文档的查询 模糊 通用 布尔检索 用户的信息需求通过词和布尔代数表示 使用倒排索引 创建索引遇到的问题 内存无法容纳所有的索引项 BSBI（Blocked sort-based Indexing） 思想 同时使用内存和磁盘 把尽可能多的工作放到内存中完成 对磁盘的访问尽量使用顺序读写 方法 将文档集分块，使得每块都能被内存容纳 在内存中对每块的内容进行排序，并写回磁盘 将各块的排序进行合并 单个计算机无法容纳所有的索引项 Parittion by term 造成单点压力过大 相应更快 Partition by docs 需要在每个节点中计算 但更均衡 google使用 文档在不断增加 两个倒排索引 位于磁盘的静态索引 位于内存中的动态辅助索引 可以规避动态增加索引对性能的影响 Indexing 对于人脸识别/图像查询/空间位置查询，可以转换为空间索引问题 KD Tree Range Query KNN Query R Tree 可以自我平衡 允许空间划分重叠 可以实现不规则物体查询 Curse of dimensionality 在高维空间中，很多计算变得很困难或者没有意义 训练样本稀缺->过拟合 聚类无效 查询/索引无效 异常检测无效 "}}