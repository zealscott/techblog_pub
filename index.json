[{"content":"Kullback-Leibler divergence Information theory  Quantify information of intuition1  Likely events should have low information content Less likely events should have higher information content Independent events should have additive information. For example, finding out that a tossed coin has come up as heads twice should convey twice as much information as finding out that a tossed coin has come up as heads once.   Self-information  $I(x)=-\\log P(x)$ Deals only with a single outcome   Shannon entropy  $H(\\mathrm{x})=\\mathbb{E}_{\\mathrm{x} \\sim P}[I(x)]=-\\mathbb{E}_{\\mathrm{x} \\sim P}[\\log P(x)]$ Quantify the amount of uncertainty in an entire probability distribution    KL divergence and cross-entropy  Measure how different two distributions over the same random variable $x$  $D_{\\mathrm{KL}}(P | Q)=\\mathbb{E}_{\\mathrm{x} \\sim P}\\left[\\log \\frac{P(x)}{Q(x)}\\right]=\\mathbb{E}_{\\mathrm{x} \\sim P}[\\log P(x)-\\log Q(x)]$   Properities  Non-negative. The KL divergence is 0 if and only if $P$ and $Q$ are the same distribution Not symmetric. $D_{\\mathrm{KL}}(P | Q) \\neq D_{\\mathrm{KL}}(Q | P)$ for some $P$ and $Q$     Cross-entropy  $H(P, Q)=H(P)+D_{\\mathrm{KL}}(P | Q) = -\\mathbb{E}_{\\mathrm{x} \\sim P}[\\log Q(x)]$ Minimizing the cross-entropy with respect to $Q$ is equivalent to minimizing the KL divergence, because $Q$ does not participate in the omitted term  In machine learning, $P$ represents real data distributioin, we need to compute the $Q$ distribution from model, which is why cross entropy is used.   Meanwhile, min cross-entropy is equal to maxmize Bernoulli log-likelihood     KL散度与交叉熵区别与联系  TODO   negative log-likelihood\n Understanding softmax and the negative log-likelihood    Focal loss\n  Noise Contrastive Estimation (NCE)\n  Neighborhood Component Analysis\n  mutual information\n  contrastive loss\n CVPR05 Learning a similarity metric discriminatively, with application to face verification a pair of either similar or dissimilar data points    triplet loss\n to learn a distance in which the anchor point is closer to the similar point than to the dissimilar one.    hinge loss / surrogate losses\n  Magnet loss\n Metric Learning with adaptive density discrimination      Deep Learning, charpter 3. Ian Goodfellow and Yoshua Bengio and Aaron Courville \u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://tech.zealscott.com/deeplearning/misc/loss/","summary":"Kullback-Leibler divergence Information theory  Quantify information of intuition1  Likely events should have low information content Less likely events should have higher information content Independent events should have additive information. For example, finding out that a tossed coin has come up as heads twice should convey twice as much information as finding out that a tossed coin has come up as heads once.   Self-information  $I(x)=-\\log P(x)$ Deals only with a single outcome   Shannon entropy  $H(\\mathrm{x})=\\mathbb{E}_{\\mathrm{x} \\sim P}[I(x)]=-\\mathbb{E}_{\\mathrm{x} \\sim P}[\\log P(x)]$ Quantify the amount of uncertainty in an entire probability distribution    KL divergence and cross-entropy  Measure how different two distributions over the same random variable $x$  $D_{\\mathrm{KL}}(P | Q)=\\mathbb{E}_{\\mathrm{x} \\sim P}\\left[\\log \\frac{P(x)}{Q(x)}\\right]=\\mathbb{E}_{\\mathrm{x} \\sim P}[\\log P(x)-\\log Q(x)]$   Properities  Non-negative.","title":"Loss functioin in neural network"},{"content":"安装 Ananconda  使用命令行安装  1  wget wget https://repo.continuum.io/archive/Anaconda3-5.2.0-Linux-x86_64.sh    注意，选择安装路径时，如果想要所有用户都能使用，则安装在usr/local/ananconda3目录下 注意修改/etc/profile.d下的conda.sh，指定环境变量（在登入另外的用户时会提醒） 更改源。创建~/.condarc文件，输入  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  channels: - defaults show_channel_urls: true channel_alias: https://mirrors.tuna.tsinghua.edu.cn/anaconda default_channels: - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/pro - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2 custom_channels: conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud    至此，已经完成 python、conda 及 jupyter-notebook 的安装。  部署远程云服务  生成Jupyter Notebook配置文件  1  jupyter notebook --generate-config     生成的配置文件，后来用来设置服务器的配置\n  设置Jupyter Notebook密码\n 设置密码用于设置服务器配置，以及登录Jupyter。打开Python终端，输入以下：    1 2 3 4  from IPython.lib import passwd passwd() Enter password: Verify password:    设置服务器配置文件  1  vim ~/.jupyter/jupyter_notebook_config.py    在末尾增加以下几行配置信息（此配置信息，也可在启动Jupyter时在参数中添加，但我认为那样看起来比较乱）  1 2 3 4 5  c.NotebookApp.ip = \u0026#39;*\u0026#39; #所有绑定服务器的IP都能访问，若想只在特定ip访问，输入ip地址即可 c.NotebookApp.port = 8888 #将端口设置为自己喜欢的吧，默认是8888 c.NotebookApp.open_browser = False #我们并不想在服务器上直接打开Jupyter Notebook，所以设置成False c.NotebookApp.notebook_dir = \u0026#39;/scott/data\u0026#39; #这里是设置Jupyter的根目录，若不设置将默认root的根目录，不安全 c.NotebookApp.allow_root = True # 为了安全，Jupyter默认不允许以root权限启动jupyter     启动Jupyter 远程服务器  1  nohup jupyter-notebook \u0026amp;   这里使用 nohup 是想在 ssh 窗口关闭后继续运行，同时使用后台运行的方式。\n 最后，在本地输入 ip:8888 即可运行服务器上的 jupyter notebook。 若需要关闭，直接强行关闭端口  1  fuser -k 8888/tcp   ","permalink":"https://tech.zealscott.com/misc/jupyter-notebook/","summary":"安装 Ananconda  使用命令行安装  1  wget wget https://repo.continuum.io/archive/Anaconda3-5.2.0-Linux-x86_64.sh    注意，选择安装路径时，如果想要所有用户都能使用，则安装在usr/local/ananconda3目录下 注意修改/etc/profile.d下的conda.sh，指定环境变量（在登入另外的用户时会提醒） 更改源。创建~/.condarc文件，输入  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  channels: - defaults show_channel_urls: true channel_alias: https://mirrors.tuna.tsinghua.edu.cn/anaconda default_channels: - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/pro - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2 custom_channels: conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud    至此，已经完成 python、conda 及 jupyter-notebook 的安装。  部署远程云服务  生成Jupyter Notebook配置文件  1  jupyter notebook --generate-config     生成的配置文件，后来用来设置服务器的配置","title":"在服务器上部署 Jupyter Notebook"},{"content":"我们通常会在本地计算机上写 Markdown 文件，然后使用 Hugo 建立静态博客网站。因此需要一种方法将本地文件同步到服务器上，同时实现 GitHub 集成，确保网站的可维护性。我使用了 Git hook 的方法进行同步与集成。\n服务器上 更新 1 2 3  yum update yum install nginx yum install git   新建 hugo 用户：\n1 2  adduser hugo passwd hugo   安装 hugo 安装 go 1 2  yum -y install golang go version   源码安装 1 2 3 4 5  mkdir $HOME/src cd $HOME/src git clone https://github.com/gohugoio/hugo.git cd hugo go install --tags extended   yum 安装 有些主题需要支持sass/scss功能，如果使用 yum 安装 hugo，则没办法安装extend版本，会导致编译失败。\n添加 epel repo 在 /etc/yum.repos.d/hugo.repo 文件中添加：\n1 2 3 4 5 6 7 8 9  [daftaupe-hugo] name=Copr repo for hugo owned by daftaupe baseurl=https://copr-be.cloud.fedoraproject.org/results/daftaupe/hugo/epel-7-$basearch/ type=rpm-md skip_if_unavailable=True gpgcheck=1 gpgkey=https://copr-be.cloud.fedoraproject.org/results/daftaupe/hugo/pubkey.gpg repo_gpgcheck=0 enabled=1   执行安装 Hugo 1 2  yum -y install hugo hugo version   注意，如果使用 CentOS，使用 yum 安装的只是 hugo 的普通版本，而不是 extend。如果需要用 extend，那么请使用 Linuxbrew 进行安装（由于 Linuxbrew 无法安装在 root 目录，因此后面在hooks/post-receive调用时请使用全路径。\n部署 切换到 Hugo 用户：\n1  su hugo   在用户目录下新建 .git 目录\n1 2 3  cd ~ mkdir .git cd .git   将本地的 id_rsa.pub 的内容保存到~/.ssh/authorized_keys 文件内\n1  vim authorized_keys   进入 vim 后按下 i 进入insert模，直接粘贴就行\n这样就可以用 hugo 用户 ssh 到服务器上了，其中，ssh公钥生效需满足至少下面两个条件：\n .ssh 目录的权限必须是 700 .ssh/authorized_keys 文件权限必须是 600  建立 Git 库 在用户目录下新建 .git 目录\n1 2 3 4 5 6  cd ~ mkdir hugo.git cd hugo.git git --bare init touch hooks/post-receive mkdir /data/www/hugo   添加下面的代码到 hooks/post-receive ：\n1 2 3 4 5 6 7 8 9 10  GIT_REPO=$HOME/hugo.git TMP_GIT_CLONE=$HOME/tmp/hugo PUBLIC_WWW=/data/www/hugo THEME=/data/www/hugoTheme/themes/meme/. git clone $GIT_REPO $TMP_GIT_CLONE cp -r $THEME $TMP_GIT_CLONE/themes/meme hugo -s $TMP_GIT_CLONE -d $PUBLIC_WWW rm -Rf $TMP_GIT_CLONE exit   并修改执行权限\n1  chmod a+x hooks/post-receive   这里需要说明一下，Git hook 是一段自动执行的代码，当使用 Git push 时，远程的服务器会自动执行 post-receive 中的代码片段。在这里，我首先将主题文件复制到服务器中，再运行 hugo 命令在制定的文件夹中生成静态博客。\n切换到root账户，然后建立/data/www/hugo文件，并将文件所有者设置为 hugo\n1 2  chown hugo /data/www/hugo/ chgrp hugo /data/www/hugo/   Nginx 我使用了 Nginx 作为 web 服务器，记录下一些小设置，给后来的朋友踩坑。\n Nginx 隐藏 html后缀\n1 2 3 4 5 6 7  location / { //添加上以下代码： if (!-e $request_filename){ rewrite ^(.*)$ /$1.html last; break; } }    自动跳转 https\n在/conf/nginx.conf文件中加入：\n1 2 3 4 5 6 7 8 9 10 11 12  # HTTPS server server { listen 443; server_name localhost; ssl on; ssl_certificate cert.pem; ssl_certificate_key cert.key; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP; ssl_prefer_server_ciphers on; location / {   在需要跳转的站点下的server中，加入：\n1 2 3 4 5 6 7 8  server { listen 80; server_name localhost; #将localhost修改为您证书绑定的域名，例如：www.example.com。 rewrite ^(.*)$ https://$host$1 permanent; #将所有http请求通过rewrite重定向到https。 location / { index index.html index.htm; } }   本机 在该网站的 Git 仓库下运行：\n1 2  git remote set-url --add origin life@yourserver.com:~/life.git git remote -v   之后只需要使用常规git操作，即可同时 push 到 GitHub 和云服务器上\n1 2 3  git add . git commit -m \u0026#34;my life website\u0026#34; git push   ","permalink":"https://tech.zealscott.com/misc/hugo-integration/","summary":"我们通常会在本地计算机上写 Markdown 文件，然后使用 Hugo 建立静态博客网站。因此需要一种方法将本地文件同步到服务器上，同时实现 GitHub 集成，确保网站的可维护性。我使用了 Git hook 的方法进行同步与集成。\n服务器上 更新 1 2 3  yum update yum install nginx yum install git   新建 hugo 用户：\n1 2  adduser hugo passwd hugo   安装 hugo 安装 go 1 2  yum -y install golang go version   源码安装 1 2 3 4 5  mkdir $HOME/src cd $HOME/src git clone https://github.com/gohugoio/hugo.git cd hugo go install --tags extended   yum 安装 有些主题需要支持sass/scss功能，如果使用 yum 安装 hugo，则没办法安装extend版本，会导致编译失败。","title":"使用 Hugo 进行持续集成写作及同步"},{"content":"在 2020 年的春节前夕，我终于完成了博客从 Hexo 到 Hugo 的迁移。期间踩过不少坑，也有不少小朋友来问我如何开始进行个人博客写作，因此觉着是时候写点东西记录记录。\nWhy Hugo 正式开始写个人博客，是两年前的春节。最开始使用了当时最流行的 Hexo 框架，选择了 Next 主题。最开始一切都很好，虽然 Hexo 框架是简单了点，但耐不住有很多热心的开发者开发了很多插件，所以基本上都能满足自己的需求。而随着博客数量越来越多，我发现 Hexo 的问题越来越让我难以忍受，那就是：速度太慢。\n举个例子，当我有 200 多篇博客的时候，用 Hexo 渲染静态网页需要将近 20 秒，这样的速度简直是不可接受的。更不要说我还有大量的静态图片、资料等等。同时，由于自己偷懒，博客中使用的图片都来自于图床，这些外链不受我控制，很多时候有打不开、加载慢的问题，让我这个强迫症觉得很不爽。\n因此2019年底，我萌发了重构个人博客的想法，一眼就看中了用 Go 语言写的 Hugo，其Slogan The world’s fastest framework for building websites也是非常吸引我。更难能可贵的是，Hugo 虽然还处于快速迭代开发的阶段，但并不是一个半成品，很多在 Hexo 上需要插件实现的功能，Hugo 上都内置了。\nHugo vs Hexo 为了方便 Hexo 用户快速上手 Hugo，我总结了 Hugo 与 Hexo 的异同点（大部分来源于官网及这篇博文）。\n结构组织 1 2 3 4 5 6 7 8 9 10 11 12  ~/blog $ tree -L 1 . # 说明 Hexo ├── archetypes/ # 文章模板 scaffolds/ ├── assets/ # Hugo 管道 ├── config.toml # 配置文件 _config.yml ├── content/ # 文章目录 source/_posts/ ├── data/ # Hugo 数据文件 source/_data/ ├── layouts/ # 布局模板 ├── public/ # 生成的静态文件 public/ ├── resources/ # Hugo 缓存 ├── static/ # 网站的静态文件 source/ └── themes/ # 主题目录 themes/   在 Hugo 中，与 Hexo 的一个很大不同：是主题目录与站点目录有一样的结构，以 MemE 主题举个例子：\n1 2 3 4 5 6 7  ~/blog/themes/meme $ tree -L 1 . ├── assets/ ├── data/ ├── i18n/ ├── layouts/ └── static/   其中，assets、data、layouts、static 的作用都是与站点目录下的相应文件夹相同的，且站点目录下的文件可以覆盖主题目录下的相应文件——这意味着你可以在不修改主题文件的前提下方便地定制主题。\n在 Hugo 中，如果你想要定制主题，你只需在站点目录下新建相应的文件即可。这是非常利于主题的维护的，你只需使用 Git 的 submodule 的方式安装 Hugo 的主题，然后更新时只需直接在站点根目录下敲一条命令回车即可，非常方便。\n此外，上面的 i18n 文件夹相当于 Hexo 的主题中的 languages 文件夹，如果你不喜欢主题的一些文字翻译，可以在站点目录下新建相应文件自定义。这里特别需要提醒的是，Hugo 中的 data 和 i18n 文件夹下的所有文件都是可以按「键」覆盖的，即你无需复制文件全文，只需添加你想自定义的那项即可。\n配置文件 Hugo 中是不区分站点和主题的配置文件的，Hugo 中只有一个位于站点根目录下的 config.toml 配置文件。你可能注意到 .toml 后缀，没错，Hugo 默认使用的配置文件是 TOML 格式的，它的语法是非常简单易懂的，它在语法上也没有缩进的要求。当然，在 Hugo 中你也可使用 Hexo 默认的 YAML 格式，但我还是建议你使用 TOML，毕竟入乡随俗嘛。此外，如果你想将文章中的 Front Matter 也从 YAML 转换成 TOML 的话，推荐一个 Python 脚本。但特别注意：尝试前务必先备份！\n分类方式 我们知道，在 Hexo 中有两种分类方式——分类和标签，它们都是在文章的 Front Matter 中设置的，其中：categories 是具有顺序性和层次性的，即你可以通过它来实现树状结构的分类；tags 则没有这种特点，它的作用只是将不同的文章联系起来。由于 Hexo 中的 categories 具有这样的特点，因此在 Hexo 中 categories 可以作为一种文章的组织方式——在 Hexo 中你可以将 categories 用在文章的 URL 结构中。\n但是在 Hugo 中这是无法实现的，在 Hugo 中你是无法将文章的 Front Matter 中的 categories 用于文章的 URL 的。为什么呢？因为 Hugo 中的 categories 与 tags 在功能上其实是完全相同的，它们的作用都是将不同的文章联系起来。其实，Front Matter 中的 categories 和 tags 在 Hugo 中都属于 Taxonomies。\n那么，在 Hugo 中你要怎么组织文章呢？分区（Sections）。所谓分区，即站点的 content 目录下的文件夹和子文件夹，一个文件夹即一个分区。很明显，这是基于文件系统的结构的，自然也就支持树状╱网状╱嵌套结构，也就能够用来实现文章的树状分类。\n我认为这是一个非常好的设计，在使用Hexo时，博客数量一多，在本地的文件系统中就容易混乱，我还使用了一个插件，来自动将文件夹名字用于Front Matter中的 categories ，而在Hugo中直接就使用了这种分类方式。需要注意的是，如果有多级文件夹，需要在文件夹下新建_index.md使得其为新的categories。\n其它方面 首先是文章的 Front Matter 中的 date 日期格式的问题。在 Hugo 中，Hexo 默认的日期格式是不能工作的，比如：你必须要修改 1969-07-20 20:17:43 为 1969-07-20T20:17:43+00:00，即添加了时区的信息。对于这点，你可以用上文提到的那个 Python 脚本批量处理一下。\n然后是文章的修改时间的问题。在 Hexo 中，会自动将文件的修改时间作为文章的修改时间，但在 Hugo 中不会。不过你可以自行配置，在配置文件 config.toml 中加入 :fileModTime：\n1 2  [frontmatter] lastmod = [\u0026#34;lastmod\u0026#34;, \u0026#34;:git\u0026#34;, \u0026#34;:fileModTime\u0026#34;, \u0026#34;:default\u0026#34;]   如此，就算你没有在文章的 Front Matter 中手动指定修改时间 lastmod，它依然会随着你的文章的改动或修改而「自动更新」。\n 在 Hexo 中，你可能会在 Markdown 中使用 Hexo 标签插件来实现一些 Markdown 语法无法实现的特殊排版需求。这些特殊的语法是无法在 Hugo 中生效的，尽管在 Hugo 中有与之对应的短代码，但它们之间的语法是不同的，故我建议最好放弃这种非 Markdown 原生语法的写法。当然，如果你非要手动将之从 Hexo 迁移到 Hugo 中也不是没有可能，比如：你可以用 hugo-notice 实现 NexT 主题的 Note 标签。\n此外，对于文章摘要的截取，即「阅读更多」上方的内容。在 Hexo 中你可以在文章中加入\u0026lt;!-- more --\u0026gt; 来控来控制，但这在 Hugo 中是不会生效的，在 Hugo 中你必须将空格删除。\n还有一个是 index.md 的问题，在 Hugo 中你必须在它的前面添加一个下划线，即 _index.md。比如：你想自定义标签页面的标题为中文，那么你先在新建一个 content/tags/_index.md 文件，然后在文件中加入：\n1 2 3  +++ title = \u0026#34;标签\u0026#34; +++    对于图片，我个人建议还是使用本地图片，而不是图床（血的教训）。在 Hugo 中，使用本地图片的方法很简单，直接在 static 文件夹中新建一个 images 子文件夹，然后在Markdown语法中使用：\n1  ![hugo-logo-wide](/images/misc/hugo-logo.svg \u0026#34;Hugo\u0026#34;)   其中，最后的 Hugo 是图片的描述。\nHugo theme Hugo 是一个很活跃的社区，有非常多的主题可供选择。我目前的主题选择的是 MemE，开发者非常活跃且乐于接受 PR，同时审美在线，速度非常快，我非常满意。\n开发者 reuixiy 有详细的主题开发介绍，我这里就不赘述了。\n由于 MemE主题使用了大量 SVG 图片来加快加载速度（包括品牌栏、图标等等），我使用了 Inkscape 来制作了自己的品牌栏（还不错吧？），可供大家参考。\n 下一篇博客我会介绍，如何使用 Hugo 进行持续集成写作，同时同步到个人服务器中。\n","permalink":"https://tech.zealscott.com/misc/go-hugo/","summary":"在 2020 年的春节前夕，我终于完成了博客从 Hexo 到 Hugo 的迁移。期间踩过不少坑，也有不少小朋友来问我如何开始进行个人博客写作，因此觉着是时候写点东西记录记录。\nWhy Hugo 正式开始写个人博客，是两年前的春节。最开始使用了当时最流行的 Hexo 框架，选择了 Next 主题。最开始一切都很好，虽然 Hexo 框架是简单了点，但耐不住有很多热心的开发者开发了很多插件，所以基本上都能满足自己的需求。而随着博客数量越来越多，我发现 Hexo 的问题越来越让我难以忍受，那就是：速度太慢。\n举个例子，当我有 200 多篇博客的时候，用 Hexo 渲染静态网页需要将近 20 秒，这样的速度简直是不可接受的。更不要说我还有大量的静态图片、资料等等。同时，由于自己偷懒，博客中使用的图片都来自于图床，这些外链不受我控制，很多时候有打不开、加载慢的问题，让我这个强迫症觉得很不爽。\n因此2019年底，我萌发了重构个人博客的想法，一眼就看中了用 Go 语言写的 Hugo，其Slogan The world’s fastest framework for building websites也是非常吸引我。更难能可贵的是，Hugo 虽然还处于快速迭代开发的阶段，但并不是一个半成品，很多在 Hexo 上需要插件实现的功能，Hugo 上都内置了。\nHugo vs Hexo 为了方便 Hexo 用户快速上手 Hugo，我总结了 Hugo 与 Hexo 的异同点（大部分来源于官网及这篇博文）。\n结构组织 1 2 3 4 5 6 7 8 9 10 11 12  ~/blog $ tree -L 1 .","title":"Go Hugo!"},{"content":"环境配置 在Laravel官网上，推荐使用Laravel Homestead虚拟机部署安装环境。Homestead是Laravel官方提供的基于Vargrant的Box，也就是虚拟机原型系统，预装了一切 Laravel 需要的东西。\n这里使用VirtualBox虚拟机，而Vagrant是一个虚拟机管理工具。\n配置Laravel环境的主要步骤有：\n 安装VirtualBox和Vagrant 安装Homestead Vagrant Box 安装Homestead（Clone 项目） 修改配置文件（Homestead.yaml和/etc/hosts） 启动虚拟机，SSH登陆虚拟机 下载Laravel  安装VirtualBox和Vagrant 直接官网安装dmg即可：\n  VirtualBox 下载地址\n  Vagrant下载地址\n  验证是否安装成功在终端使用以下命令行，显示版本信息就 OK 了。\n1  vagrant -v   安装 Homestead Vagrant Box 在线安装 直接输入以下命令行：\n1  vagrant box add laravel/homestead   这个步骤相当于下载虚拟机的预装系统，下载文件超过1个G，实测非常慢，及时是挂VPN，也太慢。\n离线导入 下载Box 最后我选择了首先下载.box文件，然后导入的方式。\n在Vagrant官网进入Homestead box，选择最新的版本，例如8.2.1，然后进入该版本页面，如https://app.vagrantup.com/laravel/boxes/homestead/versions/8.2.1，直接在后面添加/providers/virtualbox.box组成完整的URL，即可使用迅雷等下载工具进行下载，完整的URL为：\n https://app.vagrantup.com/laravel/boxes/homestead/versions/8.2.1/providers/virtualbox.box\n 下载完成后得到virtualbox.box的文件，在命令行中进入该文件的目录，然后输入以下命令即可成功导入。\n vagrant box add laravel/homestead ./virtualbox.box\n 导入 注意，这里导入时vagrant并不知道版本信息。因此，我们需要进入box的文件夹，手动增加版本信息。\nvagrant存储box的目录为~/.vagrant.d/boxes，进入其中的laravel-VAGRANTSLASH-homestead文件夹，新建一个metadata_url文件夹，输入\n https://app.vagrantup.com/laravel/homestead\n 同时，将文件夹0重命名为当前的版本号，例如8.2.1。\n输入命令vagrant box list，可查看当前安装的box及版本号。\n安装 Homestead 从GitHub上clone项目，并切换到稳定的分支，创建相关配置文件。\n1 2 3 4  git clone https://github.com/laravel/homestead.git ~/Homestead cd ~/Homestead git checkout release bash init.sh   修改配置文件 进入Homestead的根目录，打开Homestead.yaml文件修改配置：\n主要修改同步目录，例如：\n1 2 3 4 5 6  folders:- map:~/Code/OpenCionto:/home/vagrant/OpenCionsites:- map:homestead.testto:/home/vagrant/OpenCion/public  然后再将IP加入/ect/host中：\n1  192.168.10.10 homestead.test   启动虚拟机 在命令行中输入 cd ~/Homestead，切换到homestead项目所在到目录，然后输入 vagrant up\n启动成功后，在同样目录下输入vagrant ssh 登陆到 vagrant 虚拟机，如下图所示：\n在根目录下，使用composer下载 Laravel：\n1  composer create-project laravel/laravel OpenCoin --prefer-dist   这里的OpenCoin是之前设置的同步目录，–prefer-dist: 意思是下载用于 distribution 的稳定版本。\n浏览器里输入 homestead.test （预设值的域名），出现以下画面表示安装成功。\n基本操作说明 关闭/删除/重建 Homestead Homestead 相当于另一个系统，不用的时候千万要记得关闭。以下是退出登陆并关闭虚拟机命令。\n1 2 3 4  # 命令行工具退出对虚拟机系统登陆 eixt # 虚拟机关机（位置要在 Homestead 文件夹） vagrant halt   下次需要使用时，从 vagrant up 步骤开始即可。\n在测试中因为各种原因导致虚拟机坏掉的时候，只需要对虚拟机进行删除、重建即可，非常方便。\n1 2 3 4  # 删除当前虚拟机（需要在 Homestead 文件夹下） vagrant destroy --force # 重建虚拟机 vagrant up   注意删除指的是删除 vagrant up 建立的虚拟机，和删除整个 Homestead 是不同概念。如果完全不想使用 Homestead 了，想要删除可以参考下面链接。\nReference  [Laravel] mac下通过 homestead 搭建环境到运行项目 Laravel Installation  ","permalink":"https://tech.zealscott.com/misc/laravel-installation/","summary":"环境配置 在Laravel官网上，推荐使用Laravel Homestead虚拟机部署安装环境。Homestead是Laravel官方提供的基于Vargrant的Box，也就是虚拟机原型系统，预装了一切 Laravel 需要的东西。\n这里使用VirtualBox虚拟机，而Vagrant是一个虚拟机管理工具。\n配置Laravel环境的主要步骤有：\n 安装VirtualBox和Vagrant 安装Homestead Vagrant Box 安装Homestead（Clone 项目） 修改配置文件（Homestead.yaml和/etc/hosts） 启动虚拟机，SSH登陆虚拟机 下载Laravel  安装VirtualBox和Vagrant 直接官网安装dmg即可：\n  VirtualBox 下载地址\n  Vagrant下载地址\n  验证是否安装成功在终端使用以下命令行，显示版本信息就 OK 了。\n1  vagrant -v   安装 Homestead Vagrant Box 在线安装 直接输入以下命令行：\n1  vagrant box add laravel/homestead   这个步骤相当于下载虚拟机的预装系统，下载文件超过1个G，实测非常慢，及时是挂VPN，也太慢。\n离线导入 下载Box 最后我选择了首先下载.box文件，然后导入的方式。\n在Vagrant官网进入Homestead box，选择最新的版本，例如8.2.1，然后进入该版本页面，如https://app.vagrantup.com/laravel/boxes/homestead/versions/8.2.1，直接在后面添加/providers/virtualbox.box组成完整的URL，即可使用迅雷等下载工具进行下载，完整的URL为：\n https://app.vagrantup.com/laravel/boxes/homestead/versions/8.2.1/providers/virtualbox.box\n 下载完成后得到virtualbox.box的文件，在命令行中进入该文件的目录，然后输入以下命令即可成功导入。\n vagrant box add laravel/homestead ./virtualbox.box\n 导入 注意，这里导入时vagrant并不知道版本信息。因此，我们需要进入box的文件夹，手动增加版本信息。","title":"Laravel Homestead 安装小记"},{"content":"代价函数 为了量化我们神经网络的拟合效果，我们定义一个代价函数：\n$$C(w,b) = \\frac {1}{2n}\\sum\\limits_{x}||y(x)-a||^2$$\n我们训练算法的目的，就是最小化权值和偏置的代价函数$C(w,b) $。\n针对代价函数，我们试着回答以下两个问题：\n  为什么不直接采用分类（识别）正确的数量作为评价指标呢？\n 这是因为在神经网络中，被正确分类的图像数量所关于权值和偏置的函数并不是一个平滑的函数。\n大多数情况下，对权值和偏置的微小变动完全不会影响被正确分类的图像数量，这让我们很难去解决如何改变权重和偏置来取得进改进的性能。\n   为什么要用二次函数呢？\n 代价函数并不是唯一的，不同的代价函数的评价指标也是不同的。但二次函数是使用得最广泛的，并且具有特殊的语义\u0026ndash;均方误差（MSE）。我们接下来还会看到更多的代价函数，在计算时就会知道二次函数的优越性了。\n   为什么要梯度下降？ 我们现在的目标是想要找到$C$的全局最小值。当然，对于简单的二次型函数，我们很快就能找到最小值。但回想一下我们是怎么做的呢？\n一种方法就是直接用偏导去找极值点。但如果变量很多，比如神经网络至少有上千个变量和偏置，计算非常复杂。\n另外一种方法是使用梯度下降。考虑我们目前有两个变量$v_1，v_2$，当我们在$v_1和v_2$方向分别移动一个很小的量（沿着梯度方向），这时候会发生如下变化：\n$$\\Delta C\\approx \\frac{\\partial C}{\\partial v_1}\\Delta v_1 +\\frac{\\partial C}{\\partial v_2}\\Delta v_2 $$\n我们需要使用一种方法选择$\\Delta v_1和\\Delta v_2$使得$\\Delta C$为负，这样我们就可以使得$C$不断减小，逼近最小值。我们用$\\nabla C$来表示梯度向量，即：\n$$\\nabla C \\equiv (\\frac{\\partial C}{\\partial v_1},\\frac{\\partial C}{\\partial v_2})^T$$\n因此$\\Delta C$可以被重写为：\n$$\\Delta C\\approx \\nabla C \\cdot \\Delta v$$\n这个式子有着很重要的意义：我们发现$\\nabla C$将$v$的变化关联为$C$的变化，正如我们期望的用梯度表示。并且，我们知道了如何选取$\\Delta v$才能让$\\Delta C$为负数。假设我们选取：\n$$\\Delta v = -\\eta \\nabla C$$\n这里的$\\eta$是一个很小的正数，我们称为学习速率。方程告诉我们，$\\Delta C\\approx \\nabla C \\cdot \\Delta v = -\\eta ||\\nabla C||^2$。由于$ ||\\nabla C||^2 \\ge0$，这保证了$\\Delta C \\le 0$。即，如果我们按照方程的规则去改变$v$，那么$C$会一直减小，不会增加。因此我们可以计算$\\Delta v$，来移动点的位置：\n$$v \\rightarrow {v}' = v - \\eta \\nabla C$$\n然后我们用它再次更新来计算下一次移动，因此我们迭代进行，就可以获得一个全局的最小值。\n思考：\n 由上面的公式，是不是我们增大学习速率$\\eta$，就能使$\\Delta C$变得更小，使得梯度下降速率更快呢？\n​\t可惜不是的。当$\\eta$过大时，上面的等式$\\Delta C\\approx \\nabla C \\cdot \\Delta v$就不再成立，因此要选择合适的学习速率尤其重要。\n Batch gradient descent（BGD） 在神经网络中如何引用梯度下降算法去学习呢？我们很容易得到以下方程：\n$$w_k \\rightarrow {w_k}' = w_k - \\eta \\frac {\\partial C}{\\partial w_k} $$ $$b_l \\rightarrow {b_l}' = b_l - \\eta \\frac {\\partial C}{\\partial b_l} $$\n注意，我们的代价函数为$C = \\frac {1}{n} \\sum _x C_x $，它是遍历每个样本代价$C_x = \\frac {||y(x - a)||^2}{2}$的平均值。因此，我们需要为每个训练样本输入单独计算梯度值$\\nabla C_x$，然后求平均值。但当训练输入的数量过大时会花费很长时间，这样会使得学习变得相当缓慢。\n但是，在输入样本不太大时，这种方法（BGD）是经常被采用的。\nStochastic gradient descent（SGD） 随机梯度下降的算法能加速学习。其思想就是通过选取小量训练输入样本来计算$\\nabla C_x$，进而估算$\\nabla C$。通过计算少量样本的平均值我们可以快速得到一个对于实际梯度$\\nabla C$很好的估算，这有助于加速梯度下降，进而加速学习过程。\n例如我们可以随机选取小量的$m$个训练输入来工作。我们将这些训练输入记做$X_1,X_2,\u0026hellip;X_m$，并称为mini-batch。假设样本数量$m$足够大，我们期望$\\nabla C_{X_j}$的平均值大致相当于整个$\\nabla C_x$的平均值，即：\n$$\\frac {\\sum _{j=1}^m \\nabla C_{x_j}}{m} \\approx \\frac {\\sum _x^m \\nabla C_x}{n} = \\nabla C$$\n实验证明这种方法（Mini-batch BGD）能较快的收敛到一个较小的值。\n","permalink":"https://tech.zealscott.com/deeplearning/misc/gradientdescent/","summary":"代价函数 为了量化我们神经网络的拟合效果，我们定义一个代价函数：\n$$C(w,b) = \\frac {1}{2n}\\sum\\limits_{x}||y(x)-a||^2$$\n我们训练算法的目的，就是最小化权值和偏置的代价函数$C(w,b) $。\n针对代价函数，我们试着回答以下两个问题：\n  为什么不直接采用分类（识别）正确的数量作为评价指标呢？\n 这是因为在神经网络中，被正确分类的图像数量所关于权值和偏置的函数并不是一个平滑的函数。\n大多数情况下，对权值和偏置的微小变动完全不会影响被正确分类的图像数量，这让我们很难去解决如何改变权重和偏置来取得进改进的性能。\n   为什么要用二次函数呢？\n 代价函数并不是唯一的，不同的代价函数的评价指标也是不同的。但二次函数是使用得最广泛的，并且具有特殊的语义\u0026ndash;均方误差（MSE）。我们接下来还会看到更多的代价函数，在计算时就会知道二次函数的优越性了。\n   为什么要梯度下降？ 我们现在的目标是想要找到$C$的全局最小值。当然，对于简单的二次型函数，我们很快就能找到最小值。但回想一下我们是怎么做的呢？\n一种方法就是直接用偏导去找极值点。但如果变量很多，比如神经网络至少有上千个变量和偏置，计算非常复杂。\n另外一种方法是使用梯度下降。考虑我们目前有两个变量$v_1，v_2$，当我们在$v_1和v_2$方向分别移动一个很小的量（沿着梯度方向），这时候会发生如下变化：\n$$\\Delta C\\approx \\frac{\\partial C}{\\partial v_1}\\Delta v_1 +\\frac{\\partial C}{\\partial v_2}\\Delta v_2 $$\n我们需要使用一种方法选择$\\Delta v_1和\\Delta v_2$使得$\\Delta C$为负，这样我们就可以使得$C$不断减小，逼近最小值。我们用$\\nabla C$来表示梯度向量，即：\n$$\\nabla C \\equiv (\\frac{\\partial C}{\\partial v_1},\\frac{\\partial C}{\\partial v_2})^T$$\n因此$\\Delta C$可以被重写为：\n$$\\Delta C\\approx \\nabla C \\cdot \\Delta v$$\n这个式子有着很重要的意义：我们发现$\\nabla C$将$v$的变化关联为$C$的变化，正如我们期望的用梯度表示。并且，我们知道了如何选取$\\Delta v$才能让$\\Delta C$为负数。假设我们选取：\n$$\\Delta v = -\\eta \\nabla C$$","title":"梯度下降原理及理解"},{"content":"本文主要考虑的是PU learning，也就是在只有正类数据和无标记数据的情况下，对数据进行二分类。在case-control情境下（也就是two samples问题），之前大部分研究基于都基于selected completely at random的假设，但本文argue这种假设不符合实际，因此对该假设进行了放松：如果$P(o = +1| x)$越高，则$P(y = +1| x)$也越高，反之亦然，这种性质被称为invariance of order。\n使用Bayes公式推导可以得到，密度比也符合这种偏序关系。因此，论文认为，虽然我们很难得到$P(y=+1|x)$具体的值，但通过估计密度比，能得到样本间是正类的概率偏序关系，这样通过一个合理的阈值作为分类器即可区分正负类。\n作者通过两种方法来估计密度比：一种是根据之前研究定义的classification risk推广到有based的classification risk函数，然后根据公式$\\hat{r} = \\frac{\\hat f}{\\pi}$计算得到；另一种方法是直接用uLSIF进行估计。得到密度比$r$之后，根据先验信息$\\pi$，对数据进行遍历即可得到$\\theta_\\pi$阈值，通过该阈值可以实现在未标记数据上将正负样本进行区分。\n最后，作者在几个常见的数据集上进行了改造以符合PU learning的假设，同时使用了一个real-world数据集，使用论文提到的两个方法估计$\\hat{r}$，然后可以得到阈值$\\theta_\\pi$，进而得到二分类器。最后还验证了在未知先验$\\pi$的情况下，其算法的robust较好。\nIntuition  cast-control scenario  P 是从正类中采样的，U 是从整个样本空间采样的，这两者相互独立。这个假设符合现实中的认识，因为如果有标记的样本都是正例，那么一定是人为忽略或是丢弃了负类样本。换句话说，unlabel data 中既包含正样本，也包含负样本，称为为 two samples 问题，即有 P 和 U 两个采样集。   selected completely at random (SCAR)  对于cast-control的问题，常见的假设是：正类被标记的采样集和未标记的采样集是独立同分布的。 作者 argue 这种假设在现实问题中很多时候不成立，例如在异常检测中，异常的更容易被选中；在人脸识别中，用户更倾向于提供清晰的照片（labeled），而未标记的数据更可能非常不清晰。   select bias  因此在现实中，作者认为$P(x|y = +1,o = 0) \\ne P(x|y = +1,o = +1)$，不能简单的通过Bayes公式推断得到$P(y = +1 | x)$的概率。 虽然不能直接得到$P(y = +1 | x)$的值，但根据之前的假设，如果数据更容易被标记，则它是正样本的概率更大，可以得到这样的偏序关系：  $P(y = +1 | x_i) \\le P(y = +1| x_j) \\Leftrightarrow P(o = +1 | x_i)\\le P(o = +1| x_j)$   如果取等号，那么就满足了SCAR假设，因此，本文定义的invariance of order可以看作是SCAR的推广。    Strategy 作者主要的思路是：\n 使用正类数据和未标记数据，通过最小化pseduo classification risk或者LSIF对密度比$r(x)$进行估计 通过先验$\\pi$和$r(x)$，认为test data中的数据分布与先验应该相同，估计阈值$\\theta_\\pi$ 通过简单的符号函数即可构造一个二分类器将未标记数据进行区分  基本概念  density ratio  我们用密度比的概念来衡量数据之间的差异性，这种差异可以用来区分正负样本。 定义为： $r(x) = \\frac{P(x|y = +1,o = +1)}{P(x)}$，作者在这里称为打分函数  这里可以理解为从两个数据集中进行抽样的概率密度，如果相差越大（即密度比越大），则越能区分该数据   使用Bayes定理和invariance of order假设，可以得到：  $P(y = +1 | x_i) \\le P(y = +1| x_j) \\Leftrightarrow r(x_i)\\le r(x_j)$   这里给我们的启发是：虽然不能直接得到样本属于正类的概率，但通过打分函数可以捕捉到这种偏序关系。因此，我们如果能对$r$进行估计，设置一个较好的阈值，结合我们先验的$\\pi$，就可以用来区分正负样本了。   $\\theta_\\pi$的性质  我们用阈值将样本分开并逼近先验$\\pi$，很自然的问题是，选择这个阈值对于我们分类效果的影响如何？ 论文附录B证明了：该阈值使得 precision 和recall值一样，因此这个阈值称为BEP，直观的可以认为该点在false positives 和 false negetive找到了很好的平衡。    估计$r(x)$ Minimize PU risk 之前的工作已经得到，在SCAR假设下，classification risk可以表示为：\n$$R_{PU}(f) = \\pi E_P[l(f(X),+1)] - \\pi E_P[{l(f(X),-1)}] + E_u[l(f(X),-1)]$$\n如果数据没有selection bias，那么直接可以用样本均值代替这里的期望，保证估计出的risk的无偏性。\n仿照之前定义的calssification risk，在selection bias的情境下，我们可以定义完全一样的classification risk，称为psedo classicication risk，因此我们得到的是关于伪分类风险函数的无偏估计。同时定义loss function为对数损失：\n$$R_{PU} (f) = -\\pi E_P[\\log (f(X))] + \\pi E_P[\\log(1-f(X))] - E_u[\\log(1-f(X))] $$\n将期望代替为样本均值，再加上正则项，最小化分类损失函数后得到$\\hat{f}$，可以用来估计$\\hat{r} = \\frac{\\hat{f}}{\\pi}$\nLSIF 论文提供的另外一种估计 $r(x)$ 的方法，使用unconstrained Least-Squares Importance Fitting (uLSIF) 直接对密度比进行估计。其实就是最小化估计值与真实值差的平方的期望。在实际运用中常加入正则项：\n$$\\hat{r} = \\arg \\min\\limits_{s} [\\frac{1}{2}E_u[(s(X))^2] - E_P[s(X)] + R(s) ]$$\n估计$\\theta_\\pi$ 根据先验$\\pi$以及我们的假设（test data中的正类占比应该不会与先验相差太远），因此我们直接遍历每个样本点的$\\hat{r}(x)$，大于阈值的即为正类。因此，用先验得到的正类个数应该和估计的超过阈值的$\\hat{r}(x)$相同，即：\n$$\\pi N = \\sum\\limits_{i=1}^N 1(\\hat{x_i} \u0026gt; \\theta_\\pi)$$\nExperiments 论文主要用了unbiased PU learning做对比，PUSB表示用阈值预估的unbiased PU learning，DRSB表示用uLSIF和阈值估计；nnPU表示nonnegative PU learning；nnPUSB表示nonnegative PU learning和阈值估计。。。（这缩写也太多了）\n根据估计密度比的不同方法，论文给出了不同的模型：\n 直接使用LSIF对$r$进行估计，其中的$s(x)$使用了线性模型  $s(x) = \\beta^T\\Phi(x)$ 这里的$\\Phi(x)$是一系列基函数的向量，这里的基函数使用了高斯核（$\\phi_l(x) = \\exp(-||x-c_l||^2/(2\\sigma^2))$ 使用交叉验证来选择最合适的超参数   对于最小化classification risk，其中的$f(x)$使用了sigmoid函数：  $f(x) = \\frac{1}{1+\\exp(-\\beta^T\\Phi(x))}$ 对于nonegative PU learning，使用了神经网络进行学习，正则化使用了$l_2$范数    论文做了相当数量的实验来证明算法的有效性，可以分为：\n mushrooms、 shuttle、 pageblocks、 usps、 connect-4 、 spambase  首先用logistic回归估计了$P(y = +1 | x)$的概率，然后用其20倍的概率作为selection bias对正样本进行采样，然后用之前提到的最小化PU risk和LSIF方法分别对 $\\hat{r}$ 进行估计，从而得到分类器。 文中使用不同的$\\pi$和未标记数据集大小进行实验，发现其算法都好于之前的方法，但两种$r$的估计方法在不同的数据集中有好有坏。   MNIST、CIFAR-10  这些数据集原本是多分类的，作者人为的将其分为了正负样本两类（个人感觉这样强行分类不太具有说服力） 同样，使用logistic回归估计了$P(y = +1 | x)$的概率，然后用其10倍的概率作为selection bias对正样本进行采样，最后用最小化non-negative risk作为目标函数训练神经网络，估计得到$\\hat{r}$，得到分类器后计算recall和precision。   SwissProt  这是唯一一个自然存在bias的数据集。用词袋模型将文档转为高维向量，使用类似的方法训练神经网络并估计密度比，得到阈值和分类器，计算 recall 和precison。   Test for unknown class prior  由于该算法的阈值计算依赖于先验 $\\pi$，因此我们希望在先验估计得不太准确的情况下，算法的分类效果有较好的robust。使用了KM2方法*（待看）*估计了先验概率，并进行了实践，发现其准确率有较大的下降，但在先验偏离越来越远的情况下，其准确率基本趋于稳定。    Reference  Open review  ","permalink":"https://tech.zealscott.com/deeplearning/pulearning/nnpusb/","summary":"本文主要考虑的是PU learning，也就是在只有正类数据和无标记数据的情况下，对数据进行二分类。在case-control情境下（也就是two samples问题），之前大部分研究基于都基于selected completely at random的假设，但本文argue这种假设不符合实际，因此对该假设进行了放松：如果$P(o = +1| x)$越高，则$P(y = +1| x)$也越高，反之亦然，这种性质被称为invariance of order。\n使用Bayes公式推导可以得到，密度比也符合这种偏序关系。因此，论文认为，虽然我们很难得到$P(y=+1|x)$具体的值，但通过估计密度比，能得到样本间是正类的概率偏序关系，这样通过一个合理的阈值作为分类器即可区分正负类。\n作者通过两种方法来估计密度比：一种是根据之前研究定义的classification risk推广到有based的classification risk函数，然后根据公式$\\hat{r} = \\frac{\\hat f}{\\pi}$计算得到；另一种方法是直接用uLSIF进行估计。得到密度比$r$之后，根据先验信息$\\pi$，对数据进行遍历即可得到$\\theta_\\pi$阈值，通过该阈值可以实现在未标记数据上将正负样本进行区分。\n最后，作者在几个常见的数据集上进行了改造以符合PU learning的假设，同时使用了一个real-world数据集，使用论文提到的两个方法估计$\\hat{r}$，然后可以得到阈值$\\theta_\\pi$，进而得到二分类器。最后还验证了在未知先验$\\pi$的情况下，其算法的robust较好。\nIntuition  cast-control scenario  P 是从正类中采样的，U 是从整个样本空间采样的，这两者相互独立。这个假设符合现实中的认识，因为如果有标记的样本都是正例，那么一定是人为忽略或是丢弃了负类样本。换句话说，unlabel data 中既包含正样本，也包含负样本，称为为 two samples 问题，即有 P 和 U 两个采样集。   selected completely at random (SCAR)  对于cast-control的问题，常见的假设是：正类被标记的采样集和未标记的采样集是独立同分布的。 作者 argue 这种假设在现实问题中很多时候不成立，例如在异常检测中，异常的更容易被选中；在人脸识别中，用户更倾向于提供清晰的照片（labeled），而未标记的数据更可能非常不清晰。   select bias  因此在现实中，作者认为$P(x|y = +1,o = 0) \\ne P(x|y = +1,o = +1)$，不能简单的通过Bayes公式推断得到$P(y = +1 | x)$的概率。 虽然不能直接得到$P(y = +1 | x)$的值，但根据之前的假设，如果数据更容易被标记，则它是正样本的概率更大，可以得到这样的偏序关系：  $P(y = +1 | x_i) \\le P(y = +1| x_j) \\Leftrightarrow P(o = +1 | x_i)\\le P(o = +1| x_j)$   如果取等号，那么就满足了SCAR假设，因此，本文定义的invariance of order可以看作是SCAR的推广。    Strategy 作者主要的思路是：","title":"Learning from positive and unlabeled data with a selection bias"},{"content":"Papers  Learning Classiﬁers from Only Positive and Unlabeled Data KDD 2008 （PUAdapter）  经典论文，在SCAR假设下，证明了$p(y|x)$与$p(s|x)$只相差一个常数c，因此可以使用经典的分类模型，将positive和unlabel数据看成两类，直接得到$p(s|x)$的概率，进而估计$p(y|x)$。同时给出了估计常数$c$和先验$p(y)$的方法。 本文还提出了一个非常重要的思想，就是把Unlabel数据看成是Positive和Negative样本的不同权重组合，引出了后来的unbiased risk estimators。 Code available 论文笔记   Analysis of Learning from Positive and Unlabeled Data NIPS 2014  从基本的分类损失出发，推导了PU的分类问题其实就是Cost-sensitive classiﬁcation的形式。详细推导了risk function：$R(f) = 2\\pi R_1(f) + R_X(f) -\\pi $，论文以这个risk function出发，对不同的loss function进行了讨论。（部分推导可结合 Semi-Supervised Novelty Detection 再看） 同时证明了如果使用凸函数hinge loss作为loss function，会导致错误的分类边界（多一项惩罚项），因此需要使用非凸ramp loss作为loss function。同时证明了使用PU进行分类的误差小于监督学习误差的$2\\sqrt{2}$倍（这里待看）。  即loss需要满足 $l(t,+1) + l(t,-1) = 1$，也就是symmetric condition   论文笔记   Convex formulation for learning from positive and unlabeled data IMCL 2015 （uPU）  这篇文章主要是对之前提出的非凸loss进行改进，主要想法是根据risk function对正类样本和未标记样本使用不同的loss function。 从另一个方面推导了risk function： $R(g) = \\pi E_1[ \\hat{l}(g(x))] + E_X[l(-g(x))]$，考虑当$\\hat{l}$为凸时，证明了其一定为线性函数，将hinge loss修改为double hinge loss，变为凸优化问题。通过实验说明其效果不比non-convex loss function差，同时减少了计算开销。  即loss需要满足$l(t,+1) + l(t,-1) = -t$，也就是linear-odd condition   同时，这篇文章用的分类器为linear-in-parameter model，使用高斯核将样本映射到feature space，具体定义可以参考 Introduction to Statistical Machine Learning By Masashi Sugiyama 2016 一书的Chapter21。 Code available 论文笔记   Positive-Unlabeled Learning with Non-Negative Risk Estimator NIPS 2017 （nnPU）  由于之前的risk estimator $\\hat{R}_{pu}(g) = \\pi_p\\hat{R}_p^+(g) -\\pi_p\\hat{R}_p^-(g) + \\hat{R}_u^-(g)$中，有可能出现$-\\pi_p\\hat{R}_p^-(g) + \\hat{R}_u^-(g) \u0026lt; 0 $的情况，会导致risk不断减小变为负数。因此对risk进行改写，提出nnPU，能有效的防止过拟合，能使用更强大的学习器（神经网络）进行学习。同时，论文对这个risk estimator的bias，consistency和MSE reduction进行了理论分析。 Code available   Learning from positive and unlabeled data with a selection bias ICLR 2019 （nnPUSB）  放松了SCAR的假设，认为如果$P(o = +1| x)$越高，则$P(y = +1| x)$也越高（不一定相同）。使用贝叶斯公式得到密度比和$P(y = +1|x)$满足同样的偏序关系，因此使用两种方法估计密度比（risk function/uLSIF），并设定阈值实现对PU的分类。 Code available / My implementation 论文笔记    Formula Risk 推导  定义在decision function $g$ 下的risk为：  $R(g) = E_{(X,Y)\\sim p(x,y)}[l(g(X),Y)] = \\pi_pR_p^+(g) + \\pi_nR_n^-(g)$ 其中$R_p^+(g) = E_p[l(g(X)),+1]$也就是对正类分类错误的risk，$R_n^-(g) = E_p[l(g(X)),-1]$也就是对负类分类错误的risk   由于我们没有办法直接得到负类样本，因此由公式 $\\pi_np_n(x) = p(x) - \\pi_pp_p(x)$可得负类样本分类错误的损失：   $\\pi R_n^-(g) = R_u^-(g) - \\pi_pR_p^-(g)$\n  将其带入risk中可得经验risk：\n$$\\hat{R}_{pu}(g) = \\pi_p\\hat{R}_p^+(g) -\\pi_p\\hat{R}_p^-(g) + \\hat{R}_u^-(g)$$\n  这里的 $\\hat{R}_{p}^{-}(g)$ 表示在正类样本中预测值与-1的loss的均值，即：\n$$\\frac{1}{n_p}\\sum_{i=1}^{n_p}l(g(x^p_i),-1)$$\n  更常见的写法是根据loss去掉上角标，例如，对于01损失而言，$l_{0-1}(-g(x))$表示预测值与-1的loss，对于不同的损失函数，只需要更改正负号即可实现预测值与-1或者1的loss，因此，可以写为：\n $J(g) = \\pi E_1[l(g(x)) - l(-g(x))] + E_X[l(-g(x))]$    将$\\hat{l}(g) = l(g(x)) - l(-(g(x)) = l(t,+1) - l(t,-1) = -t$ 作为新的convext loss（线性），可以得到unbised UP，这个条件也称为linear-odd condition\n   同样的思路，由公式 $p(x) = \\pi_pp_p(x) +\\pi_np_n(x) $可得负样本分类错误的损失：  $R_u^-(g) = \\pi_pR_p^-(g) + \\pi_n R_n^-(g) =\\pi_p(1 - R_p^+(g)) + \\pi_nR_n^-(g) $ 注意，这里的loss需要满足 $l(t,+1) + l(t,-1) = 1$，也就是symmetric condition 将其带入risk中可得经验risk：$\\hat{R}_{pu}(g) =2 \\pi\\hat{R}_p^+(g) + \\hat{R}_u^-(g) -\\pi_p$  去掉角标，形式为：$R(f) = 2\\pi R_1(f) + R_X(f) -\\pi$   这里可以证明其为cost-sensitive learning，但由于loss不满足凸函数，因此不是凸优化问题。    Notes  Note on Learning with Positive and Unlabeled Data  非常详细的整理了2017年前PU learning的经典论文   Positive-unlabeled learning  整理了常见的PU learning的方法。    ","permalink":"https://tech.zealscott.com/deeplearning/pulearning/pu-learning-overview/","summary":"Papers  Learning Classiﬁers from Only Positive and Unlabeled Data KDD 2008 （PUAdapter）  经典论文，在SCAR假设下，证明了$p(y|x)$与$p(s|x)$只相差一个常数c，因此可以使用经典的分类模型，将positive和unlabel数据看成两类，直接得到$p(s|x)$的概率，进而估计$p(y|x)$。同时给出了估计常数$c$和先验$p(y)$的方法。 本文还提出了一个非常重要的思想，就是把Unlabel数据看成是Positive和Negative样本的不同权重组合，引出了后来的unbiased risk estimators。 Code available 论文笔记   Analysis of Learning from Positive and Unlabeled Data NIPS 2014  从基本的分类损失出发，推导了PU的分类问题其实就是Cost-sensitive classiﬁcation的形式。详细推导了risk function：$R(f) = 2\\pi R_1(f) + R_X(f) -\\pi $，论文以这个risk function出发，对不同的loss function进行了讨论。（部分推导可结合 Semi-Supervised Novelty Detection 再看） 同时证明了如果使用凸函数hinge loss作为loss function，会导致错误的分类边界（多一项惩罚项），因此需要使用非凸ramp loss作为loss function。同时证明了使用PU进行分类的误差小于监督学习误差的$2\\sqrt{2}$倍（这里待看）。  即loss需要满足 $l(t,+1) + l(t,-1) = 1$，也就是symmetric condition   论文笔记   Convex formulation for learning from positive and unlabeled data IMCL 2015 （uPU）  这篇文章主要是对之前提出的非凸loss进行改进，主要想法是根据risk function对正类样本和未标记样本使用不同的loss function。 从另一个方面推导了risk function： $R(g) = \\pi E_1[ \\hat{l}(g(x))] + E_X[l(-g(x))]$，考虑当$\\hat{l}$为凸时，证明了其一定为线性函数，将hinge loss修改为double hinge loss，变为凸优化问题。通过实验说明其效果不比non-convex loss function差，同时减少了计算开销。  即loss需要满足$l(t,+1) + l(t,-1) = -t$，也就是linear-odd condition   同时，这篇文章用的分类器为linear-in-parameter model，使用高斯核将样本映射到feature space，具体定义可以参考 Introduction to Statistical Machine Learning By Masashi Sugiyama 2016 一书的Chapter21。 Code available 论文笔记   Positive-Unlabeled Learning with Non-Negative Risk Estimator NIPS 2017 （nnPU）  由于之前的risk estimator $\\hat{R}_{pu}(g) = \\pi_p\\hat{R}_p^+(g) -\\pi_p\\hat{R}_p^-(g) + \\hat{R}_u^-(g)$中，有可能出现$-\\pi_p\\hat{R}_p^-(g) + \\hat{R}_u^-(g) \u0026lt; 0 $的情况，会导致risk不断减小变为负数。因此对risk进行改写，提出nnPU，能有效的防止过拟合，能使用更强大的学习器（神经网络）进行学习。同时，论文对这个risk estimator的bias，consistency和MSE reduction进行了理论分析。 Code available   Learning from positive and unlabeled data with a selection bias ICLR 2019 （nnPUSB）  放松了SCAR的假设，认为如果$P(o = +1| x)$越高，则$P(y = +1| x)$也越高（不一定相同）。使用贝叶斯公式得到密度比和$P(y = +1|x)$满足同样的偏序关系，因此使用两种方法估计密度比（risk function/uLSIF），并设定阈值实现对PU的分类。 Code available / My implementation 论文笔记    Formula Risk 推导  定义在decision function $g$ 下的risk为：  $R(g) = E_{(X,Y)\\sim p(x,y)}[l(g(X),Y)] = \\pi_pR_p^+(g) + \\pi_nR_n^-(g)$ 其中$R_p^+(g) = E_p[l(g(X)),+1]$也就是对正类分类错误的risk，$R_n^-(g) = E_p[l(g(X)),-1]$也就是对负类分类错误的risk   由于我们没有办法直接得到负类样本，因此由公式 $\\pi_np_n(x) = p(x) - \\pi_pp_p(x)$可得负类样本分类错误的损失：   $\\pi R_n^-(g) = R_u^-(g) - \\pi_pR_p^-(g)$","title":"PU learning Overview"},{"content":"该论文在之前PU learning中使用非凸函数作为loss的基础上，对正类样本和未标记样本使用不同的凸函数loss，从而将其转为凸优化问题。结果表明，该loss（double hinge loss）与非凸loss（ramp）精度几乎一致，但大大减少了计算量。\nIntrodution Background 论文首先强调了PU问题的重要性，举了几个例子：\n Automatic face tagging  用户对自己的画像标记为正类，其余都是未标记数据，需要正确识别用户的照片   Inlier-based outlier detection  需要在只有inliers和未标记数据中识别outliers，这种方法比完全无监督学习的效果要好   Class is too diverse  如果要识别的数据集中类别太多，也就是one-vs-rest classification   Negative-class dataset shift  由于训练数据和测试数据采集的实践差异导致负类样本的概率分布发生了变化，那么如果使用PU learning，可以减少重新标记的代价    Method 作者简单回顾了之前PU learning的常见做法：\n 直接在正类样本和未标记样本中训练一个分类器。但很显然这样的效果非常差，因为未标记样本中包含两类数据。 根据先验$\\pi$使用一个loss function来权衡每个样本的权重，目标是使得loss function最小化。但这样做的结果是会产生bias。 使用满足$l(z) + l(-z) = 1$条件的loss function可以消除这种bias，但对于ramp loss，是非凸函数，导致在优化过程中可能求导局部解。  因此，本文提出了一种新的凸函数的loss function，也就是double hinge loss，不仅能够消除bias，同时也能保证凸性。关键点在于对未标记数据和正类数据使用不同的loss function。\nNon-convex PU classification 作者回顾了在 Analysis of Learning from Positive and Unlabeled Data 这篇文章中的方法。\n  首先，根据two-simple的假设，我们可以认为正类样本和未标记样本是在两个数据集上分别进行采样得到的：\n $x_i \\sim p(x|y = 1) \\quad x^{'}_i \\sim p(x)$ 对于未标记样本来说，边际概率可以表示为：$p(x) = \\pi p(x|y=1) + (1-\\pi ) p(x|y=-1)$ 目标是训练一个分类器$g(x)$    最佳的分类器是最小化01损失：\n $J_{0-1}(g) = \\pi E_1[l_{0-1}(g(X))] + (1-\\pi )E_{-1}[l_{0-1}(-g(X))] $ 其中loss function为 $l_{0-1}(z) = \\frac{1}{2}sign(z) + \\frac{1}{2}$    但由于我们的数据集没有负类样本，因此没有办法估计$E_{-1}$，所以可以将其转换为：\n  $J_{0-1}(g) = 2 \\pi E_1[l_{0-1}(g(X))] + E_{X}[l_{0-1}(-g(X))] -\\pi$\n  其中$E_X$是在$p(x)$上的期望：$E_X[l_{0-1}(-g(X))] = \\pi E_1[l_{0-1}(-g(X))] + (1-\\pi)E_{-1}[l_{0-1}(-g(X))]$\n  但是，对01损失函数进行优化是非常困难的，因为其梯度在除了0以外的地方都为0\n    因此，直觉的使用hinge loss作为替代，但是我们发现会多出来一个惩罚项，这样会导致估计的bias。而如果使用$l(z) + l(-z) = 1$这样的loss function，就不会有bias（使用凹函数ramp loss）\n  Convex PU classifiction   由于$l_{0-1}(-g(X)) = 1 - l_{0-1}(g(X))$，可以将损失函数改写为：\n $J_{0-1}(g) = \\pi E_1[l_{0-1}(g(X)) - l_{0-1}(-g(X))] + E_{X}[l_{0-1}(-g(X))]$    我们用另外的损失函数$l(z)$代替，则可以得到：\n  $J(g) = \\pi E_1[\\hat{l}(g(X))] + E_X[l(-g(X))]$\n  注意到，在正类样本上我们的损失是composite loss：$\\hat{l}(z) = l(z) - l(-z)$\n  在正类样本上使用composite loss，在未标记样本上使用普通的损失\n    因此，最关键的就是$\\hat{l}(z)$是不是凸函数，论文做了以下的证明：\n If the composite loss $\\hat{l}(z)$ is convex, it is linear.  为了简便，论文取了最简单的线性关系：$\\hat{l}(z) = -z$ 因此，损失函数变为：$J(g) = \\pi E_1[-g(X)] + E_X[l(-g(X))]$ 作者证明该损失函数表明learning with label noise实际上就是PU learning的特例   实际中，我们用linear-inparameter mode来进行分类：  $g(x) = \\alpha^T\\phi(x) + b$ 其中$\\phi(x) = [\\phi_1(x),\u0026hellip;.,\\phi_m(x)]^T$，也就是作用在所有样本上的基函数（作者建议使用高斯核）      基于composite loss是线性的假设，用均值代替期望，可以将loss function改写为：\n $\\hat{J}(\\alpha,b) = -\\frac{\\pi}{n}\\sum\\limits_{i=1}^n \\alpha^T\\phi(x_i) - \\pi b + \\frac{1}{n^{'}} \\sum\\limits_{j=1}^{n^{'}}l(-\\alpha^T\\phi(x_j^{'})-b) + \\frac{\\lambda}{2} \\alpha^T \\alpha$ 最后一项做正则项    根据观察我们发现，在原来的损失函数中：$J(g) = \\pi E_1[-g(X)] + E_X[l(-g(X))]$，这两项始终为正数；然而在我们的经验风险函数中，由于正则项的存在，前两项可能变为可能为负数，论文说在实际中需要限制这两项始终非负（这导致了后面nnPU的出现）\n  Convex loss functions for PU classiﬁcation 可以发现，我们最终的目标函数就只需要指定$l$就完成了，本节作者讨论了多种可能的凸函数作为loss。\n  Squared loss\n 论文使用了$l_S(z) = \\frac{1}{4}(z-1)^2$作为loss，可以将目标函数变为：  $J_S(g) = \\frac{1}{4}\\int g(x)^2p(x)dx -\\frac{1}{2}\\int g(x) [2\\pi p_1(x) - p(x)]dx +C $   同时，很巧妙的定义了在$x$给定的条件下，分类为1和分类为0的概率的差：  $r(x) = p(y=1|x) - p(y=-1|x) = [2\\pi p(x|y=1) - p(x)] / p(x)$ 积分后可以是不相关的常数，带入目标函数并化简可以得到（太赞了！）： $\\frac{1}{4}\\int (g(x) - \\frac{2\\pi p_1(x) - p(x)}{p(x)})^2 p(x)dx$   论文说这个目标函数的好处是可以直接从理论分析得到数值解，如果我们省略linear-inparameter mode中的常数$b$：  $\\hat{J}_S(\\alpha) = \\frac{1}{4n^{'}} \\alpha^T\\Phi^T_U \\Phi_U\\alpha + \\frac{1}{2n^{'}}1^T\\Phi_U \\alpha - \\frac{\\pi}{n}1^T\\Phi_P \\alpha + \\frac{\\lambda}{2}\\alpha^T \\alpha$ 对这个二次型函数求导即可得到$\\alpha$的数值解（牛啊。。）   但这个loss函数并不好，原因在于$l_S(z) = \\frac{1}{4}(z-1)^2$当$z$大于1时这个loss会增大，而对于二分类来说，如果大于1说明能正确识别。    logistic loss\n 定义Logistic loss为$l_{LL}(z) = \\log(1+\\exp(-z))$，因此带入目标函数为：  $J_{LL}(g) = -\\pi E_1[g(X)] + E_X[\\log(1+\\exp(g(X)))]$   有$\\log(1+\\exp(-z)) = -\\log \\frac{1}{1+e^{-z}} = -z + \\log(1+\\exp(z))$，带入原始的分类损失中，可以得到其和目标函数是一样的，因此可以用于PU classification 最终经验风险函数可以表示为：  $\\hat{J}{LL} (\\alpha,b) = -\\frac{\\pi}{n}\\sum\\limits{i=1}^n \\alpha^T \\phi(x_i) - \\pi b + \\frac{\\lambda}{2} \\alpha^T\\alpha + \\frac{1}{n^{'}}\\sum\\limits_{j=1}^{n^{'}} l_{LL}(-\\alpha^T\\phi(x^{'}_j) - b)$      Double hinge losses\n  由于hinge loss并不是凸函数，因此不满足我们的定理（$\\hat{l}$表示线性的）\n  论文构造了Double hinge losses使得满足凸函数的性质：\n  $l_{DH}(z) = \\max(-z,\\max (0,\\frac{1}{2} - \\frac{1}{2}z))$\n  因此经验风险函数可以写为：\n $\\hat{J}{LL} (\\alpha,b) = -\\frac{\\pi}{n}\\sum\\limits{i=1}^n \\alpha^T \\phi(x_i) - \\pi b + \\frac{\\lambda}{2} \\alpha^T\\alpha + \\frac{1}{n^{'}}\\sum\\limits_{j=1}^{n^{'}} l_{DH}(-\\alpha^T\\phi(x^{'}_j) - b)$      Theoretical Analysis 待看。。。\nExperiments 三组对比实验在MNIST数据集上进行实验，将0作为正类，其余作为负类，同时假设先验已知：\n Hinge损失（会有bias） Logistic 和 Double hinge loss Ramp （非凸优化）  实验结果说明，提出的凸优化结果与非凸优化效果相当，但减少了计算量。\n","permalink":"https://tech.zealscott.com/deeplearning/pulearning/npu/","summary":"该论文在之前PU learning中使用非凸函数作为loss的基础上，对正类样本和未标记样本使用不同的凸函数loss，从而将其转为凸优化问题。结果表明，该loss（double hinge loss）与非凸loss（ramp）精度几乎一致，但大大减少了计算量。\nIntrodution Background 论文首先强调了PU问题的重要性，举了几个例子：\n Automatic face tagging  用户对自己的画像标记为正类，其余都是未标记数据，需要正确识别用户的照片   Inlier-based outlier detection  需要在只有inliers和未标记数据中识别outliers，这种方法比完全无监督学习的效果要好   Class is too diverse  如果要识别的数据集中类别太多，也就是one-vs-rest classification   Negative-class dataset shift  由于训练数据和测试数据采集的实践差异导致负类样本的概率分布发生了变化，那么如果使用PU learning，可以减少重新标记的代价    Method 作者简单回顾了之前PU learning的常见做法：\n 直接在正类样本和未标记样本中训练一个分类器。但很显然这样的效果非常差，因为未标记样本中包含两类数据。 根据先验$\\pi$使用一个loss function来权衡每个样本的权重，目标是使得loss function最小化。但这样做的结果是会产生bias。 使用满足$l(z) + l(-z) = 1$条件的loss function可以消除这种bias，但对于ramp loss，是非凸函数，导致在优化过程中可能求导局部解。  因此，本文提出了一种新的凸函数的loss function，也就是double hinge loss，不仅能够消除bias，同时也能保证凸性。关键点在于对未标记数据和正类数据使用不同的loss function。\nNon-convex PU classification 作者回顾了在 Analysis of Learning from Positive and Unlabeled Data 这篇文章中的方法。","title":"Convex Formulation for Learning from Positive and Unlabeled Data"},{"content":"本文从基本的分类损失出发，推导了PU的分类问题其实就是Cost-sensitive classiﬁcation的形式，同时，通过实验证明了如果使用凸函数作为loss function，例如hinge loss会导致错误的分类边界（有bias），因此需要使用例如ramp loss之类的凹函数。同时，论文还对先验$\\pi$存在偏差的情况进行了讨论，说明了如果样本中大部分都是正样本，那么就算先验差距比较大，但对总体的分类效果没有太大影响。最后对分类边界进行讨论，证明了使用PU进行分类的误差小于监督学习误差的$2\\sqrt{2}$倍。\n基本概念和定义  Ordinary classification  Bayes optimal classiﬁer的目标是最小化misclassiﬁcation rate，这在Introduction to Statistical Machine Learning By Masashi Sugiyama 书里有定义，直观理解就是最小化期望错分率： $R(f) = \\pi R_1 (f) + (1 - \\pi) R_{-1}(f)$ 这里的$R_1$表示false negative rate，也就是分错正类的概率，乘以先验正类的概率$\\pi$ $R_{-1}$表示false positive rate，也就是分错负类的概率，乘以先验负类的概率$1-\\pi$ 这样，对分错样本的概率分别乘以其先验概率，就是其错分概率的期望。   Cost-sensitive classiﬁcation  如果对于某种错误我们的敏感程度不一样，那么就乘以不同的权重，重新定义为： $R(f) = \\pi c_1 R_1(f) + (1-\\pi) c_{-1}R_{-1}(f)$ 这里用$c_1$和$c_{-1}$分别表示对两种错分的代价   PU classification   定义在未标记数据集$X$ 中的分布：\n  $P_X = \\pi P_1 + (1-\\pi) P_{-1}$\n  注意，这里的$P_X$可以理解为样本的分布：\n$$P(x) = P(y=1)P(x|y=1) + P(y=-1)P(x|y=-1)$$\n  也就是说，$P_1 = P(x|y = 1), P_{-1} = P(x|y=-1)$\n  论文认为两个数据集的分布不同：\n 对于positive sample：$x \\sim P(x|y=1)$ 对于unlabel sample：$x\\sim P_X$      对于PU问题，我们没有办法直接得到负类的信息，因此我们想要把目标函数中的$R_{-1}(f)$去掉。定义$R_X(f)$表示在$P_X$分布下预测为正类的风险risk：\n$$\\begin{equation}\\begin{split}R_X(f) \u0026amp;= P_X(f(X = 1)) \\\u0026amp;= \\pi P_1(f(X) = 1) + (1-\\pi) P_{-1}(f(X) = 1) \\\u0026amp;= \\pi(1-R_1(f)) + (1-\\pi) R_{-1}(f) \\end{split}\\end{equation}$$\n  这样，我们就可以将$R_{-1}$替换为$R_X(f)$：\n$$\\begin{equation}\\begin{split}R(f) \u0026amp;= \\pi R_1(f) + (1-\\pi)R_{-1}(f) \\\u0026amp;= \\pi R_1(f) - \\pi(1-R_1(f)) + R_X(f) \\\u0026amp;= 2\\pi R_1(f) + R_X(f) - \\pi \\end{split}\\end{equation}$$\n  我们可以定义$\\eta \\sim \\frac{n}{n + n'}$是$P_1$与$P_X$的占比，也就是在我们正类数据集样本数占所有样本数的比例，因此可进一步写成：\n $R(f) = c_1\\eta R_1(f) + c_X(1-\\eta)R_X(f)- \\pi$ 其中$c_1 = \\frac{2\\pi}{\\eta},c_X = \\frac{1}{1-\\eta}$    这样，我们就把PU分类问题转换为了Cost-sensitive classiﬁcation问题。通过设置不同的阈值并最小化分类错误率，就可以使用SVM等分类器进行训练。\n    Necessity of non-convex loss functions 论文认为，如果在PU分类问题中使用常见的凸函数作为loss function，可能导致结果有biased，因此需要选择非凸函数。\n Loss functions in ordinary classiﬁcation  在分类器上定义一个符号函数：$sign (g(x)) = f(x)$ 使用01损失，仿照之前的期望错分率定义损失函数：  $J_{0-1}(g) = \\pi E_1[l_{0-1}(g(X))] + (1-\\pi )E_{-1}[l_{0-1}(-g(X))] $ $l_{0-1}$在大于0的时候取0，小于0时取1   由于01损失在实际中很难优化，因此用ramp loss代替：  $l_R(z) = \\frac{1}{2}\\max(0,\\min(2,1-z))$   而为了保证凸性，因此一般使用hinge loss：  $l_H(z) = \\frac{1}{2}\\max(1-z,0)$     可以发现，ramp loss 在大于1时没有损失，在-1到1之间为线性损失，而大于1以后损失恒定为1 而hinge loss在小于1时也依然为线性损失（在SVM中使用）   Ramp loss function in PU classiﬁcation  将ramp loss带入之前定义的PU目标函数中，同时根据ramp loss的特殊性质：$l_R(-z) +l_R(z) = 1$，我们可以得到 $J_{PU-R} (g) = \\pi E_1[l_R(g(X))] + (1-\\pi)E_{-1}[l_R(-g(X))]$ 这个形式和最初的分类损失相同，也就是说，它们会有相同的分类边界   Hinge loss function in PU classiﬁcation  如果用hinge loss，同样的道理我们可以得到：     除了最初分类损失的项，还有另外的一项惩罚 作者认为，这个惩罚会导致分类边界的改变，及时$g(X)$很好的区分了数据，由于惩罚项的存在，目标函数可能并不会是最小值   论文做了一个简单的实验，说明了如果使用hinge loss，那么在先验$\\pi$增大的情况下，阈值增大的非常快，也就是说，会将所有的样本都标记为正样本（阈值为1），因此false positive概率为1。这样会导致总的分类错误率为$1-\\pi$：      因此，作者用实验和公式说明了，光光最小化分类错误率不够（因为当$\\pi$很大时，会将所有类标记为正类以获得最小的损失$1- \\pi$，因此需要使用ramp loss对其进行惩罚  Effect of inaccurate class-prior estimation 现实中有很多方法来估计先验$\\pi$，但如果估计值离实际值很大（有偏），那么会对我们的PU问题造成什么样的影响？\n Ordinary classification  考虑普通分类的情形。我们的目标函数时最小化$R(f,\\pi) = \\pi R_1(f) + (1-\\pi) R_{-1}(f)$ 注意，这是一个凹函数。 如果我们的先验为$\\hat{\\pi}$，最小化后得到的分类器为$\\hat{f}$，这时候固定$\\hat{f}$，真实的先验为$\\pi$，可以发现当靠近$\\hat{\\pi}$时两个risk 的差距最小，随着$\\pi$的变化而逐渐增大：        PU classification  通过变量替换，我们同时定义当前的先验为$\\hat{\\pi}$，真实的先验为$\\pi$，可以得到risk为：  $R(f) = (2\\hat{\\pi} - \\pi) R_1(f) + (1-\\pi)R_{-1}(f) + \\pi - \\hat{\\pi}$   可以发现，如果 $\\hat{\\pi } \\le \\frac{1}{2}\\pi$ 时，该分类就完全失效了（risk 的符号改变） 将其进行归一化，定义effective class prior为：       观察图片可以发现，当真实的$\\pi$很大，那么估计的先验就算相差大一点，影响也不大（顶部较为平缓），这与现实相符。例如，如果我们在异常检测中，正类远远大于负类，那么估计的阈值稍微小优点，也不会对risk造成太大的改变。 同样，如果真实的正类并不多，那么对正类的估计如果不准的话，会对结果造成较大改变。    Generalization error bounds for PU classiﬁcation 待完成。。。\nReference  Analysis of Learning from Positive and Unlabeled Data Introduction to Statistical Machine Learning By Masashi Sugiyama Why are the popular loss functions convex?  ","permalink":"https://tech.zealscott.com/deeplearning/pulearning/pu-learning-non-convex/","summary":"本文从基本的分类损失出发，推导了PU的分类问题其实就是Cost-sensitive classiﬁcation的形式，同时，通过实验证明了如果使用凸函数作为loss function，例如hinge loss会导致错误的分类边界（有bias），因此需要使用例如ramp loss之类的凹函数。同时，论文还对先验$\\pi$存在偏差的情况进行了讨论，说明了如果样本中大部分都是正样本，那么就算先验差距比较大，但对总体的分类效果没有太大影响。最后对分类边界进行讨论，证明了使用PU进行分类的误差小于监督学习误差的$2\\sqrt{2}$倍。\n基本概念和定义  Ordinary classification  Bayes optimal classiﬁer的目标是最小化misclassiﬁcation rate，这在Introduction to Statistical Machine Learning By Masashi Sugiyama 书里有定义，直观理解就是最小化期望错分率： $R(f) = \\pi R_1 (f) + (1 - \\pi) R_{-1}(f)$ 这里的$R_1$表示false negative rate，也就是分错正类的概率，乘以先验正类的概率$\\pi$ $R_{-1}$表示false positive rate，也就是分错负类的概率，乘以先验负类的概率$1-\\pi$ 这样，对分错样本的概率分别乘以其先验概率，就是其错分概率的期望。   Cost-sensitive classiﬁcation  如果对于某种错误我们的敏感程度不一样，那么就乘以不同的权重，重新定义为： $R(f) = \\pi c_1 R_1(f) + (1-\\pi) c_{-1}R_{-1}(f)$ 这里用$c_1$和$c_{-1}$分别表示对两种错分的代价   PU classification   定义在未标记数据集$X$ 中的分布：\n  $P_X = \\pi P_1 + (1-\\pi) P_{-1}$","title":"Analysis of Learning from Positive and Unlabeled Data"},{"content":"本文主要考虑在SCAR假设下，证明了普通的分类器和PU分类器只相差一个常数，因此可以使用普通分类器的方法来估计$p(s|x)$，进而得到$p(y|x)$。同时提供了三种方法来估计这个常数，最后，还对先验$p(y)$的估计提供了思路。\nLearning a traditional classifier   概念定义\n $x$ 表示一个样本，$y$ 表示其label（0或者1），$s$表示是否被select 那么，在PU问题中，当$s =1 $时，一定有$y = 1$ $P(s = 1| x,y=0) = 0 $ 一定成立    两种采样假设\n signle-training-set  所有的样本都是从$(x,y,s)$这个三元组的分布中采样的   case-control  两个数据集（正类，未标记）是从三元组中独立的抽样出来的。当采样正类时被称为case，采样未标记数据时称为contaminated controls   这两种假设有很明显的区别。总的来说，第一种假设比第二种假设要严格得多，也就能提供更多的信息：  两种假设都能让我们估计$p(x)$ 但只有在第一种假设下，能够让我们很容易的估计出$p(s = 1)$，因此也更容易估计出$p(y = 1)$，二第二种条件不可以。      基本假设\n 我们需要训练的传统分类器是：$f(x) = p(y = 1|x)$ 然而，对正类数据没有任何假设的前提下，我们很难得到较好的分类器 因此，论文给出的假设是，正类样本数据是从正类数据中完全随机的抽取出来的。  也就是说，当$y = 1$时，无论$x$取说明值，它们的概率都是相同的：  $p(s = 1| x,y=1) = p(s =1|y=1)$   这个假设被称为selected completedly at random   我们定义一个nontraditional classifier：$g(x) = p(s =1|x)$ 因此，我们需要一些定理来证明如何将非传统的分类器转化为传统的分类器    Lemma：假设SCAR条件成立，那么$p(y = 1|x) = \\frac{p(s=1|x)}{c}$，其中$c = p(s=1|y=1)$\n  证明：由于我们的假设是：$p(s = 1| x,y=1) = p(s =1|y=1)$，因此：\n  $$\\begin{aligned}p(s=1 | x) \u0026amp;=p(y=1 \\wedge s=1 | x) \\\n\u0026amp;=p(y=1 | x) p(s=1 | y=1, x) \\\n\u0026amp;=p(y=1 | x) p(s=1 | y=1) \\end{aligned}$$\n      将我们的分类器带入为：$f(x) = \\frac{g(x)}{p(s=1|y=1)}$\n  这里可以得到几个结论：\n $f$是$g$的单调递增函数，因此，如果我们只需要对$x$进行rank排序，那么直接可以用$g$代替$f$ $g \\le p(s=1|y=1)$恒成立。这也是很显然的，同时，我们可以定义$c = p(s=1|y=1)$为一个常数。     如何来估计$c$呢？一般采用交叉验证，设交叉验证集合为$P$\n  第一种方式是直接在正类数据集中进行抽样\n 令$P$是未标记数据集$V$的一个子集，且全是正类，因此，我们可以估计$c = p(s=1|y=1)$为$e_1$ $e_1 = \\frac{1}{n}\\sum_{x\\in P} g(x) = \\frac{1}{n}\\sum_{x\\in P} p(s=1|y=1)$ 也就是用均值来估计概率（证明很容易，见论文）    第二种方式是在两个样本集中分别进行抽样\n  $e_2 =\\sum_{x\\in P} g(x) /\\sum_{x\\in V} g(x)$\n  这个估计其实和$e_1$基本相同，这是因为：$E(\\sum_{x\\in V}g(x)) = p(s=1)m = E[n|m]$\n  其中$m$是$V$的数量，$n$是$P$的数量\n    第三种方式是根据$g \\le p(s=1|y=1)$的结论，估计$e_3 = \\max_{x\\in V}g(x)$\n    那么，这三种估计方式哪一个更好呢？\n 显然，如果我们的分类器能做到$g(x) = p(s =1|x)$，那么第一种估计一定是正确的，但现实中分类器是从一个有限的训练集中进行学习的，同时，模型的选择也是近似； 但比较其他两种方式，第一种估计的方式的方差更小    Weighting unlabeled 论文中对于$h(x,y)$函数进行估计，得到结论：对于在正类中每个样本的权重是1，而在未标记中，正类的权重是$w$，负类的权重是$1-w$\n 我们已经可以估计$c$了，那么希望将尽可能多的概率转为我们已知的估计：  $p(y=1|x,s=0) = \\frac{1-c}{c} \\frac{p(s=1|x)}{1-p(s=1|x)}$ 很显然，$p(y=1|x,s=1)=1$恒成立   因此，对于任意函数$E[h]$的估计为：  $\\frac{1}{m} (\\sum\\limits_{x,s=1}h(x,1) + \\sum\\limits_{x,s=0}w(x)h(x,1) + (1-w(x))h(x,0))$ 其中权重$w = p(y=1|x,s=0)$ 观察该式我们可以发现，在$h$的估计中，在正类中的每个样本权重为1，而在未标记中，正类的权重是$w$，负类的权重是$1-w$   因此，我们可以改写$h$使得变为一个learning algorithm，有两种思路，一种是直接对$h$进行估计，然后再用以上的式子取平均；第二种方式是在估计时就根据以上的式子对不同的样本取不同的权重 考虑一种特殊的情况：$h(x,y) = y$，也就是对$p(y)$ 进行估计，那么很显然：  $E[y] = p(y =1) = \\frac{1}{m}(n + \\sum\\limits_{x,s=0} w(x))$   另外一种估计$p(y) =1$的方法是直接用我们之前的公式：  $c = \\frac{p(s=1 \\wedge y=1)}{p(y=1)}, \\hat{c} = \\frac{1}{n}\\sum_{x\\in P} g(x), p(s=1 \\wedge y=1) = \\frac{n}{m}$ 因此可以得到估计值为：$\\frac{n^2}{m \\sum_{x\\in P}g(x)}$    Experiment 作者自己收集了SwissProt数据集，符合case-control的假设\n U：是未标记数据集  Q：未标记数据集中的正类 N：未标记数据集中的负类   P：是正类数据集  论文中做了如下的对比实验：\n 标准的分类问题（P+Q vs N），分类阈值为0.5  使用libSVM进行训练   在PU问题中先学习分类器，然后再重新调整权重（P vs U），分类阈值为0.5c  使用Platt scaling得到概率输出$p(s=1|x)$，根据分类阈值进行分类（需要对c进行估计）   先对未标记数据调整权重，再学习分类器（P vs U），分类阈值为0.5  首先用Platt scaling得到概率估计，并转为权重：  $w = p(y=1|x,s=0) = \\frac{1-c}{c} \\frac{p(s=1|x)}{1-p(s=1|x)}$   再对每个样本赋予不同的权重（需要对c进行估计），重新使用libSVM进行训练   使用biased SVM进行学习，分类阈值为0  对不同的样本设置不同的权重，重复训练多次，每次用70%作为训练，20%作为验证，得到最好的参数后再对90%的所有训练数据进行训练（10%是test data）    Related work 主要有两种方法处理PU问题\n 首先用某些启发式方法看未标记中的数据哪些是负类，然后再用常见的分类方法进行学习 对未标记数据的每个样本设置不同的权重（表示是负类的可能性大小），然后将未标记数据看作是加权的负样本数据，再进行训练 第三种方法与论文中的方法类似  首先将未标记数据看成是正类样本和负类样本的加权 提供一种计算权重的方式，同时，对于不同的样本，权重也不一样    其中第一种方法可以看成是第二种方法的特例，因为权重可以取1或者0\nBiased SVM 优化目标函数：\n$$\\min \\frac{1}{2} ||w||^2 + C_P\\sum_{i\\in P} z_i + C_U\\sum_{i\\in U} z_i$$\n$$s.t. \\quad y_i(wx+b) \\ge 1-z_i$$\n同时，$C_P$一般来说惩罚要比$C_U$大\nSummary 这篇文章最重要的地方是证明了$p(y = 1|x) = \\frac{p(s=1|x)}{c}$。在PU问题中，我们很容易使用常见的分类器得到输出概率$p(s|x)$，这样通过估计常数c（直接取概率的均值），我们就能得到普通的二分类器。\n另外一种方法是，得到输出概率$p(s|x)$后，再根据公式$w = p(y=1|x,s=0) = \\frac{1-c}{c} \\frac{p(s=1|x)}{1-p(s=1|x)}$转换为权重，对每个样本分配不同的权重再进行训练。\nReference  Learning Classiﬁers from Only Positive and Unlabeled Data SwissProt records dataset Platt scaling  ","permalink":"https://tech.zealscott.com/deeplearning/pulearning/pu-learning/","summary":"本文主要考虑在SCAR假设下，证明了普通的分类器和PU分类器只相差一个常数，因此可以使用普通分类器的方法来估计$p(s|x)$，进而得到$p(y|x)$。同时提供了三种方法来估计这个常数，最后，还对先验$p(y)$的估计提供了思路。\nLearning a traditional classifier   概念定义\n $x$ 表示一个样本，$y$ 表示其label（0或者1），$s$表示是否被select 那么，在PU问题中，当$s =1 $时，一定有$y = 1$ $P(s = 1| x,y=0) = 0 $ 一定成立    两种采样假设\n signle-training-set  所有的样本都是从$(x,y,s)$这个三元组的分布中采样的   case-control  两个数据集（正类，未标记）是从三元组中独立的抽样出来的。当采样正类时被称为case，采样未标记数据时称为contaminated controls   这两种假设有很明显的区别。总的来说，第一种假设比第二种假设要严格得多，也就能提供更多的信息：  两种假设都能让我们估计$p(x)$ 但只有在第一种假设下，能够让我们很容易的估计出$p(s = 1)$，因此也更容易估计出$p(y = 1)$，二第二种条件不可以。      基本假设\n 我们需要训练的传统分类器是：$f(x) = p(y = 1|x)$ 然而，对正类数据没有任何假设的前提下，我们很难得到较好的分类器 因此，论文给出的假设是，正类样本数据是从正类数据中完全随机的抽取出来的。  也就是说，当$y = 1$时，无论$x$取说明值，它们的概率都是相同的：  $p(s = 1| x,y=1) = p(s =1|y=1)$   这个假设被称为selected completedly at random   我们定义一个nontraditional classifier：$g(x) = p(s =1|x)$ 因此，我们需要一些定理来证明如何将非传统的分类器转化为传统的分类器    Lemma：假设SCAR条件成立，那么$p(y = 1|x) = \\frac{p(s=1|x)}{c}$，其中$c = p(s=1|y=1)$","title":"Learning Classiﬁers from Only Positive and Unlabeled Data"},{"content":"本文以Windows系统为例，介绍ThingWorx的安装步骤。\nH2版 安装  从PTC官网下载合适版本的Thingworx（h2版） 访问Tomcat 网站下载32-bit/64-bit Windows 服务安装程序。 下载JDK8以上的版本。  注意，H2为内嵌数据库，并不需要安装。\n部署 Tomcat   在“HTTP/1.1 连接器端口” 字段，键入“80” (或其他可用端口)，其余默认设置安装\n  启动Tomcat，在“Java 选项”字段中，将以下内容添加至选项字段的末尾：\n  1 2 3 4  -Dserver -Dd64 -XX:+UseG1GC -Dfile.encoding=UTF-8 -Djava.library.path=\u0026lt;path to Tomcat\u0026gt;\\webapps\\Thingworx\\WEB-INF\\extensions       清除Initial memory pool 和 Maximum memory pool字段中的任意值。\n  在Tomcat 的安装位置，打开CATALINA_HOME/conf/web.xml。通过将以下内容添加至web.xml 文件来替换默认错误页面。将以下内容置于web-app 标记内(在welcome-list 标记后)\n  1 2 3 4  \u0026lt;error-page\u0026gt; \u0026lt;exception-type\u0026gt;java.lang.Throwable\u0026lt;/exception-type\u0026gt; \u0026lt;location\u0026gt;/error.jsp\u0026lt;/location\u0026gt; \u0026lt;/error-page\u0026gt;       要增加影响静态文件缓存的默认缓存设置，请在$CATALINA_HOME/conf/context.xml 文件中的\u0026lt;context\u0026gt;\u0026lt;/context\u0026gt; 标记内添加以下行：\n  1  \u0026lt;Resources cacheMaxSize=\u0026#34;501200\u0026#34; cacheObjectMaxSize=\u0026#34;2048\u0026#34; cacheTtl=\u0026#34;60000\u0026#34;/\u0026gt;       配置Thingworx   将压缩文件中的Thingworx.war文件放置在Tomcat中的webapps文件夹中。\n  将platform-settings.json 放置在C:/ThingworxPlatform 文件夹中（没有则创建）。\n  启用扩展导入\n  将以下内容添加至platform-settings.json 文件\n  1 2 3 4 5 6 7 8 9 10  \u0026#34;ExtensionPackageImportPolicy\u0026#34;: { \u0026#34;importEnabled\u0026#34;: \u0026lt;true or false\u0026gt;, \u0026#34;allowJarResources\u0026#34;: \u0026lt;true or false\u0026gt;, \u0026#34;allowJavascriptResources\u0026#34;: \u0026lt;true or false\u0026gt;, \u0026#34;allowCSSResources\u0026#34;: \u0026lt;true or false\u0026gt;, \u0026#34;allowJSONResources\u0026#34;: \u0026lt;true or false\u0026gt;, \u0026#34;allowWebAppResources\u0026#34;: \u0026lt;true or false\u0026gt;, \u0026#34;allowEntities\u0026#34;: \u0026lt;true or false\u0026gt;, \u0026#34;allowExtensibleEntities\u0026#34;: \u0026lt;true or false\u0026gt; },       使用h2数据库\n  1 2 3 4 5 6 7 8  \u0026#34;PersistenceProviderPackageConfigs\u0026#34;:{ \u0026#34;H2PersistenceProviderPackage\u0026#34;:{ \u0026#34;ConnectionInformation\u0026#34;:{ \u0026#34;password\u0026#34;: \u0026#34;\u0026lt;addsecurepassword\u0026gt;\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;twadmin\u0026#34; } }\t},       从官网得到license.bin文件，并放入C:\\ThingworxPlatform中。\n  PostgreSQL版 安装  从官网进行下载合适的PostgreSQL版本，我这里下载的9.6.14 x64版。 从PTC官网下载合适版本的Thingworx（PostgreSQL版） 安装后打开pgAdmin，新建用户，并设置密码。  配置  默认情况下，PostgreSQL服务器是在locked-down state。为了让ThingWorx与PostgreSQL服务器连接，需要pg监听其他用户的连接。 在Windows平台下，找到PostgreSQL的data目录，默认为C:\\Program Files\\ PostgreSQL\\9.x\\data，在pg_hba.conf配置文件中，进行修改：  允许所有IPv4地址进行连接：hostallall0.0.0.0/0md5 允许所有IPv6地址进行连接：hostallall::0/0md5    执行脚thingworxPostgresDBSetup.bat时，将第10行改为全称，例如C:/ThingworxPostgresqlStorage\n  执行Thingworx脚本\n thingworxPostgresDBSetup.bat thingworxPostgresSchemaSetup.bat    同样，将Thingworx.war文件放置在Tomcat中的webapps文件夹中。\n  在platform-settings.json使用PostgreSQL数据库\n  1 2 3 4 5 6 7 8 9  \u0026#34;PersistenceProviderPackageConfigs\u0026#34;: { \u0026#34;PostgresPersistenceProviderPackage\u0026#34;: { \u0026#34;ConnectionInformation\u0026#34;: { \u0026#34;jdbcUrl\u0026#34;: \u0026#34;jdbc:postgresql://localhost:5432/thingworx\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;password\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;twadmin\u0026#34; } } }       登录系统  浏览器端输入http://localhost/Thingworx，进入系统。 首次登录，用户名为Administrator，密码为platform-settings.json中的初始密码。 若在tomcat中的log中看见SecurityManager错误，则可以参考这里。  修改密码  在Composer 中，选择“管理员”\u0026gt;“更改密码”。 在“更改密码”窗口中，输入“当前密码”、“新密码”以及“确认密码”。 删除plateform-settings.json 文件中的初始密码。 在Composer 中打开“监控”\u0026gt;“子系统”\u0026gt; “许可子系统设置”来确认许可中包括的功能列表(获得许可的实体)。  ","permalink":"https://tech.zealscott.com/misc/thingworx-installation/","summary":"本文以Windows系统为例，介绍ThingWorx的安装步骤。\nH2版 安装  从PTC官网下载合适版本的Thingworx（h2版） 访问Tomcat 网站下载32-bit/64-bit Windows 服务安装程序。 下载JDK8以上的版本。  注意，H2为内嵌数据库，并不需要安装。\n部署 Tomcat   在“HTTP/1.1 连接器端口” 字段，键入“80” (或其他可用端口)，其余默认设置安装\n  启动Tomcat，在“Java 选项”字段中，将以下内容添加至选项字段的末尾：\n  1 2 3 4  -Dserver -Dd64 -XX:+UseG1GC -Dfile.encoding=UTF-8 -Djava.library.path=\u0026lt;path to Tomcat\u0026gt;\\webapps\\Thingworx\\WEB-INF\\extensions       清除Initial memory pool 和 Maximum memory pool字段中的任意值。\n  在Tomcat 的安装位置，打开CATALINA_HOME/conf/web.xml。通过将以下内容添加至web.xml 文件来替换默认错误页面。将以下内容置于web-app 标记内(在welcome-list 标记后)\n  1 2 3 4  \u0026lt;error-page\u0026gt; \u0026lt;exception-type\u0026gt;java.lang.Throwable\u0026lt;/exception-type\u0026gt; \u0026lt;location\u0026gt;/error.jsp\u0026lt;/location\u0026gt; \u0026lt;/error-page\u0026gt;       要增加影响静态文件缓存的默认缓存设置，请在$CATALINA_HOME/conf/context.","title":"ThingWorx 安装及部署"},{"content":"基本思想 NLP中有很多sequence to sequence的问题，例如机器翻译，人机对话等等。对于句子而言，我们已经有RNN能够很好的处理序列之间的关系，但同时，RNN只能被用于输入和输出的维度都固定且已知的情况。但很多情况下，我们没办法确定输出序列的长度和维度。因此，为了处理这种general的序列问题，Seq2Seq框架被提出来了。\n流程 最基本的Seq2Seq框架主要的流程是：\n 用一个LSTM来处理input的sequence，得到一个特定维度的向量表示，我们可以认为这个向量能很好的捕捉input中的相互关系。  每一个timestep，cell将当前词的embedding向量和上一个hidden state进行concat作为输入，输出当前timestep的hidden state作为下一个cell的输入，依次进行，直到sentence的EOS标志符，得到最终的vector representation作为decoder的最初hidden state输入。   用另一个LSTM，将这个vector representation映射成target sequence。每个timestep输出一个目标单词，直到输出EOS为止。  接受来自上一个timestep的hidden state输入（最开始为vector representation），与上一个timestep的output进行concat作为当前timestep的输入，依次进行，直到最终生成的单词为EOS。    缺点  Encoder将输入编码为固定大小状态向量的过程实际上是一个信息有损压缩的过程，如果信息量越大，那么这个转化向量的过程对信息的损失就越大。 随着sequence length的增加，意味着时间维度上的序列很长，RNN模型也会出现梯度弥散，无法让Decoder关注时间间隔非常长的关联，精度下降。  Attention  在普通的seq2seq模型中，我们输出的条件概率可以表示为：  $p(y_t| {y_1,..,y_{t-1}},c)=g(y_{t-1},s_t,c) $ 其中$s_t$表示$t$时刻的hidden state，$c$表示我们从Encoder学到的context vector，$g$表示非线性映射   而在attention based seq2seq中，条件概率可以表示为：  $p(y_i|y_1,\u0026hellip;,y_{i-1},x) = g(y_{i-1},s_i,c_i)$ hidden state表示为：$s_i = f(s_{i-1},y_{i-1},c_i)$ 也就是说，这里的每个单词$y_i$的条件概率都由不同的$c_i$决定，而不仅仅依赖于同一个$c$   在Decoder中，对每个timestep，Input是上一个timestep的输出与特定的 $c_i$ (context vector)进行Attention后的结果，而hidden state和普通的seq2seq一样，为上一个timestep输出的hidden state  实现Attention的方式有很多，例如直接点积，先concat后再进行线性变换等等。   那么，现在关键的问题是，每一个$c_i$到底是如何计算的？  论文中将Encoder的BiRNN产生的同一个timestep中两个hidden state进行concat组成一个annotations：$(h_1,\u0026hellip;,h_{T_x})$，可以认为，每一个$h_i$都包含了在一个sequence中主要focus于第$i$个单词周围的相互关系 因此，我们使用这种学习到的关系在不同的位置赋予不同的权重，来组成我们的context vector $c_i$：  $c_i = \\sum\\limits_{j=1}^{T_x} \\alpha_{ij}h_j$   每一个$\\alpha_{ij}$是通过annotations $h_i$ 与上一个hidden state 计算出来，然后进入softmax函数得到当前位置的权重：  $\\alpha_{ij} = \\frac{\\exp(e_{ij})}{\\sum_{k=1}^{T_x} \\exp(e_{ik})}$   这里的每一个$e_{ij}$衡量了在input的$j$位置和output的$i$位置的匹配程度，也就是论文中提到的alignment model，是由RNN前一个timestep的hidden state $s_{i-1}$和input的$h_j$计算出来的：  $e_{ij} = a(s_{i-1},h_j)$ 这里的$a$是一个简单的前向网络      流程 Encoder：\n 与基本的Seq2Seq类似，用RNN/LSTM/GRU 来捕获序列间的相互关系，在论文中使用了BiRNN，因此同一个位置有两个hidden state，将其concat作为annotation：$h_j = [\\overrightarrow{h_j^T};\\overleftarrow{h_j^T}]^T$。  Decoder\n 对每个timestep，Input是上一个timestep的输入与特定的 $c_i$ (context vector)进行Attention后的结果，而hidden state和普通的seq2seq一样，为上一个timestep输出的hidden state  Attention的方式有很多，例如直接点积，先concat后再进行线性变化等等。   每一个 $c_i = \\sum\\limits_{j=1}^{T_x} \\alpha_{ij}h_j$ ，是用Encoder的所有的annotaion进行加权求和得到的。根据权重$\\alpha_{ij}$不同，也就体现了在不同位置，网络的注意力focus不同。 而每一个权重$\\alpha_{ij}$，是将上一个timestep的hidden state $s_{i-1}$和 $j$ 位置的annotation $h_j$ 放入一个简单的前馈神经网络中学习得到$e_{ij}$，再通过softmax转换为概率得到的：  $\\alpha_{ij} = \\frac{\\exp(e_{ij})}{\\sum_{k=1}^{T_x} \\exp(e_{ik})}$    本质   目标句子生成的每个单词对应输入句子单词的概率分布可以理解为**输入句子单词和这个目标生成单词的对齐概率，**这在机器翻译语境下是非常直观的：传统的统计机器翻译一般在做的过程中会专门有一个短语对齐的步骤，而注意力模型其实起的是相同的作用。\n 将Source中的构成元素想象成是由一系列的(Key,Value)数据对构成，此时给定Target中的某个元素Query，通过计算Query和各个Key的相关性，得到每个Key对应Value的权重系数，然后对Value进行加权求和，即得到了最终的Attention数值。\n   **所以本质上Attention机制是对Source中元素的Value值进行加权求和，而Query和Key用来计算对应Value的权重系数。**即可以将其本质思想改写为如下公式：\n      在这里，Value可以理解为 $h_1,\u0026hellip;h_{T_x}$，Query认为是 $s_{i-1}$，Key 同样是 $h_1,\u0026hellip;h_{T_x}$\n  实践 Encoder 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  class EncoderRNN(nn.Module): def __init__(self, input_size, hidden_size): super(EncoderRNN, self).__init__() self.hidden_size = hidden_size self.embedding = nn.Embedding(input_size, hidden_size) self.gru = nn.GRU(hidden_size, hidden_size) def forward(self, input, hidden): embedded = self.embedding(input).view(1, 1, -1) output = embedded output, hidden = self.gru(output, hidden) return output, hidden def initHidden(self): return torch.zeros(1, 1, self.hidden_size, device=device)   Decoder 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  class DecoderRNN(nn.Module): def __init__(self, hidden_size, output_size): super(DecoderRNN, self).__init__() self.hidden_size = hidden_size self.embedding = nn.Embedding(output_size, hidden_size) self.gru = nn.GRU(hidden_size, hidden_size) self.out = nn.Linear(hidden_size, output_size) self.softmax = nn.LogSoftmax(dim=1) def forward(self, input, hidden): output = self.embedding(input).view(1, 1, -1) output = F.relu(output) output, hidden = self.gru(output, hidden) output = self.softmax(self.out(output[0])) return output, hidden def initHidden(self): return torch.zeros(1, 1, self.hidden_size, device=device)   Attention 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  class AttnDecoderRNN(nn.Module): def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH): super(AttnDecoderRNN, self).__init__() self.hidden_size = hidden_size self.output_size = output_size self.dropout_p = dropout_p self.max_length = max_length self.embedding = nn.Embedding(self.output_size, self.hidden_size) self.attn = nn.Linear(self.hidden_size * 2, self.max_length) self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size) self.dropout = nn.Dropout(self.dropout_p) self.gru = nn.GRU(self.hidden_size, self.hidden_size) self.out = nn.Linear(self.hidden_size, self.output_size) def forward(self, input, hidden, encoder_outputs): embedded = self.embedding(input).view(1, 1, -1) embedded = self.dropout(embedded) attn_weights = F.softmax( self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1) attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0)) output = torch.cat((embedded[0], attn_applied[0]), 1) output = self.attn_combine(output).unsqueeze(0) output = F.relu(output) output, hidden = self.gru(output, hidden) output = F.log_softmax(self.out(output[0]), dim=1) return output, hidden, attn_weights def initHidden(self): return torch.zeros(1, 1, self.hidden_size, device=device)   参考资料  Sequence to Sequence Learning with Neural Networks Neural Machine Translation by Jointly Learning to Align and Translate Translate with seq2seq network and attention(pytorch)  ","permalink":"https://tech.zealscott.com/deeplearning/models/seq2seq/","summary":"基本思想 NLP中有很多sequence to sequence的问题，例如机器翻译，人机对话等等。对于句子而言，我们已经有RNN能够很好的处理序列之间的关系，但同时，RNN只能被用于输入和输出的维度都固定且已知的情况。但很多情况下，我们没办法确定输出序列的长度和维度。因此，为了处理这种general的序列问题，Seq2Seq框架被提出来了。\n流程 最基本的Seq2Seq框架主要的流程是：\n 用一个LSTM来处理input的sequence，得到一个特定维度的向量表示，我们可以认为这个向量能很好的捕捉input中的相互关系。  每一个timestep，cell将当前词的embedding向量和上一个hidden state进行concat作为输入，输出当前timestep的hidden state作为下一个cell的输入，依次进行，直到sentence的EOS标志符，得到最终的vector representation作为decoder的最初hidden state输入。   用另一个LSTM，将这个vector representation映射成target sequence。每个timestep输出一个目标单词，直到输出EOS为止。  接受来自上一个timestep的hidden state输入（最开始为vector representation），与上一个timestep的output进行concat作为当前timestep的输入，依次进行，直到最终生成的单词为EOS。    缺点  Encoder将输入编码为固定大小状态向量的过程实际上是一个信息有损压缩的过程，如果信息量越大，那么这个转化向量的过程对信息的损失就越大。 随着sequence length的增加，意味着时间维度上的序列很长，RNN模型也会出现梯度弥散，无法让Decoder关注时间间隔非常长的关联，精度下降。  Attention  在普通的seq2seq模型中，我们输出的条件概率可以表示为：  $p(y_t| {y_1,..,y_{t-1}},c)=g(y_{t-1},s_t,c) $ 其中$s_t$表示$t$时刻的hidden state，$c$表示我们从Encoder学到的context vector，$g$表示非线性映射   而在attention based seq2seq中，条件概率可以表示为：  $p(y_i|y_1,\u0026hellip;,y_{i-1},x) = g(y_{i-1},s_i,c_i)$ hidden state表示为：$s_i = f(s_{i-1},y_{i-1},c_i)$ 也就是说，这里的每个单词$y_i$的条件概率都由不同的$c_i$决定，而不仅仅依赖于同一个$c$   在Decoder中，对每个timestep，Input是上一个timestep的输出与特定的 $c_i$ (context vector)进行Attention后的结果，而hidden state和普通的seq2seq一样，为上一个timestep输出的hidden state  实现Attention的方式有很多，例如直接点积，先concat后再进行线性变换等等。   那么，现在关键的问题是，每一个$c_i$到底是如何计算的？  论文中将Encoder的BiRNN产生的同一个timestep中两个hidden state进行concat组成一个annotations：$(h_1,\u0026hellip;,h_{T_x})$，可以认为，每一个$h_i$都包含了在一个sequence中主要focus于第$i$个单词周围的相互关系 因此，我们使用这种学习到的关系在不同的位置赋予不同的权重，来组成我们的context vector $c_i$：  $c_i = \\sum\\limits_{j=1}^{T_x} \\alpha_{ij}h_j$   每一个$\\alpha_{ij}$是通过annotations $h_i$ 与上一个hidden state 计算出来，然后进入softmax函数得到当前位置的权重：  $\\alpha_{ij} = \\frac{\\exp(e_{ij})}{\\sum_{k=1}^{T_x} \\exp(e_{ik})}$   这里的每一个$e_{ij}$衡量了在input的$j$位置和output的$i$位置的匹配程度，也就是论文中提到的alignment model，是由RNN前一个timestep的hidden state $s_{i-1}$和input的$h_j$计算出来的：  $e_{ij} = a(s_{i-1},h_j)$ 这里的$a$是一个简单的前向网络      流程 Encoder：","title":"Seq2Seq 理解"},{"content":"卷积 定义 卷积是一种数学运算，称$(f*g)(n)$为$f,g$的卷积，\n其连续的定义为：\n$$(f*g)(n) = \\int_{-\\infty}^{+\\infty} f(\\tau)g(n-\\tau)d\\tau$$\n离散的定义为：\n$$(f*g)(n) = \\sum\\limits_{\\tau = -\\infty}^\\infty f(\\tau)g(n-\\tau)$$\n若令$x = \\tau,y = n-\\tau$，则$x+y = n$表示的是平行的直线。\n对于图像来说，图像上的滑动窗口很好的解释了卷积的定义：\n可以发现，我们对$f,g$进行卷积操作，保证$x,y$坐标的和都为1：\n写成卷积公式为：\n$$(f*g)(1,1) = \\sum\\limits_{k=0}^{2}\\sum\\limits_{h=0}^{2}f(h,k)g(1-h,1-k)$$\n这样就实现了使用$g$这个算子在图像上的滑动。但注意，在数学中的卷积运算中，卷积核与原始的矩阵乘积，是围绕着中心元素进行180度旋转后，才是对应的元素。\n而在实际的图像空间滤波中，我们是将设计的特定卷积核，然后将其与像素矩阵的对应元素（不进行上述的旋转）相乘得到。例如，在CV中常见的平滑滤波，高斯滤波。这些滤波被设计出来，以提取不同的特征。\n..对于神经网络来讲，最大的不同是，这些滤波不需要我们自己去定义（也就是提取特征的过程），而是通过网络自身训练每一个卷积层的滤波器..。让这些滤波器组对特定的模式有高的激活，以达到CNN网络的分类/检测等目的。因此，在CNN中，由于这些卷积核都是未知参数，需要根据数据训练学习，那么翻不翻转已经没有关系了。\n理解 对于离散卷积来说，本质上就是一种加权求和。CNN中的卷积本质上就是利用一个共享参数的过滤器（kernel），通过计算中心像素点以及相邻像素点的加权和来构成feature map实现空间特征的提取，当然加权系数就是卷积核的权重系数。\n那么卷积核的系数如何确定的呢？是随机化初值，然后根据误差函数通过反向传播梯度下降进行迭代优化。这是一个关键点，卷积核的参数通过优化求出才能实现特征提取的作用，GCN的理论很大一部分工作就是为了引入可以优化的卷积参数。\nLaplacian matrix 我们上离散数学都学过，图拉普拉斯矩阵的定义为：\n$$L = D -W$$\n其中，$D$ 是顶点的度矩阵（对角矩阵），$W$是图的邻接矩阵（带边权重）。其normalized形式为：\n$$L^{nor} = D^{-\\frac{1}{2}}LD^{-\\frac{1}{2}}$$\n但为什么是这样定义呢？我们先从拉普拉斯算子说起。\nLaplacian 其数学定义为：\n$$\\Delta = \\sum\\limits_i \\frac{\\delta^2}{\\delta x_i^2}$$\n即为非混合二阶偏导数的和。\n图像中的拉普拉斯算子 图像是一种离散数据，那么其拉普拉斯算子必然要进行离散化。\n从导数定义：\n$$f'(x) = \\frac{\\delta f(x)}{\\delta x} \\approx f(x+1) - f(x)$$\n因此可以得到二阶导为：\n$$f''(x) = \\frac{\\delta^2 f(x)}{\\delta x^2} \\approx f'(x) - f'(x-1) \\approx f(x+1) + f(x-1) - 2f(x)$$\n因此我们可以得到结论：\n 二阶导数近似等于其二阶差分。 二阶导数等于其在所有自由度上微扰之后获得的增益。一维函数其自由度可以理解为2，分别是+1和-1两个方向。  对于二维的图像来说，其有两个方向（4个自由度）可以变化，即如果对(x,y)处的像素进行扰动，其可以变为四种状态：\n$$(x+1,y)，(x-1,y)，(x,y+1)，(x,y-1)$$\n当然了，如果将对角线方向也认为是一个自由度的话，会再增加几种状态：\n$$(x+1,y+1)，(x+1,y-1)，(x-1,y+1)，(x-1,y-1)$$\n事实上图像处理上正是这种。\n为了简便起见，这里只讨论第一种：\n$$\\Delta = \\frac{\\delta^2f(x,y)}{\\delta x} + \\frac{\\delta^2f(x,y)}{\\delta y} \\approx f(x+1,y) + f(x-1,y) + f(x,y+1) + f(x,y-1) - 4f(x,y)$$\n这不就是我们常见的拉普拉斯滤波吗。\n这给我们一种形象的结论：拉普拉斯算子就是在所有自由度上进行微小变化后获得的增益。\nGraph 对于有N个节点的Graph，就设节点为$1\u0026hellip;N$，且其邻接矩阵为$W$。\n若这个Graph是一个完全图，即任意两个节点之间都有一条边，那么对一个节点进行微扰，它可能变成任意一个节点。因此，该Graph的自由度最多为$N$。\n那么对应的函数是一个$N$维向量，即$f= (f_1,\u0026hellip;,f_N)$，这里，$f_i$表示函数$f$在节点$i$的值。\n 对于任意节点$i$进行微扰，它可能变为任意一个与他相邻的节点 $j \\in\\mathcal{N_i}$，其中 $\\mathcal{N_i}$ 表示节点i的一阶邻域节点。\n 我们上面结论说了，拉普拉斯算子就是在所有自由度上进行微小变化后获得的增益。但是对于Graph，从节点$i$变化到节点$j$增益是多少呢？即 $f_j - f_i$ 是多少呢？最容易想到就是和他们之间的边权相关，设为 $W_{ij}$。\n所以，对于Graph来说，其拉普拉斯算子如下：\n$$ (\\Delta f)i = \\sum\\limits_i \\frac{\\delta^2 f}{\\delta i^2} \\approx \\sum\\limits{j \\in \\mathcal{N_i}}W_{ij}(f_j - f_i) = \\sum\\limits_jW_{ij}(f_j - f_i) $$\n继续可以简化为\n$$\\sum\\limits_jW_{ij}(f_j - f_i) = \\sum\\limits_j W_{ij}f_j - \\sum\\limits_j W_{ij}f_i = (Wf)_i - (Df)_i = [(W-D)f]_i$$\n其中，若$W_{ij}$都为1（simple graph），$\\sum\\limits_j W_{ij}f_i$可以看作在$i$节点的度($D_i$)。即：$(\\Delta f_i) = [(W-D)f]_i$\n因此，图上的拉普拉斯算子应该定义为$D-W$!\n拉普拉斯的谱分解 由于拉普拉斯矩阵是半正定对称矩阵，有如下三个性质：\n 对称矩阵一定n个线性无关的特征向量 半正定矩阵的特征值一定非负 对阵矩阵的特征向量相互正交，即所有特征向量构成的矩阵为正交矩阵。  对于拉普拉斯矩阵其谱分解为：\n$$L = U \\begin{pmatrix}\\lambda_1 \u0026amp; \u0026amp; \\ \u0026amp; \u0026hellip;\u0026amp; \\ \u0026amp; \u0026amp; \\lambda_n\\end{pmatrix} U^{-1}$$\n由于$U$是列向量为单位特征的矩阵，因此：$UU^T = E$\n所以特征分解又可以写成：\n$$L = U \\begin{pmatrix}\\lambda_1 \u0026amp; \u0026amp; \\ \u0026amp; \u0026hellip;\u0026amp; \\ \u0026amp; \u0026amp; \\lambda_n\\end{pmatrix} U^{T}$$\nFourier transform on Graph 图上的傅立叶变换 传统的傅立叶变换（参考这里）：\n$$ F(\\omega)=\\mathcal{F}[f(t)]=\\int_{}^{}f(t)e^{-i\\omega t} dt $$\n Fourier transform is the expansion of $f$ in terms of the eigenfunctions of the Laplace operator, i.e, the second derivative\n 其实就是信号 $f(t)$与基函数 $e^{-i\\omega t}$的积分，那么为什么要找$e^{-i\\omega t}$作为基函数呢？\n 广义的特征方程定义为：$AV = \\lambda V$，其中$A$是一种变换 可以证明：$\\Delta e^{-iwt} = \\frac{\\partial ^2}{\\partial t^2} = -w^2 e^{-iwt}$ $e^{-i\\omega t}$ 是拉普拉斯算子的特征函数（满足特征方程）, $\\omega$ 和特征值密切相关。  仿照以上定义Graph上的傅立叶变换：\n$$F(\\lambda_l) = \\hat{f} (\\lambda_l)= \\sum\\limits_{i=1}^N f(i) u^T_l(i)$$\n$f$ 是Graph上的 $N$ 维向量， $f(i)$ 与Graph的顶点一一对应， $u_l(i)$表示第 $l$ 个特征向量的第 $i$ 个分量。那么特征值（频率） $\\lambda_l$ 下的， $f$ 的Graph 傅里叶变换就是与 $\\lambda_l$ 对应的特征向量 $u_l$ 进行内积运算。\n利用矩阵乘法将Graph上的傅里叶变换推广到矩阵形式：\n$$\\left(\\begin{matrix} \\hat{f}(\\lambda_1)\\ \\hat{f}(\\lambda_2) \\ \\vdots \\ \\hat{f}(\\lambda_N) \\end{matrix}\\right)=\\left(\\begin{matrix}\\ u_1(1) \u0026amp;u_1(2)\u0026amp; \\dots \u0026amp;u_1(N) \\ u_2(1) \u0026amp;u_2(2)\u0026amp; \\dots \u0026amp;u_2(N)\\ \\vdots \u0026amp;\\vdots \u0026amp;\\ddots \u0026amp; \\vdots\\ u_N(1) \u0026amp;u_N(2)\u0026amp; \\dots \u0026amp;u_N(N) \\end{matrix}\\right)\\left(\\begin{matrix}f(1)\\ f(2) \\ \\vdots \\f(N) \\end{matrix}\\right)$$\n即 $f$ 在Graph上傅里叶变换的矩阵形式为： $\\hat{f}=U^Tf $\n图上的傅立叶逆变换 类似地，传统的傅里叶变换是对频率 $\\omega$ 求积分：\n$$\\mathcal{F}^{-1}[F(\\omega)]=\\frac{1}{2\\Pi}\\int_{}^{}F(\\omega)e^{i\\omega t} d\\omega$$\n迁移到Graph上变为对特征值 $\\lambda_l$ 求和：\n$$f(i)=\\sum_{l=1}^{N}{\\hat{f}(\\lambda_l) u_l(i)}$$\n利用矩阵乘法将Graph上的傅里叶逆变换推广到矩阵形式：\n$$ \\left(\\begin{matrix}f(1)\\ f(2) \\ \\vdots \\ f(N) \\end{matrix}\\right)= \\left(\\begin{matrix}\\ u_1(1) \u0026amp;u_2(1)\u0026amp; \\dots \u0026amp;u_N(1) \\ u_1(2) \u0026amp;u_2(2)\u0026amp; \\dots \u0026amp;u_N(2)\\ \\vdots \u0026amp;\\vdots \u0026amp;\\ddots \u0026amp; \\vdots\\ u_1(N) \u0026amp;u_2(N)\u0026amp; \\dots \u0026amp;u_N(N) \\end{matrix}\\right) \\left(\\begin{matrix} \\hat{f}(\\lambda_1)\\ \\hat{f}(\\lambda_2) \\ \\vdots \\ \\hat{f}(\\lambda_N) \\end{matrix}\\right)$$\n即 $f$ 在Graph上傅里叶逆变换的矩阵形式为： $f=U\\hat{f}$\n推广卷积 卷积定理   函数卷积的傅里叶变换是函数傅立叶变换的乘积，即对于函数 $f(t)$ 与 $h(t)$ 两者的卷积是其函数傅立叶变换乘积的逆变换：\n$$f*h=\\mathcal{F}^{-1}\\left[ \\hat{f}(\\omega)\\hat{h}(\\omega) \\right]=\\frac{1}{2\\pi}\\int_{}^{} \\hat{f}(\\omega)\\hat{h}(\\omega)e^{i\\omega t} d\\omega$$\n  其中$\\mathcal{F}$是傅立叶变换。那么，我们如何在图上定义卷积呢？答案是用图上拉普拉斯算子的特征方程的形式定义图上的傅立叶变换。\n  图上的卷积   $f$ 的傅里叶变换为 $\\hat{f}=U^Tf$\n  卷积核 $h$ 的傅里叶变换写成对角矩阵的形式即为：\n  $$ \\left(\\begin{matrix}\\hat h(\\lambda_1) \u0026amp; \\\u0026amp;\\ddots \\ \u0026amp;\u0026amp;\\hat h(\\lambda_n) \\end{matrix}\\right)$$\n  $\\hat{h}(\\lambda_l)=\\sum_{i=1}^{N}{h(i) u_l^T(i)}$ 是**根据需要设计的卷积核** $h$ 在Graph上的傅里叶变换\n  两者的傅立叶变换乘积即为:\n  $$\\left(\\begin{matrix}\\hat h(\\lambda_1) \u0026amp; \\\u0026amp;\\ddots \\ \u0026amp;\u0026amp;\\hat h(\\lambda_n) \\end{matrix}\\right) U^Tf $$\n 再乘以 $U$ 求两者傅立叶变换乘积的逆变换，则求出卷积：  $$(f*h)_G= U\\left(\\begin{matrix}\\hat h(\\lambda_1) \u0026amp; \\\u0026amp;\\ddots \\ \u0026amp;\u0026amp;\\hat h(\\lambda_n) \\end{matrix}\\right) U^Tf $$\n 很多论文中卷积公式表示为：$(f*h)_G=U((U^Th)\\odot(U^Tf))$，其实是完全相同的  Reference  如何理解卷积 图拉普拉斯算子为何定义为D-W 深入理解傅里叶变换 图卷积网络(GCN)新手村完全指南 如何理解 Graph Convolutional Network（GCN）  ","permalink":"https://tech.zealscott.com/deeplearning/models/gnn/","summary":"卷积 定义 卷积是一种数学运算，称$(f*g)(n)$为$f,g$的卷积，\n其连续的定义为：\n$$(f*g)(n) = \\int_{-\\infty}^{+\\infty} f(\\tau)g(n-\\tau)d\\tau$$\n离散的定义为：\n$$(f*g)(n) = \\sum\\limits_{\\tau = -\\infty}^\\infty f(\\tau)g(n-\\tau)$$\n若令$x = \\tau,y = n-\\tau$，则$x+y = n$表示的是平行的直线。\n对于图像来说，图像上的滑动窗口很好的解释了卷积的定义：\n可以发现，我们对$f,g$进行卷积操作，保证$x,y$坐标的和都为1：\n写成卷积公式为：\n$$(f*g)(1,1) = \\sum\\limits_{k=0}^{2}\\sum\\limits_{h=0}^{2}f(h,k)g(1-h,1-k)$$\n这样就实现了使用$g$这个算子在图像上的滑动。但注意，在数学中的卷积运算中，卷积核与原始的矩阵乘积，是围绕着中心元素进行180度旋转后，才是对应的元素。\n而在实际的图像空间滤波中，我们是将设计的特定卷积核，然后将其与像素矩阵的对应元素（不进行上述的旋转）相乘得到。例如，在CV中常见的平滑滤波，高斯滤波。这些滤波被设计出来，以提取不同的特征。\n..对于神经网络来讲，最大的不同是，这些滤波不需要我们自己去定义（也就是提取特征的过程），而是通过网络自身训练每一个卷积层的滤波器..。让这些滤波器组对特定的模式有高的激活，以达到CNN网络的分类/检测等目的。因此，在CNN中，由于这些卷积核都是未知参数，需要根据数据训练学习，那么翻不翻转已经没有关系了。\n理解 对于离散卷积来说，本质上就是一种加权求和。CNN中的卷积本质上就是利用一个共享参数的过滤器（kernel），通过计算中心像素点以及相邻像素点的加权和来构成feature map实现空间特征的提取，当然加权系数就是卷积核的权重系数。\n那么卷积核的系数如何确定的呢？是随机化初值，然后根据误差函数通过反向传播梯度下降进行迭代优化。这是一个关键点，卷积核的参数通过优化求出才能实现特征提取的作用，GCN的理论很大一部分工作就是为了引入可以优化的卷积参数。\nLaplacian matrix 我们上离散数学都学过，图拉普拉斯矩阵的定义为：\n$$L = D -W$$\n其中，$D$ 是顶点的度矩阵（对角矩阵），$W$是图的邻接矩阵（带边权重）。其normalized形式为：\n$$L^{nor} = D^{-\\frac{1}{2}}LD^{-\\frac{1}{2}}$$\n但为什么是这样定义呢？我们先从拉普拉斯算子说起。\nLaplacian 其数学定义为：\n$$\\Delta = \\sum\\limits_i \\frac{\\delta^2}{\\delta x_i^2}$$\n即为非混合二阶偏导数的和。\n图像中的拉普拉斯算子 图像是一种离散数据，那么其拉普拉斯算子必然要进行离散化。\n从导数定义：\n$$f'(x) = \\frac{\\delta f(x)}{\\delta x} \\approx f(x+1) - f(x)$$\n因此可以得到二阶导为：\n$$f''(x) = \\frac{\\delta^2 f(x)}{\\delta x^2} \\approx f'(x) - f'(x-1) \\approx f(x+1) + f(x-1) - 2f(x)$$","title":"图卷积神经网络入门基础"},{"content":"VIM的启动  启动命令：vi my.txt 如果文件存在，则vi显示文件内容并等待用户的命令。 如果指定的文件不存在，则vi将告知用户这是未命名的文件，并进入一个空白的界面。 启动vi时都是默认处于命令模式。用户必须使用命令切换到文本输入模式才能进行输入编辑，或者可执行删除、复制等编辑命令。  VIM的退出  冒号进命令行模式下：  :q! 不存档强制退出。 :w 保存但不退出，w(rite)后可加所要存档的文档名。 :wq 存档后退出。 :x 与:wq相同   命令模式  ZZ、ZQ  保存/不保存退出    编辑 插入模式   输入:set nu 可设置vi显示行号\n  新增 (append)\n a ：从光标所在位置后面开始新增资料 A： 从光标所在行最后面的地方开始新增资料。    插入 (insert)\n i： 从光标所在位置前面开始插入资料 I ：从光标所在行的第一个非空白字元前面开始插入资料。    开始 (open)\n o ：在光标所在行下新增一列并进入输入模式。 O: 在光标所在行上方新增一列并进入输入模式。    命令模式 删除 #表示数字\n x：删除光标所在字符  #x删除几个字符，如3x   dw：删除一个单词  #dw 删除几个单词，如3dw表示删除三个单词   dd：删除光标所在的行  #dd 删除多个行，如3dd，表示删除光标行及光标的下两行 d$ 删除光标到行尾的内容   d+光标键：  左：删除光标前面的字符； 右：删除光标所在的字符； 上：将当前行与上一行删除； 下：当前行与下一行删除   s：删除光标所在字节，并进入输入模式  恢复  u  恢复刚才被修改的文本   U  恢复光标所在行的所有修改   .  重复上一次命令的操作    复制  yy  复制整行   yw  复制光标所在的单词   nyw  复制包括光标所在的n个单词   nyy  复制包括当前行在内的n行    粘贴  P  移动  nG：移动到第n行行首 h、j、k、l  行命令 搜索  :/string  搜索指定的字符串。 如果写的是斜杠（/）：按n会从当前位置向后查找；如果写的是问号（？），按n键则从当前位置向前查找   n  在搜索字符串后继续进行搜索，若为大写N，则反向搜索    替换  :%s /SEARCH /REPLACE  把文档中所有SEARCH替换成REPLACE   :#,# s /SEARCH /REPLACE /g   ＃号表示数字，表示从多少行到多少行，把SEARCH替换成REPLACE；   :s /SEARCH /REPLACE /g   把当前光标所在行中的SEARCH单词，替换成REPLACE，并把所有SEARCH高亮显示    配置   全局的配置文件位于/etc/vim/vimrc(或者/etc/vimrc)\n  也可以拥有自己独立的配置文件，配置文件位~/.vimrc，如果没有该文件，也可以直接用如下命令创建并编辑\n setnu \u0026ldquo;显示行号 setruler \u0026ldquo;显示光标位置 set smartindent \u0026ldquo;智能缩进 syntax on(或syn on) \u0026ldquo;语法高亮  ​\n\n  ","permalink":"https://tech.zealscott.com/misc/vim/","summary":"VIM的启动  启动命令：vi my.txt 如果文件存在，则vi显示文件内容并等待用户的命令。 如果指定的文件不存在，则vi将告知用户这是未命名的文件，并进入一个空白的界面。 启动vi时都是默认处于命令模式。用户必须使用命令切换到文本输入模式才能进行输入编辑，或者可执行删除、复制等编辑命令。  VIM的退出  冒号进命令行模式下：  :q! 不存档强制退出。 :w 保存但不退出，w(rite)后可加所要存档的文档名。 :wq 存档后退出。 :x 与:wq相同   命令模式  ZZ、ZQ  保存/不保存退出    编辑 插入模式   输入:set nu 可设置vi显示行号\n  新增 (append)\n a ：从光标所在位置后面开始新增资料 A： 从光标所在行最后面的地方开始新增资料。    插入 (insert)\n i： 从光标所在位置前面开始插入资料 I ：从光标所在行的第一个非空白字元前面开始插入资料。    开始 (open)\n o ：在光标所在行下新增一列并进入输入模式。 O: 在光标所在行上方新增一列并进入输入模式。    命令模式 删除 #表示数字","title":"VIM 使用简介"},{"content":"想写博客的念头已经很久了，在年初的春节终于有时间折腾出了自己的博客。一开始，仅仅是想用博客来记录自己学习中遇到的问题，作为备忘；后来上课了发现，与其将自己课上做的笔记写在 OneNote 上，还不如直接写在博客上，也许能帮助到一些同学呢；再到后来上数学课，就索性将数学公式、笔记也写在博客上（写 LaTeX 还是件很蛋疼的事）；到现在，我将自己做的一些小项目也记录下来，也许未来也会写点琐碎的感悟，也不一定呢。\n写博客是件很美妙的事情，一方面，每次的记录其实并没有那么愉快，虽然 Markdown 已经足够简单不用担心排版的问题，但每天总得多花一两个小时总结也有点繁琐（不过慢慢就习惯了这种记录方式），另一方面，当我第一次收到陌生朋友评论的感谢时，我才发现原来我的博客也有人看呀，成就感满满。于是我开始在网站中加入百度统计和 Google Analysis，时不时看看今天有没有人看我的博客，也算是激励我不断更新的动力吧。\n很惭愧的是，自己能力有限，多数博文也仅仅是上课的笔记和总结，并没有太多“干货”。好在自己还算勤快，半年就达到了自己定的一年目标（完成 100 篇博文）。这半年来其实自己的收获是巨大的，虽然每天都学的很累，但是总算是有种 feeling \u0026ndash;终于在 cs 上入门了。转专业这一年来，拒绝了所有的活动与比赛，静下心来搞学习，总算是有所收获。一年的时间说长也长，说短也短，原专业的朋友保研的保研，考研的考研，出国的出国。总有人半开玩笑的问我，“现在你看见他们都保研清北啦，你后不后悔”。我只是笑笑，当然不后悔了。但羡慕是有点羡慕的，毕竟是更好的平台，而自己选择了竞争压力太很多的行业，很难再像以前那样“游刃有余”。好在自己是个喜欢折腾且异常固执的人，倒也不觉得有什么。\n最近博客更新得不勤，主要是因为放假了，以及自己在做两个小项目、学英语，没太多东西可以记录。经过一年的“闭关”，自己也觉得是时候参加一些比赛来实践实践（没点奖状怎么丰富自己简历啊哭），找了两三个自己认为还挺有挑战的比赛，从 9 月份开始玩玩。\n当然，目前最重要的事情还是考好雅思\u0026hellip;\u0026hellip;\n","permalink":"https://tech.zealscott.com/misc/100-blogs-goal/","summary":"想写博客的念头已经很久了，在年初的春节终于有时间折腾出了自己的博客。一开始，仅仅是想用博客来记录自己学习中遇到的问题，作为备忘；后来上课了发现，与其将自己课上做的笔记写在 OneNote 上，还不如直接写在博客上，也许能帮助到一些同学呢；再到后来上数学课，就索性将数学公式、笔记也写在博客上（写 LaTeX 还是件很蛋疼的事）；到现在，我将自己做的一些小项目也记录下来，也许未来也会写点琐碎的感悟，也不一定呢。\n写博客是件很美妙的事情，一方面，每次的记录其实并没有那么愉快，虽然 Markdown 已经足够简单不用担心排版的问题，但每天总得多花一两个小时总结也有点繁琐（不过慢慢就习惯了这种记录方式），另一方面，当我第一次收到陌生朋友评论的感谢时，我才发现原来我的博客也有人看呀，成就感满满。于是我开始在网站中加入百度统计和 Google Analysis，时不时看看今天有没有人看我的博客，也算是激励我不断更新的动力吧。\n很惭愧的是，自己能力有限，多数博文也仅仅是上课的笔记和总结，并没有太多“干货”。好在自己还算勤快，半年就达到了自己定的一年目标（完成 100 篇博文）。这半年来其实自己的收获是巨大的，虽然每天都学的很累，但是总算是有种 feeling \u0026ndash;终于在 cs 上入门了。转专业这一年来，拒绝了所有的活动与比赛，静下心来搞学习，总算是有所收获。一年的时间说长也长，说短也短，原专业的朋友保研的保研，考研的考研，出国的出国。总有人半开玩笑的问我，“现在你看见他们都保研清北啦，你后不后悔”。我只是笑笑，当然不后悔了。但羡慕是有点羡慕的，毕竟是更好的平台，而自己选择了竞争压力太很多的行业，很难再像以前那样“游刃有余”。好在自己是个喜欢折腾且异常固执的人，倒也不觉得有什么。\n最近博客更新得不勤，主要是因为放假了，以及自己在做两个小项目、学英语，没太多东西可以记录。经过一年的“闭关”，自己也觉得是时候参加一些比赛来实践实践（没点奖状怎么丰富自己简历啊哭），找了两三个自己认为还挺有挑战的比赛，从 9 月份开始玩玩。\n当然，目前最重要的事情还是考好雅思\u0026hellip;\u0026hellip;","title":"写在第 100 篇博文之际"},{"content":"很多时候当我们写了一篇博客，但并不想所有人能够访问它。对于WordPress这很容易做到，但是对于hexo，由于是静态网页，并不能做到完全的加密。\n在GitHub上发现了有个人做了一个加密的插件，还挺好用，推荐给大家。\n安装 在你的hexo根目录的package.json文件夹中添加：\n \u0026ldquo;hexo-blog-encrypt\u0026rdquo;: \u0026ldquo;2.0.*\u0026rdquo;\n 然后在命令行中输入：\n npm install\n 这样这个插件就安装好了。\n找到根目录下的_config.yml文件，添加如下：\n1 2 3 4  # Security ## encrypt: enable: true   这样就可以使用插件了。\n使用 在你要加密的文章头部写入password，例如：\n1 2 3 4 5 6 7  --- title: Hello World date: 2016-03-30 21:18:02 password: abc123 abstract: Welcome to my blog, enter password to read. message: Welcome to my blog, enter password to read. ---   这样就可以需要输入密码访问了。\nBugs   对于hexo-blog-encrypt2.0之前的版本，无法触发渲染mathjax的函数，需要进行升级。\n  如果想对TOC进行加密，以next主题为例，将next/layout/_macro/sidebar.swig的文件替换为：\n  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195  `{% macro render(is_post) %} \u0026lt;div class=\u0026#34;sidebar-toggle\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;sidebar-toggle-line-wrap\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;sidebar-toggle-line sidebar-toggle-line-first\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;sidebar-toggle-line sidebar-toggle-line-middle\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;sidebar-toggle-line sidebar-toggle-line-last\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;aside id=\u0026#34;sidebar\u0026#34; class=\u0026#34;sidebar\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;sidebar-inner\u0026#34;\u0026gt; {% set display_toc = is_post and theme.toc.enable %} {% if page.encrypt == true %} {% if display_toc and toc(page.origin).length \u0026gt; 1 %} \u0026lt;ul class=\u0026#34;sidebar-nav motion-element\u0026#34;\u0026gt; \u0026lt;li class=\u0026#34;sidebar-nav-toc sidebar-nav-active\u0026#34; data-target=\u0026#34;post-toc-wrap\u0026#34; \u0026gt; {{ __(\u0026#39;sidebar.toc\u0026#39;) }} \u0026lt;/li\u0026gt; \u0026lt;li class=\u0026#34;sidebar-nav-overview\u0026#34; data-target=\u0026#34;site-overview\u0026#34;\u0026gt; {{ __(\u0026#39;sidebar.overview\u0026#39;) }} \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; {% endif %} {% else %} {% if display_toc and toc(page.content).length \u0026gt; 1 %} \u0026lt;ul class=\u0026#34;sidebar-nav motion-element\u0026#34;\u0026gt; \u0026lt;li class=\u0026#34;sidebar-nav-toc sidebar-nav-active\u0026#34; data-target=\u0026#34;post-toc-wrap\u0026#34; \u0026gt; {{ __(\u0026#39;sidebar.toc\u0026#39;) }} \u0026lt;/li\u0026gt; \u0026lt;li class=\u0026#34;sidebar-nav-overview\u0026#34; data-target=\u0026#34;site-overview\u0026#34;\u0026gt; {{ __(\u0026#39;sidebar.overview\u0026#39;) }} \u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; {% endif %} {% endif %} \u0026lt;section class=\u0026#34;site-overview sidebar-panel{% if not display_toc or toc(page.content).length \u0026lt;= 1 %} sidebar-panel-active{% endif %}\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;site-author motion-element\u0026#34; itemprop=\u0026#34;author\u0026#34; itemscope itemtype=\u0026#34;http://schema.org/Person\u0026#34;\u0026gt; \u0026lt;img class=\u0026#34;site-author-image\u0026#34; itemprop=\u0026#34;image\u0026#34; src=\u0026#34;{{ url_for( theme.avatar | default(theme.images + \u0026#39;/avatar.gif\u0026#39;) ) }}\u0026#34; alt=\u0026#34;{{ theme.author }}\u0026#34; /\u0026gt; \u0026lt;p class=\u0026#34;site-author-name\u0026#34; itemprop=\u0026#34;name\u0026#34;\u0026gt;{{ theme.author }}\u0026lt;/p\u0026gt; {% if theme.seo %} \u0026lt;p class=\u0026#34;site-description motion-element\u0026#34; itemprop=\u0026#34;description\u0026#34;\u0026gt;{{ theme.signature }}\u0026lt;/p\u0026gt; {% else %} \u0026lt;p class=\u0026#34;site-description motion-element\u0026#34; itemprop=\u0026#34;description\u0026#34;\u0026gt;{{ theme.description }}\u0026lt;/p\u0026gt; {% endif %} \u0026lt;/div\u0026gt; \u0026lt;nav class=\u0026#34;site-state motion-element\u0026#34;\u0026gt; {% if config.archive_dir != \u0026#39;/\u0026#39; %} \u0026lt;div class=\u0026#34;site-state-item site-state-posts\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;{{ url_for(theme.menu.archives) }}\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;site-state-item-count\u0026#34;\u0026gt;{{ site.posts.length }}\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;site-state-item-name\u0026#34;\u0026gt;{{ __(\u0026#39;state.posts\u0026#39;) }}\u0026lt;/span\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; {% endif %} {% if site.categories.length \u0026gt; 0 %} {% set categoriesPageQuery = site.pages.find({type: \u0026#39;categories\u0026#39;}, {lean: true}) %} {% set hasCategoriesPage = categoriesPageQuery.length \u0026gt; 0 %} \u0026lt;div class=\u0026#34;site-state-item site-state-categories\u0026#34;\u0026gt; {% if hasCategoriesPage %}\u0026lt;a href=\u0026#34;{{ url_for(categoriesPageQuery[0].path) }}\u0026#34;\u0026gt;{% endif %} \u0026lt;span class=\u0026#34;site-state-item-count\u0026#34;\u0026gt;{{ site.categories.length }}\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;site-state-item-name\u0026#34;\u0026gt;{{ __(\u0026#39;state.categories\u0026#39;) }}\u0026lt;/span\u0026gt; {% if hasCategoriesPage %}\u0026lt;/a\u0026gt;{% endif %} \u0026lt;/div\u0026gt; {% endif %} {% if site.tags.length \u0026gt; 0 %} {% set tagsPageQuery = site.pages.find({type: \u0026#39;tags\u0026#39;}, {lean: true}) %} {% set hasTagsPage = tagsPageQuery.length \u0026gt; 0 %} \u0026lt;div class=\u0026#34;site-state-item site-state-tags\u0026#34;\u0026gt; {% if hasTagsPage %}\u0026lt;a href=\u0026#34;{{ url_for(tagsPageQuery[0].path) }}\u0026#34;\u0026gt;{% endif %} \u0026lt;span class=\u0026#34;site-state-item-count\u0026#34;\u0026gt;{{ site.tags.length }}\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;site-state-item-name\u0026#34;\u0026gt;{{ __(\u0026#39;state.tags\u0026#39;) }}\u0026lt;/span\u0026gt; {% if hasTagsPage %}\u0026lt;/a\u0026gt;{% endif %} \u0026lt;/div\u0026gt; {% endif %} \u0026lt;/nav\u0026gt; {% if theme.rss %} \u0026lt;div class=\u0026#34;feed-link motion-element\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;{{ url_for(theme.rss) }}\u0026#34; rel=\u0026#34;alternate\u0026#34;\u0026gt; \u0026lt;i class=\u0026#34;fa fa-rss\u0026#34;\u0026gt;\u0026lt;/i\u0026gt; RSS \u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; {% endif %} \u0026lt;div class=\u0026#34;links-of-author motion-element\u0026#34;\u0026gt; {% if theme.social %} {% for name, link in theme.social %} \u0026lt;span class=\u0026#34;links-of-author-item\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;{{ link }}\u0026#34; target=\u0026#34;_blank\u0026#34; title=\u0026#34;{{ name }}\u0026#34;\u0026gt; {% if theme.social_icons.enable %} \u0026lt;i class=\u0026#34;fa fa-fw fa-{{ theme.social_icons[name] | default(\u0026#39;globe\u0026#39;) | lower }}\u0026#34;\u0026gt;\u0026lt;/i\u0026gt; {% endif %} {{ name }} \u0026lt;/a\u0026gt; \u0026lt;/span\u0026gt; {% endfor %} {% endif %} \u0026lt;/div\u0026gt; {% set cc = {\u0026#39;by\u0026#39;: 1, \u0026#39;by-nc\u0026#39;: 1, \u0026#39;by-nc-nd\u0026#39;: 1, \u0026#39;by-nc-sa\u0026#39;: 1, \u0026#39;by-nd\u0026#39;: 1, \u0026#39;by-sa\u0026#39;: 1, \u0026#39;zero\u0026#39;: 1} %} {% if theme.creative_commons in cc %} \u0026lt;div class=\u0026#34;cc-license motion-element\u0026#34; itemprop=\u0026#34;license\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;https://creativecommons.org/{% if theme.creative_commons === \u0026#39;zero\u0026#39; %}publicdomain/zero/1.0{% else %}licenses/{{ theme.creative_commons }}/4.0{% endif %}/\u0026#34; class=\u0026#34;cc-opacity\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;{{ url_for(theme.images) }}/cc-{{ theme.creative_commons }}.svg\u0026#34; alt=\u0026#34;Creative Commons\u0026#34; /\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; {% endif %} {# Blogroll #} {% if theme.links %} \u0026lt;div class=\u0026#34;links-of-blogroll motion-element {{ \u0026#34;links-of-blogroll-\u0026#34; + theme.links_layout | default(\u0026#39;inline\u0026#39;) }}\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;links-of-blogroll-title\u0026#34;\u0026gt; \u0026lt;i class=\u0026#34;fa fa-fw fa-{{ theme.links_icon | default(\u0026#39;globe\u0026#39;) | lower }}\u0026#34;\u0026gt;\u0026lt;/i\u0026gt; {{ theme.links_title }} \u0026lt;/div\u0026gt; \u0026lt;ul class=\u0026#34;links-of-blogroll-list\u0026#34;\u0026gt; {% for name, link in theme.links %} \u0026lt;li class=\u0026#34;links-of-blogroll-item\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;{{ link }}\u0026#34; title=\u0026#34;{{ name }}\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;{{ name }}\u0026lt;/a\u0026gt; \u0026lt;/li\u0026gt; {% endfor %} \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; {% endif %} {% include \u0026#39;../_custom/sidebar.swig\u0026#39; %} \u0026lt;/section\u0026gt; {% if page.encrypt == true %} {% if display_toc and toc(page.origin).length \u0026gt; 1 %} \u0026lt;!--noindex--\u0026gt; \u0026lt;section class=\u0026#34;post-toc-wrap motion-element sidebar-panel sidebar-panel-active\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;post-toc\u0026#34;\u0026gt; {% if page.toc_number === undefined %} {% set toc = toc(page.origin, { \u0026#34;class\u0026#34;: \u0026#34;nav\u0026#34;, list_number: theme.toc.number }) %} {% else %} {% set toc = toc(page.origin, { \u0026#34;class\u0026#34;: \u0026#34;nav\u0026#34;, list_number: page.toc_number }) %} {% endif %} {% if toc.length \u0026lt;= 1 %} \u0026lt;p class=\u0026#34;post-toc-empty\u0026#34;\u0026gt;{{ __(\u0026#39;post.toc_empty\u0026#39;) }}\u0026lt;/p\u0026gt; {% else %} \u0026lt;div class=\u0026#34;post-toc-content\u0026#34;\u0026gt;{{ toc }}\u0026lt;/div\u0026gt; {% endif %} \u0026lt;/div\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;!--/noindex--\u0026gt; {% endif %} {% else %} {% if display_toc and toc(page.content).length \u0026gt; 1 %} \u0026lt;!--noindex--\u0026gt; \u0026lt;section class=\u0026#34;post-toc-wrap motion-element sidebar-panel sidebar-panel-active\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;post-toc\u0026#34;\u0026gt; {% if page.toc_number === undefined %} {% set toc = toc(page.content, { \u0026#34;class\u0026#34;: \u0026#34;nav\u0026#34;, list_number: theme.toc.number }) %} {% else %} {% set toc = toc(page.content, { \u0026#34;class\u0026#34;: \u0026#34;nav\u0026#34;, list_number: page.toc_number }) %} {% endif %} {% if toc.length \u0026lt;= 1 %} \u0026lt;p class=\u0026#34;post-toc-empty\u0026#34;\u0026gt;{{ __(\u0026#39;post.toc_empty\u0026#39;) }}\u0026lt;/p\u0026gt; {% else %} \u0026lt;div class=\u0026#34;post-toc-content\u0026#34;\u0026gt;{{ toc }}\u0026lt;/div\u0026gt; {% endif %} \u0026lt;/div\u0026gt; \u0026lt;/section\u0026gt; \u0026lt;!--/noindex--\u0026gt; {% endif %} {% endif %} {% if theme.sidebar.b2t %} \u0026lt;div class=\u0026#34;back-to-top\u0026#34;\u0026gt; \u0026lt;i class=\u0026#34;fa fa-arrow-up\u0026#34;\u0026gt;\u0026lt;/i\u0026gt; {% if theme.sidebar.scrollpercent %} \u0026lt;span id=\u0026#34;scrollpercent\u0026#34;\u0026gt;\u0026lt;span\u0026gt;0\u0026lt;/span\u0026gt;%\u0026lt;/span\u0026gt; {% endif %} \u0026lt;/div\u0026gt; {% endif %} \u0026lt;/div\u0026gt; \u0026lt;/aside\u0026gt; {% endmacro %}   ","permalink":"https://tech.zealscott.com/misc/hexo-encrypt/","summary":"很多时候当我们写了一篇博客，但并不想所有人能够访问它。对于WordPress这很容易做到，但是对于hexo，由于是静态网页，并不能做到完全的加密。\n在GitHub上发现了有个人做了一个加密的插件，还挺好用，推荐给大家。\n安装 在你的hexo根目录的package.json文件夹中添加：\n \u0026ldquo;hexo-blog-encrypt\u0026rdquo;: \u0026ldquo;2.0.*\u0026rdquo;\n 然后在命令行中输入：\n npm install\n 这样这个插件就安装好了。\n找到根目录下的_config.yml文件，添加如下：\n1 2 3 4  # Security ## encrypt: enable: true   这样就可以使用插件了。\n使用 在你要加密的文章头部写入password，例如：\n1 2 3 4 5 6 7  --- title: Hello World date: 2016-03-30 21:18:02 password: abc123 abstract: Welcome to my blog, enter password to read. message: Welcome to my blog, enter password to read. ---   这样就可以需要输入密码访问了。","title":"Hexo 博文加密"},{"content":"启发式策略 对于新拿到的一个训练集，我们首先的目的是：训练出来的结果至少要比随机要好。\n初看这个目的很简单，但实际上很困难，尤其是遇到一种新类型的问题时。\n简化数据集 例如，如果我们处理MNIST分类集，我们可以只处理0，1两个数字的集合，这样，不仅简化了分类目的，也能让神经网络的训练速度得到5倍的提升。\n当使用更简单的分类集时，我们能更好的洞察神经网络的结构调整。\n简化网络 我们应该从简单的网络开始进行训练，例如，只含一层的隐藏层，这样的训练速率更快，而且，若简单的网络都不能得到较好的结果，那么训练复杂的网络将会更加困难。\n提高监控频率 我们可以在神经网络框架中每隔几百次epoch就打印当前的准确率，这样会让我们更好的洞察网络的拟合情况，提早发现过拟合或学习速率过慢等问题。\n在每一步，我们使用验证集来衡量网络的性能，这些度量将会帮助我们找到更好的超参数。一旦准确率上升或者loss开始下降，就可以通过微调超参数获得快速的性能提升。\n基本超参数 学习速率（learning rate） 对于学习速率，我们可以使用不同量级的参数（0.1，1，10等）先初步进行训练，根据loss的大小确定参数量级。\n一般来说，我们使用验证集准确率来调整超参数，但在learning rate中倾向于使用loss，这是因为学习速率的主要目的是控制梯度下降的步长，监控训练loss是最好的检验步长过大的方法。\n学习速率调整 一直以来，我们都将学习速率设置成常数。但通常来讲，可变的学习速率更加有效。\n 在学习的前期，学习速率比较大，可以让训练变快 在准确率开始变差或者不变时，按照某个量依次减少学习速率（除以10）。  规范化参数 在开始时不包含规范化参数，直到确定了学习速率后，在根据验证数据来选择好的 规范化参数。一般规范化参数从1开始调整。\n迭代期（epoch） Early stopping表示在每个回合的最后，我们都要计算验证集上的分类准确率。当准确率不再提升，就终止训练。\n但一般来说，在训练过程中总会存在波动，每次准确率下降一点点就直接终止不是一个好的策略。一般来说，当分类准确率在一段时间内不再提升的时候终止比较好。\n这样，使用Early stopping就可以简单的选择迭代期。\nMini Batch 如果值太小，不会用到并行计算的资源，速度也不会有所提升，倒会使得学习缓慢；\n如果值太大，则不能够频繁的更新权重。\n经验表明，Mini Batch其实时一个相对独立的参数，可以将其他参数选取合适的值之后，再来根据训练集准确率调整。\n随机梯度下降的改进 Hessian技术 实际上就是二阶导的矩阵，理论上来说Hessian方法比标准的SGD收敛速度更快。\nMomentum 我们可以认为这种方法引入了类似于摩擦力的量，使得梯度下降变化规则从原始的\n$w→w′=w−η∇C$变为：\n$$v \\to v' = \\mu v +\\eta \\triangledown C$$\n$$w′=w+v′$$\n其中，$\\eta$是用来控制阻碍或者摩擦力的量的超参数。\n以上的公式可以理解为，力$\\triangledown C$改变了速度$v$，速度再控制$w$的变化率。\n$\\eta$被称为moment coefficient，在物理中为动量。\n","permalink":"https://tech.zealscott.com/deeplearning/misc/parameters/","summary":"启发式策略 对于新拿到的一个训练集，我们首先的目的是：训练出来的结果至少要比随机要好。\n初看这个目的很简单，但实际上很困难，尤其是遇到一种新类型的问题时。\n简化数据集 例如，如果我们处理MNIST分类集，我们可以只处理0，1两个数字的集合，这样，不仅简化了分类目的，也能让神经网络的训练速度得到5倍的提升。\n当使用更简单的分类集时，我们能更好的洞察神经网络的结构调整。\n简化网络 我们应该从简单的网络开始进行训练，例如，只含一层的隐藏层，这样的训练速率更快，而且，若简单的网络都不能得到较好的结果，那么训练复杂的网络将会更加困难。\n提高监控频率 我们可以在神经网络框架中每隔几百次epoch就打印当前的准确率，这样会让我们更好的洞察网络的拟合情况，提早发现过拟合或学习速率过慢等问题。\n在每一步，我们使用验证集来衡量网络的性能，这些度量将会帮助我们找到更好的超参数。一旦准确率上升或者loss开始下降，就可以通过微调超参数获得快速的性能提升。\n基本超参数 学习速率（learning rate） 对于学习速率，我们可以使用不同量级的参数（0.1，1，10等）先初步进行训练，根据loss的大小确定参数量级。\n一般来说，我们使用验证集准确率来调整超参数，但在learning rate中倾向于使用loss，这是因为学习速率的主要目的是控制梯度下降的步长，监控训练loss是最好的检验步长过大的方法。\n学习速率调整 一直以来，我们都将学习速率设置成常数。但通常来讲，可变的学习速率更加有效。\n 在学习的前期，学习速率比较大，可以让训练变快 在准确率开始变差或者不变时，按照某个量依次减少学习速率（除以10）。  规范化参数 在开始时不包含规范化参数，直到确定了学习速率后，在根据验证数据来选择好的 规范化参数。一般规范化参数从1开始调整。\n迭代期（epoch） Early stopping表示在每个回合的最后，我们都要计算验证集上的分类准确率。当准确率不再提升，就终止训练。\n但一般来说，在训练过程中总会存在波动，每次准确率下降一点点就直接终止不是一个好的策略。一般来说，当分类准确率在一段时间内不再提升的时候终止比较好。\n这样，使用Early stopping就可以简单的选择迭代期。\nMini Batch 如果值太小，不会用到并行计算的资源，速度也不会有所提升，倒会使得学习缓慢；\n如果值太大，则不能够频繁的更新权重。\n经验表明，Mini Batch其实时一个相对独立的参数，可以将其他参数选取合适的值之后，再来根据训练集准确率调整。\n随机梯度下降的改进 Hessian技术 实际上就是二阶导的矩阵，理论上来说Hessian方法比标准的SGD收敛速度更快。\nMomentum 我们可以认为这种方法引入了类似于摩擦力的量，使得梯度下降变化规则从原始的\n$w→w′=w−η∇C$变为：\n$$v \\to v' = \\mu v +\\eta \\triangledown C$$\n$$w′=w+v′$$\n其中，$\\eta$是用来控制阻碍或者摩擦力的量的超参数。\n以上的公式可以理解为，力$\\triangledown C$改变了速度$v$，速度再控制$w$的变化率。\n$\\eta$被称为moment coefficient，在物理中为动量。","title":"如何选择神经网络中的超参数"},{"content":"发现过拟合问题 在训练神经网络时，我们常常有训练集、测试集和验证集三种数据集。\n有时候我们会发现，训练出来的神经网络在训练集上表现很好（准确率很高），但在测试集上的准确率比较差。这种现象一般被认为是过拟合，也就是过度学习了训练集上的特征，导致泛化能力较差。\nhold out 方法 那么如何发现是否存在过拟合方法呢？一种简单的思路就是把训练集分为训练集和验证集，其中训练集用来训练数据，验证集用来检测准确率。\nEarly stop 我们在每个迭代期的最后都计算在验证集上的分类准确率，一旦分类准确率已经饱和，就停止训练。这个策略被称为提前停止。\n示例 以MNIST数据集为例，这里使用1000个样本作为训练集，迭代周期为400，使用交叉熵代价函数，随机梯度下降，我们可以画出其损失值与准确率。\n训练集上的损失值和准确率：\n验证集上的损失值和准确率：\n对比测试集与验证集的准确率：\n可以发现：训练集上的损失值越来越小，正确率已经达到了100%，而验证集上的损失会突然增大，正确率没有提升。这就产生了过拟合问题。\n增大训练量 一个最直观，也是最有效的方式就是增大训练量。有了足够的训练数据，就算是一个规模很大的网络也不太容易过拟合。\n例如，如果我们将MNIST的训练数据增大到50000（扩大了50倍），则可以发现训练集和测试集的正确率差距不大，且一直在增加（这里只迭代了30次）：\n但很不幸，一般来说，训练数据时有限的，这种方法不太实际。\n人为扩展训练数据 当我们缺乏训练数据时，可以使用一种巧妙的方式人为构造数据。\n例如，对于MNIST手写数字数据集，我们可以将每幅图像左右旋转15°。这应该还是被识别成同样的数字，但对于我们的神经网络来说（像素级），这就是完全不同的输入。\n因此，将这些样本加入到训练数据中很可能帮助我们的网络学习更多如何分类数字。\n这个想法很强大并且已经被广泛应用了，更多讨论可以查看这篇论文。\n再举个例子，当我们训练神经网络进行语音识别时，我们可以对这些语音随机加上一些噪音\u0026ndash;加速或减速。\n规范化（regularization） 除了增大训练样本，另一种能减轻过拟合的方法是**降低网络的规模。**但往往大规模的神经网络有更强的潜力，因此我们想使用另外的技术。\n规范化是神经网络中常用的方法，虽然没有足够的理论，但规范化的神经网络往往能够比非规范化的泛化能力更强。\n一般来说，我们只需要对$w$进行规范化，而几乎不对$b$进行规范化。\nL2规范化 学习规则 最常用的规范化手段，也称为权重衰减（weight decay）。\nL2规范化的想法是增加一个额外的项到代价函数上，这个项被称为**规范化项。**例如，对于规范化的交叉熵：\n$$C= -\\frac{1}{n}\\sum\\limits_{x}[y_j\\ln a_j^L+ (1-y_j)\\ln (1-a_j^L)]+ \\frac{\\lambda}{2n}\\sum\\limits_ww^2$$\n对于其他形式的代价函数，都可以写成：\n$$C =C_0+\\frac{\\lambda}{2n}\\sum\\limits_ww^2$$\n由于我们的目的是使得代价函数越小越好，因此直觉的看，规范化的效果是让网络倾向于学习小一点的权重。\n换言之，规范化可以当做一种寻找小的权重和最小化原始代价函数之间的折中。\n现在，我们再对$w$和$b$求偏导：\n$$\\frac{\\partial C}{\\partial w} =\\frac{\\partial C_0}{\\partial w}+\\frac{\\lambda}{n}w $$\n$$\\frac{\\partial C}{\\partial w} =\\frac{\\partial C_0}{\\partial b} $$\n因此，我们计算规范化的代价函数的梯度是很简单的：仅仅需要反向传播，然后加上$\\frac{\\lambda}{n}w$得到所有权重的偏导数。而偏置的偏导数不需要变化。所以权重的学习规则为：\n$$w\\to (1-\\frac{\\lambda\\eta}{n})w-\\frac{\\eta}{m}\\sum\\limits_x\\frac{\\partial C_x}{\\partial w}$$\n$$b\\to b-\\frac{\\eta}{m}\\sum\\limits_x\\frac{\\partial C_x}{\\partial b}$$\n这里也表明，我们倾向于使得权重更小一点。\n那这样，是否会让权重不断下降变为0呢？但实际上不是这样的，因为如果在原始代价函数中的下降会造成其他项使得权重增加。\n示例 我们依然来看MNIST的例子。这里，我使用$\\lambda = 0.1$的规范化项进行学习。\n训练集上的准确率和损失值和之前一样：\n测试集上的损失值不断减少，准确率不断提高，符合预期：\nL1规范化 学习规则 这个方法是在未规范化的代价函数上加一个权重绝对值的和：\n$$C = C_0+ \\frac{\\lambda}{n}\\sum\\limits_w|w|$$\n对其进行求偏导得：\n$$\\frac{\\partial C}{\\partial w} =\\frac{\\partial C_0}{\\partial w}+\\frac{\\lambda}{n}sgn(w ) $$\n其中$sgn()$就是$w$的正负号。\n与L2规范化的联系 我们将L1规范化与L2规范化进行对比（Mini-Batch = $m$）：\n$$w\\to w - \\frac{\\lambda\\eta}{nm}\\sum sgn(w )-\\frac{\\eta}{m}\\sum\\limits_x\\frac{\\partial C_x}{\\partial w}$$\n$$w\\to (1-\\frac{\\lambda\\eta}{n})w-\\frac{\\eta}{m}\\sum\\limits_x\\frac{\\partial C_x}{\\partial w}$$\n两种规范化都惩罚大的权重，但权重缩小的方式不同。\n在L1规范化中，权重通过一个常量向0进行收缩；\n而L2规范化中，权重通过一个和$w$成比例的量进行收缩。\n所以，当一个特定的权重绝对值$|w|$很大时，L1规范化的权重缩小远比L2小很多；而当$|w|$很小时，L1规范化的缩小又比L2大很多。\n因此，L1规范化倾向于聚集网络的权值在相对少量的高重要连接上，而其他权重就会被趋向于0。\nDropout Dropout是一种相当激进的技术，和之前的规范化技术不同，它不改变网络本身，而是会随机地删除网络中的一般隐藏的神经元，并且让输入层和输出层的神经元保持不变。\n我们每次使用梯度下降时，只使用随机的一般神经元进行更新权值和偏置，因此我们的神经网络时再一半隐藏神经元被丢弃的情况下学习的。\n而当我们运行整个网络时，是两倍的神经元会被激活。因此，我们将从隐藏神经元的权重减半。\n这种技术的直观理解为：**当我们Dropout不同的神经元集合时，有点像我们在训练不同的神经网络。**而不同的神经网络会以不同的方式过拟合，所以Dropout就类似于不同的神经网络以投票的方式降低过拟合。\n对于不同的技术，其实都可以理解为：**我们在训练网络的健壮性。**无论是L1、L2规范化倾向于学习小的权重，还是Dropout强制学习在神经元子集中更加健壮的特征，都是让网络对丢失个体连接的场景更加健壮。\nwhy works? 在论文中由这样一段话解释Dropout方法：\n This technique reduces complex co-adaptations of neurons, since a neuron cannot rely on the presence of particular other neurons. It is, therefore, forced to learn more robust features that are useful in conjunction with many different random subsets of the other neurons.\n 参考  What is regularization in machine learning? Improving neural networks by preventing co-adaptation of feature detectors best practices for convolutional neural networks applied to visual  ","permalink":"https://tech.zealscott.com/deeplearning/misc/overfit/","summary":"发现过拟合问题 在训练神经网络时，我们常常有训练集、测试集和验证集三种数据集。\n有时候我们会发现，训练出来的神经网络在训练集上表现很好（准确率很高），但在测试集上的准确率比较差。这种现象一般被认为是过拟合，也就是过度学习了训练集上的特征，导致泛化能力较差。\nhold out 方法 那么如何发现是否存在过拟合方法呢？一种简单的思路就是把训练集分为训练集和验证集，其中训练集用来训练数据，验证集用来检测准确率。\nEarly stop 我们在每个迭代期的最后都计算在验证集上的分类准确率，一旦分类准确率已经饱和，就停止训练。这个策略被称为提前停止。\n示例 以MNIST数据集为例，这里使用1000个样本作为训练集，迭代周期为400，使用交叉熵代价函数，随机梯度下降，我们可以画出其损失值与准确率。\n训练集上的损失值和准确率：\n验证集上的损失值和准确率：\n对比测试集与验证集的准确率：\n可以发现：训练集上的损失值越来越小，正确率已经达到了100%，而验证集上的损失会突然增大，正确率没有提升。这就产生了过拟合问题。\n增大训练量 一个最直观，也是最有效的方式就是增大训练量。有了足够的训练数据，就算是一个规模很大的网络也不太容易过拟合。\n例如，如果我们将MNIST的训练数据增大到50000（扩大了50倍），则可以发现训练集和测试集的正确率差距不大，且一直在增加（这里只迭代了30次）：\n但很不幸，一般来说，训练数据时有限的，这种方法不太实际。\n人为扩展训练数据 当我们缺乏训练数据时，可以使用一种巧妙的方式人为构造数据。\n例如，对于MNIST手写数字数据集，我们可以将每幅图像左右旋转15°。这应该还是被识别成同样的数字，但对于我们的神经网络来说（像素级），这就是完全不同的输入。\n因此，将这些样本加入到训练数据中很可能帮助我们的网络学习更多如何分类数字。\n这个想法很强大并且已经被广泛应用了，更多讨论可以查看这篇论文。\n再举个例子，当我们训练神经网络进行语音识别时，我们可以对这些语音随机加上一些噪音\u0026ndash;加速或减速。\n规范化（regularization） 除了增大训练样本，另一种能减轻过拟合的方法是**降低网络的规模。**但往往大规模的神经网络有更强的潜力，因此我们想使用另外的技术。\n规范化是神经网络中常用的方法，虽然没有足够的理论，但规范化的神经网络往往能够比非规范化的泛化能力更强。\n一般来说，我们只需要对$w$进行规范化，而几乎不对$b$进行规范化。\nL2规范化 学习规则 最常用的规范化手段，也称为权重衰减（weight decay）。\nL2规范化的想法是增加一个额外的项到代价函数上，这个项被称为**规范化项。**例如，对于规范化的交叉熵：\n$$C= -\\frac{1}{n}\\sum\\limits_{x}[y_j\\ln a_j^L+ (1-y_j)\\ln (1-a_j^L)]+ \\frac{\\lambda}{2n}\\sum\\limits_ww^2$$\n对于其他形式的代价函数，都可以写成：\n$$C =C_0+\\frac{\\lambda}{2n}\\sum\\limits_ww^2$$\n由于我们的目的是使得代价函数越小越好，因此直觉的看，规范化的效果是让网络倾向于学习小一点的权重。\n换言之，规范化可以当做一种寻找小的权重和最小化原始代价函数之间的折中。\n现在，我们再对$w$和$b$求偏导：\n$$\\frac{\\partial C}{\\partial w} =\\frac{\\partial C_0}{\\partial w}+\\frac{\\lambda}{n}w $$\n$$\\frac{\\partial C}{\\partial w} =\\frac{\\partial C_0}{\\partial b} $$\n因此，我们计算规范化的代价函数的梯度是很简单的：仅仅需要反向传播，然后加上$\\frac{\\lambda}{n}w$得到所有权重的偏导数。而偏置的偏导数不需要变化。所以权重的学习规则为：\n$$w\\to (1-\\frac{\\lambda\\eta}{n})w-\\frac{\\eta}{m}\\sum\\limits_x\\frac{\\partial C_x}{\\partial w}$$\n$$b\\to b-\\frac{\\eta}{m}\\sum\\limits_x\\frac{\\partial C_x}{\\partial b}$$","title":"防止神经网络过拟合的基本方法"},{"content":"二次代价函数 之前我们一直使用二次代价函数，貌似在一定程度上也挺work。但其实，当输入值与目标值差距很大时，二次代价函数就不是很恰当了；**这是因为当差距很大时，此函数的学习速率会很慢。**我们可以通过一个简单的例子观察这种变化：\n假设我们只使用一个神经元与一个输出神经元，定义代价函数为：\n$$C = \\frac{(y-a)^2}{2}$$\n使用链式法则计算权重和偏置的导数：\n$$\\frac{\\partial C}{\\partial w}= (a-y)\\sigma'(z)x$$\n$$\\frac{\\partial C}{\\partial b} = (a-y)\\sigma'(z)$$\n假设我们训练输入为$x = 1$，目标输出为$y = 0$，可以看见此时输入输出差距很大，则带入：\n$$\\frac{\\partial C}{\\partial w}= a\\sigma'(z)$$\n$$\\frac{\\partial C}{\\partial b} = a\\sigma'(z)$$\n回忆一下$\\sigma$函数：\n可以看出，当神经元的输出接近于1时，曲线变得相当平缓，因此$\\sigma'(z)$就很小了。这就是学习缓慢的原因。\n交叉熵代价函数 因此，我们引入交叉熵代价函数，我们希望这个函数能弥补我们之前遇到的问题（在差距较大时学习缓慢）：\n$$C = -\\frac{1}{n}\\sum\\limits _x [y\\ln a+(1-y)\\ln (1-a)]$$\n这个函数的表达式看起来十分晦涩难懂，首先我们来看它为什么能成为一个代价函数。\nwhy cost function   $C \u0026gt; 0$\n代价函数需要满足非负性。\n在求和中，由于$y、a\\in [0,1]$，因此都是负数，在前面加上一个负号就变为正数。\n  在神经元输出接近目标值时，代价函数接近于0\n我们假设$y = 0 , a \\approx 0 $，则带入可发现$C\\approx 0$\n同样，在$y = 1,a \\approx 1$，也发现$C \\approx 0$\n因此，满足这个性质。\n  交叉熵是非负的，并且在神经元达到很好的正确率时会接近于0，这就是我们想要的代价函数的性质。\nwhy works 接下来我们就要来搞清楚为什么交叉熵代价函数能比二次代价函数更好地避免学习速率下降的问题：\n我们对其求权重$w$的偏导数：\n$$\\begin{eqnarray*} \\frac{\\partial C}{\\partial w_j} \u0026=\u0026 -\\frac{1}{n}\\sum\\limits _x [\\frac{y}{\\sigma(z)}-\\frac{(1-y)}{1-\\sigma(z)}]\\frac{d \\sigma(z)}{dz}\\frac{\\partial z}{\\partial w_j} \\\\ \u0026=\u0026 -\\frac{1}{n}\\sum\\limits _x [\\frac{y}{\\sigma(z)}-\\frac{(1-y)}{1-\\sigma(z)}]\\sigma'(z)x_j \\\\ \u0026=\u0026 \\frac{1}{n} \\sum\\limits _x \\frac {\\sigma'(z)x_j}{\\sigma(z)(1-\\sigma(z))}(\\sigma(z) - y) \\end{eqnarray*} $$ 由于我们使用sigmoid函数，因此$\\sigma(z)= 1/(1+e^{-z})$，很容易得到$\\sigma'(z) = \\sigma(z)(1-\\sigma(z))$。带入可约去：\n$$ \\frac{\\partial C}{\\partial w_j} =\\frac{1}{n} \\sum\\limits _xx_j(\\sigma(z) - y) $$\n**这是一个优美的公式，它告诉我们权重学习的速率受到$\\sigma(z)- y$的影响，也就是输出中的误差的控制：在误差较大时有更大的学习速度。**因此，这个代价函数还避免了像二次代价函数中类似$\\sigma'(z)$导致学习缓慢的问题（因为我们把它约去了）。\n类似的，我们也可以计算出关于偏置的偏导数，可以验证得到：\n$$ \\frac{\\partial C}{\\partial b} =\\frac{1}{n} \\sum\\limits _x(\\sigma(z) - y) $$\n再一次验证了交叉熵代价函数的优越性。\n这里需要注意：当我们选择不同的代价函数时，也需要选择不同的学习速率，并不能通过相同的学习速率去比较不同的代价函数。\n然而，我们比较不同的代价函数在犯错误较大时的学习速度，并不要求学习速率一定一致，因为交叉熵代价函数在犯错误时学习得更快，这个现象并不依赖于如何设置学习速率。\n二元熵 我们已经证明了当$y=0$或者$y=1$时如果有$\\sigma(z) = y$，那么交叉熵很小。但如果$y$可以取[0,1]中的所有数字呢？\n可以证明，交叉熵对所有训练输入在$\\sigma(z) \\approx y$依然有最小值。此时的交叉熵被称为二元熵（Binary entropy function）：\n$$C = -\\frac{1}{n}\\sum\\limits _x [y\\ln y+(1-y)\\ln (1-y)]$$\none more thing 我们已经推导了一层神经元的公式，现在扩展到多层多元神经网络。借用这里的公式，我们知道：\n$$\\begin{eqnarray*} \\frac {\\partial C}{\\partial w_{jk}^L} \u0026amp;=\u0026amp; a_k^{L-1}\\delta_j^L \\\\ \u0026amp;=\u0026amp; a_k^{L-1} \\frac {\\partial C}{\\partial a_j^l} \\sigma'(z_j^L) \\\\ \u0026amp;=\u0026amp; a_k^{L-1} (a_j^L - y_j)\\end{eqnarray*} $$\n这里，$\\sigma'(z)$就消失了，因此避免了学习缓慢的问题。\n可以证明，如果输出层使用线性神经元，这时候使用二次代价函数就会是不错的选择。\n直观理解 我们知道，交叉熵是来源于信息论，但我们不去追踪那些琐碎的细节，就算是从直观上，我们也能推导得到这个公式：\n我们的目的就是在进行反向传播时，计算的关于$w$和$b$的偏导能不受$\\sigma \u0026lsquo;$的影响，因此我们可以想象这样一个偏导数(不包含$\\sigma\u0026rsquo;$)：\n$$\\frac{\\partial C}{\\partial w_j} = x_j(a-y)$$\n$$\\frac{\\partial C}{\\partial b} = (a-y)$$\n如果我们选择的代价函数满足这些条件，那么他们就能以简单的方式呈现我们想要的特性：初始误差越大，神经元学习的越快。\n由链式法则：\n$$\\frac{\\partial C}{\\partial b} = \\frac{\\partial C}{\\partial a}\\sigma \u0026lsquo;(z) $$\n使用$\\sigma\u0026rsquo;(z) = \\sigma(z)(1-\\sigma(z)) = a(1-a)$\n$$\\frac{\\partial C}{\\partial b} = \\frac{\\partial C}{\\partial a} a(1-a) $$\n对比可得：\n$$\\frac{\\partial C}{\\partial a} = \\frac{a-y }{a(1-a)}$$\n对其进行积分：\n$$C = -[y\\ln a+(1-y)\\ln (1-a)]+const$$\n这就是对于一个训练样本$x$对代价函数的贡献，我们很容易推广到所有样本的平均，这就确定了交叉熵的形式。\n实现 实现就比理论简单多了，我们只需要定义这样一个函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  class CrossEntropyCost(object): @staticmethod def fn(a, y): \u0026#34;\u0026#34;\u0026#34;Return the cost associated with an output ``a`` and desired output ``y``. Note that np.nan_to_num is used to ensure numerical stability. In particular, if both ``a`` and ``y`` have a 1.0 in the same slot, then the expression (1-y)*np.log(1-a) returns nan. The np.nan_to_num ensures that that is converted to the correct value (0.0). \u0026#34;\u0026#34;\u0026#34; return np.sum(np.nan_to_num(-y*np.log(a)-(1-y)*np.log(1-a)))   softmax softmax是为神经网络定义了一种新的输出层，回想一下，我们之前的神经网络都是使用sigmoid fuction,而我们将会看见，softmax激活函数会有一些特别的好处。\n首先定义这个函数，第$j$个神经元的激活值为：\n$$a_j^L = \\frac{e^{z_j^L}}{\\sum _k e^{z^L_k}}$$\n由表达式可以看见，以前的激活值只是将输出值直接作用于sigmoid function上，而softmax函数则将激活值与所有神经元的输出值联系在一起。\n性质 概率分布函数  我们不难看出，所有神经元的激活值加起来为1：  $$\\sum\\limits _j a_j^L = \\frac{\\sum_j e^L_j}{\\sum _k e^{Z^L_k}} =1$$\n 方程同样保证了输出激活值都是正数\u0026ndash;因为指数函数都是正的。  将这两点结合起来，我们可以将softmax funciton看成是一个概率分布函数。\n这样的理解是很直观的，因为在很多问题中，能够将激活值$a_j^L$理解为正确输出为$j$的概率估计是非常方便的。\n而作为对比，如果输出层是sigmoid function，则没有这样一个关于输出激活值的简单解释。\n单调性 现在我们来考虑softmax的单调性。\n  当$j= k$时：\n$$\\frac{\\partial a_j^L}{\\partial z_k^L} = \\frac{e^{z_j^L}(\\sum e^{z_k^L})- e^{2z_j^L}}{(\\sum e^{z_k^L})^2} = a_j^L(1-a_j^L)\u0026gt;0$$\n  当$j \\ne k$时：\n$$\\frac{\\partial a_j^L}{\\partial z_k^L} = -a_j^L a_k^L \u0026lt; 0$$\n  因此，增加$z_j^L$的值会提高对应的输出激活值并降低所有其他的输出激活值。\n非局部性 sigmoid function的一个好处是对应的带权输入$a_j^L = \\sigma(z_j^L)$，然而，对应softmax active function，任何特定的输出激活值依赖于所有的带权输入。\n逆转softmax层 如果我们已知有一个使用softmax active function的神经网络，激活值$a_j^L$已知，可以由定义很容易的证明其带权输入为：\n$$z_j^L = \\ln a_j^L + C$$\n其中$C$是独立于$j$的常数。\n学习缓慢问题 我们目前只定义了一个激活函数，而我们关心这个激活函数与学习速率的关系。\n对数似然代价函数 首先定义一个对数似然代价函数(log-likehood):\n$$C = -\\ln a_y^L = - \\sum _ky_k\\log a_k$$\n其中，当$y_k$取目标值时为1，其余为0。\n对于这个函数，我们可以想象：\n 当网络表现得很好地时，估计的对应概率$a_k^L$与1非常接近，那么代价函数会很小； 当网络表现得很糟糕，则对应的概率$a_k^L$与0非常接近，那么代价函数会很大。  所以说对数似然函数也是我们满足期待的代价函数条件。\n推导 那么这个代价函数作用在softmax active function上时，表现如何呢？\n对于$b_j^L$，我们可以求偏导：\n$$\\begin{eqnarray*} \\frac{\\partial C}{\\partial b_j^L} \u0026=\u0026 \\frac{\\partial C}{\\partial z_j^L} \\frac{\\partial z_j^L}{\\partial b_j^L} \\\\ \u0026=\u0026 \\frac{\\partial C}{\\partial z_j^L} \\\\ \u0026=\u0026 -\\sum_k y_k \\frac{1}{a_k} \\frac {\\partial a_k^L}{\\partial z_j^L} \\\\ \u0026=\u0026 -y_j \\frac {1}{a_j^L} \\frac {\\partial a_j^L}{\\partial z_j^L} - \\sum_{k\\ne j} y_k \\frac {1}{a_k^L} \\frac {\\partial a_k^L}{\\partial z_j^L} \\\\ \u0026=\u0026 -y_j \\frac {1}{a_j^L} a_j^L(1-a_j^L) + \\sum_{k\\ne j} y_k \\frac {1}{a_k^L}a_j^La_k^L \\\\ \u0026=\u0026 -y_j (1-a_j^L) + \\sum_{k\\ne j} y_k a_j^L \\\\ \u0026=\u0026 -y_i + a_j^L \\sum y_k \\\\ \u0026=\u0026 a_j^L - y_i \\end{eqnarray*}$$ 同理，我们可以得到$w_j^L$的偏导： $$\\begin{eqnarray*} \\frac{\\partial C}{\\partial w_j^L} \u0026amp;=\u0026amp; \\frac{\\partial C}{\\partial z_j^L} \\frac{\\partial z_j^L}{\\partial w_j^L} \\\\ \u0026amp;=\u0026amp; \\frac{\\partial C}{\\partial z_j^L} a_k^{L-1} \\\\ \u0026amp;=\u0026amp; a_k^{L-1} (a_j^L - y_i)\\end{eqnarray*}$$\n通过推导，我们发现通过这种方法计算反向传播会异常简单。\n我们发现，用softmax active fuction + log-likehood代价函数得到的偏导和之前用corss entropy function+sigmoid function得到的式子几乎一样。我们后面会发现，这种相似性很有用。\n总之，我们验证了使用softmax fuction + log-likehood组合也能避免学习缓慢的问题。\n从一种更为通用的视角来看，虽然这两种组合在实际应用中都不错，但softmax fuction + log-likehood更适用于那些需要将输出激活值解释为概率的场景。\nwhy softmax 另外一个值得思考的问题是，为什么这个函数叫柔性最大值？\n在Quora上有一个很好地解释，简单来说，就是:\n it highlights the largest input and suppresses all the significantly smaller ones.\n 参考资料 neuralnetworksanddeeplearning\n","permalink":"https://tech.zealscott.com/deeplearning/misc/softmax/","summary":"二次代价函数 之前我们一直使用二次代价函数，貌似在一定程度上也挺work。但其实，当输入值与目标值差距很大时，二次代价函数就不是很恰当了；**这是因为当差距很大时，此函数的学习速率会很慢。**我们可以通过一个简单的例子观察这种变化：\n假设我们只使用一个神经元与一个输出神经元，定义代价函数为：\n$$C = \\frac{(y-a)^2}{2}$$\n使用链式法则计算权重和偏置的导数：\n$$\\frac{\\partial C}{\\partial w}= (a-y)\\sigma'(z)x$$\n$$\\frac{\\partial C}{\\partial b} = (a-y)\\sigma'(z)$$\n假设我们训练输入为$x = 1$，目标输出为$y = 0$，可以看见此时输入输出差距很大，则带入：\n$$\\frac{\\partial C}{\\partial w}= a\\sigma'(z)$$\n$$\\frac{\\partial C}{\\partial b} = a\\sigma'(z)$$\n回忆一下$\\sigma$函数：\n可以看出，当神经元的输出接近于1时，曲线变得相当平缓，因此$\\sigma'(z)$就很小了。这就是学习缓慢的原因。\n交叉熵代价函数 因此，我们引入交叉熵代价函数，我们希望这个函数能弥补我们之前遇到的问题（在差距较大时学习缓慢）：\n$$C = -\\frac{1}{n}\\sum\\limits _x [y\\ln a+(1-y)\\ln (1-a)]$$\n这个函数的表达式看起来十分晦涩难懂，首先我们来看它为什么能成为一个代价函数。\nwhy cost function   $C \u0026gt; 0$\n代价函数需要满足非负性。\n在求和中，由于$y、a\\in [0,1]$，因此都是负数，在前面加上一个负号就变为正数。\n  在神经元输出接近目标值时，代价函数接近于0\n我们假设$y = 0 , a \\approx 0 $，则带入可发现$C\\approx 0$\n同样，在$y = 1,a \\approx 1$，也发现$C \\approx 0$","title":"交叉熵与 softmax "},{"content":"编辑技巧  跳出括号  直接再输入一次右括号   快速换行  默认快捷键Ctrl + Enter，可以使用键盘映射将Shift + Enter转换为快速换行   选中一行  默认ctrl +i   切换显示侧边栏  默认ctrl+B   搜索  ctrl+d匹配当前词 alt+w搜索时以当前完整词 alt+c搜索时区分大小写    插件及设置  使用C/C++，将自带的代码补全关闭，下载clang以及对应的插件，设置：  \u0026quot;C_Cpp.autocomplete\u0026quot;: \u0026quot;Disabled\u0026quot;， \u0026quot;clang.executable\u0026quot;: \u0026quot;C:\\\\Program Files\\\\LLVM\\\\bin\\\\clang.exe\u0026quot;,   使用sync插件自动同步  shift + alt + U自动上传配置 shift + alt + D 自动下载配置 牢记自己的token    ","permalink":"https://tech.zealscott.com/misc/vscode/","summary":"编辑技巧  跳出括号  直接再输入一次右括号   快速换行  默认快捷键Ctrl + Enter，可以使用键盘映射将Shift + Enter转换为快速换行   选中一行  默认ctrl +i   切换显示侧边栏  默认ctrl+B   搜索  ctrl+d匹配当前词 alt+w搜索时以当前完整词 alt+c搜索时区分大小写    插件及设置  使用C/C++，将自带的代码补全关闭，下载clang以及对应的插件，设置：  \u0026quot;C_Cpp.autocomplete\u0026quot;: \u0026quot;Disabled\u0026quot;， \u0026quot;clang.executable\u0026quot;: \u0026quot;C:\\\\Program Files\\\\LLVM\\\\bin\\\\clang.exe\u0026quot;,   使用sync插件自动同步  shift + alt + U自动上传配置 shift + alt + D 自动下载配置 牢记自己的token    ","title":"VScode 使用技巧"},{"content":"引言 前馈神经网络是所有神经网络中最简单，也是最有效的一种。从单个神经元的角度看，不过就是设计权值与偏置的简单感知机运算。但到底网络是如何实现的？特别是back propagation的原理？我相信刚刚入门的很多朋友与我一样有很多疑惑，但又不想总是调包，那么我们就慢慢推导公式吧。\n需要准备  良好的线性代数知识，特别是矩阵的运算。 微积分知识，特别是偏导和链式公式的应用。 基本的python技巧。  符号说明 $w_{jk}^{l}$:表示从$（l-1）$层的第$k$个神经元到第$l$层的第$j$个神经元的连接上的权重。虽然从直观上不太好理解为什么要这样表示（通常应该表示为$w_{kj}^{l}$），但请先接受这种写法。可以对相邻两层的所有权重用矩阵的形式表示为$w^l$。\n$\\sigma $：表示激活函数，本文都使用Sigmoid function。\n$b_{j}^{l}$：表示第$l$层$j$神经元的偏置，可以对同一层的神经元表示为$b^l$，记为偏置向量。\n$a_{j}^l$：表示第$l$层$j$神经元的激活值，可以对同一层的神经元表示为$a^l$，记为激活向量。 由BP神经网络的定义可得：$a^l = \\sigma (w^la^{l-1}+b^l)$。\n$z^l$：表示带权输入，$z^l = w^la^{l-1}+b^l\\quad a^l = \\sigma(z^l)$。\n$C$ ：表示代价函数，定义为$C = \\frac {1}{2n} \\sum ||y(x) - a^L(x)||^2$，其中$y(x)$表示每个样本的真实输出，$L$表示神经网络的总层数。\n代价函数 BP神经网络的向前传播很简单，就使用之前提到的矩阵形式就可以计算，当我们初始化所有权重和偏置时，得到的结果输出与目标输出肯定有较大差距，我们使用代价函数来度量这种差距。定义如下：\n$$C = \\frac {1}{2n} \\sum ||y(x) - a^L(x)||^2$$\n那么，当输入和输出固定时，$C$就是关于$w和b$的函数，我们需要对其进行求偏导，以此来更新代价函数。\n我们需要对代价函数进行如下定义（假设）：\n 代价函数可以写成一个在每个训练样本$x$上的代价函数$C_x$的均值$C = \\frac{1}{n}\\sum _xC_x$。 将$C$仅看成输出激活值$a^L$的函数。  以下公式，不加说明，$C$都指特定的$C_x$。\n反向传播的四个方程 反向传播其实就是对权重和偏置变化影响函数过程的理解。最终就是需要计算$\\frac{\\partial C}{\\partial w_{jk}^{l}}和 \\frac{\\partial C}{\\partial b_{j}^{l}}$。\n我们首先定义一个中间量$\\delta_j^l = \\frac{\\partial C}{\\partial z_{j}^{l}} $，表示为第$l层第j$个神经元的误差，然后将$\\delta_j^l $关联到$\\frac{\\partial C}{\\partial w_{jk}^{l}}和 \\frac{\\partial C}{\\partial b_{j}^{l}}$。\n这里可能会感到疑惑，为什么会定义这样一个误差呢？ 我们想象，当在一个神经元的带权输入上增加一个很小的变化$\\Delta z_j^l$，使得神经元输出由$\\sigma (z_j^l)$变为$\\sigma (z_j^l + \\Delta z_j^l)$，那么这个变化将会向网络后面的层进行传播，最终导致整个代价产生$\\frac{\\partial C}{\\partial z_{j}^{l}}\\Delta z_j^l$的变化。因此，这里有一种启发式的认识，$\\frac{\\partial C}{\\partial z_{j}^{l}}$是神经元误差的度量：\n$$\\delta_j^l = \\frac{\\partial C}{\\partial z_{j}^{l}} $$\n在给出方程严谨的证明前，我们不妨从直观上看一下这些方程，这有助于我们的进一步理解。\n 输出层误差方程：  $$\\delta _j^L =\\frac{\\partial C}{\\partial a_j^L} {\\sigma}' (z^L_j)$$ 右边的第一个项$\\frac{\\partial C}{\\partial a_j^L}$表示代价随着第$j$个输出激活值的变化而变化的速度。第二项刻画了在$z_j^l$处激活函数$\\sigma $变化的速度，可以理解为$\\Delta a_j^l$。 注意到这个式子的每一部分都是很好计算的。我们如果已知了一个代价函数和激活函数，那么在前向传播中就可以算得每一个$\\delta _j^L$。 用矩阵的形式表示第一个式子则更加简单和美妙，注意$\\odot$表示矩阵对应元素相乘： $$\\delta ^L = \\nabla_aC\\odot {\\sigma}' (z^L)$$   使用下一层的误差来表示当前层的误差：  $$\\delta^l = ((w^{l+1})^T\\delta^{l+1})\\odot {\\sigma}'(z^l)$$ 当我们知道$l+1$层的误差$\\delta^{l+1}$，当我们应用转置的权重矩阵$(w^{l+1})^T$，我们可以凭直觉理解为它是沿着网络反向移动误差，给我们度量在$l$层输出误差的计算方法。 然后，使用hadamard乘积运算，让误差通过$l$层的激活函数反向传递回来并给出在第$l$层带权输入的误差$\\delta$。 通过组合前两个公式，我们可以计算出任意一层的带权输入误差。   代价函数关于网络中任意偏置的改变率：  $$\\frac{\\partial C}{\\partial b_j^i} = \\delta _j^l$$ 通过这个方程我们发现，我们需要计算的$\\frac{\\partial C}{\\partial b_j^i} $与$\\delta _j^l$完全一致。   代价函数关于任何一个权重的改变率：  $$\\frac{\\partial C}{\\partial w_{jk}^i} = a_k^{l-1}\\delta_j^l$$ 这告诉我们如何求$\\frac{\\partial C}{\\partial w_{jk}^i} $。其中$a_k^{l-1}和\\delta_j^l$我们都已经知道如何计算了，便于理解，我们可以将其化简为： $$\\frac{\\partial C}{\\partial w} = a_{in} \\delta_{out}$$ 我们发现，当激活值$a_{in}$很小时，$\\frac{\\partial C}{\\partial w} $也会变得很小。这时候，我们就说权重缓慢学习，表示在进行梯度下降时，这个权重不会改变太多。    通过之前的式子，我们可以发现，如果输入神经元激活值很低，或者输出神经元已经饱和了，权重会学习的非常缓慢。这可以帮助我们选择激活函数。例如，我们可以选择一个不是sigmoid函数的激活函数，使得${\\sigma}'$总是证书，不会趋近于0，这样会防止原始的S型神经元饱和时学习速率下降的情况。\n四个基本方程的推导 总结下来一共有四个重要公式：\n $\\boldsymbol {\\delta ^L = \\nabla_aC\\odot {\\sigma}' (z^L)}$  $$\\because \\delta_j^L = \\frac{\\partial C}{\\partial z_{j}^{L}} $$ $$\\therefore \\delta_j^L =\\sum\\limits _k \\frac{\\partial C}{\\partial a_k^L} \\frac {\\partial a_k^L}{\\partial z_{j}^{L}} = \\frac{\\partial C}{\\partial a_j^L} \\frac {\\partial a_j^L}{\\partial z_{j}^{L}} = \\frac{\\partial C}{\\partial a_j^L} {\\sigma}' (z^L_j)$$   $\\boldsymbol {\\delta^l = ((w^{l+1})^T\\delta^{l+1})\\odot {\\sigma}'(z^l)}$  $$\\because \\delta_j^l = \\frac{\\partial C}{\\partial z_{j}^{l}} = \\sum\\limits _k \\frac{\\partial C}{\\partial z_{k}^{l+1}} \\frac{\\partial z_k^{l+1}}{\\partial z_{j}^{l}}，表示这一层的神经元对下一层都有影响$$ $$\\therefore \\delta_j^l = \\sum\\limits _k\\delta_k^{l+1} \\frac{\\partial z_k^{l+1}}{\\partial z_{j}^{l}}$$ $$\\because z_k^{l+1} =\\sum\\limits_j w_{kj}^{l+1}\\sigma(z_j^l) + b_k^{l+1}$$ $$\\therefore \\frac {\\partial z_k^{l+1}}{\\partial z_j^l} = w_{kj}^{l+1}{\\sigma}'(z_j^l)$$ $$带入可得：\\delta_j^l = \\sum\\limits _k\\delta_k^{l+1} w_{kj}^{l+1}{\\sigma}'(z_j^l)$$   $\\boldsymbol {\\frac{\\partial C}{\\partial b_j^i} = \\delta _j^l}$  $$\\because b_k^l = z_k^l - \\sum\\limits _j w_{kj}^l\\sigma(z_j^{l-1})$$ $$\\therefore \\delta_j^l = \\frac{\\partial C}{\\partial z_{j}^{l}} = \\frac{\\partial C}{\\partial b_j^l} \\frac{\\partial b_j^l}{\\partial z_j^l} = \\frac{\\partial C}{\\partial b_j^l}$$   $\\boldsymbol {\\frac{\\partial C}{\\partial w_{jk}^i} = a_k^{l-1}\\delta_j^l}$  $$\\because z_j^l = \\sum\\limits _k w_{jk}^l a_k^{l-1} + b_j^l$$ $$\\therefore \\frac {\\partial z_j^l}{\\partial w_{jk}^l} = a_k^{l-1} \\Rightarrow \\frac {\\partial C}{\\partial z_j^l} \\frac {\\partial z_j^l}{\\partial w_{jk}^l} = a_k^{l-1} \\frac {\\partial C}{\\partial z_{j}^l}$$ $$\\therefore \\frac{\\partial C}{\\partial w_{jk}^i} = a_k^{l-1}\\sigma _j^l$$    首先我们可以通过第一个公式算出$\\delta ^L$，然后利用第二个公式的递推关系可以算出所有的$\\delta$，这样，我们就可以很轻松的算出我们想要的每一个$\\frac{\\partial C}{\\partial b_j^i} 以及\\frac{\\partial C}{\\partial w_{jk}^i}$。\n在反向传播中，为了减少计算量，很常见的方法是使用随机梯度下降。思想也很简单，每一个样本都需要进行参与求导实在是计算量太大，但我们可以只去一小部分来进行更新权重，多算几次取平均。\n总结 我们使用Mini-batch BGD来进行BP神经网络训练，具体步骤为：\n 输入训练样本集合 对每个训练样本$x$：设置对应的输入激活$a_x^{1}$，并进行：  前向传播：对每个$l = 2,3,4\u0026hellip;,L$,计算$z_x^{l}$ 输出误差$\\sigma _x^{l } = \\nabla_aCx\\odot {\\sigma}' (z_x^L)$ 反向转播误差：对每个$l = L-1,L-2,\u0026hellip;,2$，计算$\\delta_x^l = ((w^{l+1})^T\\delta_x^{l+1})\\odot {\\sigma}'(z_x^l)$   梯度下降：根据$w^l \\rightarrow w^l - \\frac {\\eta}{m}\\sum _x\\delta_x^l(a_x^{l-1})^T$和$b^l \\rightarrow b^l - \\frac {\\eta}{m}\\sum _x\\delta_x^l $更新权值和偏置。  反向传播到底在干什么？ 首先，反向传播算法加速了神经网络的学习。设想，我们如果只按照最基本的思路计算权重：\n$$\\frac {\\partial C}{\\partial w_j} \\approx \\frac{C(w+\\epsilon e_j)- C(w)}{\\epsilon }$$\n那么，我们可以使用两个相近的权重来估计$\\frac {\\partial C}{\\partial w_j}$。但如果我们这样做，需要对每个权重进行前向传播估算，计算量是非常大的。\n反向传播聪明的地方就是它确保我们可以同时计算所有的偏导数$\\frac {\\partial C}{\\partial w_j}$因此，比起直接计算导数，显然反向传播有着更大优势。\n参考资料 neuralnetworksanddeeplearning\n","permalink":"https://tech.zealscott.com/deeplearning/misc/fnn/","summary":"引言 前馈神经网络是所有神经网络中最简单，也是最有效的一种。从单个神经元的角度看，不过就是设计权值与偏置的简单感知机运算。但到底网络是如何实现的？特别是back propagation的原理？我相信刚刚入门的很多朋友与我一样有很多疑惑，但又不想总是调包，那么我们就慢慢推导公式吧。\n需要准备  良好的线性代数知识，特别是矩阵的运算。 微积分知识，特别是偏导和链式公式的应用。 基本的python技巧。  符号说明 $w_{jk}^{l}$:表示从$（l-1）$层的第$k$个神经元到第$l$层的第$j$个神经元的连接上的权重。虽然从直观上不太好理解为什么要这样表示（通常应该表示为$w_{kj}^{l}$），但请先接受这种写法。可以对相邻两层的所有权重用矩阵的形式表示为$w^l$。\n$\\sigma $：表示激活函数，本文都使用Sigmoid function。\n$b_{j}^{l}$：表示第$l$层$j$神经元的偏置，可以对同一层的神经元表示为$b^l$，记为偏置向量。\n$a_{j}^l$：表示第$l$层$j$神经元的激活值，可以对同一层的神经元表示为$a^l$，记为激活向量。 由BP神经网络的定义可得：$a^l = \\sigma (w^la^{l-1}+b^l)$。\n$z^l$：表示带权输入，$z^l = w^la^{l-1}+b^l\\quad a^l = \\sigma(z^l)$。\n$C$ ：表示代价函数，定义为$C = \\frac {1}{2n} \\sum ||y(x) - a^L(x)||^2$，其中$y(x)$表示每个样本的真实输出，$L$表示神经网络的总层数。\n代价函数 BP神经网络的向前传播很简单，就使用之前提到的矩阵形式就可以计算，当我们初始化所有权重和偏置时，得到的结果输出与目标输出肯定有较大差距，我们使用代价函数来度量这种差距。定义如下：\n$$C = \\frac {1}{2n} \\sum ||y(x) - a^L(x)||^2$$\n那么，当输入和输出固定时，$C$就是关于$w和b$的函数，我们需要对其进行求偏导，以此来更新代价函数。\n我们需要对代价函数进行如下定义（假设）：\n 代价函数可以写成一个在每个训练样本$x$上的代价函数$C_x$的均值$C = \\frac{1}{n}\\sum _xC_x$。 将$C$仅看成输出激活值$a^L$的函数。  以下公式，不加说明，$C$都指特定的$C_x$。\n反向传播的四个方程 反向传播其实就是对权重和偏置变化影响函数过程的理解。最终就是需要计算$\\frac{\\partial C}{\\partial w_{jk}^{l}}和 \\frac{\\partial C}{\\partial b_{j}^{l}}$。\n我们首先定义一个中间量$\\delta_j^l = \\frac{\\partial C}{\\partial z_{j}^{l}} $，表示为第$l层第j$个神经元的误差，然后将$\\delta_j^l $关联到$\\frac{\\partial C}{\\partial w_{jk}^{l}}和 \\frac{\\partial C}{\\partial b_{j}^{l}}$。","title":"前馈神经网络原理与实现"},{"content":"准备工作  Sublime Text3 安装并配置好Package Control，若没有安装也没关系，我已经把常用的插件都放到了我的GitHub，可以按照说明复制到指定路径即可。 MiKTeX,下载并安装。 LaTeXTools(后面会有安装介绍) Sumatra PDF，下载并安装。  LaTeXTools 安装 最简单的方法是直接fork我的GitHub，按照ReadMe文件中的指示复制到指定路径。 或者使用Package Control，按组合键Ctrl+Shift+P，然后再输入install，选择 Package Control: install package。进入库后，搜索LaTeXTools，直接回车即可安装。\n配置 重启sublime text3，按组合键Ctrl+Shift+P，然后再输入LaTeXTools：Reset user settings to default，回车。再在 Sublime Text3 的安装路径中找LaTeXTools.sublime-settings文件，例如，我的默认的文件路径为C:\\Users\\scott\\AppData\\Roaming\\Sublime Text 3\\Packages\\User。打开文件，搜索关键词texpath，再输入\n \u0026ldquo;texpath\u0026rdquo; : \u0026ldquo;C:\\Program Files\\MiKTeX 2.9\\miktex\\bin\\x64;$PATH\u0026rdquo;,\n 如图所示： 配置SumatraPDF 添加环境变量 打开环境变量设置，在user的环境变量中添加SumatraPDF 的主程序目录，如图所示： 配置反向搜索 打开命令提示符（win+R），执行以下命令：（将其中的安装路径替换成你实际的安装路径）\n sumatrapdf.exe -inverse-search \u0026ldquo;\u0026quot;C:\\Program Files\\Sublime Text 3\\sublime_text.exe\u0026quot; \u0026quot;%f:%l\u0026quot;\u0026rdquo;\n 使用 自动补全 现在环境已经基本配置好了。但我们习惯了自动补全，没有自动补全哪行。因此在 Sublime Text3 中，Preference-settings-user，添加\n \u0026ldquo;auto_complete_selector\u0026rdquo;: \u0026ldquo;source, text\u0026rdquo;,\n 即可实现自动补全。\n中文支持 在.tex文件的开头，加上\\documentclass[UTF8]{ctexart}，即可实现中文支持。第一次编译可能需要下载安装支持包，一直continue即可。\n使用和编译 每次在 Sublime Text3 中新建文件，保存为.tex格式，写完之后保存（新建的文件一定要先保存），然后按下快捷键Ctrl+B，Sublime Text3 就会自动调用 LaTeXTools 的 build 系统来进行编译，然后自动打开 SumatraPDF 进行预览。之后每次修改后只要Ctrl+B 一下，SumatraPDF 里的内容就会自动更新。 现在，就可以使用我们熟悉的 Sublime Text3 写LaTex啦。\n","permalink":"https://tech.zealscott.com/misc/sublime/","summary":"准备工作  Sublime Text3 安装并配置好Package Control，若没有安装也没关系，我已经把常用的插件都放到了我的GitHub，可以按照说明复制到指定路径即可。 MiKTeX,下载并安装。 LaTeXTools(后面会有安装介绍) Sumatra PDF，下载并安装。  LaTeXTools 安装 最简单的方法是直接fork我的GitHub，按照ReadMe文件中的指示复制到指定路径。 或者使用Package Control，按组合键Ctrl+Shift+P，然后再输入install，选择 Package Control: install package。进入库后，搜索LaTeXTools，直接回车即可安装。\n配置 重启sublime text3，按组合键Ctrl+Shift+P，然后再输入LaTeXTools：Reset user settings to default，回车。再在 Sublime Text3 的安装路径中找LaTeXTools.sublime-settings文件，例如，我的默认的文件路径为C:\\Users\\scott\\AppData\\Roaming\\Sublime Text 3\\Packages\\User。打开文件，搜索关键词texpath，再输入\n \u0026ldquo;texpath\u0026rdquo; : \u0026ldquo;C:\\Program Files\\MiKTeX 2.9\\miktex\\bin\\x64;$PATH\u0026rdquo;,\n 如图所示： 配置SumatraPDF 添加环境变量 打开环境变量设置，在user的环境变量中添加SumatraPDF 的主程序目录，如图所示： 配置反向搜索 打开命令提示符（win+R），执行以下命令：（将其中的安装路径替换成你实际的安装路径）\n sumatrapdf.exe -inverse-search \u0026ldquo;\u0026quot;C:\\Program Files\\Sublime Text 3\\sublime_text.exe\u0026quot; \u0026quot;%f:%l\u0026quot;\u0026rdquo;\n 使用 自动补全 现在环境已经基本配置好了。但我们习惯了自动补全，没有自动补全哪行。因此在 Sublime Text3 中，Preference-settings-user，添加\n \u0026ldquo;auto_complete_selector\u0026rdquo;: \u0026ldquo;source, text\u0026rdquo;,\n 即可实现自动补全。\n中文支持 在.tex文件的开头，加上\\documentclass[UTF8]{ctexart}，即可实现中文支持。第一次编译可能需要下载安装支持包，一直continue即可。\n使用和编译 每次在 Sublime Text3 中新建文件，保存为.","title":"在 Sublime Text3 中配置并使用 LaTex "},{"content":"环境要求 已经能正常使用和deploy的hexo仓库，一个GitHub账号，对Git使用较为熟悉。\n使用网盘同步 最简单的方式其实就是直接把你博客的文件夹保存在网盘中，可自动实现同步。推荐使用OneDrive或者Google Drive。当需要使用新设备写作时，可直接复制这个文件夹，然后安装node.js和hexo即可。\n这种方法的好处当然是简单直观，但无法做到版本同步，作为计算机的学生，怎么能不使用GitHub进行同步呢~\n使用GitHub进行同步 使用分支搭建博客 其实，Hexo生成的网站文件中有.gitignore文件，因此它的本意也是想我们将Hexo生成的网站文件存放到GitHub上进行管理。\n博客搭建流程：\n  创建仓库，youraccount.github.io\n  创建两个分支：master 与 hexo\n  设置hexo为默认分支（因为我们只需要手动管理这个分支上的Hexo网站文件，master分支为hexo deploy自动生成和管理）\n  使用git clone git@github.com:youraccount/youraccount.github.io.git拷贝仓库\n  在本地youraccount.github.io文件夹下通过Git bash依次执行npm install hexo、hexo init、npm install 和 npm install hexo-deployer-git（此时当前分支应显示为hexo）\n  修改_config.yml中的deploy参数，分支应为master\n  依次执行git add .、git commit -m “…”、git push origin hexo提交网站相关的文件\n  执行hexo generate -d生成网站并部署到GitHub上\n  这样一来，在GitHub上的youraccount.github.io仓库就有两个分支，一个hexo分支用来存放网站的原始文件，一个master分支用来存放生成的静态网页\n在新设备中安装node.js和Git 无需多说，直接点击链接安装：node.js，Git。\n给新设备添加SSH KEYS 在Git Bash中输入：\n ssh-keygen -t rsa -C \u0026ldquo;你的邮箱地址\u0026rdquo;\n 按三次回车（密码为空），生成密匙。\n在C:\\Users\\Administrator.ssh中（Administrator为自己对应的管理员账号），得到两个文件，分别为id_rsa和id_rsa.pub。\n打开id_rsa.pub，复制全文。进入GitHub中的SSH设置 ，Add SSH key，粘贴进去。\n新设备同步 使用git clone git@github.com:youraccount/youraccount.github.io.git拷贝仓库（默认分支为hexo） 在本地得到的youraccount.github.io文件夹下通过Git bash依次执行下列指令：\nnpm install -g hexo、npm install、npm install hexo-deployer-git即可将最新的博客文件全部同步。\n日常维护 在本地对博客进行修改（添加新博文、修改样式等等）后，通过下面的流程进行管理：\n  依次执行git add .、git commit -m “…”、git push origin hexo指令将改动推送到GitHub（此时当前分支应为hexo）\n  执行hexo generate -d发布网站到master分支上\n  参考资料 GitHub Pages + Hexo搭建博客\n知乎讨论\n","permalink":"https://tech.zealscott.com/misc/hexo-sync/","summary":"环境要求 已经能正常使用和deploy的hexo仓库，一个GitHub账号，对Git使用较为熟悉。\n使用网盘同步 最简单的方式其实就是直接把你博客的文件夹保存在网盘中，可自动实现同步。推荐使用OneDrive或者Google Drive。当需要使用新设备写作时，可直接复制这个文件夹，然后安装node.js和hexo即可。\n这种方法的好处当然是简单直观，但无法做到版本同步，作为计算机的学生，怎么能不使用GitHub进行同步呢~\n使用GitHub进行同步 使用分支搭建博客 其实，Hexo生成的网站文件中有.gitignore文件，因此它的本意也是想我们将Hexo生成的网站文件存放到GitHub上进行管理。\n博客搭建流程：\n  创建仓库，youraccount.github.io\n  创建两个分支：master 与 hexo\n  设置hexo为默认分支（因为我们只需要手动管理这个分支上的Hexo网站文件，master分支为hexo deploy自动生成和管理）\n  使用git clone git@github.com:youraccount/youraccount.github.io.git拷贝仓库\n  在本地youraccount.github.io文件夹下通过Git bash依次执行npm install hexo、hexo init、npm install 和 npm install hexo-deployer-git（此时当前分支应显示为hexo）\n  修改_config.yml中的deploy参数，分支应为master\n  依次执行git add .、git commit -m “…”、git push origin hexo提交网站相关的文件\n  执行hexo generate -d生成网站并部署到GitHub上\n  这样一来，在GitHub上的youraccount.github.io仓库就有两个分支，一个hexo分支用来存放网站的原始文件，一个master分支用来存放生成的静态网页\n在新设备中安装node.js和Git 无需多说，直接点击链接安装：node.js，Git。\n给新设备添加SSH KEYS 在Git Bash中输入：\n ssh-keygen -t rsa -C \u0026ldquo;你的邮箱地址\u0026rdquo;","title":"Hexo 多设备同步与版本控制实现"},{"content":"配置信息 这是我的hexo版本和package信息(与LaTeX相关)：\n1 2 3  \u0026#34;hexo\u0026#34;: \u0026#34;^3.5.0\u0026#34;, \u0026#34;hexo-math\u0026#34;: \u0026#34;^3.0.4\u0026#34;, \u0026#34;hexo-renderer-kramed\u0026#34;: \u0026#34;^0.1.4\u0026#34;,   安装插件 首先我们需要安装Mathjax插件\n npm install hexo-math \u0026ndash;save\n 更换Hexo的markdown渲染引擎，hexo-renderer-kramed引擎是在默认的渲染引擎hexo-renderer-marked的基础上修改了一些bug，两者比较接近，也比较轻量级。\n npm uninstall hexo-renderer-marked \u0026ndash;save npm install hexo-renderer-kramed \u0026ndash;save\n 解决语义冲突 由于LaTeX与markdown语法有语义冲突，在markdown中，斜体和加粗可以用*或者_表示，在这里我们修改变量，将_用于LaTeX，而使用*表示markdown中的斜体和加粗。 在博客根目录下，进入node_modules\\kramed\\lib\\rules\\inline.js，把第11行的escape变量的值做相应的修改：\n1 2  escape: /^\\\\([\\\\`*{}\\[\\]()#$+\\-.!_\u0026gt;])/, escape: /^\\\\([`*\\[\\]()#$+\\-.!_\u0026gt;])/,   这一步是在原基础上取消了对,{,}的转义(escape)。 同时把第20行的em变量也要做相应的修改:\n1 2  // em: /^\\b_((?:__|[\\s\\S])+?)_\\b|^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/, em: /^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/,   更改配置文件 这里是最重要的一步，我找了好久才在这个网站中找到适用的解决办法。 进入到主题目录，找到_config.yml配置问题，把mathjax默认的false修改为true，并更换cdn的url，具体如下：\n1 2 3 4 5 6  # MathJax Support mathjax: enable: true per_page: true #cdn: //cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML cdn: //cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML   写博客 在每次需要用LaTeX渲染的博文中，在文章的Front-matter里打开mathjax开关，具体如下：\n1 2 3 4 5 6  --- title: index.html date: 2018-2-8 21:01:30 tags: mathjax: true --   测试 输入：\n1  $$lim_{1\\to+\\infty}P(|\\frac{1}{n}\\sum_i^nX_i-\\mu|\u0026lt;\\epsilon)=1, i=1,...,n$$   $$lim_{1\\to+\\infty}P(|\\frac{1}{n}\\sum_i^nX_i-\\mu|\u0026lt;\\epsilon)=1, i=1,\u0026hellip;,n$$ 看是否能正常显示。\n","permalink":"https://tech.zealscott.com/misc/hexo-latex/","summary":"配置信息 这是我的hexo版本和package信息(与LaTeX相关)：\n1 2 3  \u0026#34;hexo\u0026#34;: \u0026#34;^3.5.0\u0026#34;, \u0026#34;hexo-math\u0026#34;: \u0026#34;^3.0.4\u0026#34;, \u0026#34;hexo-renderer-kramed\u0026#34;: \u0026#34;^0.1.4\u0026#34;,   安装插件 首先我们需要安装Mathjax插件\n npm install hexo-math \u0026ndash;save\n 更换Hexo的markdown渲染引擎，hexo-renderer-kramed引擎是在默认的渲染引擎hexo-renderer-marked的基础上修改了一些bug，两者比较接近，也比较轻量级。\n npm uninstall hexo-renderer-marked \u0026ndash;save npm install hexo-renderer-kramed \u0026ndash;save\n 解决语义冲突 由于LaTeX与markdown语法有语义冲突，在markdown中，斜体和加粗可以用*或者_表示，在这里我们修改变量，将_用于LaTeX，而使用*表示markdown中的斜体和加粗。 在博客根目录下，进入node_modules\\kramed\\lib\\rules\\inline.js，把第11行的escape变量的值做相应的修改：\n1 2  escape: /^\\\\([\\\\`*{}\\[\\]()#$+\\-.!_\u0026gt;])/, escape: /^\\\\([`*\\[\\]()#$+\\-.!_\u0026gt;])/,   这一步是在原基础上取消了对,{,}的转义(escape)。 同时把第20行的em变量也要做相应的修改:\n1 2  // em: /^\\b_((?:__|[\\s\\S])+?)_\\b|^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/, em: /^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/,   更改配置文件 这里是最重要的一步，我找了好久才在这个网站中找到适用的解决办法。 进入到主题目录，找到_config.yml配置问题，把mathjax默认的false修改为true，并更换cdn的url，具体如下：\n1 2 3 4 5 6  # MathJax Support mathjax: enable: true per_page: true #cdn: //cdn.","title":"Hexo 下 LaTeX 无法显示的解决方案"},{"content":"由于经常要写同一类型的文章，懒得每篇文章都添加同样的tags和categories，因此可使用scaffolds创建模板，每次只需要hexo new layout \u0026quot;标题\u0026quot;即可生成相同样式的文章。\n但近期使用时发现一些问题，如下图所示，我创建了一个名为Hexo的模板，并正确放到scaffolds中： 然后再git中输入： 到这一步都没有任何问题，但当我们查看文章时，发现并没有生成我们想要的tags和categories，而是多了一个layout，这不是我们想要的。 后来发现，在scaffolds中创建模板时，模板标题不能为大写，中文也可以，但就是不能大写，不知道为什么，先占个坑，望有同样问题的同学能看见这篇文章。\n","permalink":"https://tech.zealscott.com/misc/hexo-scaffolds/","summary":"由于经常要写同一类型的文章，懒得每篇文章都添加同样的tags和categories，因此可使用scaffolds创建模板，每次只需要hexo new layout \u0026quot;标题\u0026quot;即可生成相同样式的文章。\n但近期使用时发现一些问题，如下图所示，我创建了一个名为Hexo的模板，并正确放到scaffolds中： 然后再git中输入： 到这一步都没有任何问题，但当我们查看文章时，发现并没有生成我们想要的tags和categories，而是多了一个layout，这不是我们想要的。 后来发现，在scaffolds中创建模板时，模板标题不能为大写，中文也可以，但就是不能大写，不知道为什么，先占个坑，望有同样问题的同学能看见这篇文章。","title":"Hexo 中 scaffolds 创建模板问题"},{"content":"配置环境 首先安装transmission：\n sudo apt-get install transmission-daemon\n 然后创建下载目录，一个是下载完成的目录（complete），一个是未完成的目录（incomplete），不建议将移动硬盘长时间挂载在树莓派上运行\n1 2  mkdir -p /home/pi/incomplete # for incomplete downloads mkdir /home/pi/complete # finished downloads   设置权限\n1 2 3 4 5  sudo usermod -a -G debian-transmission pi sudo chgrp debian-transmission /home/pi/incomplete sudo chgrp debian-transmission /home/pi/complete chmod 770 /home/pi/incomplete chmod 770 /home/pi/complete   修改配置文件,配置文件目录为\n vim /etc/transmission-daemon/settings.json\n 打开文件如图所示 修改其中的三项即可，分别为：\n1 2 3  \u0026#34;download-dir\u0026#34;: \u0026#34;/home/pi/complete\u0026#34;, \u0026#34;incomplete-dir\u0026#34;: \u0026#34;/home/pi/incomplete\u0026#34;, \u0026#34;rpc-whitelist\u0026#34;: \u0026#34;192.168.0.*\u0026#34;,   其中第三项为设置白名单，根据自己实际的IP地址设置。 配置好之后重启 transmission：\n1 2  sudo service transmission-daemon reload sudo service transmission-daemon restart   开始使用 在浏览器中访问IP加9091端口，比如：http://192.168.0.200:9091。 访问时输入用户名和密码，默认都是：transmission。 进入之后点击upload，即可顺利下载。 ","permalink":"https://tech.zealscott.com/misc/bt-downloader/","summary":"配置环境 首先安装transmission：\n sudo apt-get install transmission-daemon\n 然后创建下载目录，一个是下载完成的目录（complete），一个是未完成的目录（incomplete），不建议将移动硬盘长时间挂载在树莓派上运行\n1 2  mkdir -p /home/pi/incomplete # for incomplete downloads mkdir /home/pi/complete # finished downloads   设置权限\n1 2 3 4 5  sudo usermod -a -G debian-transmission pi sudo chgrp debian-transmission /home/pi/incomplete sudo chgrp debian-transmission /home/pi/complete chmod 770 /home/pi/incomplete chmod 770 /home/pi/complete   修改配置文件,配置文件目录为\n vim /etc/transmission-daemon/settings.json\n 打开文件如图所示 修改其中的三项即可，分别为：\n1 2 3  \u0026#34;download-dir\u0026#34;: \u0026#34;/home/pi/complete\u0026#34;, \u0026#34;incomplete-dir\u0026#34;: \u0026#34;/home/pi/incomplete\u0026#34;, \u0026#34;rpc-whitelist\u0026#34;: \u0026#34;192.","title":"树莓派之BT下载器"},{"content":"首先打开树莓派的命令行，输入：\n sudo vi /etc/dhcpcd.conf\n 即可用vi编辑配置文件。\n在文件末尾输入：\n1 2 3 4 5 6 7 8 9 10 11  interface eth0 static ip_address=192.168.0.10/24 static routers=192.168.0.1 static domain_name_servers=192.168.0.1 interface wlan0 static ip_address=192.168.0.200/24 static routers=192.168.0.1 static domain_name_servers=192.168.0.1   其中，eth0是有线的配置，wlan0是无线配置\nip_address就是静态IP，后面要接/24\nrouters是网关\nstatic domain_name_servers是DNS\n然后再在命令行执行\n sudo reboot\n 重启树莓派，即可根据树莓派的联网方式用静态IP连接。\n","permalink":"https://tech.zealscott.com/misc/static-ip/","summary":"首先打开树莓派的命令行，输入：\n sudo vi /etc/dhcpcd.conf\n 即可用vi编辑配置文件。\n在文件末尾输入：\n1 2 3 4 5 6 7 8 9 10 11  interface eth0 static ip_address=192.168.0.10/24 static routers=192.168.0.1 static domain_name_servers=192.168.0.1 interface wlan0 static ip_address=192.168.0.200/24 static routers=192.168.0.1 static domain_name_servers=192.168.0.1   其中，eth0是有线的配置，wlan0是无线配置\nip_address就是静态IP，后面要接/24\nrouters是网关\nstatic domain_name_servers是DNS\n然后再在命令行执行\n sudo reboot\n 重启树莓派，即可根据树莓派的联网方式用静态IP连接。","title":"树莓派设置静态IP地址"},{"content":"配置环境 首先要在个人电脑中装上PyCharm，注意，一定要是专业版的。 树莓派需已经设置好联网和SSH，并与电脑处于同一局域网下。 本文所有代码均为python3.x下可用，python2.x略有不同。\n写测试代码 首先在个人电脑中建立一个工程，写一个tkinter程序（注意文件名不可为tkinter），并在本机上测试运行。代码如下：\n1 2 3  import tkinter a = tkinter.Tk() a.mainloop()   运行成功后可以看见一个标题为Tk()的窗口。\n配置PyCharm环境 使用SSH连接树莓派 进入之前新建的python文件下，依次打开File -\u0026gt; Settings -\u0026gt; Project Interpreter，点旁边的小齿轮，选择Add Romote,进入环境配置。 选择SSH Credentials，Host中填写树莓派的IP地址，User name 和 Password默认为pi 和 raspberry，注意，选择Python interpreter path时，如果想使用python3版本，请务必按照截图输入，若为python2版本，则去掉后面的版本号即可。最后点击ok完成设置。 配置上传路径 依次打开Tool -\u0026gt; Deployment -\u0026gt; Configure,在打开的页面中Type选择SFTP协议，然后继续填写树莓派的IP地址以及用户名和密码，其余默认。 点开Mapping选项卡，配置工程目录，这里主要是设置Deployment path on server，该选项会将电脑上的文件上传到树莓派的对应位置，一般建议目录为/Desktop/py，其他可以默认，点击ok完成配置。\n上传工程 依次点击Tool -\u0026gt; Upload to xxx,点击调试按钮自动安装调试插件，安装完成后自动开始调试。 这时候你就可以看见你的工程已经自动上传到树莓派中。\n运行程序 如果直接运行程序，也许你会发现有如下错误： 这是由于远程调试不是在桌面环境下进行的。程序不知道我们使用了显示设备，这个时候就需要手动指定显示设备。 因此，我们打开树莓派的命令行，输入\n printenv grep DISPLAY\n 本机显示结果为 复制这行字符，然后再该文件中添加这个参数如下：\n1 2 3  import tkinter a = tkinter.Tk(screenName=\u0026#39;:1.0\u0026#39;)#树莓派默认显示设备 a.mainloop()   点击运行按钮，即可在树莓派中看见新的窗口，表明成功运行。 因此，每次在电脑上写好python文件后，先保存，然后再上传到树莓派，再运行，即可在树莓派中看到运行结果。\n","permalink":"https://tech.zealscott.com/misc/raspberry-python/","summary":"配置环境 首先要在个人电脑中装上PyCharm，注意，一定要是专业版的。 树莓派需已经设置好联网和SSH，并与电脑处于同一局域网下。 本文所有代码均为python3.x下可用，python2.x略有不同。\n写测试代码 首先在个人电脑中建立一个工程，写一个tkinter程序（注意文件名不可为tkinter），并在本机上测试运行。代码如下：\n1 2 3  import tkinter a = tkinter.Tk() a.mainloop()   运行成功后可以看见一个标题为Tk()的窗口。\n配置PyCharm环境 使用SSH连接树莓派 进入之前新建的python文件下，依次打开File -\u0026gt; Settings -\u0026gt; Project Interpreter，点旁边的小齿轮，选择Add Romote,进入环境配置。 选择SSH Credentials，Host中填写树莓派的IP地址，User name 和 Password默认为pi 和 raspberry，注意，选择Python interpreter path时，如果想使用python3版本，请务必按照截图输入，若为python2版本，则去掉后面的版本号即可。最后点击ok完成设置。 配置上传路径 依次打开Tool -\u0026gt; Deployment -\u0026gt; Configure,在打开的页面中Type选择SFTP协议，然后继续填写树莓派的IP地址以及用户名和密码，其余默认。 点开Mapping选项卡，配置工程目录，这里主要是设置Deployment path on server，该选项会将电脑上的文件上传到树莓派的对应位置，一般建议目录为/Desktop/py，其他可以默认，点击ok完成配置。\n上传工程 依次点击Tool -\u0026gt; Upload to xxx,点击调试按钮自动安装调试插件，安装完成后自动开始调试。 这时候你就可以看见你的工程已经自动上传到树莓派中。\n运行程序 如果直接运行程序，也许你会发现有如下错误： 这是由于远程调试不是在桌面环境下进行的。程序不知道我们使用了显示设备，这个时候就需要手动指定显示设备。 因此，我们打开树莓派的命令行，输入\n printenv grep DISPLAY\n 本机显示结果为 复制这行字符，然后再该文件中添加这个参数如下：\n1 2 3  import tkinter a = tkinter.","title":"远程调试树莓派（PyCharm实现）"},{"content":"准备工作  树莓派3b，一张TF卡（32G），读卡器，电源线，网线，路由器。\n 安装操作系统 首先肯定是安装系统，我是用的比较流行的RASPBIAN系统。建议下载torrent，然后用迅雷下载会比较快。 然后再下载一个叫Win32 Disk Imager的磁盘映像工具，个人理解就是往TF卡里用iso制作系统嘛。\n前面两步都很简单，接下来，在root盘里（Windows下）根目录，添加一个__不带后缀的文件__，文件名为ssh，这会让树莓派开启ssh，方便接下来的操作。\n使用显示器进行安装 如果你身边有一个带HDMI接口的显示器，那么恭喜你，接下来的安装会变得很简单。但如果你直接将HDMI插到树莓派和显示器中，很遗憾，显示器是不会有任何显示的。我参考了这篇文章，其实就是需要你在首次运行前配置文件config.txt里的参数（也是在root盘里）。 我修改的参数如下\n1 2 3 4 5 6  _\\#_ _uncomment if you get no picture on HDMI for a default \u0026#34;safe\u0026#34; mode_ hdmi_safe=1 overscan_left=-30 overscan_right=-30 overscan_top=-30 overscan_bottom=-30   因为我的显示器是有HDMI接口的，因此没有设置hdmi_group等信息，如果你使用VGA转换器，需要另外修改其他参数，在config.txt文件中都有很详细的解释，只要能看懂英文就应该明白：） 接下来就可以直接利用显示器操作啦，不需要我多说。\n无显示器进行安装 如果你身边没有一台显示器供你折腾，则会相对复杂一点，但我相信对于大部分人来说，这是更实用的一种选择，因为我们之后的维护和开发用自己的笔记本电脑进行操作更加方便一些。\n查找树莓派IP地址 首先我们要找到树莓派的IP地址，网上提供了很多种方法，但现在家里都应该是有路由器的，因此本文只介绍用路由器操作的方法，若你的开发环境比较复杂，可以参考这篇文章。 用网线将树莓派连接上路由器，登录路由器的管理页面，可以看见当前连接的设备。如下图所示，我们很容易就得到了树莓派的IP地址，记下来。 PuTTY软件连接树莓派 先下载一个叫PuTTY的软件，此软件可以让我们用IP地址控制树莓派。安装过程很简单不必多说，输入树莓派的初始名称pi和密码raspberry,即可用命令行控制树莓派。 但目前还不能看见图形界面。我们需要输入\n sudo apt-get install tightvncserver\n 安装一个名为VNC Server的软件（在电脑上也要安装），此时会提示你设置两次密码。 启动树莓派VNC Server\n vncserver :1 -geometry 800x600\n 如下图所示，记录下端口号：1（每个人可能不同） 使用之前得到的树莓派IP地址+端口号进行登录，例如192.168.0.106:1,登录界面如下： 不出问题的话，这时候你就可以看见久违的桌面啦！ ","permalink":"https://tech.zealscott.com/misc/setup/","summary":"准备工作  树莓派3b，一张TF卡（32G），读卡器，电源线，网线，路由器。\n 安装操作系统 首先肯定是安装系统，我是用的比较流行的RASPBIAN系统。建议下载torrent，然后用迅雷下载会比较快。 然后再下载一个叫Win32 Disk Imager的磁盘映像工具，个人理解就是往TF卡里用iso制作系统嘛。\n前面两步都很简单，接下来，在root盘里（Windows下）根目录，添加一个__不带后缀的文件__，文件名为ssh，这会让树莓派开启ssh，方便接下来的操作。\n使用显示器进行安装 如果你身边有一个带HDMI接口的显示器，那么恭喜你，接下来的安装会变得很简单。但如果你直接将HDMI插到树莓派和显示器中，很遗憾，显示器是不会有任何显示的。我参考了这篇文章，其实就是需要你在首次运行前配置文件config.txt里的参数（也是在root盘里）。 我修改的参数如下\n1 2 3 4 5 6  _\\#_ _uncomment if you get no picture on HDMI for a default \u0026#34;safe\u0026#34; mode_ hdmi_safe=1 overscan_left=-30 overscan_right=-30 overscan_top=-30 overscan_bottom=-30   因为我的显示器是有HDMI接口的，因此没有设置hdmi_group等信息，如果你使用VGA转换器，需要另外修改其他参数，在config.txt文件中都有很详细的解释，只要能看懂英文就应该明白：） 接下来就可以直接利用显示器操作啦，不需要我多说。\n无显示器进行安装 如果你身边没有一台显示器供你折腾，则会相对复杂一点，但我相信对于大部分人来说，这是更实用的一种选择，因为我们之后的维护和开发用自己的笔记本电脑进行操作更加方便一些。\n查找树莓派IP地址 首先我们要找到树莓派的IP地址，网上提供了很多种方法，但现在家里都应该是有路由器的，因此本文只介绍用路由器操作的方法，若你的开发环境比较复杂，可以参考这篇文章。 用网线将树莓派连接上路由器，登录路由器的管理页面，可以看见当前连接的设备。如下图所示，我们很容易就得到了树莓派的IP地址，记下来。 PuTTY软件连接树莓派 先下载一个叫PuTTY的软件，此软件可以让我们用IP地址控制树莓派。安装过程很简单不必多说，输入树莓派的初始名称pi和密码raspberry,即可用命令行控制树莓派。 但目前还不能看见图形界面。我们需要输入\n sudo apt-get install tightvncserver\n 安装一个名为VNC Server的软件（在电脑上也要安装），此时会提示你设置两次密码。 启动树莓派VNC Server\n vncserver :1 -geometry 800x600\n 如下图所示，记录下端口号：1（每个人可能不同） 使用之前得到的树莓派IP地址+端口号进行登录，例如192.168.0.106:1,登录界面如下： 不出问题的话，这时候你就可以看见久违的桌面啦！ ","title":"树莓派首次上手"}]