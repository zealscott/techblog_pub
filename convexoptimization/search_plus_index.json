{"./":{"url":"./","title":"Introduction","keywords":"","body":"Convex Optimization 传统的机器学习中最难理解的就是SVM了，只学过高数和线代的普通本科生的确很难理解。因此，想要入门机器学习，第一件事就是增强数学基础。而凸优化是其中无法越过的一道坎。 本人以备受推崇的Stephen Boyd的Convex Optimization为例，分享本人学习期间的笔记和资料，方便大家参考。 官方网站： Convex Optimization - Boyd and Vandenberghe 配套matlab代码： additional_exercises 本书也有配套的video，但是并不太建议，一是只有英文版，语速较快，二是书上已经够详细的了。 This GitBook notes are maintained by zealscott. @Last updated at 1/25/2021 "},"matrix.html":{"url":"matrix.html","title":"矩阵求导法则与性质","keywords":"","body":" 介绍矩阵求导法则，以及常用的求导公式、迹函数、行列式求导结论。 矩阵求导法则 矩阵求导应该分为标量求导、向量求导、矩阵求导三个方面来介绍，公式繁多，但仔细看看其实是有规律可循的。 标量求导 无论是矩阵、向量对标量求导，或者是标量对矩阵、向量求导，其结论都是一样的：等价于对矩阵（向量）的每个分量求导，并且保持维数不变。 例如，我们可以计算标量对向量求导： 设yyy为一个元素，xT=[x1...xq]x^T = [x_1...x_q]xT=[x1​...xq​]是qqq维行向量，则： ∂y∂xT=[∂y∂x1...∂y∂xq]\\frac{\\partial y}{\\partial x^T} = [\\frac{\\partial y}{\\partial x_1}...\\frac{\\partial y}{\\partial x_q}]∂xT∂y​=[∂x1​∂y​...∂xq​∂y​] 向量求导 对于向量求导，我们可以先将向量看做一个标量，然后使用标量求导法则，最后将向量形式化为标量进行。 例如，我们可以计算行向量对列向量求导： 设yT=[y1...yn]y^T=[y_1...y_n]yT=[y1​...yn​]是nnn维行向量，x=[x1,...,xp]x=[x_1,...,x_p]x=[x1​,...,xp​]是ppp维列向量，则： ∂yT∂x=[∂y1∂x⋅⋯∂yn∂x]=[∂y1∂x1⋯∂yn∂x1⋯⋯⋯∂y1∂xp⋯∂yn∂xp] \\begin{aligned} \\frac{\\partial y^{T}}{\\partial x} &=\\left[\\frac{\\partial y_{1}}{\\partial x} \\cdot \\cdots \\frac{\\partial y_{n}}{\\partial x}\\right] \\\\ &=\\left[\\begin{array}{lll} \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{n}}{\\partial x_{1}} \\\\ \\cdots & \\cdots & \\cdots \\\\ \\frac{\\partial y_{1}}{\\partial x_{p}} & \\cdots & \\frac{\\partial y_{n}}{\\partial x_{p}} \\end{array}\\right] \\end{aligned} ∂x∂yT​​=[∂x∂y1​​⋅⋯∂x∂yn​​]=⎣⎢⎡​∂x1​∂y1​​⋯∂xp​∂y1​​​⋯⋯⋯​∂x1​∂yn​​⋯∂xp​∂yn​​​⎦⎥⎤​​ 矩阵求导 与向量求导类似，先将矩阵化当做一个标量，再使用标量对矩阵的运算进行。 例如，我们可以计算矩阵对列向量求导： 设 Y=(y11…y1n………ym1…ymn) Y=\\left(\\begin{array}{lll} y_{11} & \\ldots & y_{1 n} \\\\ \\ldots & \\ldots & \\ldots \\\\ y_{m 1} & \\ldots & y_{m n} \\end{array}\\right) Y=⎝⎛​y11​…ym1​​………​y1n​…ymn​​⎠⎞​ 是m×nm\\times nm×n矩阵，x=[x1,...,xp]x=[x_1,...,x_p]x=[x1​,...,xp​]是ppp维列向量，则： ∂Y∂x=[∂Y∂x1,...,∂Y∂xp]\\frac{\\partial Y}{\\partial x} = [\\frac{\\partial Y}{\\partial x_1},...,\\frac{\\partial Y}{\\partial x_p}] ∂x∂Y​=[∂x1​∂Y​,...,∂xp​∂Y​] 矩阵微积分 常见求导性质 实值函数相对于实向量的梯度 设f(x)=x=[x1,...,xn]Tf(x) = x = [x_1,...,x_n]^Tf(x)=x=[x1​,...,xn​]T ∂f(x)∂xT=∂x∂xT=In×n\\frac{\\partial f (x)}{\\partial x^T} = \\frac{\\partial x}{\\partial x^T} = I_{n\\times n}∂xT∂f(x)​=∂xT∂x​=In×n​ ∂(f(x))T∂x=∂xT∂x=In×n\\frac{\\partial (f (x))^T}{\\partial x} = \\frac{\\partial x^T}{\\partial x} = I_{n\\times n}∂x∂(f(x))T​=∂x∂xT​=In×n​ ∂f(x)∂x=∂x∂x=vec(In×n)\\frac{\\partial f (x)}{\\partial x} = \\frac{\\partial x}{\\partial x} = vec(I_{n\\times n})∂x∂f(x)​=∂x∂x​=vec(In×n​) ∂(f(x))T∂xT=∂xT∂xT=vec(In×n)T\\frac{\\partial (f (x))^T}{\\partial x^T} = \\frac{\\partial x^T}{\\partial x^T} = vec(I_{n\\times n})^T∂xT∂(f(x))T​=∂xT∂xT​=vec(In×n​)T 其中，vecvecvec表示向量化矩阵，按列将矩阵表示为向量，具体可见Wikipedia。 常见性质 f(x)=Axf(x) = Axf(x)=Ax，则 ∂f(x)∂xT=∂(Ax)∂xT=A\\frac{\\partial f (x)}{\\partial x^T} = \\frac{\\partial (Ax)}{\\partial x^T} =A∂xT∂f(x)​=∂xT∂(Ax)​=A f(x)=xTAxf(x) = x^TAxf(x)=xTAx，则 ∂f(x)∂x=∂(xTAx)∂x=Ax+ATx\\frac{\\partial f (x)}{\\partial x} = \\frac{\\partial (x^TAx)}{\\partial x} =Ax+A^Tx∂x∂f(x)​=∂x∂(xTAx)​=Ax+ATx f(x)=aTxf(x) = a^Txf(x)=aTx，则 ∂aTx∂x=∂xTa∂x=a\\frac{\\partial a^Tx}{\\partial x} = \\frac{\\partial x^Ta}{\\partial x} =a∂x∂aTx​=∂x∂xTa​=a f(x)=xTAyf(x) = x^TAyf(x)=xTAy，则 ∂xTAy∂x=Ay\\frac{\\partial x^TAy}{\\partial x} = Ay∂x∂xTAy​=Ay ∂xTAy∂A=xyT\\frac{\\partial x^TAy}{\\partial A} = xy^T ∂A∂xTAy​=xyT df(X)=tr((∂f(X)∂X)TdX)df(X) = tr((\\frac{\\partial f(X)}{\\partial X})^T d X)df(X)=tr((∂X∂f(X)​)TdX) 矩阵微分也满足线性法则、乘积法则。 矩阵的逆的微分 d(X−1)=−X−1(dX)X−1d(X^{-1}) = -X^{-1}(dX)X^{-1}d(X−1)=−X−1(dX)X−1 迹函数 迹函数相对于矩阵的梯度 ∂(tr(ZZT))∂Z=∂(tr(ZTZ))∂Z=2Z\\frac{\\partial (tr (ZZ^T))}{\\partial Z} = \\frac{\\partial (tr (Z^TZ))}{\\partial Z} = 2Z∂Z∂(tr(ZZT))​=∂Z∂(tr(ZTZ))​=2Z 矩阵微分算子和迹算子的可交换性 d(tr(X))=tr(d(X))=∑i=1ndxiid(tr(X)) = tr(d(X)) = \\sum\\limits_{i=1}^{n} dx_{ii}d(tr(X))=tr(d(X))=i=1∑n​dxii​ 常见性质 ∂tr(A)∂A=In×n\\frac{\\partial tr(A)}{\\partial A} = I_{n\\times n}∂A∂tr(A)​=In×n​ ∂tr(AB)∂A=BT\\frac{\\partial tr(AB)}{\\partial A} = B^T∂A∂tr(AB)​=BT d(tr(AXB))=tr(A(dX)B)=tr(BA(dX))d(tr(AXB)) = tr(A(dX)B) = tr(BA(dX))d(tr(AXB))=tr(A(dX)B)=tr(BA(dX)) ∂tr(AXB)∂X=(BA)T=ATBT\\frac{\\partial tr(AXB)}{\\partial X} = (BA)^T = A^TB^T∂X∂tr(AXB)​=(BA)T=ATBT d(tr(AX−1B))=tr(A(dX−1)B)=−tr(AX−1(dX)X−1B)=−tr(X−1BAX−1dX)d(tr(AX^{-1}B)) = tr(A(dX^{-1})B) = -tr(AX^{-1}(dX)X^{-1}B) = -tr(X^{-1}BAX^{-1}dX)d(tr(AX−1B))=tr(A(dX−1)B)=−tr(AX−1(dX)X−1B)=−tr(X−1BAX−1dX) ∂tr(AX−1B)∂X=−(X−1BAX−1)T=−X−TATBTX−T\\frac{\\partial tr(AX^{-1}B)}{\\partial X} = -(X^{-1}BAX^{-1})^T = -X^{-T}A^TB^TX^{-T} ∂X∂tr(AX−1B)​=−(X−1BAX−1)T=−X−TATBTX−T ∂tr(XTX)∂X=2X\\frac{\\partial tr(X^TX)}{\\partial X} = 2X∂X∂tr(XTX)​=2X 行列式 行列式相对于矩阵的梯度 ∂∣Z∣∂Z=∣Z∣(Z−1)T\\frac{\\partial |Z|}{\\partial Z} = |Z|(Z^{-1})^T∂Z∂∣Z∣​=∣Z∣(Z−1)T 微分形式 d∣X∣=tr(∣X∣X−1dX)d|X| = tr(|X| X^{-1} dX)d∣X∣=tr(∣X∣X−1dX) 常见性质 d∣AXB∣=tr⁡(∣AXB∣(AXB)−1d(AXB))=tr⁡(∣AXB∣(AXB)−1A(dX)B)=tr⁡(∣AXB∣B(AXB)−1A(dX)) \\begin{aligned} d|A X B| &=\\operatorname{tr}\\left(|A X B|(A X B)^{-1} d(A X B)\\right) \\\\ &=\\operatorname{tr}\\left(|A X B|(A X B)^{-1} A(d X) B\\right) \\\\ &=\\operatorname{tr}\\left(|A X B| B(A X B)^{-1} A(d X)\\right) \\end{aligned} d∣AXB∣​=tr(∣AXB∣(AXB)−1d(AXB))=tr(∣AXB∣(AXB)−1A(dX)B)=tr(∣AXB∣B(AXB)−1A(dX))​ ∂∣AXB∣∂X=∣AXB∣AT(BTXTAT)−1BT \\frac{\\partial|A X B|}{\\partial X}=|A X B| A^{T}\\left(B^{T} X^{T} A^{T}\\right)^{-1} B^{T} ∂X∂∣AXB∣​=∣AXB∣AT(BTXTAT)−1BT ∂∣X∣∂X=∣X∣X−T \\frac{\\partial|X|}{\\partial X}=|X| X^{-T} ∂X∂∣X∣​=∣X∣X−T ∂∣XXT∣∂X=2∣XXT∣(XXT)−1X \\frac{\\partial |XX^T|}{\\partial X} = 2|XX^T| (XX^{T})^{-1}X ∂X∂∣XXT∣​=2∣XXT∣(XXT)−1X reference 矩阵的导数与迹 "},"convex optimization.html":{"url":"convex optimization.html","title":"凸优化基本概念总结","keywords":"","body":"凸集 仿射集合和凸集 仿射集合 仿射集合p20{p_{20}}p20​ 任意仿射集合可以表示为一个线性方程组的解集 仿射组合 可以将仿射集合表示为线性空间＋偏移量 仿射包p20{p_{20}}p20​ 包含CCC的最小仿射集合，其中CCC为任意集合 仿射维数p21{p_{21}}p21​ 集合CCC的仿射维数为仿射包的维数 定义集合CCC的相对内部为它相对于仿射包的内部，记做relintCrelint CrelintC 可根据仿射维数定义相对边界为clC/relintCcl C /relint CclC/relintC，此时clCclCclC为CCC的闭包 凸集 对任意x1,x2∈Cx_1,x_2\\in Cx1​,x2​∈C，和满足0≤θ≤10\\le \\theta\\le 10≤θ≤1都有： θx1+(1−θ)x2∈C\\theta x_1 +(1-\\theta)x_2 \\in Cθx1​+(1−θ)x2​∈C 直观理解，集合中的每一点都可以被其他点沿着他们之间一条无阻碍的路径看见，那么这个集合就是凸集。 可类似定义凸组合 一个集合是凸集等价于集合包含所有点的凸组合 点的凸组合可以看做是混合或加权平均 凸包 集合CCC中所有点的凸组合的集合为凸包 锥 对于任意x∈Cx\\in Cx∈C和θ≥0\\theta \\ge 0θ≥0都有θx∈C\\theta x \\in Cθx∈C，则称集合CCC为锥或者非负齐次。 在二维上为扇形，注意，锥一定包含原点 可类似定义锥组合 锥包p23{p_{23}}p23​ 集合CCC中所有点的锥组合的集合为锥包，是包含CCC的最小凸锥 例子 空集、单点集合、全空间都是仿射的。 一条射线是凸的，但不是仿射的。 若射线的基点是原点，则为凸锥。 任意直线是仿射的，如果直线过原点，则为子空间（也是凸锥）。 超平面与半空间 可看成法线方向为aaa的超平面，而常数bbb则决定了这个平面从原点的偏移 {x∣aTx=b}\\{x | a^Tx=b\\}{x∣aTx=b} 超平面由所有正交于法向量aaa的向量+偏移x0x_0x0​组成。 {x∣aT(x−x0)=0}\\{x | a^T(x-x_0)=0\\}{x∣aT(x−x0​)=0} 一个超平面将RnR^nRn分为两个半空间p24{p_{24}}p24​ 半空间是凸的，但不是仿射的 多面体 为有限个线性等式和不等式的解集 P={x∣ajTx≤bj,j=1,...,m,cjTx=dj,j=1,...,p}P = \\{x| a_j^Tx\\le b_j,j=1,...,m,c^T_jx= d_j,j=1,...,p\\}P={x∣ajT​x≤bj​,j=1,...,m,cjT​x=dj​,j=1,...,p} 可以用更紧凑的形式表示： P={x∣Ax⪯b,Cx=d}P = \\{x| Ax\\preceq b,Cx= d \\}P={x∣Ax⪯b,Cx=d} 单纯形式一类重要的多面体p29{p_{29}}p29​ 设k+1k+1k+1个点x0,...,vk∈Rnx_0,...,v_k\\in R^nx0​,...,vk​∈Rn仿射独立，即v1−v0,...,vk−v0v_1-v_0,...,v_k-v_0v1​−v0​,...,vk​−v0​线性独立，那么这些点决定了一个单纯形： C=conv{v0,...,vk}={θ0v0+...+θkvk∣θ⪰0,1Tθ=1}C = conv\\{v_0,...,v_k\\} = \\{\\theta_0v_0+...+\\theta_kv_k| \\theta\\succeq0,1^T\\theta =1\\}C=conv{v0​,...,vk​}={θ0​v0​+...+θk​vk​∣θ⪰0,1Tθ=1} 这个单纯形的仿射维数为kkk，因此也称为RnR^nRn空间的kkk维单纯形。 单纯形有更容易理解的表达形式p29{p_{29}}p29​ 半正定锥 我们用S+nS_{+}^nS+n​表示对称半正定矩阵的集合： S+n={X∈Sn∣X⪰0}S_{+}^n = \\{X\\in S^n|X\\succeq 0\\}S+n​={X∈Sn∣X⪰0} 同样也可以表示对称正定集合S++nS_{++}^nS++n​ 很容易得到验证，集合S+nS_{+}^nS+n​是一个凸锥。 xT(θ1A+θ2B)x=θ1xTAx+θ2xTBx≥0x^T(\\theta_1A+\\theta_2B)x = \\theta_1x^TAx + \\theta_2x^TBx \\ge 0xT(θ1​A+θ2​B)x=θ1​xTAx+θ2​xTBx≥0 保凸运算 除了介绍一些凸集之外，我们需要一些运算，这些运算能帮助我们构造更多的凸集。 交集 交集运算时保凸的 例如，每一个闭集是包含它的所有半空间的交集p32{p_{32}}p32​。 仿射函数p33{p_{33}}p33​ 仿射函数具有如下形式；即为一个线性函数和常数的和： f(x)=Ax+bf(x)= Ax+bf(x)=Ax+b 因此，伸缩和平移是保凸的； 一个凸集向它的几个坐标的投影是凸的（投影矩阵）； 笛卡尔积也是保凸的； 凸集的部分和也是凸的； 线性分式和透视函数 透视函数 定义P:Rn+1→Rn,P(z,t)=z/tP: R^{n+1}\\to R^n, P(z,t) = z/tP:Rn+1→Rn,P(z,t)=z/t为透视函数 透视函数对向量进行伸缩（规范化），使得最后一维分量为1并舍弃 一个凸集在透视函数下的原象也是凸的 可以通过小孔成像的例子来解释p35{p_{35}}p35​ 线性分式 线性分式函数由透视函数和仿射函数复合而成： g(x)=(Ax+b,cTx+d)g(x) = (Ax+b,c^Tx+d)g(x)=(Ax+b,cTx+d) f(x)=(Ax+b)/(cTx+d)f(x) = (Ax+b)/(c^Tx+d)f(x)=(Ax+b)/(cTx+d) 其中g(x)g(x)g(x)为仿射函数，PPP为透视函数，f=P⊙gf=P\\odot gf=P⊙g为线性分式函数 广义不等式 正常锥p38{p_{38}}p38​ 我们定义KKK为正常锥，如果它满足： KKK是凸的 KKK是闭的 KKK是实的，即具有非空内部 KKK是尖的，即不包含直线 可以使用正常锥来定义广义不等式，即为RnR^nRn上的偏序关系 x⪯Ky⇔y−k∈Kx\\preceq_K y \\Leftrightarrow y-k \\in K x⪯K​y⇔y−k∈K x≺Ky⇔y−k∈int(K)x\\prec_K y \\Leftrightarrow y-k \\in int (K )x≺K​y⇔y−k∈int(K) 广义不等式满足一般不等式的很多性质p39{p_{39}}p39​，但并不是一个线性序，也就是说，两点不一定能比 最小元和极小元 一个集合可能有多个极大元和极小元p40{p_{40}}p40​ 不一定有最小元，极小元定义为： (x−K)⋂S={x}(x-K)\\bigcap S =\\{x\\}(x−K)⋂S={x} (x−K)(x-K)(x−K)表示可以与xxx相比并且小于等于xxx的所有元素 分离与支撑超平面 超平面分离定理p42{p_{42}}p42​ 两个不相交的凸集，一定存在一个超平面能将其分开p42{p_{42}}p42​。 设存在c∈C,d∈Dc\\in C,d\\in Dc∈C,d∈D使得两个集合的距离最小，则： f(x)=(d−c)T(x−(1/2)(d+c))f(x) = (d-c)^T(x-(1/2)(d+c))f(x)=(d−c)T(x−(1/2)(d+c)) 若在两个凸集中有aTxb,aTx>ba^{T}xaTxb,aTx>b，则能够严格分离。 支撑超平面 若x0x_0x0​是边界上的一点，对于任意xxx都满足aTx≤aTx0a^Tx\\le a^Tx_0aTx≤aTx0​，则超平面{x∣aTx=aTx0}\\{x| a^Tx = a^Tx_0\\}{x∣aTx=aTx0​}为集合CCC在点x0x_0x0​处的支撑超平面。 支撑超平面定理p46{p_{46}}p46​： 对任意非空凸集和任意x0x_0x0​，都存在支撑超平面 如果一个集合是闭的，具有非空内部，并且其边界上每个点均存在支撑超平面，则它是凸的。 对偶锥和广义不等式 定义KKK的对偶锥为： K⋆={y∣xTy≥0,∀x∈K}K^\\star = \\{y| x^Ty\\ge 0,\\forall x\\in K\\}K⋆={y∣xTy≥0,∀x∈K} 如论KKK是否为凸锥，对偶锥K⋆K^\\starK⋆一定是凸的。 我们之前根据正常锥定义了广义不等式和最小元，因此也可以对对偶锥定义同样的性质。 广义不等式的对偶 有两条重要性质，将广义不等式和对偶联系起来p48{p_{48}}p48​ x⪯Kyx\\preceq _K y x⪯K​y当且仅当对于任意λ⪰K⋆0\\lambda \\succeq_{K^\\star}0λ⪰K⋆​0，有λTx⪯λTy\\lambda^T x \\preceq\\lambda^TyλTx⪯λTy x≺Kyx\\prec_K y x≺K​y当且仅当对于任意λ⪰K⋆0\\lambda \\succeq_{K^\\star}0λ⪰K⋆​0和λ≠0\\lambda\\ne0λ≠0，有λTx≺λTy\\lambda^Tx \\prec\\lambda^TyλTx≺λTy 凸函数 基本性质 若domfdom fdomf为为凸集，且对于任意x,y∈domfx,y\\in dom fx,y∈domf和任意0≤θ≤10\\le \\theta\\le10≤θ≤1，有： f(θx+(1−θ)y)≤θf(x)+(1−θ)f(y)f(\\theta x + (1-\\theta)y) \\le \\theta f(x) + (1-\\theta)f(y)f(θx+(1−θ)y)≤θf(x)+(1−θ)f(y) 则fff是凸函数。 仿射函数既凸又凹。 若fff为凸函数，则对于x∈domfx \\in dom fx∈domf和任意vvv，都有g(t)=f(x+tv)g(t) = f(x+tv)g(t)=f(x+tv)是凸的。这个性质非常有用： 函数是凸的，当且仅当在其定义域相交的任何直线上都是凸的。 扩展值延伸 将凸函数在定义域外的值令为∞\\infty∞，从而将这个凸函数延伸至全空间。 将延伸后的函数记为f~\\tilde{f}f~​，因此可得： f~(θx+(1−θ)y)≤θf~(x)+(1−θ)f~(y)\\tilde{f}(\\theta x + (1-\\theta)y) \\le \\theta \\tilde{f}(x) + (1-\\theta)\\tilde{f}(y)f~​(θx+(1−θ)y)≤θf~​(x)+(1−θ)f~​(y) 一阶条件 假设fff可微，则函数是凸函数的充要条件是对于任意x,y∈domfx,y\\in dom fx,y∈domf，都有： f(y)≥f(x)+▽f(x)T(y−x)f(y) \\ge f(x) + \\bigtriangledown f(x)^T(y-x)f(y)≥f(x)+▽f(x)T(y−x) 其一阶Taylor近似是原函数的一个全局下估计。 不等式从一个凸函数的局部信息可以得到全局信息，这可以得到凸优化问题的一些非常重要的信息： 例如，当▽f(x)=0\\bigtriangledown f(x) = 0▽f(x)=0时，我们可以知道xxx是函数fff 的全局极小点。 二阶条件 fff是凸函数的充要条件是其Hessian矩阵是半正定的。 对于RRR上的函数，可以简化为f′′(x)≥0f''(x)\\ge 0f′′(x)≥0，可以理解为函数图像在点xxx处有正向上的曲率。 注意，在判断函数凸性之前，其定义域是凸集这个前提条件必须满足。 例子p65{p_{65}}p65​ 指数函数（eaxe^{ax}eax) 幂函数（xax^axa） 绝对值幂函数（当p≥1p\\ge 1p≥1时，∣x∣p|x|^p∣x∣p为凸函数） 对数函数（log⁡x\\log xlogx）为凹函数 负熵（xlog⁡xx\\log xxlogx） 范数 最大值函数 二次-线性分式函数（f(x,y)=x2/yf(x,y)=x^2/yf(x,y)=x2/y） 几何平均是凹函数 f(x)=(∏i=1nxi)1/nf(x) = (\\prod\\limits_{i=1}^n x_i)^{1/n}f(x)=(i=1∏n​xi​)1/n 对数行列式是凹函数 f(x)=log⁡det⁡Xf(x) = \\log \\det Xf(x)=logdetX 下水平集p69{p_{69}}p69​ 函数fff的α−\\alpha-α−下水平集为： Cα={x∈domf∣f(x)≤α}C_{\\alpha} = \\{x\\in dom f| f(x) \\le \\alpha\\}Cα​={x∈domf∣f(x)≤α} 对于任意α\\alphaα，凸函数的下水平集依然为凸函数。 但反过来不一定成立：某个函数的所有下水平集都是凸集，但这个函数可能不是凸函数。 如果fff为凹函数，则α−\\alpha-α−上水平集也是凸集。 上镜图 函数fff的上镜图定义为： epif={(x,t)∣x∈domf,f(x)≤t}epi f =\\{(x,t)| x\\in dom f,f(x) \\le t\\}epif={(x,t)∣x∈domf,f(x)≤t} 一个函数是凸函数，当且仅当其上镜图是凸集。 一个函数是凹函数，当且仅当其亚图是凹集： hypof={(x,t)∣t≤f(x)}hypo f = \\{(x,t)|t\\le f(x)\\}hypof={(x,t)∣t≤f(x)} Jensen不等式p71{p_{71}}p71​ 若函数fff是凸函数，x1,...,xk∈domfx_1,...,x_k \\in dom fx1​,...,xk​∈domf，θ1,...,θk≥0\\theta_1,...,\\theta_k \\ge 0θ1​,...,θk​≥0且和为1，则下式成立： f(θ1x1+...+θkxk)≤θ1f(x1)+...+θkf(xk)f(\\theta_1x_1 + ... + \\theta_k x_k)\\le \\theta_1f(x_1)+...+\\theta_kf(x_k)f(θ1​x1​+...+θk​xk​)≤θ1​f(x1​)+...+θk​f(xk​) 保凸运算p73{p_{73}}p73​ 以下运算后的函数依然为凸函数： 非负加权求和 复合仿射变换 逐点最大和逐点上确界 几乎所有凸函数都可以表示为一簇仿射函数的逐点上确界p77{p_{77}}p77​ 标量（矢量）复合运算 最小化函数 透视函数（g(x,t)=tf(x/t)g(x,t) = tf(x/t)g(x,t)=tf(x/t)) 共轭函数p85{p_{85}}p85​ f⋆(y)=sup⁡x∈domf(yTx−f(x))f^\\star(y) = \\sup_{x\\in dom f}(y^Tx - f(x))f⋆(y)=x∈domfsup​(yTx−f(x)) 此函数称为fff的共轭函数；即差值yTx−f(x)y^Tx - f(x)yTx−f(x)在domfdom fdomf所有上界构成了共轭函数的定义域 因为共轭函数是一系列仿射函数的逐点下确界，则f⋆f^\\starf⋆为凸函数。 重点掌握以下凸函数的共轭函数： 负对数函数 负熵函数f(x)=xlog⁡xf(x) = x\\log xf(x)=xlogx 严格凸的二次函数f(x)=12xTQxf(x) = \\frac{1}{2}x^TQxf(x)=21​xTQx 其共轭函数为f⋆(y)=12yTQ−1yf^\\star(y) = \\frac{1}{2}y^TQ^{-1}yf⋆(y)=21​yTQ−1y 对数行列式 其共轭函数为f⋆(Y)=log⁡det⁡(−Y)−1−nf^\\star(Y) = \\log \\det (-Y)^{-1} -nf⋆(Y)=logdet(−Y)−1−n Fenchel不等式p89{p_{89}}p89​ 从共轭函数的定义可以得到，对于任意的xxx和yyy，有下列不等式成立： f(x)+f∗(y)≥xTyf(x) + f^*(y) \\ge x^Tyf(x)+f∗(y)≥xTy 拟凸函数p90{p_{90}}p90​ 函数fff称为拟凸函数，如果其定义域与及所有下水平集都是凸集： Sα={x∈domf∣f(x)≤α}S_{\\alpha} = \\{x \\in dom f| f(x)\\le \\alpha\\}Sα​={x∈domf∣f(x)≤α} 同样的，若−f-f−f是拟凸函数，即所有上水平集都是凸集，则fff为拟凹函数。 拟凸函数的函数图像最多只有一个“峰”，因此也被称为单峰函数。 拟凸函数可能是凹函数，也有可能是不连续的。 基本性质 函数fff是拟凸函数的充要条件为： 对于任意x,y∈domfx,y\\in dom fx,y∈domf，且0≤θ≤10\\le \\theta \\le 10≤θ≤1有： f(θx+(1−θ)y)≤max⁡{f(x),f(y)}f(\\theta x + (1-\\theta)y) \\le \\max\\{f(x),f(y)\\}f(θx+(1−θ)y)≤max{f(x),f(y)} 即线段中的任何一点都不超过其端点函数值最大的那一个。 保拟凸运算p95{p_{95}}p95​ 非负加权最大 复合运算 最小化 对数-凸函数p98{p_{98}}p98​ 如果对于所有的x∈domfx\\in dom fx∈domf都有f(x)>0f(x) > 0f(x)>0且log⁡f\\log flogf是凸函数，则函数fff是对数-凸函数。 可以不使用对数来进行表达： 若对于任意xxx，y∈domfy\\in dom fy∈domf，0≤θ≤10\\le \\theta \\le 10≤θ≤1，有： f(θx+(1−θy))≥f(x)θ+f(y)1−θf(\\theta x + (1-\\theta y)) \\ge f(x)^{\\theta} + f(y)^{1-\\theta}f(θx+(1−θy))≥f(x)θ+f(y)1−θ 则函数为对数-凸的。 可以根据函数复合来得到对数-凸函数： 如果函数是凸函数，则efe^fef也是凸函数。 因此，对数-凸函数是凸函数。 例子 仿射函数 幂函数 指数函数 Gamma函数 "},"problem statement.html":{"url":"problem statement.html","title":"问题的基本描述及转化","keywords":"","body":"优化问题 问题的标准形式p122{p_{122}}p122​ min⁡f0(x)\\min f_0(x)minf0​(x) s.t. fi(x)≤0, i=1,..,ms.t. \\space f_i(x)\\le 0,\\space i = 1,..,ms.t. fi​(x)≤0, i=1,..,m hi(x)=0, i=1,..,ph_i(x)=0,\\space i = 1,..,phi​(x)=0, i=1,..,p 描述在满足所有条件下的xxx中寻找极小化f0(x)f_0(x)f0​(x)的问题。 其中xxx为优化变量，函数f0(x)f_0(x)f0​(x)为目标函数或费用函数，fi(x)≤0f_i(x)\\le 0fi​(x)≤0为不等式约束，h0(x)=0h_0(x)=0h0​(x)=0为等式约束，对目标函数和约束函数都有定义的点为优化问题的定义域。 问题的最优值定义为p∗p^*p∗： p∗=inf⁡{f0(x)∣fi(x)≤0,hi(x)=0}p^* = \\inf \\{f_0(x)|f_i(x)\\le 0,h_i(x)=0\\}p∗=inf{f0​(x)∣fi​(x)≤0,hi​(x)=0} 当p∗p^*p∗为无穷时，则问题无可行解。 最优点和局部最优点 若x⋆x^\\starx⋆是可行的并且f0(x⋆)=p⋆f_0(x^\\star) = p^\\starf0​(x⋆)=p⋆，则x⋆x^\\starx⋆为最优点，所有最优解的集合为最优集。 若问题不存在最优解，则最优值是不可达的，满足f0(x)≤p⋆+ϵf_0(x) \\le p^\\star+\\epsilon f0​(x)≤p⋆+ϵ的可行解为xxx的ϵ− \\epsilon -\\spaceϵ− 次优。 局部最优xxx定义为：存在R>0R> 0R>0，使得： f0(x)=inf⁡{f0(z)∣fi(z)≤0,hi(z)=0,∣∣z−x∣∣2≤R}f_0(x) = \\inf \\{f_0(z)| f_i(z) \\le 0, h_i(z) = 0, || z- x|| _2 \\le R\\}f0​(x)=inf{f0​(z)∣fi​(z)≤0,hi​(z)=0,∣∣z−x∣∣2​≤R} 粗略的讲，这意味着xxx在可行集内的一个点的周围极小化了f0f_0f0​。 等价问题p124{p_{124}}p124​ 可以将最大化问题转化为标准形式（最小化问题）。 伸缩变换与原问题是等价的。 变量替换是等价的。 单调增的复合函数与原问题等价。 松弛变量 fi(x)≤0f_i(x)\\le 0 fi​(x)≤0等价于存在一个si≥0s_i\\ge 0si​≥0满足fi(x)+si=0f_i(x)+s_i=0fi​(x)+si​=0。 可以将不等式约束替换为一个等式和一个非负约束。 消除等式约束p126{p_{126}}p126​ 可以显式的参数化等式约束，来进行变量替换，进而消除等式约束。 如hi(x)=0h_i(x)=0hi​(x)=0若可以表示为x=ϕ(z)x = \\phi (z)x=ϕ(z)，则可以将xxx带入不等式约束。 消除线性等式约束 若等式约束是线性的Ax=bAx =bAx=b，则可以将其表示为x=Fz+x0x = Fz+x_0x=Fz+x0​，将其带入其他约束条件。 引入等式约束 将复合函数当做新变量，引入等式。 优化部分变量 inf⁡x,yf(x,y)=inf⁡xinf⁡yf(x,y)\\inf\\limits_{x,y} f(x,y) = \\inf\\limits_{x} \\inf\\limits_{y}f(x,y)x,yinf​f(x,y)=xinf​yinf​f(x,y) 可优化一部分变量再优化另一部分变量来达到优化函数的目的。 上镜图问题形式 min⁡t\\min tmint s.t. fo(x)−t≤0s.t. \\space f_o(x) - t \\le 0s.t. fo​(x)−t≤0  fi(x)≤0, i=1,..,m \\space f_i(x)\\le 0,\\space i = 1,..,m fi​(x)≤0, i=1,..,m hi(x)=0, i=1,..,ph_i(x)=0,\\space i = 1,..,phi​(x)=0, i=1,..,p 凸优化 标准形式 min⁡f0(t)\\min f_0(t)minf0​(t) s.t. fi(x)≤0, i=1,..,ms.t. \\space f_i(x) \\le 0,\\space i = 1,..,ms.t. fi​(x)≤0, i=1,..,m aiTx=bi, i=1,..,pa_i^Tx = b_i,\\space i = 1,..,paiT​x=bi​, i=1,..,p 与一般的优化问题对照，其附加要求为： 目标函数必须是凸的 不等式约束函数必须是凸的 等式约束函数aiTx=bia_i^Tx = b_iaiT​x=bi​必须是仿射的 我们可以发现，凸优化问题的可行集是凸的，因为它是下水平集、超平面的交集。 重要性质 对于凸优化问题来说，一个基础的性质是p132{p_{132}}p132​： 其任意局部最优解也是全局最优解。 但对于拟凸优化问题，这一性质不成立。 可微函数的最优性准则 若目标函数f0f_0f0​是可微的，对于所有x,y∈domf0x,y\\in dom f_0x,y∈domf0​，都有： f0(y)≥f0(x)+▽f0(x)T(y−x)f_0(y) \\ge f_0(x) + \\bigtriangledown f_0(x)^T(y-x)f0​(y)≥f0​(x)+▽f0​(x)T(y−x) 若xxx是最优解，则当且仅当xxx属于可行集且： ▽f0(x)T(y−x)≥0\\bigtriangledown f_0(x)^T(y-x) \\ge 0▽f0​(x)T(y−x)≥0 无约束问题p133{p_{133}}p133​ 对于无约束问题，可以简化为一个简单的最优解充要条件： ▽f0(x)=0\\bigtriangledown f_0(x) = 0▽f0​(x)=0 可以通过可微函数的最优性准则得到。 根据解的数量，有几种情况的可能： 如果等式没有解，那么没有最优点，问题无下界或最优值有限但不可达 可能有多解，那么这些解都是最优集 只含等式约束的问题p134{p_{134}}p134​ min⁡f0(x)\\min f_0(x)minf0​(x) s.t. Ax=bs.t. \\space Ax = bs.t. Ax=b 我们由可微函数的最优性准则可以得到，对于任意满足Ax=b Ax = bAx=b的yyy： ▽f0(x)T(y−x)≥0\\bigtriangledown f_0(x)^T(y-x) \\ge 0▽f0​(x)T(y−x)≥0 因此，每个可行解yyy都可以写成y=x+vy= x+vy=x+v的形式，其中v∈N(A)v \\in N(A)v∈N(A)。因此，最优性条件表示为： ▽f0(x)Tv≥0, ∀v∈N(A)\\bigtriangledown f_0(x)^Tv \\ge 0,\\space \\forall v \\in N(A)▽f0​(x)Tv≥0, ∀v∈N(A) 若一个线性函数在子空间中非负，则它在子空间中必恒等为0。因此，▽f0(x)Tv=0\\bigtriangledown f_0(x)^Tv = 0▽f0​(x)Tv=0，即： ▽f0(x)⊥N(A)\\bigtriangledown f_0(x) \\perp N(A)▽f0​(x)⊥N(A) 即▽f0(x)∈C(A)T\\bigtriangledown f_0(x) \\in C(A)^T▽f0​(x)∈C(A)T，即存在v∈Rv\\in Rv∈R，使得： ▽f0(x)+ATv=0\\bigtriangledown f_0(x) + A^Tv = 0▽f0​(x)+ATv=0 这是经典的lagrange乘子最优性条件。 非负象限中的极小化 min⁡f0(x)\\min f_0(x)minf0​(x) s.t. x⪰0s.t. \\space x\\succeq 0s.t. x⪰0 这里的唯一不等式约束是变量的非负约束。因此，最优化条件变为： x⪰0, ▽f0(x)(y−x)≥0,∀y⪰0x\\succeq 0, \\space\\bigtriangledown f_0(x)(y-x)\\ge 0,\\forall y \\succeq 0 x⪰0, ▽f0​(x)(y−x)≥0,∀y⪰0 函数▽f0(x)Ty\\bigtriangledown f_0(x)^Ty▽f0​(x)Ty只有在▽f0(x)T⪰0\\bigtriangledown f_0(x)^T\\succeq0▽f0​(x)T⪰0时才有下界，因此，条件简化为−▽f0(x)Tx≥0-\\bigtriangledown f_0(x)^Tx\\ge 0−▽f0​(x)Tx≥0。 但是x⪰0x \\succeq 0 x⪰0且▽f0(x)⪰0\\bigtriangledown f_0(x)\\succeq0▽f0​(x)⪰0，因此必须有▽f0(x)Tx=0\\bigtriangledown f_0(x)^Tx= 0▽f0​(x)Tx=0，即： ∑i=1n(▽f0(x))ixi=0\\sum\\limits_{i=1}^{n}(\\bigtriangledown f_0(x))_ix_i= 0i=1∑n​(▽f0​(x))i​xi​=0 因此，最优性条件可以表示为： x⪰0, ▽⪰0,(▽f0(x))ixi=0x\\succeq 0, \\space\\bigtriangledown \\succeq 0,(\\bigtriangledown f_0(x))_ix_i= 0x⪰0, ▽⪰0,(▽f0​(x))i​xi​=0 最后一个条件称为互补性，意味着向量xxx和▽f0(x)\\bigtriangledown f_0(x)▽f0​(x)的稀疏模式是互补的。 等价的凸问题p136{p_{136}}p136​ 消除等式约束 只需利用标准的线性代数运算，将等式约束转换解出带入，可以保持问题的凸性。 引入等式约束 约束必须是线性的 松弛变量 可以将fi(x)≤0f_i(x)\\le 0fi​(x)≤0 通过松弛变量转化为等式约束fi(x)+si=0f_i(x)+s_i = 0fi​(x)+si​=0，其中fi(x)f_i(x)fi​(x)必须是仿射的。 上镜图问题形式 min⁡t\\min tmint s.t. fo(x)−t≤0s.t. \\space f_o(x) - t \\le 0s.t. fo​(x)−t≤0  fi(x)≤0, i=1,..,m \\space f_i(x)\\le 0,\\space i = 1,..,m fi​(x)≤0, i=1,..,m aiTx=bi i=1,..,pa_i^Tx = b_i\\space i = 1,..,paiT​x=bi​ i=1,..,p 极小化部分变量 拟凸优化 当目标函数是拟凸时，称为拟凸优化问题。 拟凸优化的重要区别是局部最优可能不是全局最优的。 可以使用二分法来解决拟凸优化问题。 线性规划 当目标函数和约束函数都是仿射时，称作LP问题： min⁡ cTx+d\\min \\space c^Tx+dmin cTx+d s.t. Gx⪯hs.t. \\space Gx \\preceq hs.t. Gx⪯h Ax=bAx =bAx=b LP问题当然是凸优化问题，并且，其可行集是多面体。 标准形式与不标准形式 在标准形式的线性规划问题中，仅有的不等式约束都是分量的非负约束： min⁡ cTx\\min \\space c^Txmin cTx s.t. Ax=bs.t. \\space Ax =bs.t. Ax=b x⪰0x\\succeq 0x⪰0 如果没有等式约束，则称为不等式线性规划： min⁡ cTx\\min \\space c^Txmin cTx s.t. Ax⪯bs.t. \\space Ax \\preceq bs.t. Ax⪯b 可以使用引入松弛变量和变量替换的方法将一般的线性规划转化为标准形式p140{p_{140}}p140​。 例子 食谱问题 多面体的chebyshev中心 分片线性极小化（Piecewise Linear Minimization ） 线性分式规划 min⁡ cTx+deTx+f\\min \\space \\frac{c^Tx+d}{e^Tx+f}min eTx+fcTx+d​ s.t. Gx⪯hs.t. \\space Gx \\preceq hs.t. Gx⪯h Ax=bAx =bAx=b 其中domf={x∣eTx+f>0}dom f=\\{x| e^Tx+f >0\\}domf={x∣eTx+f>0} 这个目标函数是拟凸的，因此为拟凸优化问题。 转为线性规划问题 如果可行集非空，则可以转化为等价的LP： min⁡ cTy+dz\\min \\space c^Ty + dzmin cTy+dz s.t. Gy−hz⪯0s.t. \\space Gy-hz\\preceq0s.t. Gy−hz⪯0 Ay−bz=0Ay - bz = 0Ay−bz=0 eTy+fz=0e^Ty +fz= 0eTy+fz=0 z≥0z\\ge 0z≥0 其中，如果xxx是可行解，那么y=xeTx+fy = \\frac{x}{e^Tx+f}y=eTx+fx​,z=1eTx+fz = \\frac{1}{e^Tx+f}z=eTx+f1​ 二次优化p145{p_{145}}p145​ 当凸优化问题的目标函数是（凸）二次型且约束函数为仿射时，该问题为二次规划（QP），可以表示为： min⁡ (1/2)xTPx+qTx+r\\min \\space (1/2) x^TPx + q^Tx + rmin (1/2)xTPx+qTx+r s.t. Gx⪯hs.t. \\space Gx\\preceq hs.t. Gx⪯h Ax=bAx=bAx=b 其中PPP为半正定对称矩阵。从集合上讲，我们是在多面体上极小化一个凸二次函数。 若在上式中，不等式约束也是（凸）二次型，那么这问题为二次约束二次规划（QCQP），此时是在椭圆的交集构成的可行集上极小化凸二次函数。 例子 最小二乘及回归p146{p_{146}}p146​ 极小化凸二次函数： ∣∣Ax−b∣∣22=aTATAx−2bTAx+bTb||Ax-b||^2_2 = a^TA^TAx - 2b^TAx + b^Tb∣∣Ax−b∣∣22​=aTATAx−2bTAx+bTb 这个问题很简单，有解析解ATAx=ATbA^TAx = A^TbATAx=ATb，可见最小二乘法这篇文章。 增加线性不等式约束后的问题为约束回归或约束最小二乘，此问题不再有简单的解析解，例如： min⁡ ∣∣Ax−b∣∣22\\min \\space ||Ax-b||^2_2min ∣∣Ax−b∣∣22​ s.t. li≤xi≤uis.t. \\space l_i\\le x_i\\le u_is.t. li​≤xi​≤ui​ 这是一个二次规划。 二阶锥规划p149{p_{149}}p149​ 一个与二次规划紧密相关的问题是二阶锥规划（SOCP）： min⁡ fTx\\min \\space f^Txmin fTx s.t. ∣∣Aix+bi∣∣2≤ciTx+dis.t. \\space ||A_ix+b_i||_2 \\le c_i^Tx+d_is.t. ∣∣Ai​x+bi​∣∣2​≤ciT​x+di​ Fx=gFx=gFx=g 其中xxx是优化变量，称∣∣Aix+bi∣∣2≤ciTx+di||A_ix+b_i||_2 \\le c_i^Tx+d_i∣∣Ai​x+bi​∣∣2​≤ciT​x+di​为二阶锥约束。 鲁棒线性规划 min⁡ cTx\\min \\space c^Txmin cTx s.t. aiTx≤bi,∀ai∈ϵi,i=1,..,ms.t. \\space a_i^Tx \\le b_i ,\\forall a_i \\in \\epsilon_i, i = 1,..,m s.t. aiT​x≤bi​,∀ai​∈ϵi​,i=1,..,m 其中，aia_iai​是在变化的，这一鲁棒线性约束可以表示为： sup⁡{aiTx∣ai∈ϵi}≤bi\\sup \\{a_i^Tx|a_i\\in \\epsilon_i \\} \\le b_isup{aiT​x∣ai​∈ϵi​}≤bi​ 而aia_iai​的变化可以表示为： ai∈ϵi={ai^+Piu∣∣∣u∣∣2≤1}a_i\\in \\epsilon_i = \\{\\hat{a_i} + P_iu| ||u||_2 \\le 1\\}ai​∈ϵi​={ai​^​+Pi​u∣∣∣u∣∣2​≤1} 因此，原约束可以表示为： sup⁡{aiTx∣ai∈ϵi}=ai^Tx+sup⁡{uTPix∣∣∣u∣∣2≤1}=ai^Tx+∣∣PiTx∣∣2\\sup \\{a_i^Tx|a_i\\in \\epsilon_i \\} = \\hat{a_i}^Tx + \\sup \\{u^TP_ix | ||u||_2 \\le 1\\} = \\hat{a_i}^Tx + ||P_i^Tx||_2sup{aiT​x∣ai​∈ϵi​}=ai​^​Tx+sup{uTPi​x∣∣∣u∣∣2​≤1}=ai​^​Tx+∣∣PiT​x∣∣2​ 鲁棒性约束可以表示为： ai^Tx+∣∣PiTx∣∣2≤b\\hat{a_i}^Tx + ||P_i^Tx||_2\\le bai​^​Tx+∣∣PiT​x∣∣2​≤b 这是一个二阶锥规划，因此，可以将其转化为SOCP: min⁡ cTx\\min \\space c^Txmin cTx s.t. ai^Tx+∣∣PiTx∣∣2≤bs.t.\\space \\hat{a_i}^Tx + ||P_i^Tx||_2\\le bs.t. ai​^​Tx+∣∣PiT​x∣∣2​≤b 几何规划 这是一类特殊的优化问题，他们的自然形式并不是凸的，但通过变量替换或目标函数、约束函数的转换，可以将其转换为凸优化问题。 单项式和正项式p153{p_{153}}p153​ 函数fff 定义为: f(x)=cx1a1x2a2...xnanf(x) = cx_1^{a_1}x_2^{a_2}...x_n^{a_n}f(x)=cx1a1​​x2a2​​...xnan​​ 其中c>0c > 0c>0，被称为单项式函数。 以下函数被称为正项式函数： f(x)=∑k=1Kckx1a1kx2a2k...xnankf(x) = \\sum\\limits_{k=1}^K c_kx_1^{a_{1k}}x_2^{a_{2k}}...x_n^{a_{nk}}f(x)=k=1∑K​ck​x1a1k​​x2a2k​​...xnank​​ 其中ckc_kck​大于0。 正项式对于加法、数乘和非负的伸缩变化是封闭的。 单项式对于数乘和除是封闭的。 几何规划 具有以下形式的优化问题被称为几何规划（GP）： min⁡ f0(x)\\min \\space f_0(x)min f0​(x) s.t. fi(x)≤1,i=1,...,ms.t. \\space f_i(x) \\le1, i =1,...,ms.t. fi​(x)≤1,i=1,...,m hi(x)=1,i=1,...,ph_i(x)=1,i=1,...,phi​(x)=1,i=1,...,p 凸形式的几何规划 几何规划一般不是凸优化问题，但我们可以将其转换为凸优化。 用yi=log⁡xiy_i =\\log x_i yi​=logxi​定义变量，因此xi=eyix_i = e^{y_i}xi​=eyi​。如果fff是xxx的单项式函数，即：f(x)=cx1a1x2a2...xnanf(x) = cx_1^{a_1}x_2^{a_2}...x_n^{a_n}f(x)=cx1a1​​x2a2​​...xnan​​，则： f(x)=f(ey1,...,eyn)=eaTy+bf(x) = f(e^{y_1},...,e^{y_n}) = e^{a^Ty+b}f(x)=f(ey1​,...,eyn​)=eaTy+b 其中b=log⁡cb = \\log cb=logc，变量替换将一个单项式函数转化为以仿射函数为指数的函数。 类似，若fff是正项式，则可以转化为： f(x)=∑k=1KeakTy+bkf(x) = \\sum \\limits_{k=1}^K e^{a^T_ky+b_k}f(x)=k=1∑K​eakT​y+bk​ 经过变换，正项式转换为以仿射函数为指数的函数的和。 因此，集合规划可以用新变量yyy的形式表示： min⁡∑k=1KeakTy+bk\\min \\sum \\limits_{k=1}^K e^{a^T_ky+b_k}mink=1∑K​eakT​y+bk​ s.t. ∑k=1KieaikTy+biks.t.\\space \\sum \\limits_{k=1}^{K_i} e^{a^T_{ik}y+b_{ik}}s.t. k=1∑Ki​​eaikT​y+bik​ egiTy+hi=1e^{g^T_iy}+h_i = 1egiT​y+hi​=1 如果正则式目标函数和所有约束函数都只含一项，即都是单项式，那么凸形式的集合规划将退化为一般的线性规划。 "},"duality.html":{"url":"duality.html","title":"对偶","keywords":"","body":" 凸函数的对偶问题是解决最优化的有效方法。 Lagrange对偶函数 Lagrangep207{p_{207}}p207​ 考虑标准形式的优化问题： min⁡ fo(x)\\min \\space f_o(x)min fo​(x) s.t. fi(x)≤0,i=1,...,ms.t. \\space f_i(x)\\le 0,i=1,...,ms.t. fi​(x)≤0,i=1,...,m hi(x)=0,i=1,...,ph_i(x) = 0,i=1,...,phi​(x)=0,i=1,...,p 注意这里并没有假设问题是凸优化问题。 Lagrange对偶的基本思想是在目标函数中考虑问题的约束条件，即添加约束条件的加权和，得到目标的增广函数。 上述函数的Lagrange函数为： L(x,λ,v)=f0(x)+∑i=1mλifi(x)+∑i=1pvihi(x) L(x, \\lambda, v)=f_{0}(x)+\\sum_{i=1}^{m} \\lambda_{i} f_{i}(x)+\\sum_{i=1}^{p} v_{i} h_{i}(x) L(x,λ,v)=f0​(x)+i=1∑m​λi​fi​(x)+i=1∑p​vi​hi​(x) 其中λi\\lambda_iλi​、viv_ivi​为对应的Lagrange乘子。 向量称为对偶变量或问题的Lagrange乘子向量。 Lagrange对偶函数 定义Lagrange对偶函数为Lagrange函数关于xxx取得的最小值，即： g(λ,v)=inf⁡x∈DL(x,λ,v)=inf⁡x∈D(f0(x)+∑i=1mλifi(x)+∑i=1pvihi(x)) g(\\lambda, v)=\\inf _{x \\in D} L(x, \\lambda, v)=\\inf _{x \\in D}\\left(f_{0}(x)+\\sum_{i=1}^{m} \\lambda_{i} f_{i}(x)+\\sum_{i=1}^{p} v_{i} h_{i}(x)\\right) g(λ,v)=x∈Dinf​L(x,λ,v)=x∈Dinf​(f0​(x)+i=1∑m​λi​fi​(x)+i=1∑p​vi​hi​(x)) 若Lagrange函数关于xxx无下界，则对偶函数取值−∞- \\infty−∞。 因为对偶函数是一簇关于(λ,v)(\\lambda,v)(λ,v)的仿射函数的逐点下确界，所以即使原问题不是凸的，对偶函数也是凹函数。 最优值的下界 很容易验证，对偶函数构成了原问题最优值p⋆p^\\starp⋆的下界，即对于任意λ⪰0\\lambda \\succeq 0λ⪰0，有下式成立： g(λ,v)≤p⋆g(\\lambda,v)\\le p^\\starg(λ,v)≤p⋆ 例子 线性方程组的最小二乘解p210{p_{210}}p210​ min⁡ xTx\\min \\space x^Txmin xTx s.t. Ax=bs.t.\\space Ax = bs.t. Ax=b 这个问题没有不等式约束，有ppp个线性等式约束。其Lagrange函数是： L(x,v)=xTx+vT(Ax−b)L(x,v) = x^Tx + v^T (Ax-b)L(x,v)=xTx+vT(Ax−b) 对偶问题是： g(v)=inf⁡xL(x,v)g(v) = \\inf _x L(x,v)g(v)=xinf​L(x,v) 因为L(x,v)L(x,v)L(x,v)是xxx的二次凸函数，因此可以通过求解以下最优性条件得到函数的最小值（无约束条件）： ▽xL(x,v)=2x+ATv=0\\bigtriangledown_xL(x,v) = 2x +A^Tv = 0▽x​L(x,v)=2x+ATv=0 在点x=−(1/2)ATvx = -(1/2)A^Tvx=−(1/2)ATv处Lagrange函数达到最小值。 标准形式的线性规划 min⁡cTx\\min c^TxmincTx s.t. Ax=bs.t. \\space Ax = bs.t. Ax=b x⪰0x \\succeq 0x⪰0 转化为Lagrange函数为： L(x,λ,v)=cTx−∑i=1nλixi+vT(Ax−b)=−bTv+(c+ATv−λ)TxL(x,\\lambda,v) = c^Tx - \\sum\\limits_{i=1}^n\\lambda_ix_i + v^T(Ax -b) = -b^Tv + (c + A^Tv - \\lambda)^TxL(x,λ,v)=cTx−i=1∑n​λi​xi​+vT(Ax−b)=−bTv+(c+ATv−λ)Tx 对偶函数为： g(λ,v)=inf⁡xL(x,λ,v)=−bTv+inf⁡x(c+ATv−λ)Txg(\\lambda,v) = \\inf_xL(x,\\lambda,v) = -b^Tv + \\inf_x(c + A^Tv - \\lambda)^Txg(λ,v)=xinf​L(x,λ,v)=−bTv+xinf​(c+ATv−λ)Tx 因为线性函数只有在恒为零时才有下界，因此，当c+ATv−λ=0c + A^Tv - \\lambda=0c+ATv−λ=0时，g(λ,v)=−bTvg(\\lambda,v) = -b^Tvg(λ,v)=−bTv，其余情况下g(λ,v)=−∞g(\\lambda,v) = - \\inftyg(λ,v)=−∞。 Lagrange对偶函数和共轭函数p212{p_{212}}p212​ 回忆共轭函数定义为： f⋆(y)=sup⁡x∈domf(yTx−f(x))f^\\star(y) = \\sup\\limits_{x\\in dom f} (y^Tx - f(x))f⋆(y)=x∈domfsup​(yTx−f(x)) 事实上，共轭函数与Lagrange对偶函数密切相关。我们可以考虑一个优化问题： min⁡f0(x)\\min f_0(x)minf0​(x) s.t. Ax⪯bs.t. \\space Ax \\preceq bs.t. Ax⪯b Cx=dCx = dCx=d 利用共轭函数，可以将问题的对偶函数表示为： g(λ,v)=inf⁡x(f0(x)+λT(Ax−b)+vT(Cx−d))=−bTλ−dTv+inf⁡x(f0(x)+(ATλ+CTv)Tx)=−bTλ−dTv−f0⋆(−ATλ−CTv) \\begin{aligned} g(\\lambda, v) &=\\inf _{x}\\left(f_{0}(x)+\\lambda^{T}(A x-b)+v^{T}(C x-d)\\right) \\\\ &=-b^{T} \\lambda-d^{T} v+\\inf _{x}\\left(f_{0}(x)+\\left(A^{T} \\lambda+C^{T} v\\right)^{T} x\\right) \\\\ &=-b^{T} \\lambda-d^{T} v-f_{0}^{\\star}\\left(-A^{T} \\lambda-C^{T} v\\right) \\end{aligned} g(λ,v)​=xinf​(f0​(x)+λT(Ax−b)+vT(Cx−d))=−bTλ−dTv+xinf​(f0​(x)+(ATλ+CTv)Tx)=−bTλ−dTv−f0⋆​(−ATλ−CTv)​ 熵的最大化p214{p_{214}}p214​ 考虑熵的最大化问题： min⁡ f0(x)=∑i=1nxilog⁡xi\\min \\space f_0(x) = \\sum\\limits_{i=1}^nx_i\\log x_imin f0​(x)=i=1∑n​xi​logxi​ s.t. Ax⪯bs.t. \\space Ax \\preceq bs.t. Ax⪯b 1Tx=11^Tx = 11Tx=1 关于xxx的负熵函数ulog⁡uu\\log uulogu的共轭函数是ev−1e^{v-1}ev−1（见p86{p_{86}}p86​）。因为函数f0f_0f0​是不同变量的负熵函数的和，因此其共轭函数为： f0⋆(y)=∑i=1neyi−1f^\\star _0(y) = \\sum\\limits_{i=1}^ne^{y_i-1}f0⋆​(y)=i=1∑n​eyi​−1 根据之前的结论，可以知道其对偶函数为： g(λ,v)=−bTλ−v−∑i=1ne−aiTλ−v−1g(\\lambda,v) = -b^T\\lambda -v -\\sum\\limits_{i=1}^n e^{-a_i^T\\lambda -v-1} g(λ,v)=−bTλ−v−i=1∑n​e−aiT​λ−v−1 其中aia_iai​是矩阵AAA的第iii列向量。 Lagrange对偶问题 定义 对于任意一组（λ,v\\lambda,vλ,v），Lagrange对偶函数给出优化问题的最优值的下界。因此，我们关心的是从Lagrange函数中能得到的最好下界是什么？ max⁡g(λ,v)\\max g(\\lambda,v)maxg(λ,v) s.t. λ⪰0s.t. \\space \\lambda \\succeq 0s.t. λ⪰0 上述问题为Lagrange对偶问题，是一个凸优化问题（与原问题的凹凸性无关）。 例子 标准形式线性规划的Lagrange对偶 我们之前已经写出了线性规划的对偶函数，因此不难写出该问题的对偶问题： max⁡−bTx\\max -b^Txmax−bTx s.t.ATv−λ+c=0s.t. A^Tv - \\lambda +c = 0s.t.ATv−λ+c=0 λ⪰0\\lambda \\succeq 0λ⪰0 我们还可以将λ\\lambdaλ去掉，进一步简化问题为： max⁡−bTx\\max -b^Txmax−bTx ATv+c⪰0A^Tv + c \\succeq 0ATv+c⪰0 这是一个不等式形式的线性规划（我们将等式形式的线性规划通过对偶问题转化为不等式）。 不等式形式的线性规划的Lagrange对偶 类似的，我们可以写出不等式形式的线性规划问题： min⁡cTx\\min c^TxmincTx s.t.Ax⪯bs.t. Ax \\preceq bs.t.Ax⪯b 其Lagrange函数为： L(x,λ)=cTx+λT(Ax−b)=−bTλ+(ATλ+c)TxL(x,\\lambda) = c^Tx + \\lambda^T(Ax - b) = -b^T\\lambda +(A^T\\lambda + c)^TxL(x,λ)=cTx+λT(Ax−b)=−bTλ+(ATλ+c)Tx 所以对偶函数为： g(λ)=inf⁡xL(x,λ)=−bTλ+inf⁡x(ATλ+c)Txg(\\lambda) = \\inf_x L(x,\\lambda) = -b^T\\lambda +\\inf _x(A^T\\lambda + c)^Txg(λ)=xinf​L(x,λ)=−bTλ+xinf​(ATλ+c)Tx 因此，当ATλ+c=0A^T\\lambda + c = 0ATλ+c=0且λ⪰0\\lambda \\succeq 0λ⪰0时，g(λ)=−bTλg(\\lambda) = -b^T\\lambdag(λ)=−bTλ 同样，我们可以写出其Lagrange对偶问题： max⁡−bTλ\\max -b^T\\lambdamax−bTλ s.t.ATλ+c=0s.t. A^T\\lambda +c = 0s.t.ATλ+c=0 λ⪰0\\lambda \\succeq 0λ⪰0 很有趣的是，我们发现不等式形式的线性规划问题，通过Lagrange对偶问题可以转化为等式形式。 因此，不等式和等式形式的线性规划与其对偶问题存在着对称性。 弱对偶性 用d⋆d^\\stard⋆表示Lagrange对偶问题的最优值，原问题的最优值用p⋆p^\\starp⋆表示，很容易，我们可以有以下不等式： d⋆≤p⋆d^\\star \\le p^\\star d⋆≤p⋆ 即使原问题不是凸问题，上述不等式依然成立，这个性质称为弱对偶性。 最优对偶间隙定义为p⋆−d⋆p^\\star - d^\\starp⋆−d⋆，给出了原问题最优值以及通过Lagrange对偶函数所能得到的最好下界之差，总是非负的。 为什么我们要大费周折来求对偶问题呢？这是因为当原问题很难求解时，弱对偶不等式可以给出原问题最优值的一个下界，这是因为对偶问题总是凸问题，更容易求解。 强对偶性与Slater准则 如果等式d⋆=p⋆d^\\star = p^\\star d⋆=p⋆成立，即最优对偶间隙为零，则强对偶性成立。 这是我们愿意看见的情形，因为这样我们可以通过求解对偶问题从而得到原问题的最优解。 凸函数 对于一般情况，强对偶性不成立。但是，如果原问题是凸问题，即可以表述为以下形式： min⁡f0(x)\\min f_0(x)minf0​(x) s.t.fi(x)≤0s.t. f_i(x) \\le 0s.t.fi​(x)≤0 Ax=bAx = bAx=b 其中fif_ifi​都是凸函数，则强对偶性通常（不总是）成立。 Slater条件 一个简单的强对偶性成立的条件，我们称为Slater条件，表述为存在一点x∈relint(D)x \\in relint (D)x∈relint(D) fi(x)0,i=1,...,m, Ax=bf_i(x) fi​(x)0,i=1,...,m, Ax=b 即每一个约束条件都严格满足。 Slater定理表明，当条件成立且原问题为凸问题时，强对偶性成立。 同时，当不等式约束fif_ifi​中有一些仿射函数时，Slater条件可以进一步放宽。如果前kkk个条件约束是仿射的，则若下列弱化的条件成立，强对偶性成立（仿射不等式不需要严格成立）。即： fi(x)≤0,i=1,...,k fi(x)0,i=k+1,...,m Ax=bf_i(x)\\le 0, i=1,...,k \\space f_i(x)fi​(x)≤0,i=1,...,k fi​(x)0,i=k+1,...,m Ax=b 例子 二次约束二次规划QCQPp220{p_{220}}p220​ 考虑约束和目标函数都是二次函数的优化问题： min⁡(1/2)xTP0x+q0Tx+r0\\min (1/2)x^TP_0x + q_0^Tx + r_0min(1/2)xTP0​x+q0T​x+r0​ s.t. (1/2)xTPix+qiTx+ri≤0s.t. \\space (1/2)x^TP_ix + q_i^Tx + r_i \\le0s.t. (1/2)xTPi​x+qiT​x+ri​≤0 其Lagrange函数为： L(x,λ)=(1/2)xTP(λ)x+q(λ)Tx+r(λ)L(x,\\lambda) = (1/2 )x^TP(\\lambda)x + q(\\lambda)^Tx + r(\\lambda)L(x,λ)=(1/2)xTP(λ)x+q(λ)Tx+r(λ) 其中P(λ)=P0+∑λiPiP(\\lambda) = P_0 + \\sum \\lambda_iP_iP(λ)=P0​+∑λi​Pi​，q(λ)=q0+∑λiqiq(\\lambda) = q_0 + \\sum \\lambda_iq_iq(λ)=q0​+∑λi​qi​，r(λ)=ro+∑λirir(\\lambda) = r_o + \\sum \\lambda_ir_ir(λ)=ro​+∑λi​ri​ 对于P(λ)≻0P(\\lambda)\\succ 0P(λ)≻0，可以表述对偶问题为： max⁡−(1/2)q(λ)TP(λ)−1q(λ)+r(λ)\\max -(1/2)q(\\lambda)^TP(\\lambda)^{-1}q(\\lambda) + r(\\lambda)max−(1/2)q(λ)TP(λ)−1q(λ)+r(λ) s.t.λ⪰0s.t. \\lambda \\succeq 0s.t.λ⪰0 根据Slater条件，当二次不等式约束严格成立时，即存在一点xxx使得： (1/2)xTPix+qiTx+ri0(1/2)x^TP_ix + q_i^Tx + r_i (1/2)xTPi​x+qiT​x+ri​0 强对偶性成立。 小结 总的来说，传统的Lagrange函数的作用是使得有约束的问题变为无约束： 通过拉格朗日的办法重新定义一个无约束问题这个无约束问题等价于原来的约束优化问题，从而将约束问题无约束化。 而Lagrange对偶问题则进一步，将最小化最大值问题转化为最大化最小值问题，即最大化Lagrange对偶函数来求得原问题的解的下界（在Slater条件下相等），而对偶函数的好处是它始终是一个凸函数。 对偶性我们可以从之前线性规划的对偶问题看出眉目。 最优性条件p233{p_{233}}p233​ 互补松弛性 设原问题和对偶问题得到最优值都可以达到且相等（即强对偶性成立）。令x⋆x^\\starx⋆是原问题的最优解，(λ⋆,v⋆)(\\lambda ^\\star,v^\\star)(λ⋆,v⋆)是对偶问题的最优解，则： f0(x⋆)=g(λ⋆,v⋆)=inf⁡x(f0(x)+∑λi⋆fi(x)+∑vi⋆hi(x))≤f0(x⋆)+∑λi⋆fi(x⋆)+∑vi⋆hi(x⋆)≤f0(x⋆) \\begin{aligned} f_{0}\\left(x^{\\star}\\right) &=g\\left(\\lambda^{\\star}, v^{\\star}\\right) \\\\ &=\\inf _{x}\\left(f_{0}(x)+\\sum \\lambda_{i}^{\\star} f_{i}(x)+\\sum v_{i}^{\\star} h_{i}(x)\\right) \\\\ & \\leq f_{0}\\left(x^{\\star}\\right)+\\sum \\lambda_{i}^{\\star} f_{i}\\left(x^{\\star}\\right)+\\sum v_{i}^{\\star} h_{i}\\left(x^{\\star}\\right) \\\\ & \\leq f_{0}\\left(x^{\\star}\\right) \\end{aligned} f0​(x⋆)​=g(λ⋆,v⋆)=xinf​(f0​(x)+∑λi⋆​fi​(x)+∑vi⋆​hi​(x))≤f0​(x⋆)+∑λi⋆​fi​(x⋆)+∑vi⋆​hi​(x⋆)≤f0​(x⋆)​ 可以得到一个重要的结论： λi⋆fi(x⋆)=0\\lambda_i^\\star f_i(x^\\star) = 0λi⋆​fi​(x⋆)=0 这个条件被称为互补松弛性。它对任意原问题最优解x⋆x^\\starx⋆以及对偶问题的最优解(λ⋆,v⋆)(\\lambda^\\star,v^\\star)(λ⋆,v⋆)都成立。可以将互补松弛条件写成： λ⋆>0⇒fi(x⋆)=0\\lambda ^\\star > 0 \\Rightarrow f_i(x^\\star) =0λ⋆>0⇒fi​(x⋆)=0 fi(x⋆)0⇒λ⋆=0f_i(x^\\star) fi​(x⋆)0⇒λ⋆=0 因此，除了第iii个约束起作用外，最优Lagrange乘子的第iii项都为零。 KKT最优性条件 假设函数fif_ifi​都可微（定义域是开集），但并不假设其为凸函数。 非凸问题的KKT条件p235{p_{235}}p235​ 当对偶间隙为0时，因为L(x,λ⋆,v⋆)L(x,\\lambda^\\star,v^\\star)L(x,λ⋆,v⋆)关于xxx求极小在x⋆x^\\starx⋆处取得最小值，因此函数在x⋆x^\\starx⋆处的导数必须为零，因此： ▽f0(x⋆)+∑λi⋆▽fi(x⋆)+∑vi⋆▽hi(x⋆)=0\\triangledown f_0(x^\\star)+\\sum\\lambda_i^\\star\\triangledown f_i(x^\\star) + \\sum v_i^\\star\\triangledown h_i(x^\\star) = 0▽f0​(x⋆)+∑λi⋆​▽fi​(x⋆)+∑vi⋆​▽hi​(x⋆)=0 因此，我们可以得到： fi(x⋆)≤0f_i(x^\\star) \\le 0fi​(x⋆)≤0 hi(x⋆)=0h_i(x^\\star) = 0hi​(x⋆)=0 λi⋆≥0\\lambda_i^\\star \\ge 0λi⋆​≥0 λi⋆fi(x⋆)=0\\lambda_i^\\star f_i(x^\\star )= 0λi⋆​fi​(x⋆)=0 ▽f0(x⋆)+∑λi⋆▽fi(x⋆)+∑vi⋆▽hi(x⋆)=0\\triangledown f_0(x^\\star)+\\sum\\lambda_i^\\star\\triangledown f_i(x^\\star) + \\sum v_i^\\star\\triangledown h_i(x^\\star) = 0▽f0​(x⋆)+∑λi⋆​▽fi​(x⋆)+∑vi⋆​▽hi​(x⋆)=0 上述条件为KKT条件，如果强对偶性成立，那么任何一对原问题的最优解和对偶问题的最优解必须满足KKT条件。 凸问题的KKT条件 当原问题是凸问题时，满足KKT条件的点也是原、对偶最优解。即若函数fif_ifi​是凸函数，hih_ihi​是仿射函数，x~,λ~,v~\\tilde{x},\\tilde{\\lambda},\\tilde{v}x~,λ~,v~是任意满足KKT条件的点： fi(x~)≤0f_i(\\tilde{x}) \\le 0fi​(x~)≤0 hi(x~)=0h_i(\\tilde{x}) = 0hi​(x~)=0 λi~≥0\\tilde{\\lambda_i} \\ge 0λi​~​≥0 λi~fi(x~)=0\\tilde{\\lambda_i} f_i(\\tilde{x})= 0λi​~​fi​(x~)=0 ▽f0(x~)+∑λi~▽fi(x~)+∑vi~▽hi(x~)=0\\triangledown f_0(\\tilde{x})+\\sum\\tilde{\\lambda_i}\\triangledown f_i(\\tilde{x}) + \\sum \\tilde{v_i}\\triangledown h_i(\\tilde{x}) = 0▽f0​(x~)+∑λi​~​▽fi​(x~)+∑vi​~​▽hi​(x~)=0 那么x~,λ~,v~\\tilde{x},\\tilde{\\lambda},\\tilde{v}x~,λ~,v~分别是原问题和对偶问题的最优解。 小结 若原问题为普通优化问题，如果强对偶性成立，那么任何一对原问题的最优解和对偶问题的最优解必须满足KKT条件。 而如果是目标函数和约束函数可微的凸优化问题，任意满足KKT条件的点分别是原问题、对偶问题的最优解。 因此，我们可以通过求解KKT条件，来求解原问题的最优解。 扰动及灵敏度分析 当强对偶性成立时，对原问题的约束进行扰动，对偶问题最优变量为原问题最优值的灵敏度分析提供了很多有用的信息。 扰动问题p241{p_{241}}p241​ min⁡f0(x)\\min f_0(x)minf0​(x) s.t. fi(x)≤uis.t.\\space f_i(x)\\le u_is.t. fi​(x)≤ui​ hi(x)=vih_i(x)=v_ihi​(x)=vi​ 若uiu_iui​大于0，则我们放松了第iii个不等式约束；若uiu_iui​小于0，则我们加强了第iii个不等式约束。 定义p⋆(u,v)p^\\star(u,v)p⋆(u,v)为扰动问题的最优值： p⋆(u,v)=inf⁡{fo(x)∣∃x∈D,fi(x)≤ui,hi(x)=vi}p^\\star(u,v) = \\inf\\{f_o(x)| \\exists x\\in D ,f_i(x)\\le u_i,h_i(x) = v_i\\}p⋆(u,v)=inf{fo​(x)∣∃x∈D,fi​(x)≤ui​,hi​(x)=vi​} 若定义p⋆p^\\starp⋆为原始问题的最优解，可以发现p⋆(0,0)=p⋆p^\\star(0,0) = p^\\starp⋆(0,0)=p⋆。 全局不等式 假设强对偶性成立且对偶问题的最优值可以达到。我们由如下推导： p⋆(0,0)=g(λ⋆,v⋆)≤f0(x)+∑λi⋆fi(x)+∑vi⋆hi(x)≤f0(x)+λ⋆Tu+v⋆Tv \\begin{aligned} p^{\\star}(0,0) &=g\\left(\\lambda^{\\star}, v^{\\star}\\right) \\\\ & \\leq f_{0}(x)+\\sum \\lambda_{i}^{\\star} f_{i}(x)+\\sum v_{i}^{\\star} h_{i}(x) \\\\ & \\leq f_{0}(x)+\\lambda^{\\star T} u+v^{\\star T} v \\end{aligned} p⋆(0,0)​=g(λ⋆,v⋆)≤f0​(x)+∑λi⋆​fi​(x)+∑vi⋆​hi​(x)≤f0​(x)+λ⋆Tu+v⋆Tv​ 因此，对于任意扰动问题的可行解xxx： f0(x)≥p⋆(0,0)−λ⋆Tu−v⋆Tvf_0(x) \\ge p^\\star (0,0) - {\\lambda^\\star}^T u - {v^\\star}^T vf0​(x)≥p⋆(0,0)−λ⋆Tu−v⋆Tv 即p⋆(u,v)≥p⋆(0,0)−λ⋆Tu−v⋆Tvp^\\star(u,v) \\ge p^\\star (0,0) - {\\lambda^\\star}^T u - {v^\\star}^T vp⋆(u,v)≥p⋆(0,0)−λ⋆Tu−v⋆Tv 解释 如果λ⋆\\lambda^\\starλ⋆较大，我们加强第iii个约束(选择ui0u_i ui​0)，则最优值p⋆(λ⋆,v⋆)p^\\star(\\lambda^\\star ,v^\\star) p⋆(λ⋆,v⋆)会大幅增加； 如果v⋆v^\\starv⋆较大且大于0，选择v0vv0；或者如果v⋆v^\\starv⋆较大且小于0，我们选择vi>0v_i > 0vi​>0，这两种情况下最优值也会大幅增加； 类似，如果λ⋆\\lambda^\\starλ⋆较小，我们放松第iii个约束(选择ui>0u_i > 0ui​>0)，则最优值p⋆(λ⋆,v⋆)p^\\star(\\lambda^\\star ,v^\\star) p⋆(λ⋆,v⋆)不会减小太多； 然而，这个不等式只能给出扰动之后最优值的一个下界，结论不是对称的。 局部灵敏度分析p243{p_{243}}p243​ 假设p⋆(u,v)p^\\star(u,v)p⋆(u,v)在u=0u = 0u=0和v=0v = 0v=0处可微，假设强对偶性成立，则： λi⋆=−∂p⋆(0,0)∂uivi⋆=−∂p⋆(0,0)∂vi\\lambda^\\star_i = -\\frac{\\partial p^\\star(0,0)}{\\partial u_i} \\quad v^\\star_i = -\\frac{\\partial p^\\star(0,0)}{\\partial v_i} λi⋆​=−∂ui​∂p⋆(0,0)​vi⋆​=−∂vi​∂p⋆(0,0)​ 可以发现，最优Lagrange乘子就是最优值关于约束扰动的局部灵敏度。 并且，这种关系是对称的：若稍微加强不等式约束，会使得最优值增大；若稍微放松不等式约束，会使得最优值减小。 Reference 拉格朗日对偶问题 "},"fitting.html":{"url":"fitting.html","title":"逼近与拟合","keywords":"","body":" 这一章开始，进入凸优化的应用。 拟合、逼近、插值 拟合 一般是对于离散点 用函数代替列表函数使得误差在某种意义下最小 插值 一般是对于离散点 用一个函数来近似代替列表函数，并要求函数通过列表函数中给定的数据点 逼近 一般是对于连续函数 为复杂函数寻找近似替代函数，其误差在某种度量下最小 范数逼近 基本问题p286{p_{286}}p286​ 最简单的范数逼近问题具有以下形式的无约束问题： min⁡∣∣Ax−b∣∣\\min ||Ax -b ||min∣∣Ax−b∣∣ 向量r=Ax−br = Ax-br=Ax−b称为这个问题的残差，其分量称为个体残差。 很明显，范数逼近问题是一个凸问题，也就是说，至少存在一个最优解。 由线性代数的知识，当b∈C(A)b \\in C(A)b∈C(A)时，最优值为0，但我们更关心其不为AAA的列空间的情况。 解释 Ax=x1a1+...+xnanAx = x_1a_1 + ... + x_n a_nAx=x1​a1​+...+xn​an​ 可以看出，范数逼近问题目标是用AAA的列空间的线性组合尽可能的逼近bbb向量，其偏差由范数度量。 在几何上有更好的解释，其中，xxx可认为是向量bbb在AAA的子空间中的投影点，也就是最靠近bbb的点。 最小二乘逼近 最常见的范数逼近是l2l_2l2​范数。其问题描述为： min⁡∣∣Ax−b∣∣22=r12+...+rm2\\min ||Ax - b||^2_2 = r_1^2 + ...+r^2_mmin∣∣Ax−b∣∣22​=r12​+...+rm2​ 其目标函数为残差平方和。我们可以将目标函数转化为凸二次函数： f(x)=xTATAx−2bTAx+bTbf(x) = x^TA^TAx - 2b^TAx + b^Tbf(x)=xTATAx−2bTAx+bTb 可以解析的求解得到： ATAx=ATbA^TAx = A^TbATAx=ATb 这个方程为正规方程，并且总是有解的。 Chebyshev逼近 当使用l∞l _{\\infty}l∞​范数时，逼近问题转化为： min⁡∣∣Ax−b∣∣∞=min⁡max⁡{∣r1∣,...,∣rm∣}\\min ||Ax -b||_{\\infty} = \\min \\max \\{|r_1|,...,|r_m|\\}min∣∣Ax−b∣∣∞​=minmax{∣r1​∣,...,∣rm​∣} 表示为极小化最大残差。可以将其描述为线性规划问题： min⁡t\\min \\quad tmint s.t.−t1⪯Ax−b⪯t1s.t.\\quad -t1 \\preceq Ax -b \\preceq t1 s.t.−t1⪯Ax−b⪯t1 残差绝对值之和逼近 如果使用l1l_1l1​范数，逼近问题表示为： min⁡∣∣Ax−b∣∣=min⁡∣r1∣+...+∣rm∣\\min ||Ax -b|| = \\min |r_1| + ... + |r_m|min∣∣Ax−b∣∣=min∣r1​∣+...+∣rm​∣ 这是一种鲁棒估计器。也可以表示为线性规划问题： min⁡1Tt\\min \\quad 1^Ttmin1Tt s.t.−t⪯Ax−b⪯ts.t.\\quad -t \\preceq Ax -b \\preceq t s.t.−t⪯Ax−b⪯t 罚函数逼近 我们把范数扩展开来，可以考虑目标函数： (∣r1∣p+...+∣rm∣p)1/p(|r_1|^p+ ... + |r_m|^p)^{1/p}(∣r1​∣p+...+∣rm​∣p)1/p 我们可以不用管外面的幂次，具体来说，可写成如下罚函数逼近问题： min⁡ϕ(r1)+...+ϕ(rm)\\min \\phi(r_1) + ... +\\phi(r_m)minϕ(r1​)+...+ϕ(rm​) s.t.r=Ax−bs.t. \\quad r = Ax -bs.t.r=Ax−b 其中，ϕ\\phiϕ称为罚函数，若其为凸函数，则该问题为凸优化问题。 我们可以将目标函数理解为总体惩罚：每个残差的罚函数之和。 有一些常见的罚函数p288{p_{288}}p288​： ϕ(u)=∣u∣p\\phi(u) = |u|^pϕ(u)=∣u∣p，为范数逼近问题 带有死区的线性罚函数 对数障碍罚函数 Huber罚函数 对于这些罚函数的解释可以参考书上p288{p_{288}}p288​。 书中还考虑了野值（很大的噪声值）对用罚函数设计的影响。 最小范数问题 之前我们考虑的是范数逼近问题（在某种度量下残差最小），现在考虑范数最小问题： min⁡∣∣x∣∣\\min ||x||min∣∣x∣∣ s.t.Ax=bs.t. \\quad Ax =bs.t.Ax=b 该问题的解为Ax=bAx=bAx=b的最小范数解。 可重构为范数逼近问题，令x0x_0x0​为任意解，ZZZ的列是AAA的零空间的基： min⁡∣∣x0+Zu∣∣\\min ||x_0 + Zu||min∣∣x0​+Zu∣∣ 几何解释 可行集{x∣Ax=b}\\{x |Ax = b\\}{x∣Ax=b}是仿射的，最小范数问题是在仿射集合中寻找距离0最近的点，即寻找0向仿射集合的投影。 线性方程组的最小二乘解p296{p_{296}}p296​ 最常见的最小范数问题为l2l_2l2​范数： min⁡∣∣x∣∣22\\min ||x||^2_2min∣∣x∣∣22​ s.t.Ax=bs.t. \\quad Ax = bs.t.Ax=b 其唯一解称为方程Ax=bAx= bAx=b的最小二乘解。类似于最小二乘逼近，此问题也可以被解析的求解。我们可以使用对偶问题来解决此凸优化问题，最优性条件为： 2x⋆+ATv⋆=0,Ax⋆=b2x^\\star + A^Tv^\\star = 0 , \\quad Ax^\\star = b2x⋆+ATv⋆=0,Ax⋆=b 这很容易求解，不再赘述。 最小罚问题 min⁡ϕ(x1)+...+ϕ(xn)\\min \\phi (x_1) + ... + \\phi (x_n)minϕ(x1​)+...+ϕ(xn​) s.t.Ax=bs.t. \\quad Ax = bs.t.Ax=b 在约束Ax=bAx=bAx=b下，最小罚问题找到了具有最小总惩罚的xxx。 正则化逼近 双准则式 在正则化逼近中，我们的目标是寻找向量xxx使其较小，同时使得残差较小的值。 可以描述为双目标凸向量优化问题： min⁡(∣∣Ax−b∣∣,∣∣x∣∣)\\min (||Ax - b||,||x||)min(∣∣Ax−b∣∣,∣∣x∣∣) 注意，这两个范数可能是不同的，第一个用以度量残差的规模，第二个用于度量xxx的规模。 正则化 正则化是求解双准则问题的一个常用的标量化方法： min⁡∣∣Ax−b∣∣+γ∣∣x∣∣\\min ||Ax -b || + \\gamma||x||min∣∣Ax−b∣∣+γ∣∣x∣∣ 其中γ>0\\gamma> 0γ>0为问题参数。 Tikhonov正则化p298{p_{298}}p298​ 最常见的正则化基于上式并利用Euclid范数，得到一个凸二次优化问题（也称为领回归）： min⁡∣∣Ax−b∣∣22+δ∣∣x∣∣22=xT(ATA+δI)x−2bTAx+bTb\\min ||Ax-b||^2_2 + \\delta||x||^2_2 = x^T(A^TA+\\delta I)x -2b^TAx + b^Tbmin∣∣Ax−b∣∣22​+δ∣∣x∣∣22​=xT(ATA+δI)x−2bTAx+bTb 这个正则化有解析解： x=(ATA+δI)−1ATbx = (A^TA+\\delta I)^{-1} A^Tbx=(ATA+δI)−1ATb 鲁棒逼近 随机鲁棒逼近 当矩阵数据AAA允许不确定和可能的变化时，记起均值为Aˉ\\bar{A}Aˉ，UUU为均值为0的随机矩阵，则可以将AAA表示为： A=Aˉ+UA = \\bar{A}+UA=Aˉ+U 自然的，可以用∣∣Ax−b∣∣||Ax-b||∣∣Ax−b∣∣的期望来作为目标函数： min⁡E∣∣Ax−b∣∣\\min E||Ax-b||minE∣∣Ax−b∣∣ 这种问题被称为随机鲁棒逼近问题。虽然是凸优化，但并不好解。 若AAA仅有有限个可能值（离散点）时，即P(A=Ai)=piP(A = A_i) = p_iP(A=Ai​)=pi​，则问题可以写为： min⁡pi∣∣A1x−b∣∣+...+pk∣∣Akx−b∣∣\\min p_i||A_1x-b|| + ... + p_k ||A_kx-b||minpi​∣∣A1​x−b∣∣+...+pk​∣∣Ak​x−b∣∣ 这被称为范数和问题。可以表述为： min⁡pTt\\min \\quad p^TtminpTt s.t.∣∣Aix−b∣∣≤tis.t. \\quad ||A_ix -b|| \\le t_is.t.∣∣Ai​x−b∣∣≤ti​ 可见，若为l2l_2l2​范数，则范数和问题是一个二阶锥规划。 鲁棒最小二乘问题 min⁡E∣∣Ax−b∣∣22\\min E||Ax-b||^2_2minE∣∣Ax−b∣∣22​ 由于A=Aˉ+UA = \\bar{A}+ UA=Aˉ+U，则可以将目标函数改写为： E∥Ax−b∥22=E(Aˉx−b+Ux)T(Aˉx−b+Ux)=(Aˉx−b)T(Aˉx−b)+E(xTUTUx)=∥Aˉx−b∥22+xTPx \\begin{aligned} E\\|A x-b\\|_{2}^{2} &=E(\\bar{A} x-b+U x)^{T}(\\bar{A} x-b+U x) \\\\ &=(\\bar{A} x-b)^{T}(\\bar{A} x-b)+E\\left(x^{T} U^{T} U x\\right) \\\\ &=\\|\\bar{A} x-b\\|_{2}^{2}+x^{T} P x \\end{aligned} E∥Ax−b∥22​​=E(Aˉx−b+Ux)T(Aˉx−b+Ux)=(Aˉx−b)T(Aˉx−b)+E(xTUTUx)=∥Aˉx−b∥22​+xTPx​ 其中P=E(UTU)P=E(U^TU)P=E(UTU)。因此，可以将该问题化为正则化最小二乘形式： min⁡∣∣Aˉx−b∣∣22+∣∣P1/2x∣∣22\\min ||\\bar{A}x-b||^2_2 + ||P^{1/2}x||^2_2min∣∣Aˉx−b∣∣22​+∣∣P1/2x∣∣22​ 不难通过求导可以得到解为： x=(AˉTAˉ+P)−1AˉTbx= (\\bar{A}^T\\bar{A}+P)^{-1}\\bar{A}^Tbx=(AˉTAˉ+P)−1AˉTb 最坏鲁棒逼近 我们用AAA的可能值集合χ\\chi χ描述其不确定性，我们定义候选的逼近解xxx的最坏误差为： ewc(x)=sup⁡{∣∣Ax−b∣∣∣A∈χ}e_{wc}(x) = \\sup\\{||Ax-b|| |A\\in \\chi \\}ewc​(x)=sup{∣∣Ax−b∣∣∣A∈χ} 最坏情况鲁棒逼近问题是极小化最差情况的误差： min⁡ewc(x)\\min \\quad e_{wc}(x)minewc​(x) "},"unconstrain.html":{"url":"unconstrain.html","title":"无约束优化","keywords":"","body":" 本章进入凸优化问题的求解、算法阶段。 无约束优化问题 本文讨论一下无约束问题： min⁡f(x)\\min f(x)minf(x) 其中，fff是二次可微凸函数。假定该问题可解，即存在最优解x⋆x^\\starx⋆，用p⋆p^\\starp⋆表示最优值为：inf⁡xf(x)=f(x⋆)\\inf _xf(x) = f(x^\\star)infx​f(x)=f(x⋆)。 因为fff可微，则最优点x⋆x^\\starx⋆满足以下条件： ▽f(x⋆)=0\\triangledown f(x^\\star)= 0▽f(x⋆)=0 在特殊情况下，我们可以通过解析法求解最优性方程，但大多数情况下没有办法求得解析解。因此，最常见的方法是使用迭代法。 我们需要计算点列：x(0),x(1),..x^{(0)},x^{(1)},..x(0),x(1),..，使得k→∞,f(x(k))→p⋆k\\rightarrow \\infty ,f(x^{(k)}) \\rightarrow p^\\stark→∞,f(x(k))→p⋆。使用ϵ\\epsilon ϵ表示容许误差值，当f(x(k))−p⋆≤ϵf(x^{(k)}) - p^\\star \\le \\epsilon f(x(k))−p⋆≤ϵ时，算法终止。 例子p438{p_{438}}p438​ 二次优化 min⁡(1/2)xTPx+qTx+r\\min (1/2)x^TPx + q^Tx +rmin(1/2)xTPx+qTx+r 很容易我们可以对其求导得到Px⋆+q=0Px^\\star +q= 0Px⋆+q=0。 因此，若PPP为正定矩阵，则存在唯一解x⋆=−P−1qx^\\star = -P^{-1}qx⋆=−P−1q。 若此方程无解，则优化问题无下界。 最小二乘 作为二次优化的特例： min⁡∣∣Ax−b∣∣22=xT(ATA)x−2(ATb)Tx+bTb\\min ||Ax - b||^2_2= x^T(A^TA)x - 2(A^Tb)^Tx + b^Tbmin∣∣Ax−b∣∣22​=xT(ATA)x−2(ATb)Tx+bTb 其最优性解为其正规方程： ATAx⋆=ATbA^TAx^\\star = A^TbATAx⋆=ATb 强凸性 强凸是指： ▽2f(x)⪰mI\\triangledown^2 f(x) \\succeq mI▽2f(x)⪰mI 对任意x∈Sx\\in Sx∈S都成立。这里的▽2f(x)\\triangledown^2 f(x)▽2f(x)表示Hessian矩阵。 我们可以通过强凸性推导出有意义的方程。 次优性条件 f(y)=f(x)+∇f(x)T(y−x)+12(y−x)T∇2f(z)(y−x)≥f(x)+∇f(x)T(y−x)+m2∥y−x∥22 \\begin{aligned} f(y) &=f(x)+\\nabla f(x)^{T}(y-x)+\\frac{1}{2}(y-x)^{T} \\nabla^{2} f(z)(y-x) \\\\ & \\geq f(x)+\\nabla f(x)^{T}(y-x)+\\frac{m}{2}\\|y-x\\|_{2}^{2} \\end{aligned} f(y)​=f(x)+∇f(x)T(y−x)+21​(y−x)T∇2f(z)(y−x)≥f(x)+∇f(x)T(y−x)+2m​∥y−x∥22​​ 当m=0m =0 m=0时，上式变为凸性的基本不等式（一阶可微），当m≥0m\\ge 0m≥0时，对f(y)f(y)f(y)的下界得到了更好的估计结果。 对上式进行求导可得：▽f(x)+m(y−x)=0\\triangledown f(x) + m(y-x) = 0▽f(x)+m(y−x)=0 因此，带入原式可得： f(y)≥f(x)+∇f(x)T(y−x)+m2∥y−x∥22≥f(x)−12m∥∇f(x)∥22 \\begin{aligned} f(y) & \\geq f(x)+\\nabla f(x)^{T}(y-x)+\\frac{m}{2}\\|y-x\\|_{2}^{2} \\\\ & \\geq f(x)-\\frac{1}{2 m}\\|\\nabla f(x)\\|_{2}^{2} \\end{aligned} f(y)​≥f(x)+∇f(x)T(y−x)+2m​∥y−x∥22​≥f(x)−2m1​∥∇f(x)∥22​​ 既然该式子对任意y∈Sy\\in Sy∈S都成立，则： p⋆≥f(x)−12m∣∣▽f(x)∣∣22p^\\star \\ge f(x) - \\frac{1}{2m}||\\triangledown f(x)||^2_2p⋆≥f(x)−2m1​∣∣▽f(x)∣∣22​ 由于∣∣▽f(x)∣∣2≤(2mϵ)1/2||\\triangledown f(x)||_2 \\le (2m\\epsilon )^{1/2} ∣∣▽f(x)∣∣2​≤(2mϵ)1/2，因此带入可得到次优性条件： f(x)−p⋆≤ϵf(x) - p^\\star \\le \\epsilon f(x)−p⋆≤ϵ 我们也可以得到xxx与任意最优解x⋆x^\\starx⋆之间的距离与∣∣▽f(x)∣∣2||\\triangledown f(x)||_2∣∣▽f(x)∣∣2​的关系： ∣∣x−x⋆∣∣2≤2m∣∣▽f(x)∣∣2||x- x^\\star||_2 \\le \\frac {2}{m}||\\triangledown f(x)||_2∣∣x−x⋆∣∣2​≤m2​∣∣▽f(x)∣∣2​ 关于▽2f(x)\\triangledown^2 f(x)▽2f(x)的上界 由于∣∣▽2f(x)∣∣||\\triangledown^2 f(x)||∣∣▽2f(x)∣∣的最大特征值是xxx在SSS上的连续函数，因此他在SSS上有界，即存在常数MMM，使得(没懂)： ∣∣▽2f(x)∣∣⪯MI||\\triangledown^2 f(x)|| \\preceq MI∣∣▽2f(x)∣∣⪯MI 与上面类似，我们可以得到p⋆p^\\starp⋆的上界： p⋆≤f(x)−12M∣∣▽2f(x)∣∣22p^\\star \\le f(x) - \\frac{1}{2M}||\\triangledown^2 f(x)||_2^2 p⋆≤f(x)−2M1​∣∣▽2f(x)∣∣22​ 对比p⋆p^\\starp⋆的上界： p⋆≥f(x)−12m∣∣▽f(x)∣∣22p^\\star \\ge f(x) - \\frac{1}{2m}||\\triangledown f(x)||^2_2p⋆≥f(x)−2m1​∣∣▽f(x)∣∣22​ 下水平集的条件数 从之前的分析我们可以得到： mI⪯∣∣▽2f(x)∣∣⪯MImI \\preceq ||\\triangledown^2 f(x)|| \\preceq MImI⪯∣∣▽2f(x)∣∣⪯MI 因此，比值M/mM/mM/m是矩阵▽2f(x)\\triangledown^2 f(x) ▽2f(x)的条件数的上界，这是影响其计算效率的重要因素。 下降方法 我们讨论的所有方法都是下降方法，只要不是最优点则应该满足： f(x(k+1))f(x(k))f(x^{(k+1)}) f(x(k+1))f(x(k)) 而优化点列为： x(k+1)=x(k)+t(k)△x(k),t(k)>0x^{(k+1)} = x^{(k)} + t^{(k)}\\triangle x^{(k)},\\quad t^{(k)} > 0x(k+1)=x(k)+t(k)△x(k),t(k)>0 由凸性可知▽f(x(k))T(y−k(k))≥0\\triangledown f(x^{(k)})^T(y-k^{(k)}) \\ge 0▽f(x(k))T(y−k(k))≥0意味着f(y)≥f(x(k))f(y)\\ge f(x^{(k)})f(y)≥f(x(k))，因此，一个下降方法的搜索方向必须满足： ▽f(x(k))TΔx(k)0\\triangledown f(x^{(k)})^T\\Delta x^{(k)} ▽f(x(k))TΔx(k)0 这将作为我们判断后面下降算法的条件之一。 通用下降算法 确定下降方向Δx\\Delta xΔx 直线搜索。选择步长t>0t > 0t>0 修改。x:=x+tΔxx := x+t\\Delta xx:=x+tΔx 直到满足停止条件 精确直线搜索p444{p_{444}}p444​ ttt值是通过沿着射线{x+t△x∣t≥0}\\{x+t\\triangle x| t\\ge 0\\}{x+t△x∣t≥0}优化fff而确定的： t=arg⁡min⁡s≥0f(x+s△x)t = \\arg\\min_{s\\ge0} f(x+s\\triangle x)t=args≥0min​f(x+s△x) 当求解式中的单变量优化问题的成本比计算搜索方向的成本低时，采用精确直线搜索。 特殊情况可以用解析的方法确定最优解。 回溯直线搜索 很多时候我们并不需要找到一个最小的ttt，只需要fff有“足够的”减少即可。 常用的方法为： 给定下降方向Δx\\Delta xΔx,参数α∈(0,0.5),β∈(0,1)\\alpha\\in (0,0.5),\\beta\\in (0,1)α∈(0,0.5),β∈(0,1) 设定初始t=1t = 1t=1 iff(x+t△x)>f(x)+αt▽f(x)T△x,thent:=βtif \\quad f(x+t\\triangle x )> f(x) + \\alpha t \\triangledown f(x)^T \\triangle x,then \\quad t :=\\beta tiff(x+t△x)>f(x)+αt▽f(x)T△x,thent:=βt 回溯算法从单位步长开始，按比例逐渐减小，直到满足停止条件。 由于Δx\\Delta xΔx是下降方向，▽f(x)TΔx0\\triangledown f(x)^T \\Delta x▽f(x)TΔx0，所以只要ttt足够小，一定有： f(x+tΔx)≈f(x)+t▽f(x)TΔxf(x)+tα▽f(x)TΔxf(x+t\\Delta x) \\approx f(x) + t\\triangledown f(x)^T\\Delta xf(x+tΔx)≈f(x)+t▽f(x)TΔxf(x)+tα▽f(x)TΔx 因此回溯算法一定会停止。 梯度下降方法 梯度下降利用△x=−▽f(x)\\triangle x = -\\triangledown f(x) △x=−▽f(x)，是一种自然的选择。 算法过程 给定初始点x∈domfx\\in dom fx∈domf，Δx:=▽f(x)\\Delta x := \\triangledown f(x)Δx:=▽f(x) 直线搜索。通过精确或回溯直线搜索确定步长ttt 修改x:=x+tΔxx:=x+t\\Delta xx:=x+tΔx 直到满足停止准则 收敛性分析 我们可以推导得出： f(x(k))−p⋆≤ck(f(x(0))−p⋆)f(x^{(k)}) - p^\\star \\le c^k(f(x^{(0)}) - p^\\star)f(x(k))−p⋆≤ck(f(x(0))−p⋆) 其中c=1−m/M1c = 1-m/M c=1−m/M1，因此最多经过log⁡(f(x(0))−p⋆)/ϵlog⁡(1/c)\\frac{\\log (f(x^{(0)}) -p^\\star)/ \\epsilon }{\\log (1/c)}log(1/c)log(f(x(0))−p⋆)/ϵ​次迭代，可以收敛到次优性条件。 例子 R2R^2R2空间中的二次问题 考虑二次目标函数 f(x)=12(x12+γx22)f(x) = \\frac{1}{2}(x_1^2 + \\gamma x_2^2)f(x)=21​(x12​+γx22​) 其中γ\\gamma γ大于0。很容易得到其Hessian矩阵为常数，特征值为1和γ\\gamma γ，因此其下水平集的条件数都等于： max⁡(1,γ)min⁡(1,γ)=max⁡(γ,1/γ)\\frac{\\max(1,\\gamma)}{\\min(1,\\gamma)} = \\max (\\gamma ,1/\\gamma )min(1,γ)max(1,γ)​=max(γ,1/γ) 我们选取初始点x(0)=(γ,1)x^{(0)} = (\\gamma ,1)x(0)=(γ,1)，可以计算： 最速下降方法p454{p_{454}}p454​ 对f(x+v)f(x+v)f(x+v)在xxx处进行一阶Taylor展开： f(x+v)≈f^(x+v)=f(x)+▽f(x)Tvf(x+v) \\approx \\hat f(x+v) = f(x) +\\triangledown f(x)^Tv f(x+v)≈f^​(x+v)=f(x)+▽f(x)Tv 其中▽f(x)Tv\\triangledown f(x)^Tv▽f(x)Tv是fff在xxx在沿着方向vvv的方向导数，若其为负数，则vvv为下降方向。 如何选择vvv使得其方向导数尽可能小（下降最快），我们定义一个规范化的最速下降方向： Δxnsd=arg⁡min⁡{▽f(x)Tv ∣ ∣∣v∣∣=1}\\Delta x_{nsd} = \\arg\\min \\{\\triangledown f(x)^T v\\space | \\space ||v|| =1 \\}Δxnsd​=argmin{▽f(x)Tv ∣ ∣∣v∣∣=1} 我们也可以考虑将最速下降方向乘以一个特殊的比例因子，从而考虑非规范化的最速下降方向： Δxsd=∣∣▽f(x)∣∣⋆Δxnsd\\Delta x_{sd} = ||\\triangledown f(x)|| _\\star \\Delta x_{nsd}Δxsd​=∣∣▽f(x)∣∣⋆​Δxnsd​ 其中∣∣⊙∣∣⋆|| \\odot ||_\\star∣∣⊙∣∣⋆​定义为对偶范数（∣∣z∣∣⋆=sup⁡{zTx∣∣∣x∣∣≤1}||z||_\\star = \\sup\\{z^Tx | ||x||\\le1\\}∣∣z∣∣⋆​=sup{zTx∣∣∣x∣∣≤1}）。 对于这种最速下降步径，我们有： ∇f(x)TΔxsd=∥∇f(x)∥⋆∇f(x)TΔxnsd=−∥∇f(x)∥⋆20 \\nabla f(x)^{T} \\Delta x_{s d}=\\|\\nabla f(x)\\|_{\\star} \\nabla f(x)^{T} \\Delta x_{n s d}=-\\|\\nabla f(x)\\|_{\\star}^{2}∇f(x)TΔxsd​=∥∇f(x)∥⋆​∇f(x)TΔxnsd​=−∥∇f(x)∥⋆2​0 Newton方法p462{p_{462}}p462​ Newton步径 Δxnt=−▽2f(x)−1▽f(x)\\Delta x_{nt} = -\\triangledown^2 f(x)^{-1}\\triangledown f(x)Δxnt​=−▽2f(x)−1▽f(x) 由▽2f(x)\\triangledown^2f(x)▽2f(x)的正定性可知（凸函数的二阶条件），除非▽f(x)=0\\triangledown f(x) = 0▽f(x)=0，否则： ▽f(x)TΔx=−▽f(x)T▽2f(x)−1▽f(x)0\\triangledown f(x)^T\\Delta x = -\\triangledown f(x)^T \\triangledown^2 f(x)^{-1}\\triangledown f(x) ▽f(x)TΔx=−▽f(x)T▽2f(x)−1▽f(x)0 因此，Δxnt\\Delta x_{nt}Δxnt​与负梯度方向为锐角，Δxnt\\Delta x_{nt}Δxnt​是下降方向。 可以从以下几个方面来了解Newton步径。 二阶近似的最优解 考虑函数fff在xxx处的二阶Taylor近似为： f(x+v)^=f(x)+▽f(x)Tv+12vTf(x)v\\hat{f(x+v)} = f(x)+\\triangledown f(x)^Tv+\\frac{1}{2}v^Tf(x)vf(x+v)^​=f(x)+▽f(x)Tv+21​vTf(x)v 这是vvv的二次凸函数，在v=Δxntv =\\Delta x_{nt}v=Δxnt​处达到最小值。 因此，将xxx加上Newton步径Δxnt\\Delta x_{nt}Δxnt​能够极小化fff在xxx处的二阶近似。 如果函数是二次的，那么使用Newton步径是fff的精确最优解。若函数近似二次，则x+Δxntx+ \\Delta x_{nt}x+Δxnt​是fff的最优解，即x⋆x^\\starx⋆的很好的估计值。 Hessian范数下的最速下降方向 若定义Hessian矩阵▽2f(x)\\triangledown^2 f(x)▽2f(x)定义的二次范数，即： ∣∣u∣∣▽2f(x)=(uT▽2f(x)u)1/2||u||_{\\triangledown^2 f(x)} = (u^T\\triangledown^2 f(x)u)^{1/2}∣∣u∣∣▽2f(x)​=(uT▽2f(x)u)1/2 那么可以通过最速下降方向推出Δxnt\\Delta x_{nt}Δxnt​。 线性化最优性条件的解 若我们在xxx附近对最优性条件▽f(x⋆)=0\\triangledown f(x^\\star)=0▽f(x⋆)=0进行线性化，可得到： ▽f(x+v)≈▽f(x)+▽2f(x)v=0\\triangledown f(x+v) \\approx \\triangledown f(x) + \\triangledown^2 f(x)v = 0 ▽f(x+v)≈▽f(x)+▽2f(x)v=0 其解就是我们的Newton步径。 Newton减量p464{p_{464}}p464​ λ(x)=(▽f(x)T▽2f(x)−1▽f(x))1/2\\lambda(x) = (\\triangledown f(x) ^T\\triangledown^2 f(x)^{-1}\\triangledown f(x))^{1/2}λ(x)=(▽f(x)T▽2f(x)−1▽f(x))1/2 λ(x)\\lambda(x)λ(x)称为Newton减量，可以用来设计停止准则。 将Δxnt\\Delta x_{nt}Δxnt​带入f(x+tΔx)f(x+t\\Delta x)f(x+tΔx)得：f(x+tΔx)=f(x)−12▽Tf(x)▽2f(x)−1▽f(x)f(x+t\\Delta x) = f(x)- \\frac{1}{2}\\triangledown ^Tf(x)\\triangledown^2 f(x)^{-1}\\triangledown f(x)f(x+tΔx)=f(x)−21​▽Tf(x)▽2f(x)−1▽f(x) 因此：f(x)−f(x+tΔx)=12▽Tf(x)▽2f(x)−1▽f(x)=12λ(x)2f(x) - f(x+t\\Delta x) = \\frac{1}{2}\\triangledown ^Tf(x)\\triangledown^2 f(x)^{-1}\\triangledown f(x) = \\frac{1}{2}\\lambda(x)^2f(x)−f(x+tΔx)=21​▽Tf(x)▽2f(x)−1▽f(x)=21​λ(x)2 因此，λ/2\\lambda^/2λ/2是fff在xxx处的二阶近似对f(x)−p⋆f(x) - p^\\starf(x)−p⋆作出的估计。 我们也可以将Newton减量表示为λ=(ΔxntT▽2f(x)Δxnt)1/2\\lambda = (\\Delta x_{nt}^T\\triangledown ^2f(x)\\Delta x_{nt})^{1/2}λ=(ΔxntT​▽2f(x)Δxnt​)1/2，表明λ\\lambdaλ是Newton步径的二次范数，该范数由Hessian矩阵定义。 Newton减量也出现在回溯直线搜索中，因为我们可以得到： ▽Tf(x)Δxnt=−λ(x)2\\triangledown ^Tf(x)\\Delta x_{nt} = -\\lambda(x)^2▽Tf(x)Δxnt​=−λ(x)2 Newton方法 给定初始点x∈domfx \\in dom fx∈domf，误差阈值ϵ>0\\epsilon >0ϵ>0 计算Newton步径和减量 停止准则：如果λ2/2≤ϵ\\lambda^2/2\\le \\epsilon λ2/2≤ϵ，退出 直线搜索，根据回溯直线搜索确定步长ttt 改进：x:=x+tΔxntx:=x + t\\Delta x_{nt}x:=x+tΔxnt​ "},"equality.html":{"url":"equality.html","title":"等式约束优化","keywords":"","body":"等式约束优化问题 min⁡f(x)\\min f(x)minf(x) s.t.Ax=bs.t.\\quad Ax=bs.t.Ax=b 其中fff为二次可微凸函数，假设等式约束少于变量数，并且等式约束互相独立。假定存在一个最优解x⋆x^\\starx⋆，并用p⋆p^\\starp⋆表示其最优值，即： p⋆=inf⁡{f(x)∣Ax=b}=f(x⋆)p^\\star = \\inf \\{f(x) | Ax = b\\} = f(x^\\star)p⋆=inf{f(x)∣Ax=b}=f(x⋆) 由KKT条件，其最优解的重要条件是满足： Ax⋆=b▽f(x⋆)+ATv⋆=0Ax^\\star = b \\quad \\triangledown f(x^\\star) + A^Tv^\\star = 0Ax⋆=b▽f(x⋆)+ATv⋆=0 对于求解等式约束问题有两种方法： 任何等式约束优化问题都可以通过消除等式约束转化为等价的无约束问题。 使用对偶方法解决。 很多时候，直接处理等式约束比转化为无约束问题要好，这是因为转化之后可能会破坏问题的结构。 等式约束凸二次规划 min⁡f(x)=(1/2)xTPx+qTx+r\\min f(x) = (1/2)x^TPx+q^Tx+rminf(x)=(1/2)xTPx+qTx+r s.t.Ax=bs.t. \\quad Ax= bs.t.Ax=b 此问题的最优性条件为： Ax⋆=bPx⋆+q+ATv⋆=0Ax^\\star =b \\quad Px^\\star+q+A^Tv^\\star = 0Ax⋆=bPx⋆+q+ATv⋆=0 可以将其写成矩阵形式： [PATA0][x⋆v⋆]=[−qb]\\begin{bmatrix}P &A^T \\\\ A&0 \\end{bmatrix}\\begin{bmatrix}x^\\star\\\\v^\\star \\end{bmatrix} = \\begin{bmatrix}-q\\\\b \\end{bmatrix} [PA​AT0​][x⋆v⋆​]=[−qb​] 这个矩阵称为`KKT矩阵`，接下来会经常用到。 ## 消除等式约束 我们以参数化可行集的形式表示等式约束： {x∣Ax=b}={Fz+x^}\\{x|Ax=b\\}=\\{Fz+\\hat x\\}{x∣Ax=b}={Fz+x^} 其中x^\\hat xx^为任意特解，FFF为AAA的零空间的任意矩阵，可以消除等式约束为： min⁡f^(z)=f(Fz+x^)\\min \\hat f(z) = f(Fz + \\hat x)minf^​(z)=f(Fz+x^) 这里的变量zzz没有约束，利用它的解z⋆z^\\starz⋆可以确定等式约束问题的解x⋆=Fz⋆+x^x^\\star = Fz^\\star + \\hat xx⋆=Fz⋆+x^ ## 对偶方法求解等式约束 可得约束问题的对偶函数为： g(v)=−bTv+inf⁡x(f(x)+vTAx)=−bTx−sup⁡x((−ATv)Tx−f(x))=−bTv−f⋆(−ATv) \\begin{aligned} g(v) &=-b^{T} v+\\inf _{x}\\left(f(x)+v^{T} A x\\right) \\\\ &=-b^{T} x-\\sup _{x}\\left(\\left(-A^{T} v\\right)^{T} x-f(x)\\right) \\\\ &=-b^{T} v-f^{\\star}\\left(-A^{T} v\\right) \\end{aligned} g(v)​=−bTv+xinf​(f(x)+vTAx)=−bTx−xsup​((−ATv)Tx−f(x))=−bTv−f⋆(−ATv)​ 因此，对偶问题为： max⁡−bTv−f⋆(−ATv)\\max -b^Tv - f^\\star(-A^Tv) max−bTv−f⋆(−ATv) 若Slater条件成立，则强对偶性成立，即g(v⋆)=p⋆g(v^\\star) = p^\\starg(v⋆)=p⋆ 等式约束的Newton方法 讨论扩展的Newton方法，与之前无约束类似，但初始点必须可行（即满足Ax=bAx=bAx=b），并且需要保证Newton方向是可行的方向，即AΔxnt=0A\\Delta x_{nt} = 0AΔxnt​=0 Newton方向 基于二阶近似的定义 将目标函数换成在其xxx附近的二阶Taylor近似： min⁡f^(x+v)=f(x)+▽f(x)Tv+(1/2)vT▽2f(x)v\\min \\hat f(x+v) = f(x) +\\triangledown f(x)^Tv + (1/2)v^T\\triangledown ^2f(x) vminf^​(x+v)=f(x)+▽f(x)Tv+(1/2)vT▽2f(x)v s.t.A(x+v)=bs.t.\\quad A(x+v) =bs.t.A(x+v)=b 根据之前对等式约束二次问题的分析，得到KKT矩阵： [▽2f(x)ATA0][Δxntw]=[−▽f(x)0]\\begin{bmatrix}\\triangledown^2 f(x) &A^T \\\\ A&0 \\end{bmatrix}\\begin{bmatrix}\\Delta x_{nt}\\\\w \\end{bmatrix} = \\begin{bmatrix}-\\triangledown f(x)\\\\0 \\end{bmatrix} [▽2f(x)A​AT0​][Δxnt​w​]=[−▽f(x)0​] 线性化最优性条件的解 可以将Newton方向Δxnt\\Delta x_{nt}Δxnt​解释为最优性条件： Ax⋆=b▽f(x⋆)+ATv⋆=0Ax^\\star =b \\quad \\triangledown f(x^\\star)+A^Tv^\\star = 0Ax⋆=b▽f(x⋆)+ATv⋆=0 我们用x+Δxntx+\\Delta x_{nt}x+Δxnt​替代x⋆x^\\starx⋆，用www替代v⋆v^\\starv⋆，将梯度换为二阶近似，得到： A(x+Δxnt)=b,▽f(x+Δxnt)+ATw≈▽f(x)+▽2f(x)Δxnt+ATw=0A(x+\\Delta x_{nt} )= b,\\quad \\triangledown f(x+\\Delta x_{nt}) + A^Tw\\approx \\triangledown f(x) + \\triangledown^2 f(x)\\Delta x_{nt}+A^Tw = 0A(x+Δxnt​)=b,▽f(x+Δxnt​)+ATw≈▽f(x)+▽2f(x)Δxnt​+ATw=0 利用Ax=bAx = bAx=b,上式变为： AΔxnt=0▽2f(x)Δxnt+ATw=−▽f(x)A\\Delta x_{nt} = 0\\quad \\triangledown^2 f(x)\\Delta x_{nt}+A^Tw= -\\triangledown f(x) AΔxnt​=0▽2f(x)Δxnt​+ATw=−▽f(x) 这和上面的KKT矩阵完全一样。 Newton减量 λ(x)=(ΔxntT▽2f(x)Δxnt)1/2\\lambda(x) = (\\Delta x_{nt}^T\\triangledown^2 f(x)\\Delta x_{nt})^{1/2}λ(x)=(ΔxntT​▽2f(x)Δxnt​)1/2 这和无约束问题的Newton减量完全一样。因此也可以进行同样的解释。可参考这里。 等式约束的Newton方法 给定初始点x∈domfx \\in dom fx∈domf，误差阈值ϵ>0\\epsilon >0ϵ>0 计算Newton步径和减量 停止准则：如果λ2/2≤ϵ\\lambda^2/2\\le \\epsilon λ2/2≤ϵ，退出 直线搜索，根据回溯直线搜索确定步长ttt 改进：x:=x+tΔxntx:=x + t\\Delta x_{nt}x:=x+tΔxnt​ 不可行初始点的Newton方法 不可行点的Newton方向 和Newton方法一样，我们从等式约束优化的最优性条件开始： Ax⋆=b▽f(x⋆)+ATv⋆=0Ax^\\star =b \\quad \\triangledown f(x^\\star)+A^Tv^\\star = 0Ax⋆=b▽f(x⋆)+ATv⋆=0 用xxx表示当前点，不假设它是可行的，因此我们的目的是找到一个方向Δx\\Delta xΔx使得x+Δxx+\\Delta xx+Δx满足最优性条件，即x+Δx≈x⋆x + \\Delta x\\approx x^\\starx+Δx≈x⋆。因此我们用x+Δxx + \\Delta xx+Δx代替x⋆x^\\starx⋆，并利用梯度的一阶近似： A(x+Δx)=bx▽f(x)+▽2f(x)Δx+ATw=0A(x+\\Delta x) = b\\quad x \\triangledown f(x) +\\triangledown ^2f(x)\\Delta x+A^Tw = 0A(x+Δx)=bx▽f(x)+▽2f(x)Δx+ATw=0 写成矩阵形式为： [▽2f(x)ATA0][Δxw]=−[▽f(x)Ax−b]\\begin{bmatrix}\\triangledown^2 f(x) &A^T \\\\ A&0 \\end{bmatrix}\\begin{bmatrix}\\Delta x\\\\w \\end{bmatrix} = -\\begin{bmatrix}\\triangledown f(x)\\\\Ax-b \\end{bmatrix} [▽2f(x)A​AT0​][Δxw​]=−[▽f(x)Ax−b​] 与之前的KKT矩阵的差别在于Ax−bAx-bAx−b，表示为残差向量。 "},"Interior Point.html":{"url":"Interior Point.html","title":"内点法","keywords":"","body":" 简单介绍处理不等式约束问题的内点法的算法流程。 不等式约束的极小化问题 min⁡f0(x)\\min f_0(x)minf0​(x) s.t.fi(x)≤0s.t.\\quad f_i(x)\\le0s.t.fi​(x)≤0 Ax=bAx=bAx=b 假设该问题可解，即存在最优的x⋆x^\\starx⋆，用p⋆p^\\starp⋆表示最优值f0(x⋆)f_0(x^\\star)f0​(x⋆)。 用内点法求解问题，主要分为两种： 用Newton方法或者求解一系列等式约束问题 求解一系列KKT条件的修改形式 这里只讨论一种特殊的内点法--障碍法。 对数障碍函数和中心路径 一种尝试是将不等式约束问题近似转化为等式约束问题，从而应用Newton方法求解。 因此，可以将原问题写成： min⁡f0(x)+∑i=1mI(fi(x))\\min f_0(x)+\\sum_{i=1}^m I(f_i(x))minf0​(x)+i=1∑m​I(fi​(x)) s.t.Ax=bs.t.\\quad Ax= bs.t.Ax=b 其中I()I()I()是非正实数的示性函数： I(u){0u≤0∞u>0 I(u)\\left\\{\\begin{array}{ll} 0 & u \\leq 0 \\\\ \\infty & u>0 \\end{array}\\right. I(u){0∞​u≤0u>0​ 这样，我们就成功转化为等式约束，可以，目标函数一般情况下不可微，因此不能运用Newton方法。 对数障碍 既然示性函数不可微，我们很自然的想法就是找一个近似的可微函数来代替： I^(u)=−(1/t)log⁡(−u) \\hat{I}(u)=-(1 / t) \\log (-u) I^(u)=−(1/t)log(−u) 我们可以画出对数障碍函数的图像发现，是非减函数，并且当u>0u>0u>0时取值为∞\\infty∞，符合我们的要求。 我们将函数ϕ(x)=−∑i=1mlog⁡(−fi(x))\\phi (x) = -\\sum_{i=1}^m \\log (-f_i(x))ϕ(x)=−∑i=1m​log(−fi​(x))称为对数障碍函数。可以将等式约束问题重写为： min⁡f0(x)+∑i=1m−(1/t)log⁡(−fi(x)) \\min f_{0}(x)+\\sum_{i=1}^{m}-(1 / t) \\log \\left(-f_{i}(x)\\right) minf0​(x)+i=1∑m​−(1/t)log(−fi​(x)) s.t.Ax=b s.t.\\quad Ax= b s.t.Ax=b 既然对数障碍只是原问题的近似，因此需要回答的问题就是其解的效果与最优解差距多大？这个问题将在中心路径中解决。 先给出对数障碍的梯度和Hessian矩阵： ∇ϕ(x)=∑i=1m1−fi(x)∇fi(x) \\nabla \\phi(x)=\\sum_{i=1}^{m} \\frac{1}{-f_{i}(x)} \\nabla f_{i}(x) ∇ϕ(x)=i=1∑m​−fi​(x)1​∇fi​(x) ∇2ϕ(x)=∑i=1m1fi(x)2∇fi(x)∇fi(x)T+∑i=1m1−fi(x)∇2fi(x) \\nabla^{2} \\phi(x)=\\sum_{i=1}^{m} \\frac{1}{f_{i}(x)^{2}} \\nabla f_{i}(x) \\nabla f_{i}(x)^{T}+\\sum_{i=1}^{m} \\frac{1}{-f_{i}(x)} \\nabla^{2} f_{i}(x) ∇2ϕ(x)=i=1∑m​fi​(x)21​∇fi​(x)∇fi​(x)T+i=1∑m​−fi​(x)1​∇2fi​(x) 中心路径 考虑等价问题： min⁡tf0(x)+ϕ(x)\\min tf_0(x)+\\phi (x)mintf0​(x)+ϕ(x) s.t.Ax=bs.t.\\quad Ax= bs.t.Ax=b 这里只是多乘了一个ttt，对最优解没有影响。 对任意t>0t>0t>0，我们用x⋆(t)x^\\star(t)x⋆(t)表示问题的最优解，ttt为中心点，将这些点的集合定义为问题的中心路径。 所有中心路径上的点满足以下充要条件： Ax⋆(t)=b,fi(x⋆(t))0Ax^\\star(t)=b,\\quad f_i(x^\\star(t))Ax⋆(t)=b,fi​(x⋆(t))0 t▽f0(x⋆(t))+▽ϕ(x⋆(t))+ATv^=0t\\triangledown f_{0}(x^\\star(t))+\\triangledown \\phi (x^\\star(t))+A^T \\hat{v} = 0 t▽f0​(x⋆(t))+▽ϕ(x⋆(t))+ATv^=0 中心路径的对偶点 g(λ⋆(t),v⋆(t))=f0(x⋆(t))−m/t≤p⋆g(\\lambda^\\star(t),v^\\star(t)) = f_0(x^\\star(t)) - m/t \\le p^\\starg(λ⋆(t),v⋆(t))=f0​(x⋆(t))−m/t≤p⋆ 证明了x⋆(t)x^\\star(t)x⋆(t)随着t⇒∞t \\Rightarrow \\inftyt⇒∞而收敛于最优解。 "}}